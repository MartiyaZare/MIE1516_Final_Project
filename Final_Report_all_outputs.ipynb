{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<style>\n",
    ".nbviewer div.output_area {\n",
    "  overflow-y: auto;\n",
    "  max-height: 500px; /* or value of your choosing */\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation and Comparison of three deep learning architectures in anomaly detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Security has always been of paramount importance in cyber and cyber-physical systems. On the other hand, integration of cyber systems with more sensitive infrastructures has incentivized hackers to trigger more and more attacks in recent years. This has resulted in more global investment on cybersecurity. Moreover, the amount of data flow is beyond human supervision capabilities. Hence, machine learning algorithms can be good candidates to build Intrusion Detection Systems (IDS).\n",
    "<p>\n",
    "In general, there are two types of IDS. Misuse-based in which the attacks signatures are known and anomaly-based that attempt to capture deviation from normal behaviour. In this project, our focus is on anomaly-based detection. The main idea of anomaly-based intrusion detection is to measure the deviation from normal behaviour. In case of network intrusion detection, we can use sequential traffic data to learn behaviours of the system. \n",
    "</p>\n",
    "<p>\n",
    "In this project we want to implement three well-known deep learning architectures, and compare their performance in intrusion detection task. The main question that this project is supposed to address is, which of these three architectures works better in detecting anomalies. \n",
    "</p>\n",
    "\n",
    "##### Three Architectures:\n",
    "<ol>\n",
    "    <li>\n",
    "        <b>Fully Connected Auto-Encoders:</b>\n",
    "        Autoencoders try to model the distribution of normal data (without intrusion). The main idea is to feed the normal sequence of data into autoencoder. In this case, we expect to be able to reconstruct the data with low error. Otherwise, the error of reconstruction will be high, because the network is not trained on data in case of intrusion. \n",
    "        <figure text=\"center\" style=\"text-align:center\">\n",
    "            <img src=\"images/fully_connected_autoencoder.png\" width=\"300px\"/>\n",
    "            <figcaption>Figure 1 Fully Connected Auto-encoder network</figcaption>\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>LSTM:</b>\n",
    "        The idea here is the same as Auto-encoder, i.e. we try to encode and then reconstruct the sequence with an architecture like Fig. 2.\n",
    "        <figure text=\"center\" style=\"text-align:center\">\n",
    "            <img src=\"images/LSTM_many_to_many.png\" width=\"120px\"/>\n",
    "            <figcaption>Figure 2 Encoder-Decoder LSTM network</figcaption>\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b>1-D Convolutional Network:</b>\n",
    "        We know that 2D-CNN Models work well for image related tasks. But here as we are working on sequential statistical data, we should use 1D-CNN Models. Here first we encode the sequence using a convolutional encoder, then using de-convolution layers try to reconstruct the sequence. Idea is very similar to Fully connected auto-encoder but here we are using convolutional encoder and decoder.\n",
    "    </li>\n",
    "</ol>\n",
    "In this notebook, we first try to find the best structure in each of three aforementioned architectures by tuning the parameters with respect to their power in reconstructing the sequences. Then we evaluate them in detecting the anomalies.\n",
    "\n",
    "In rest of this notebook you can see the implementation of tuning, training and evaluation in more details and in the end we conclude which architecture works the best with our dataset.\n",
    "\n",
    "##### Dataset:\n",
    "We are using the synthetic data generated in [1] which contains 1000 normal sequences, each with length of 100. We use 900 of this data set for training and 100 for validation. For testing we have 142 labled sequences, that 50 of them are labled as anomalous sequences.\n",
    "\n",
    "##### Anomally detection evaluation:\n",
    "As usually the data in anomally detection tasks are heavily imbalanced, also, we care more to most suspicous sequences, we will use top-k ranked recall and precision to evaluate models power in anomaly detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10823129447438044971\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1420898713\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8208876367481353555\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LSTM, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape, ZeroPadding1D, Cropping1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['training_data_A', 'test_data_A', 'anomalous_data_A', 'test_labels_A'])\n"
     ]
    }
   ],
   "source": [
    "with open('data_a.pickle', 'rb') as handle1:\n",
    "    data = pickle.load(handle1)\n",
    "    \n",
    "training_data = data['training_data_A']\n",
    "test_data = data['test_data_A']\n",
    "test_labels = data['test_labels_A']\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLen = training_data.shape[1]\n",
    "trainDataSize = training_data.shape[0]\n",
    "testDataSize = test_data.shape[0]\n",
    "LSTMTraining_data = np.reshape(training_data, (trainDataSize,sequenceLen,1), order='C')\n",
    "LSTMTest_data = np.reshape(test_data, (testDataSize,sequenceLen,1), order='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "Here we defined rankedPrecision() and rankedRecal() functions which are our evaluation functions in anomaly detection. The overall idea here is that, we first sort the samples loss from highest to lowest. Then, calculate precision and recall in top-K samples using definitions below:<br>\n",
    "<p style=\"text-align:center\">\n",
    "$Precision=\\frac{True Positive}{True Positive + False Positive}$<br/><br/>\n",
    "$Recall=\\frac{True Positive}{True Positive + False Negative}$<br/><br/>\n",
    "</p>\n",
    "As we know the number of anomalies in our test set, we pick K to be that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankedPrecision(mse_labels):\n",
    "    sorted_mse_label = mse_label[mse_label[:,0].argsort()[::-1]]\n",
    "    totalNumberOfAnomalies = sum(sorted_mse_label[:,1] == 1)\n",
    "    TP = sum(sorted_mse_label[0:totalNumberOfAnomalies,1] == 1)\n",
    "    FP = sum(sorted_mse_label[0:totalNumberOfAnomalies,1] == 0)\n",
    "    TN = sum(sorted_mse_label[totalNumberOfAnomalies:,1] == 0)\n",
    "    FN = sum(sorted_mse_label[totalNumberOfAnomalies:,1] == 1)\n",
    "    precision = TP/(TP+FP)\n",
    "    return precision\n",
    "    \n",
    "    \n",
    "def rankedRecall(mse_labels):\n",
    "    sorted_mse_label = mse_label[mse_label[:,0].argsort()[::-1]]\n",
    "    totalNumberOfAnomalies = sum(sorted_mse_label[:,1] == 1)\n",
    "    TP = sum(sorted_mse_label[0:totalNumberOfAnomalies,1] == 1)\n",
    "    FP = sum(sorted_mse_label[0:totalNumberOfAnomalies,1] == 0)\n",
    "    TN = sum(sorted_mse_label[totalNumberOfAnomalies:,1] == 0)\n",
    "    FN = sum(sorted_mse_label[totalNumberOfAnomalies:,1] == 1)\n",
    "    recall = TP/(TP+FN)\n",
    "    return recall\n",
    "\n",
    "# show_curve() is for plotting training and validation losses\n",
    "def show_curve(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Here we defined a function to train LSTM using different parameters, later we try to tune them. In this notebook, we tuned number of LSTM layers and number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLSTM(numOfLayers, numOfNeurons, printSummary = 1, vrbs = 1, return_best = 0):\n",
    "    \n",
    "        print('Training model.')\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(numOfNeurons, input_shape=(sequenceLen, 1), return_sequences=True))\n",
    "        for j in range(0, numOfLayers - 1):\n",
    "            model.add(LSTM(numOfNeurons, return_sequences=True))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation(\"linear\"))\n",
    "\n",
    "        if(printSummary == True):\n",
    "            model.summary()\n",
    "\n",
    "        model.compile(optimizer='adam', # rmsprop\n",
    "                  loss='mean_squared_error',\n",
    "                  )\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "        callbacksArray = [es]\n",
    "        if(return_best):\n",
    "            mc = ModelCheckpoint('best_lstm.h5', monitor='val_loss', mode='min')\n",
    "            callbacksArray = [es, mc]\n",
    "\n",
    "        history=model.fit(LSTMTraining_data, LSTMTraining_data,\n",
    "                        batch_size=180,\n",
    "                        shuffle=True,\n",
    "                        epochs=1000, \n",
    "                        validation_split=0.1,\n",
    "                        callbacks=callbacksArray,\n",
    "                        verbose = vrbs,\n",
    "                        )\n",
    "\n",
    "        if(return_best):\n",
    "            best_model = load_model('best_lstm.h5')\n",
    "        returnModel = model\n",
    "        if(return_best):\n",
    "            returnModel = best_model\n",
    "        return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning number of neurons\n",
    "First we tune the number of neurons in LSTM layer. In basic model we considerd 1 LSTM layer and a Dense layer on top. We tried the range of 1 to 10 for the number of neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 1)            12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100, 1)            2         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1293 - val_loss: 0.1280\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.1272 - val_loss: 0.1259\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.1251 - val_loss: 0.1240\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.1232 - val_loss: 0.1221\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.1214 - val_loss: 0.1204\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.1198 - val_loss: 0.1189\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.1183 - val_loss: 0.1175\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.1170 - val_loss: 0.1162\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.1158 - val_loss: 0.1151\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.1146 - val_loss: 0.1140\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.1136 - val_loss: 0.1131\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.1127 - val_loss: 0.1122\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.1119 - val_loss: 0.1114\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.1111 - val_loss: 0.1106\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.1104 - val_loss: 0.1100\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.1097 - val_loss: 0.1093\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.1091 - val_loss: 0.1087\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.1085 - val_loss: 0.1082\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.1080 - val_loss: 0.1076\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.1074 - val_loss: 0.1071\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.1069 - val_loss: 0.1067\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.1065 - val_loss: 0.1062\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.1060 - val_loss: 0.1058\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1056 - val_loss: 0.1053\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.1052 - val_loss: 0.1049\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.1047 - val_loss: 0.1045\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.1043 - val_loss: 0.1041\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.1039 - val_loss: 0.1037\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.1035 - val_loss: 0.1033\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.1031 - val_loss: 0.1029\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.1028 - val_loss: 0.1025\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.1024 - val_loss: 0.1022\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.1020 - val_loss: 0.1018\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.1016 - val_loss: 0.1014\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.1013 - val_loss: 0.1010\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.1009 - val_loss: 0.1007\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.1005 - val_loss: 0.1003\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.1002 - val_loss: 0.1000\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0998 - val_loss: 0.0996\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0995 - val_loss: 0.0993\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0991 - val_loss: 0.0989\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0988 - val_loss: 0.0985\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0984 - val_loss: 0.0982\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0981 - val_loss: 0.0978\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0977 - val_loss: 0.0975\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0974 - val_loss: 0.0971\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0970 - val_loss: 0.0968\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0967 - val_loss: 0.0964\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.0963 - val_loss: 0.0961\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0960 - val_loss: 0.0957\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0956 - val_loss: 0.0954\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0953 - val_loss: 0.0950\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0949 - val_loss: 0.0947\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0945 - val_loss: 0.0943\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0942 - val_loss: 0.0939\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0938 - val_loss: 0.0936\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0934 - val_loss: 0.0932\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0931 - val_loss: 0.0928\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0927 - val_loss: 0.0924\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0923 - val_loss: 0.0920\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0919 - val_loss: 0.0917\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0915 - val_loss: 0.0913\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0911 - val_loss: 0.0909\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0908 - val_loss: 0.0905\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0904 - val_loss: 0.0901\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0899 - val_loss: 0.0896\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0895 - val_loss: 0.0892\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0891 - val_loss: 0.0888\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0887 - val_loss: 0.0884\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0883 - val_loss: 0.0879\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0878 - val_loss: 0.0875\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0874 - val_loss: 0.0870\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0869 - val_loss: 0.0866\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0865 - val_loss: 0.0861\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0860 - val_loss: 0.0857\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0855 - val_loss: 0.0852\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0851 - val_loss: 0.0847\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0846 - val_loss: 0.0842\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0831 - val_loss: 0.0827\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0821 - val_loss: 0.0817\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0815 - val_loss: 0.0812\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0810 - val_loss: 0.0806\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0805 - val_loss: 0.0801\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0800 - val_loss: 0.0796\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0795 - val_loss: 0.0791\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0789 - val_loss: 0.0785\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0784 - val_loss: 0.0780\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0779 - val_loss: 0.0775\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0774 - val_loss: 0.0770\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0769 - val_loss: 0.0765\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0764 - val_loss: 0.0760\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0759 - val_loss: 0.0755\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0754 - val_loss: 0.0751\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0750 - val_loss: 0.0746\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0745 - val_loss: 0.0741\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0741 - val_loss: 0.0737\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0736 - val_loss: 0.0732\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.0732 - val_loss: 0.0728\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0727 - val_loss: 0.0724\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0723 - val_loss: 0.0719\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0719 - val_loss: 0.0715\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0715 - val_loss: 0.0711\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0711 - val_loss: 0.0707\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0706 - val_loss: 0.0703\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0702 - val_loss: 0.0699\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0694 - val_loss: 0.0691\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0690 - val_loss: 0.0687\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0686 - val_loss: 0.0683\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0682 - val_loss: 0.0679\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0678 - val_loss: 0.0675\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0674 - val_loss: 0.0671\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0670 - val_loss: 0.0667\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0666 - val_loss: 0.0663\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0662 - val_loss: 0.0659\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0658 - val_loss: 0.0655\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0654 - val_loss: 0.0651\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0650 - val_loss: 0.0647\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0646 - val_loss: 0.0643\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0642 - val_loss: 0.0639\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0638 - val_loss: 0.0635\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0634 - val_loss: 0.0630\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0630 - val_loss: 0.0626\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0626 - val_loss: 0.0622\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0622 - val_loss: 0.0618\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0618 - val_loss: 0.0614\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0614 - val_loss: 0.0610\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0609 - val_loss: 0.0606\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0605 - val_loss: 0.0602\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0601 - val_loss: 0.0597\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0597 - val_loss: 0.0593\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0593 - val_loss: 0.0589\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0589 - val_loss: 0.0585\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0584 - val_loss: 0.0581\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0580 - val_loss: 0.0577\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0576 - val_loss: 0.0572\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0572 - val_loss: 0.0568\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0568 - val_loss: 0.0564\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0563 - val_loss: 0.0560\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0559 - val_loss: 0.0555\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0555 - val_loss: 0.0551\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0551 - val_loss: 0.0547\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0546 - val_loss: 0.0543\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0542 - val_loss: 0.0538\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 757us/step - loss: 0.0538 - val_loss: 0.0534\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0534 - val_loss: 0.0530\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0529 - val_loss: 0.0526\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0525 - val_loss: 0.0522\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0521 - val_loss: 0.0517\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0517 - val_loss: 0.0513\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0513 - val_loss: 0.0509\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0508 - val_loss: 0.0505\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0504 - val_loss: 0.0500\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0500 - val_loss: 0.0496\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0496 - val_loss: 0.0492\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0491 - val_loss: 0.0488\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0487 - val_loss: 0.0484\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0483 - val_loss: 0.0479\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0479 - val_loss: 0.0475\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0475 - val_loss: 0.0471\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.0471 - val_loss: 0.0467\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0466 - val_loss: 0.0463\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0462 - val_loss: 0.0459\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0458 - val_loss: 0.0454\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0454 - val_loss: 0.0450\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0450 - val_loss: 0.0446\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0446 - val_loss: 0.0442\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0442 - val_loss: 0.0438\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0438 - val_loss: 0.0434\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0433 - val_loss: 0.0430\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0429 - val_loss: 0.0426\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 0.0425 - val_loss: 0.0422\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0421 - val_loss: 0.0418\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0417 - val_loss: 0.0414\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0413 - val_loss: 0.0410\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0409 - val_loss: 0.0406\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0405 - val_loss: 0.0402\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0401 - val_loss: 0.0398\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0397 - val_loss: 0.0394\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0393 - val_loss: 0.0390\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0390 - val_loss: 0.0386\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0386 - val_loss: 0.0382\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0382 - val_loss: 0.0378\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0378 - val_loss: 0.0375\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0375 - val_loss: 0.0371\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0368 - val_loss: 0.0365\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0365 - val_loss: 0.0362\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0362 - val_loss: 0.0359\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0355 - val_loss: 0.0352\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0352 - val_loss: 0.0349\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0349 - val_loss: 0.0346\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0346 - val_loss: 0.0343\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0343 - val_loss: 0.0340\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0340 - val_loss: 0.0337\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0337 - val_loss: 0.0334\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0334 - val_loss: 0.0331\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0331 - val_loss: 0.0328\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0328 - val_loss: 0.0325\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0325 - val_loss: 0.0322\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0322 - val_loss: 0.0319\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0316 - val_loss: 0.0313\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0313 - val_loss: 0.0310\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0310 - val_loss: 0.0307\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0308 - val_loss: 0.0304\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0305 - val_loss: 0.0302\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0302 - val_loss: 0.0299\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 0.0299 - val_loss: 0.0296\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0296 - val_loss: 0.0293\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.0293 - val_loss: 0.0290\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0291 - val_loss: 0.0287\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0288 - val_loss: 0.0285\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0282 - val_loss: 0.0279\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0280 - val_loss: 0.0276\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0277 - val_loss: 0.0274\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0274 - val_loss: 0.0271\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0271 - val_loss: 0.0268\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0269 - val_loss: 0.0266\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0266 - val_loss: 0.0263\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0261 - val_loss: 0.0258\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0258 - val_loss: 0.0255\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.0256 - val_loss: 0.0252\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0250 - val_loss: 0.0247\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0248 - val_loss: 0.0245\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0245 - val_loss: 0.0242\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0243 - val_loss: 0.0240\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0240 - val_loss: 0.0237\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.0238 - val_loss: 0.0235\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0235 - val_loss: 0.0232\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0233 - val_loss: 0.0230\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0226 - val_loss: 0.0222\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0223 - val_loss: 0.0220\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0219 - val_loss: 0.0215\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0216 - val_loss: 0.0213\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0211 - val_loss: 0.0208\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0207 - val_loss: 0.0204\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0200 - val_loss: 0.0197\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0194 - val_loss: 0.0190\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0189 - val_loss: 0.0186\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0187 - val_loss: 0.0184\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0185 - val_loss: 0.0182\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0183 - val_loss: 0.0179\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0181 - val_loss: 0.0177\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0179 - val_loss: 0.0175\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0175 - val_loss: 0.0171\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0172 - val_loss: 0.0169\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0170 - val_loss: 0.0167\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0168 - val_loss: 0.0165\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0166 - val_loss: 0.0163\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0164 - val_loss: 0.0161\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0163 - val_loss: 0.0159\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0161 - val_loss: 0.0157\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0159 - val_loss: 0.0155\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0157 - val_loss: 0.0153\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0151 - val_loss: 0.0148\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0149 - val_loss: 0.0146\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0147 - val_loss: 0.0144\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0146 - val_loss: 0.0142\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0142 - val_loss: 0.0139\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0139 - val_loss: 0.0135\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0137 - val_loss: 0.0133\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0135 - val_loss: 0.0132\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0133 - val_loss: 0.0130\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0132 - val_loss: 0.0128\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0130 - val_loss: 0.0127\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0125 - val_loss: 0.0122\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 749us/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0090 - val_loss: 0.0086\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.007 - 1s 756us/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 724us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 721us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0013 - val_loss: 9.9721e-04\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0013 - val_loss: 9.8290e-04\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0013 - val_loss: 9.6884e-04\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0013 - val_loss: 9.5511e-04\n",
      "Epoch 456/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 758us/step - loss: 0.0013 - val_loss: 9.4194e-04\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0013 - val_loss: 9.2857e-04\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0012 - val_loss: 9.1564e-04\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0012 - val_loss: 9.0316e-04\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0012 - val_loss: 8.9056e-04\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0012 - val_loss: 8.7854e-04\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0012 - val_loss: 8.6669e-04\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0012 - val_loss: 8.5487e-04\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0012 - val_loss: 8.4334e-04\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0012 - val_loss: 8.3201e-04\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0011 - val_loss: 8.2103e-04\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.0011 - val_loss: 8.1012e-04\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0011 - val_loss: 7.9962e-04\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0011 - val_loss: 7.8939e-04\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0011 - val_loss: 7.7901e-04\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0011 - val_loss: 7.6910e-04\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0011 - val_loss: 7.5928e-04\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0011 - val_loss: 7.4941e-04\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0011 - val_loss: 7.4004e-04\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0010 - val_loss: 7.3077e-04\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0010 - val_loss: 7.2176e-04\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0010 - val_loss: 7.1258e-04\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0010 - val_loss: 7.0391e-04\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0010 - val_loss: 6.9534e-04\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0010 - val_loss: 6.8688e-04\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.9545e-04 - val_loss: 6.7861e-04\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 9.8701e-04 - val_loss: 6.7054e-04\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.7870e-04 - val_loss: 6.6262e-04\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.7051e-04 - val_loss: 6.5477e-04\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.6247e-04 - val_loss: 6.4708e-04\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.5456e-04 - val_loss: 6.3962e-04\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.4682e-04 - val_loss: 6.3229e-04\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.3926e-04 - val_loss: 6.2508e-04\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.3181e-04 - val_loss: 6.1800e-04\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 9.2445e-04 - val_loss: 6.1098e-04\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.1721e-04 - val_loss: 6.0417e-04\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.1011e-04 - val_loss: 5.9746e-04\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.0312e-04 - val_loss: 5.9087e-04\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.9629e-04 - val_loss: 5.8441e-04\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.8958e-04 - val_loss: 5.7818e-04\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.8300e-04 - val_loss: 5.7187e-04\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 8.7647e-04 - val_loss: 5.6581e-04\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 8.7009e-04 - val_loss: 5.5982e-04\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.6382e-04 - val_loss: 5.5389e-04\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.5759e-04 - val_loss: 5.4815e-04\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.5156e-04 - val_loss: 5.4244e-04\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.4554e-04 - val_loss: 5.3689e-04\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.3969e-04 - val_loss: 5.3146e-04\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.3392e-04 - val_loss: 5.2606e-04\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.2822e-04 - val_loss: 5.2078e-04\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.2264e-04 - val_loss: 5.1561e-04\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.1718e-04 - val_loss: 5.1061e-04\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.1180e-04 - val_loss: 5.0564e-04\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.0646e-04 - val_loss: 5.0072e-04\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.0120e-04 - val_loss: 4.9580e-04\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.9604e-04 - val_loss: 4.9113e-04\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.9096e-04 - val_loss: 4.8641e-04\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 7.8595e-04 - val_loss: 4.8182e-04\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 823us/step - loss: 7.8104e-04 - val_loss: 4.7732e-04\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.7619e-04 - val_loss: 4.7291e-04\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.7142e-04 - val_loss: 4.6856e-04\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 7.6674e-04 - val_loss: 4.6428e-04\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.6215e-04 - val_loss: 4.6009e-04\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.5757e-04 - val_loss: 4.5600e-04\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.5316e-04 - val_loss: 4.5190e-04\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.4870e-04 - val_loss: 4.4791e-04\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.4433e-04 - val_loss: 4.4401e-04\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.4001e-04 - val_loss: 4.4011e-04\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.3579e-04 - val_loss: 4.3631e-04\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.3163e-04 - val_loss: 4.3257e-04\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.2750e-04 - val_loss: 4.2890e-04\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 7.2348e-04 - val_loss: 4.2530e-04\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.1950e-04 - val_loss: 4.2173e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.1562e-04 - val_loss: 4.1823e-04\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.1177e-04 - val_loss: 4.1481e-04\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.0795e-04 - val_loss: 4.1141e-04\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 7.0421e-04 - val_loss: 4.0809e-04\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.0050e-04 - val_loss: 4.0481e-04\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.9686e-04 - val_loss: 4.0157e-04\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.9323e-04 - val_loss: 3.9838e-04\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.8967e-04 - val_loss: 3.9524e-04\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.8615e-04 - val_loss: 3.9218e-04\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.8272e-04 - val_loss: 3.8915e-04\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.7929e-04 - val_loss: 3.8611e-04\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.7589e-04 - val_loss: 3.8316e-04\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.7259e-04 - val_loss: 3.8025e-04\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.6929e-04 - val_loss: 3.7738e-04\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.6603e-04 - val_loss: 3.7455e-04\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.6282e-04 - val_loss: 3.7177e-04\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.5964e-04 - val_loss: 3.6902e-04\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.5653e-04 - val_loss: 3.6632e-04\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.5341e-04 - val_loss: 3.6365e-04\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.5037e-04 - val_loss: 3.6101e-04\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.4731e-04 - val_loss: 3.5842e-04\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.4433e-04 - val_loss: 3.5585e-04\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.4140e-04 - val_loss: 3.5333e-04\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.3846e-04 - val_loss: 3.5085e-04\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.3560e-04 - val_loss: 3.4839e-04\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.3272e-04 - val_loss: 3.4595e-04\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.2989e-04 - val_loss: 3.4355e-04\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 6.2712e-04 - val_loss: 3.4117e-04\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 6.2432e-04 - val_loss: 3.3884e-04\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 6.2157e-04 - val_loss: 3.3653e-04\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.1889e-04 - val_loss: 3.3425e-04\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.1620e-04 - val_loss: 3.3200e-04\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.1353e-04 - val_loss: 3.2978e-04\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.1096e-04 - val_loss: 3.2759e-04\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.0832e-04 - val_loss: 3.2544e-04\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.0579e-04 - val_loss: 3.2329e-04\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.0320e-04 - val_loss: 3.2117e-04\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 6.0072e-04 - val_loss: 3.1909e-04\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9820e-04 - val_loss: 3.1702e-04\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.9573e-04 - val_loss: 3.1497e-04\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9330e-04 - val_loss: 3.1297e-04\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.9086e-04 - val_loss: 3.1096e-04\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.8848e-04 - val_loss: 3.0900e-04\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.8609e-04 - val_loss: 3.0708e-04\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.8370e-04 - val_loss: 3.0512e-04\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.8141e-04 - val_loss: 3.0322e-04\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 5.7909e-04 - val_loss: 3.0134e-04\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.7680e-04 - val_loss: 2.9947e-04\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.7453e-04 - val_loss: 2.9764e-04\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.7228e-04 - val_loss: 2.9583e-04\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.7001e-04 - val_loss: 2.9400e-04\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.6783e-04 - val_loss: 2.9222e-04\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.6562e-04 - val_loss: 2.9045e-04\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.6346e-04 - val_loss: 2.8870e-04\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 5.6129e-04 - val_loss: 2.8697e-04\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 5.5913e-04 - val_loss: 2.8525e-04\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 838us/step - loss: 5.5702e-04 - val_loss: 2.8356e-04\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.5491e-04 - val_loss: 2.8188e-04\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.5283e-04 - val_loss: 2.8022e-04\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.5074e-04 - val_loss: 2.7858e-04\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.4870e-04 - val_loss: 2.7695e-04\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.4666e-04 - val_loss: 2.7534e-04\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.4463e-04 - val_loss: 2.7375e-04\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.4262e-04 - val_loss: 2.7216e-04\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 5.4064e-04 - val_loss: 2.7060e-04\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 5.3866e-04 - val_loss: 2.6906e-04\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.3669e-04 - val_loss: 2.6752e-04\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.3476e-04 - val_loss: 2.6601e-04\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.3283e-04 - val_loss: 2.6450e-04\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.3091e-04 - val_loss: 2.6300e-04\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.2899e-04 - val_loss: 2.6151e-04\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.2712e-04 - val_loss: 2.6005e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.2526e-04 - val_loss: 2.5859e-04\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.2335e-04 - val_loss: 2.5714e-04\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.2151e-04 - val_loss: 2.5571e-04\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.1967e-04 - val_loss: 2.5430e-04\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 5.1787e-04 - val_loss: 2.5290e-04\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.1603e-04 - val_loss: 2.5151e-04\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.1426e-04 - val_loss: 2.5013e-04\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.1245e-04 - val_loss: 2.4877e-04\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.1069e-04 - val_loss: 2.4741e-04\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.0893e-04 - val_loss: 2.4607e-04\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.0718e-04 - val_loss: 2.4474e-04\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.0544e-04 - val_loss: 2.4341e-04\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.0373e-04 - val_loss: 2.4210e-04\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.0197e-04 - val_loss: 2.4080e-04\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.0029e-04 - val_loss: 2.3951e-04\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.9859e-04 - val_loss: 2.3823e-04\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.9692e-04 - val_loss: 2.3696e-04\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.9525e-04 - val_loss: 2.3570e-04\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 4.9358e-04 - val_loss: 2.3445e-04\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.9192e-04 - val_loss: 2.3321e-04\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.9028e-04 - val_loss: 2.3198e-04\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.8864e-04 - val_loss: 2.3077e-04\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.8705e-04 - val_loss: 2.2956e-04\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.8542e-04 - val_loss: 2.2837e-04\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.8383e-04 - val_loss: 2.2717e-04\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.8224e-04 - val_loss: 2.2599e-04\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.8065e-04 - val_loss: 2.2482e-04\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.7907e-04 - val_loss: 2.2365e-04\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 4.7752e-04 - val_loss: 2.2249e-04\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.7596e-04 - val_loss: 2.2135e-04\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.7444e-04 - val_loss: 2.2021e-04\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.7289e-04 - val_loss: 2.1908e-04\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.7134e-04 - val_loss: 2.1795e-04\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.6984e-04 - val_loss: 2.1684e-04\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 4.6834e-04 - val_loss: 2.1574e-04\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.6684e-04 - val_loss: 2.1464e-04\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.6535e-04 - val_loss: 2.1355e-04\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.6386e-04 - val_loss: 2.1247e-04\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.6238e-04 - val_loss: 2.1139e-04\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.6093e-04 - val_loss: 2.1032e-04\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.5945e-04 - val_loss: 2.0926e-04\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.5803e-04 - val_loss: 2.0821e-04\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.5657e-04 - val_loss: 2.0717e-04\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.5512e-04 - val_loss: 2.0613e-04\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.5370e-04 - val_loss: 2.0510e-04\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.5233e-04 - val_loss: 2.0409e-04\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.5088e-04 - val_loss: 2.0307e-04\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.4948e-04 - val_loss: 2.0207e-04\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.4807e-04 - val_loss: 2.0106e-04\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.4671e-04 - val_loss: 2.0007e-04\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 4.4532e-04 - val_loss: 1.9908e-04\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.4396e-04 - val_loss: 1.9810e-04\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 4.4257e-04 - val_loss: 1.9712e-04\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.4124e-04 - val_loss: 1.9615e-04\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.3988e-04 - val_loss: 1.9519e-04\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.3854e-04 - val_loss: 1.9424e-04\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.3722e-04 - val_loss: 1.9329e-04\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.3585e-04 - val_loss: 1.9234e-04\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.3454e-04 - val_loss: 1.9140e-04\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.3322e-04 - val_loss: 1.9047e-04\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.3192e-04 - val_loss: 1.8954e-04\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.3063e-04 - val_loss: 1.8863e-04\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.2931e-04 - val_loss: 1.8773e-04\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.2805e-04 - val_loss: 1.8682e-04\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.2676e-04 - val_loss: 1.8592e-04\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.2547e-04 - val_loss: 1.8502e-04\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.2420e-04 - val_loss: 1.8413e-04\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.2297e-04 - val_loss: 1.8324e-04\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.2169e-04 - val_loss: 1.8236e-04\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 720us/step - loss: 4.2044e-04 - val_loss: 1.8150e-04\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 4.1920e-04 - val_loss: 1.8062e-04\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 4.1795e-04 - val_loss: 1.7976e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.1673e-04 - val_loss: 1.7891e-04\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.1550e-04 - val_loss: 1.7806e-04\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.1429e-04 - val_loss: 1.7721e-04\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.1306e-04 - val_loss: 1.7636e-04\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.1187e-04 - val_loss: 1.7553e-04\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.1066e-04 - val_loss: 1.7470e-04\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 4.0948e-04 - val_loss: 1.7388e-04\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.0829e-04 - val_loss: 1.7306e-04\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 4.0708e-04 - val_loss: 1.7224e-04\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.0591e-04 - val_loss: 1.7142e-04\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.0473e-04 - val_loss: 1.7061e-04\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 4.0357e-04 - val_loss: 1.6982e-04\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 4.0242e-04 - val_loss: 1.6903e-04\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.0126e-04 - val_loss: 1.6824e-04\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.0011e-04 - val_loss: 1.6745e-04\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.9896e-04 - val_loss: 1.6667e-04\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.9781e-04 - val_loss: 1.6588e-04\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.9667e-04 - val_loss: 1.6512e-04\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.9557e-04 - val_loss: 1.6435e-04\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.9444e-04 - val_loss: 1.6359e-04\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.9332e-04 - val_loss: 1.6284e-04\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.9221e-04 - val_loss: 1.6209e-04\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.9110e-04 - val_loss: 1.6133e-04\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8999e-04 - val_loss: 1.6057e-04\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.8889e-04 - val_loss: 1.5983e-04\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8780e-04 - val_loss: 1.5909e-04\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.8672e-04 - val_loss: 1.5837e-04\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.8564e-04 - val_loss: 1.5764e-04\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 716us/step - loss: 3.8455e-04 - val_loss: 1.5691e-04\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.8347e-04 - val_loss: 1.5619e-04\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.8242e-04 - val_loss: 1.5548e-04\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.8136e-04 - val_loss: 1.5477e-04\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.8028e-04 - val_loss: 1.5405e-04\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.7925e-04 - val_loss: 1.5335e-04\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.7818e-04 - val_loss: 1.5264e-04\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.7715e-04 - val_loss: 1.5196e-04\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.7612e-04 - val_loss: 1.5128e-04\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.7507e-04 - val_loss: 1.5059e-04\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7404e-04 - val_loss: 1.4990e-04\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.7301e-04 - val_loss: 1.4921e-04\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.7198e-04 - val_loss: 1.4853e-04\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7098e-04 - val_loss: 1.4785e-04\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.6996e-04 - val_loss: 1.4719e-04\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 3.6896e-04 - val_loss: 1.4653e-04\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.6794e-04 - val_loss: 1.4587e-04\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.6696e-04 - val_loss: 1.4521e-04\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.6594e-04 - val_loss: 1.4456e-04\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.6500e-04 - val_loss: 1.4392e-04\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.6400e-04 - val_loss: 1.4327e-04\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.6300e-04 - val_loss: 1.4261e-04\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.6203e-04 - val_loss: 1.4197e-04\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.6106e-04 - val_loss: 1.4134e-04\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.6007e-04 - val_loss: 1.4071e-04\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.5913e-04 - val_loss: 1.4008e-04\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.5817e-04 - val_loss: 1.3945e-04\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.5719e-04 - val_loss: 1.3882e-04\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.5627e-04 - val_loss: 1.3821e-04\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.5531e-04 - val_loss: 1.3761e-04\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.5438e-04 - val_loss: 1.3700e-04\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.5342e-04 - val_loss: 1.3638e-04\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 721us/step - loss: 3.5251e-04 - val_loss: 1.3577e-04\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 3.5155e-04 - val_loss: 1.3516e-04\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.5062e-04 - val_loss: 1.3456e-04\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.4969e-04 - val_loss: 1.3396e-04\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.4880e-04 - val_loss: 1.3338e-04\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.4787e-04 - val_loss: 1.3279e-04\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.4697e-04 - val_loss: 1.3221e-04\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 723us/step - loss: 3.4605e-04 - val_loss: 1.3162e-04\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 3.4514e-04 - val_loss: 1.3104e-04\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.4424e-04 - val_loss: 1.3046e-04\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.4334e-04 - val_loss: 1.2989e-04\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.4244e-04 - val_loss: 1.2932e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 724us/step - loss: 3.4157e-04 - val_loss: 1.2876e-04\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.4069e-04 - val_loss: 1.2819e-04\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.3979e-04 - val_loss: 1.2762e-04\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.3890e-04 - val_loss: 1.2705e-04\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 3.3803e-04 - val_loss: 1.2650e-04\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 3.3716e-04 - val_loss: 1.2596e-04\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.3631e-04 - val_loss: 1.2542e-04\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.3545e-04 - val_loss: 1.2487e-04\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.3457e-04 - val_loss: 1.2431e-04\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.3371e-04 - val_loss: 1.2376e-04\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.3287e-04 - val_loss: 1.2323e-04\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.3202e-04 - val_loss: 1.2270e-04\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.3115e-04 - val_loss: 1.2216e-04\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.3031e-04 - val_loss: 1.2163e-04\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 3.2948e-04 - val_loss: 1.2111e-04\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 822us/step - loss: 3.2863e-04 - val_loss: 1.2058e-04\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.2780e-04 - val_loss: 1.2006e-04\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.2698e-04 - val_loss: 1.1955e-04\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.2616e-04 - val_loss: 1.1903e-04\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.2532e-04 - val_loss: 1.1851e-04\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.2449e-04 - val_loss: 1.1799e-04\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.2369e-04 - val_loss: 1.1749e-04\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.2287e-04 - val_loss: 1.1699e-04\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2205e-04 - val_loss: 1.1648e-04\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.2126e-04 - val_loss: 1.1598e-04\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.2044e-04 - val_loss: 1.1548e-04\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.1964e-04 - val_loss: 1.1499e-04\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 3.1885e-04 - val_loss: 1.1450e-04\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.1806e-04 - val_loss: 1.1400e-04\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 3.1726e-04 - val_loss: 1.1351e-04\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.1646e-04 - val_loss: 1.1302e-04\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.1568e-04 - val_loss: 1.1253e-04\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.1489e-04 - val_loss: 1.1205e-04\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.1412e-04 - val_loss: 1.1158e-04\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.1333e-04 - val_loss: 1.1111e-04\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.1256e-04 - val_loss: 1.1064e-04\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.1180e-04 - val_loss: 1.1016e-04\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.1101e-04 - val_loss: 1.0968e-04\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.1025e-04 - val_loss: 1.0922e-04\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 723us/step - loss: 3.0950e-04 - val_loss: 1.0876e-04\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.0873e-04 - val_loss: 1.0830e-04\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.0799e-04 - val_loss: 1.0785e-04\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.0723e-04 - val_loss: 1.0739e-04\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.0648e-04 - val_loss: 1.0693e-04\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.0572e-04 - val_loss: 1.0646e-04\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.0497e-04 - val_loss: 1.0601e-04\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.0423e-04 - val_loss: 1.0557e-04\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.0349e-04 - val_loss: 1.0513e-04\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.0275e-04 - val_loss: 1.0469e-04\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.0202e-04 - val_loss: 1.0425e-04\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.0129e-04 - val_loss: 1.0380e-04\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.0057e-04 - val_loss: 1.0337e-04\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.9983e-04 - val_loss: 1.0293e-04\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.9911e-04 - val_loss: 1.0249e-04\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.9839e-04 - val_loss: 1.0206e-04\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.9768e-04 - val_loss: 1.0164e-04\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.9696e-04 - val_loss: 1.0121e-04\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.9623e-04 - val_loss: 1.0077e-04\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.9554e-04 - val_loss: 1.0035e-04\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.9481e-04 - val_loss: 9.9930e-05\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.9410e-04 - val_loss: 9.9507e-05\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.9342e-04 - val_loss: 9.9106e-05\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.9271e-04 - val_loss: 9.8692e-05\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9200e-04 - val_loss: 9.8270e-05\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.9131e-04 - val_loss: 9.7856e-05\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.9062e-04 - val_loss: 9.7455e-05\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8994e-04 - val_loss: 9.7057e-05\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.8924e-04 - val_loss: 9.6645e-05\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.8857e-04 - val_loss: 9.6238e-05\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.8788e-04 - val_loss: 9.5832e-05\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.8719e-04 - val_loss: 9.5426e-05\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.8652e-04 - val_loss: 9.5037e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 2.8584e-04 - val_loss: 9.4649e-05\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 721us/step - loss: 2.8517e-04 - val_loss: 9.4254e-05\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.8451e-04 - val_loss: 9.3864e-05\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.8383e-04 - val_loss: 9.3466e-05\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.8315e-04 - val_loss: 9.3070e-05\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.8250e-04 - val_loss: 9.2690e-05\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.8183e-04 - val_loss: 9.2308e-05\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.8118e-04 - val_loss: 9.1930e-05\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.8052e-04 - val_loss: 9.1547e-05\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 2.7987e-04 - val_loss: 9.1166e-05\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.7921e-04 - val_loss: 9.0783e-05\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.7857e-04 - val_loss: 9.0416e-05\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 719us/step - loss: 2.7790e-04 - val_loss: 9.0032e-05\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.7725e-04 - val_loss: 8.9658e-05\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.7664e-04 - val_loss: 8.9309e-05\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 723us/step - loss: 2.7599e-04 - val_loss: 8.8940e-05\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.7534e-04 - val_loss: 8.8560e-05\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.7470e-04 - val_loss: 8.8186e-05\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.7408e-04 - val_loss: 8.7830e-05\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.7344e-04 - val_loss: 8.7473e-05\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.7282e-04 - val_loss: 8.7122e-05\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.7217e-04 - val_loss: 8.6749e-05\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.7156e-04 - val_loss: 8.6395e-05\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.7093e-04 - val_loss: 8.6040e-05\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.7031e-04 - val_loss: 8.5690e-05\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 2.6969e-04 - val_loss: 8.5337e-05\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.6908e-04 - val_loss: 8.4986e-05\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6845e-04 - val_loss: 8.4631e-05\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.6783e-04 - val_loss: 8.4283e-05\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.6723e-04 - val_loss: 8.3948e-05\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.6663e-04 - val_loss: 8.3613e-05\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.6601e-04 - val_loss: 8.3261e-05\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.6542e-04 - val_loss: 8.2924e-05\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6480e-04 - val_loss: 8.2576e-05\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6421e-04 - val_loss: 8.2239e-05\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.6360e-04 - val_loss: 8.1903e-05\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6301e-04 - val_loss: 8.1571e-05\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.6242e-04 - val_loss: 8.1245e-05\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.6182e-04 - val_loss: 8.0909e-05\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.6122e-04 - val_loss: 8.0571e-05\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.6064e-04 - val_loss: 8.0244e-05\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6006e-04 - val_loss: 7.9928e-05\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 2.5946e-04 - val_loss: 7.9598e-05\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.5889e-04 - val_loss: 7.9278e-05\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 2.5830e-04 - val_loss: 7.8952e-05\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5772e-04 - val_loss: 7.8630e-05\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.5714e-04 - val_loss: 7.8312e-05\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.5656e-04 - val_loss: 7.7993e-05\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.5600e-04 - val_loss: 7.7685e-05\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.5542e-04 - val_loss: 7.7363e-05\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.5484e-04 - val_loss: 7.7039e-05\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.5430e-04 - val_loss: 7.6745e-05\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.5371e-04 - val_loss: 7.6426e-05\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.5315e-04 - val_loss: 7.6111e-05\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.5260e-04 - val_loss: 7.5811e-05\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.5202e-04 - val_loss: 7.5497e-05\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.5147e-04 - val_loss: 7.5193e-05\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 2.5091e-04 - val_loss: 7.4892e-05\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.5037e-04 - val_loss: 7.4599e-05\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.4980e-04 - val_loss: 7.4290e-05\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.4925e-04 - val_loss: 7.3982e-05\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4869e-04 - val_loss: 7.3675e-05\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 2.4815e-04 - val_loss: 7.3387e-05\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4759e-04 - val_loss: 7.3095e-05\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 2.4706e-04 - val_loss: 7.2811e-05\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.4651e-04 - val_loss: 7.2514e-05\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.4597e-04 - val_loss: 7.2212e-05\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4543e-04 - val_loss: 7.1918e-05\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.4490e-04 - val_loss: 7.1641e-05\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.4437e-04 - val_loss: 7.1352e-05\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4381e-04 - val_loss: 7.1048e-05\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.4329e-04 - val_loss: 7.0767e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.4275e-04 - val_loss: 7.0489e-05\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.4223e-04 - val_loss: 7.0217e-05\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.4170e-04 - val_loss: 6.9933e-05\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4119e-04 - val_loss: 6.9649e-05\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.4064e-04 - val_loss: 6.9352e-05\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4012e-04 - val_loss: 6.9078e-05\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3961e-04 - val_loss: 6.8816e-05\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 784us/step - loss: 2.3909e-04 - val_loss: 6.8544e-05\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.3856e-04 - val_loss: 6.8253e-05\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.3805e-04 - val_loss: 6.7978e-05\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.3752e-04 - val_loss: 6.7704e-05\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3701e-04 - val_loss: 6.7445e-05\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.3651e-04 - val_loss: 6.7184e-05\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.3598e-04 - val_loss: 6.6898e-05\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.3549e-04 - val_loss: 6.6635e-05\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.3497e-04 - val_loss: 6.6368e-05\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.3448e-04 - val_loss: 6.6112e-05\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.3397e-04 - val_loss: 6.5847e-05\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.3346e-04 - val_loss: 6.5576e-05\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.3297e-04 - val_loss: 6.5315e-05\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.3246e-04 - val_loss: 6.5054e-05\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.3196e-04 - val_loss: 6.4799e-05\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3147e-04 - val_loss: 6.4542e-05\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.3098e-04 - val_loss: 6.4288e-05\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.3048e-04 - val_loss: 6.4027e-05\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.2999e-04 - val_loss: 6.3772e-05\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.2950e-04 - val_loss: 6.3520e-05\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.2901e-04 - val_loss: 6.3266e-05\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.2851e-04 - val_loss: 6.3005e-05\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2804e-04 - val_loss: 6.2771e-05\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.2755e-04 - val_loss: 6.2523e-05\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.2707e-04 - val_loss: 6.2274e-05\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 2.2658e-04 - val_loss: 6.2018e-05\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 721us/step - loss: 2.2609e-04 - val_loss: 6.1761e-05\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.2563e-04 - val_loss: 6.1535e-05\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.2515e-04 - val_loss: 6.1313e-05\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2472e-04 - val_loss: 6.1158e-05\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2434e-04 - val_loss: 6.1008e-05\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2400e-04 - val_loss: 6.0887e-05\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.2367e-04 - val_loss: 6.0773e-05\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.2331e-04 - val_loss: 6.0626e-05\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2298e-04 - val_loss: 6.0494e-05\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2265e-04 - val_loss: 6.0371e-05\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2230e-04 - val_loss: 6.0233e-05\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2198e-04 - val_loss: 6.0116e-05\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.2165e-04 - val_loss: 5.9998e-05\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2130e-04 - val_loss: 5.9861e-05\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 724us/step - loss: 2.2097e-04 - val_loss: 5.9727e-05\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.2064e-04 - val_loss: 5.9608e-05\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.2031e-04 - val_loss: 5.9489e-05\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2000e-04 - val_loss: 5.9378e-05\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.1967e-04 - val_loss: 5.9249e-05\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.1934e-04 - val_loss: 5.9115e-05\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.1902e-04 - val_loss: 5.8998e-05\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 2.1869e-04 - val_loss: 5.8884e-05\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.1837e-04 - val_loss: 5.8768e-05\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.1804e-04 - val_loss: 5.8639e-05\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.1772e-04 - val_loss: 5.8522e-05\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.1739e-04 - val_loss: 5.8391e-05\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.1708e-04 - val_loss: 5.8285e-05\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.1674e-04 - val_loss: 5.8157e-05\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1643e-04 - val_loss: 5.8041e-05\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.1610e-04 - val_loss: 5.7917e-05\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1579e-04 - val_loss: 5.7806e-05\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.1545e-04 - val_loss: 5.7677e-05\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.1515e-04 - val_loss: 5.7571e-05\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.1482e-04 - val_loss: 5.7448e-05\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.1449e-04 - val_loss: 5.7318e-05\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.1417e-04 - val_loss: 5.7205e-05\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.1386e-04 - val_loss: 5.7100e-05\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.1354e-04 - val_loss: 5.6979e-05\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1322e-04 - val_loss: 5.6858e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1290e-04 - val_loss: 5.6737e-05\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.1258e-04 - val_loss: 5.6625e-05\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.1225e-04 - val_loss: 5.6499e-05\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.1195e-04 - val_loss: 5.6399e-05\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1164e-04 - val_loss: 5.6290e-05\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1131e-04 - val_loss: 5.6159e-05\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.1099e-04 - val_loss: 5.6033e-05\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.1067e-04 - val_loss: 5.5919e-05\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.1035e-04 - val_loss: 5.5811e-05\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1004e-04 - val_loss: 5.5707e-05\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0973e-04 - val_loss: 5.5588e-05\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.0942e-04 - val_loss: 5.5466e-05\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0910e-04 - val_loss: 5.5345e-05\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0878e-04 - val_loss: 5.5228e-05\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.0847e-04 - val_loss: 5.5136e-05\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0817e-04 - val_loss: 5.5040e-05\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.0786e-04 - val_loss: 5.4919e-05\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0757e-04 - val_loss: 5.4825e-05\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.0728e-04 - val_loss: 5.4750e-05\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.0697e-04 - val_loss: 5.4643e-05\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.0668e-04 - val_loss: 5.4538e-05\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0637e-04 - val_loss: 5.4436e-05\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0609e-04 - val_loss: 5.4360e-05\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0578e-04 - val_loss: 5.4260e-05\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.0549e-04 - val_loss: 5.4156e-05\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0519e-04 - val_loss: 5.4055e-05\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.0490e-04 - val_loss: 5.3974e-05\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.0460e-04 - val_loss: 5.3874e-05\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.0431e-04 - val_loss: 5.3785e-05\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.0401e-04 - val_loss: 5.3679e-05\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.0371e-04 - val_loss: 5.3578e-05\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 2.0343e-04 - val_loss: 5.3495e-05\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0313e-04 - val_loss: 5.3399e-05\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0284e-04 - val_loss: 5.3306e-05\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.0254e-04 - val_loss: 5.3208e-05\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0225e-04 - val_loss: 5.3110e-05\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0196e-04 - val_loss: 5.3017e-05\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0165e-04 - val_loss: 5.2916e-05\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0136e-04 - val_loss: 5.2826e-05\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.0107e-04 - val_loss: 5.2742e-05\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100, 2)            32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100, 1)            3         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0928 - val_loss: 0.0921\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0916 - val_loss: 0.0908\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0903 - val_loss: 0.0896\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0891 - val_loss: 0.0884\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0880 - val_loss: 0.0873\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0869 - val_loss: 0.0863\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0858 - val_loss: 0.0852\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0848 - val_loss: 0.0842\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0829 - val_loss: 0.0823\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0819 - val_loss: 0.0814\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0810 - val_loss: 0.0804\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0801 - val_loss: 0.0795\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0792 - val_loss: 0.0786\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0783 - val_loss: 0.0777\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0774 - val_loss: 0.0768\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0764 - val_loss: 0.0759\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0755 - val_loss: 0.0750\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0746 - val_loss: 0.0740\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0736 - val_loss: 0.0731\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0727 - val_loss: 0.0721\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0717 - val_loss: 0.0711\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0706 - val_loss: 0.0700\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0696 - val_loss: 0.0689\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0685 - val_loss: 0.0678\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0674 - val_loss: 0.0667\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0662 - val_loss: 0.0655\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0650 - val_loss: 0.0643\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0638 - val_loss: 0.0630\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0625 - val_loss: 0.0618\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0613 - val_loss: 0.0605\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0600 - val_loss: 0.0593\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0587 - val_loss: 0.0580\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0575 - val_loss: 0.0568\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0563 - val_loss: 0.0556\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0551 - val_loss: 0.0545\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0540 - val_loss: 0.0533\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0528 - val_loss: 0.0522\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.0517 - val_loss: 0.0512\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0507 - val_loss: 0.0501\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0496 - val_loss: 0.0491\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0486 - val_loss: 0.0480\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0475 - val_loss: 0.0470\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0465 - val_loss: 0.0460\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0455 - val_loss: 0.0450\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0445 - val_loss: 0.0440\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0435 - val_loss: 0.0429\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0425 - val_loss: 0.0419\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0415 - val_loss: 0.0409\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0405 - val_loss: 0.0400\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0395 - val_loss: 0.0390\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0385 - val_loss: 0.0380\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0375 - val_loss: 0.0370\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0365 - val_loss: 0.0360\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0355 - val_loss: 0.0351\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0346 - val_loss: 0.0341\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0336 - val_loss: 0.0332\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0327 - val_loss: 0.0322\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0317 - val_loss: 0.0313\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0308 - val_loss: 0.0304\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0299 - val_loss: 0.0295\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0290 - val_loss: 0.0286\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0281 - val_loss: 0.0277\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0272 - val_loss: 0.0268\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0263 - val_loss: 0.0259\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0255 - val_loss: 0.0251\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0246 - val_loss: 0.0242\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0238 - val_loss: 0.0234\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0229 - val_loss: 0.0226\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0190 - val_loss: 0.0187\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0183 - val_loss: 0.0180\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0175 - val_loss: 0.0173\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0168 - val_loss: 0.0166\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0161 - val_loss: 0.0159\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0148 - val_loss: 0.0146\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0136 - val_loss: 0.0134\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0124 - val_loss: 0.0122\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.010 - 1s 746us/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0055 - val_loss: 0.0056\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0046 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.9214e-04 - val_loss: 0.0011\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.7803e-04 - val_loss: 0.0010\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.6403e-04 - val_loss: 0.0010\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.5009e-04 - val_loss: 0.0010\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.3633e-04 - val_loss: 9.9379e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.2274e-04 - val_loss: 9.7937e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.0930e-04 - val_loss: 9.6506e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.9597e-04 - val_loss: 9.5089e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.8269e-04 - val_loss: 9.3690e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.6965e-04 - val_loss: 9.2302e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.5674e-04 - val_loss: 9.0927e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.4386e-04 - val_loss: 8.9569e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.3120e-04 - val_loss: 8.8223e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.1867e-04 - val_loss: 8.6890e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.0625e-04 - val_loss: 8.5570e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.9394e-04 - val_loss: 8.4264e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.8184e-04 - val_loss: 8.2969e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.6976e-04 - val_loss: 8.1690e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 7.5784e-04 - val_loss: 8.0424e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 7.4606e-04 - val_loss: 7.9172e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3439e-04 - val_loss: 7.7934e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.2289e-04 - val_loss: 7.6708e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1156e-04 - val_loss: 7.5491e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0022e-04 - val_loss: 7.4292e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8908e-04 - val_loss: 7.3105e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.7801e-04 - val_loss: 7.1934e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.6715e-04 - val_loss: 7.0775e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.5635e-04 - val_loss: 6.9629e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.4574e-04 - val_loss: 6.8496e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.3517e-04 - val_loss: 6.7377e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.2482e-04 - val_loss: 6.6269e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.1454e-04 - val_loss: 6.5175e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.0438e-04 - val_loss: 6.4094e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.9435e-04 - val_loss: 6.3025e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.8443e-04 - val_loss: 6.1970e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.7471e-04 - val_loss: 6.0925e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.6498e-04 - val_loss: 5.9896e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.5548e-04 - val_loss: 5.8878e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.4606e-04 - val_loss: 5.7872e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.3669e-04 - val_loss: 5.6882e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.2754e-04 - val_loss: 5.5904e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.1847e-04 - val_loss: 5.4938e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0957e-04 - val_loss: 5.3982e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.0071e-04 - val_loss: 5.3041e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.9202e-04 - val_loss: 5.2111e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.8341e-04 - val_loss: 5.1194e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.7493e-04 - val_loss: 5.0290e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 4.6657e-04 - val_loss: 4.9397e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.5831e-04 - val_loss: 4.8518e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.5017e-04 - val_loss: 4.7651e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.4219e-04 - val_loss: 4.6794e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3428e-04 - val_loss: 4.5949e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.2647e-04 - val_loss: 4.5117e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.1878e-04 - val_loss: 4.4297e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.1123e-04 - val_loss: 4.3488e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.0375e-04 - val_loss: 4.2691e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.9643e-04 - val_loss: 4.1904e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.8916e-04 - val_loss: 4.1130e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.8201e-04 - val_loss: 4.0366e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.7493e-04 - val_loss: 3.9612e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.6802e-04 - val_loss: 3.8866e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.6112e-04 - val_loss: 3.8133e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.5437e-04 - val_loss: 3.7411e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.4774e-04 - val_loss: 3.6699e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.4119e-04 - val_loss: 3.5998e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.3475e-04 - val_loss: 3.5309e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.2841e-04 - val_loss: 3.4630e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.2216e-04 - val_loss: 3.3964e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.1603e-04 - val_loss: 3.3308e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.1001e-04 - val_loss: 3.2662e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.0409e-04 - val_loss: 3.2026e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.9822e-04 - val_loss: 3.1402e-04\n",
      "Epoch 255/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 770us/step - loss: 2.9253e-04 - val_loss: 3.0786e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.8685e-04 - val_loss: 3.0182e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.8130e-04 - val_loss: 2.9589e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.7588e-04 - val_loss: 2.9005e-04\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.7050e-04 - val_loss: 2.8432e-04\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.6526e-04 - val_loss: 2.7867e-04\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6007e-04 - val_loss: 2.7313e-04\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.5502e-04 - val_loss: 2.6767e-04\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4999e-04 - val_loss: 2.6233e-04\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4512e-04 - val_loss: 2.5706e-04\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.4032e-04 - val_loss: 2.5187e-04\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3555e-04 - val_loss: 2.4679e-04\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.3091e-04 - val_loss: 2.4181e-04\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.2634e-04 - val_loss: 2.3692e-04\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.2188e-04 - val_loss: 2.3210e-04\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 2.1747e-04 - val_loss: 2.2739e-04\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1317e-04 - val_loss: 2.2275e-04\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.0893e-04 - val_loss: 2.1820e-04\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.0477e-04 - val_loss: 2.1374e-04\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.0072e-04 - val_loss: 2.0935e-04\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9670e-04 - val_loss: 2.0506e-04\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9278e-04 - val_loss: 2.0084e-04\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8894e-04 - val_loss: 1.9670e-04\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.8516e-04 - val_loss: 1.9265e-04\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.8146e-04 - val_loss: 1.8867e-04\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.7785e-04 - val_loss: 1.8476e-04\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7430e-04 - val_loss: 1.8093e-04\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.7080e-04 - val_loss: 1.7718e-04\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6738e-04 - val_loss: 1.7351e-04\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.6403e-04 - val_loss: 1.6990e-04\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.6078e-04 - val_loss: 1.6636e-04\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5755e-04 - val_loss: 1.6289e-04\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.5440e-04 - val_loss: 1.5950e-04\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5131e-04 - val_loss: 1.5618e-04\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4830e-04 - val_loss: 1.5292e-04\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4533e-04 - val_loss: 1.4973e-04\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4246e-04 - val_loss: 1.4659e-04\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3962e-04 - val_loss: 1.4353e-04\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3682e-04 - val_loss: 1.4054e-04\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3411e-04 - val_loss: 1.3760e-04\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.3145e-04 - val_loss: 1.3472e-04\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.2885e-04 - val_loss: 1.3191e-04\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2630e-04 - val_loss: 1.2915e-04\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2381e-04 - val_loss: 1.2645e-04\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.2137e-04 - val_loss: 1.2381e-04\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1898e-04 - val_loss: 1.2123e-04\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.1665e-04 - val_loss: 1.1870e-04\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.1436e-04 - val_loss: 1.1623e-04\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1213e-04 - val_loss: 1.1381e-04\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.0995e-04 - val_loss: 1.1144e-04\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0781e-04 - val_loss: 1.0913e-04\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0572e-04 - val_loss: 1.0687e-04\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0369e-04 - val_loss: 1.0466e-04\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0169e-04 - val_loss: 1.0249e-04\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.9749e-05 - val_loss: 1.0037e-04\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.7837e-05 - val_loss: 9.8310e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.5979e-05 - val_loss: 9.6290e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 9.4172e-05 - val_loss: 9.4310e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.2391e-05 - val_loss: 9.2379e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.0652e-05 - val_loss: 9.0496e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.8954e-05 - val_loss: 8.8657e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.7309e-05 - val_loss: 8.6854e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.5693e-05 - val_loss: 8.5095e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.4117e-05 - val_loss: 8.3376e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.2571e-05 - val_loss: 8.1701e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 8.1068e-05 - val_loss: 8.0065e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.9612e-05 - val_loss: 7.8460e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.8178e-05 - val_loss: 7.6895e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.6775e-05 - val_loss: 7.5371e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.5409e-05 - val_loss: 7.3884e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.4090e-05 - val_loss: 7.2425e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.2781e-05 - val_loss: 7.1009e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.1514e-05 - val_loss: 6.9628e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.0283e-05 - val_loss: 6.8275e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 6.9077e-05 - val_loss: 6.6957e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.7904e-05 - val_loss: 6.5670e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.6753e-05 - val_loss: 6.4416e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.5637e-05 - val_loss: 6.3192e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.4559e-05 - val_loss: 6.1991e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.3483e-05 - val_loss: 6.0828e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.2447e-05 - val_loss: 5.9694e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.1442e-05 - val_loss: 5.8584e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.0449e-05 - val_loss: 5.7509e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.9506e-05 - val_loss: 5.6449e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.8563e-05 - val_loss: 5.5421e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.7653e-05 - val_loss: 5.4419e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.6760e-05 - val_loss: 5.3445e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.5907e-05 - val_loss: 5.2489e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.5056e-05 - val_loss: 5.1562e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.4237e-05 - val_loss: 5.0658e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.3439e-05 - val_loss: 4.9775e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.2659e-05 - val_loss: 4.8915e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.1895e-05 - val_loss: 4.8082e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.1165e-05 - val_loss: 4.7264e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.0446e-05 - val_loss: 4.6466e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9740e-05 - val_loss: 4.5694e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.9066e-05 - val_loss: 4.4935e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.8392e-05 - val_loss: 4.4203e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.7749e-05 - val_loss: 4.3487e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.7122e-05 - val_loss: 4.2784e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.6504e-05 - val_loss: 4.2094e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.5889e-05 - val_loss: 4.1423e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.5303e-05 - val_loss: 4.0761e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4723e-05 - val_loss: 4.0116e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.4159e-05 - val_loss: 3.9488e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.3607e-05 - val_loss: 3.8877e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.3073e-05 - val_loss: 3.8281e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.2549e-05 - val_loss: 3.7703e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.2043e-05 - val_loss: 3.7139e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.1549e-05 - val_loss: 3.6591e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.1073e-05 - val_loss: 3.6055e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.0606e-05 - val_loss: 3.5534e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.0149e-05 - val_loss: 3.5030e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.9711e-05 - val_loss: 3.4535e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.9278e-05 - val_loss: 3.4057e-05\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.8864e-05 - val_loss: 3.3589e-05\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.8454e-05 - val_loss: 3.3137e-05\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.8062e-05 - val_loss: 3.2693e-05\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.7676e-05 - val_loss: 3.2263e-05\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.7303e-05 - val_loss: 3.1845e-05\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.6938e-05 - val_loss: 3.1439e-05\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.6589e-05 - val_loss: 3.1039e-05\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.6240e-05 - val_loss: 3.0655e-05\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.5907e-05 - val_loss: 3.0280e-05\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.5580e-05 - val_loss: 2.9915e-05\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.5266e-05 - val_loss: 2.9558e-05\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.4957e-05 - val_loss: 2.9212e-05\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4658e-05 - val_loss: 2.8873e-05\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4366e-05 - val_loss: 2.8545e-05\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.4081e-05 - val_loss: 2.8226e-05\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.3805e-05 - val_loss: 2.7915e-05\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.3536e-05 - val_loss: 2.7613e-05\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.3272e-05 - val_loss: 2.7319e-05\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.3020e-05 - val_loss: 2.7032e-05\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2771e-05 - val_loss: 2.6753e-05\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2532e-05 - val_loss: 2.6479e-05\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2295e-05 - val_loss: 2.6215e-05\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.2067e-05 - val_loss: 2.5958e-05\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.1843e-05 - val_loss: 2.5707e-05\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.1629e-05 - val_loss: 2.5461e-05\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.1416e-05 - val_loss: 2.5224e-05\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.1210e-05 - val_loss: 2.4993e-05\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.1010e-05 - val_loss: 2.4766e-05\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.0816e-05 - val_loss: 2.4545e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.0625e-05 - val_loss: 2.4331e-05\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.0440e-05 - val_loss: 2.4122e-05\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.0260e-05 - val_loss: 2.3918e-05\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.0083e-05 - val_loss: 2.3721e-05\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.9912e-05 - val_loss: 2.3526e-05\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.9746e-05 - val_loss: 2.3337e-05\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.9581e-05 - val_loss: 2.3155e-05\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 2.9423e-05 - val_loss: 2.2975e-05\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.9269e-05 - val_loss: 2.2799e-05\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.9118e-05 - val_loss: 2.2628e-05\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.8970e-05 - val_loss: 2.2463e-05\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.8826e-05 - val_loss: 2.2299e-05\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.8686e-05 - val_loss: 2.2140e-05\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.8549e-05 - val_loss: 2.1986e-05\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.8414e-05 - val_loss: 2.1837e-05\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 2.8283e-05 - val_loss: 2.1689e-05\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.8157e-05 - val_loss: 2.1544e-05\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.8032e-05 - val_loss: 2.1405e-05\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.7909e-05 - val_loss: 2.1268e-05\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.7790e-05 - val_loss: 2.1134e-05\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.7674e-05 - val_loss: 2.1003e-05\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.7562e-05 - val_loss: 2.0875e-05\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.7448e-05 - val_loss: 2.0752e-05\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.7340e-05 - val_loss: 2.0630e-05\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 2.7234e-05 - val_loss: 2.0511e-05\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.7129e-05 - val_loss: 2.0395e-05\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.7028e-05 - val_loss: 2.0281e-05\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6928e-05 - val_loss: 2.0169e-05\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.6831e-05 - val_loss: 2.0060e-05\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6735e-05 - val_loss: 1.9954e-05\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.6640e-05 - val_loss: 1.9851e-05\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.6549e-05 - val_loss: 1.9748e-05\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.6459e-05 - val_loss: 1.9649e-05\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.6370e-05 - val_loss: 1.9551e-05\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6285e-05 - val_loss: 1.9454e-05\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.6199e-05 - val_loss: 1.9361e-05\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6116e-05 - val_loss: 1.9268e-05\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.6034e-05 - val_loss: 1.9178e-05\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.5953e-05 - val_loss: 1.9091e-05\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.5874e-05 - val_loss: 1.9004e-05\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.5797e-05 - val_loss: 1.8919e-05\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.5720e-05 - val_loss: 1.8837e-05\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5646e-05 - val_loss: 1.8755e-05\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.5572e-05 - val_loss: 1.8674e-05\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.5499e-05 - val_loss: 1.8597e-05\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.5428e-05 - val_loss: 1.8519e-05\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.5358e-05 - val_loss: 1.8443e-05\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.5290e-05 - val_loss: 1.8368e-05\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.5221e-05 - val_loss: 1.8295e-05\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.5154e-05 - val_loss: 1.8224e-05\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.5088e-05 - val_loss: 1.8153e-05\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5023e-05 - val_loss: 1.8084e-05\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 753us/step - loss: 2.4959e-05 - val_loss: 1.8016e-05\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4896e-05 - val_loss: 1.7949e-05\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.4834e-05 - val_loss: 1.7882e-05\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.4772e-05 - val_loss: 1.7818e-05\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4711e-05 - val_loss: 1.7754e-05\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.4652e-05 - val_loss: 1.7691e-05\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.4593e-05 - val_loss: 1.7629e-05\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.4534e-05 - val_loss: 1.7568e-05\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4477e-05 - val_loss: 1.7507e-05\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4419e-05 - val_loss: 1.7448e-05\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.4363e-05 - val_loss: 1.7390e-05\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.4307e-05 - val_loss: 1.7333e-05\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4253e-05 - val_loss: 1.7275e-05\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.4198e-05 - val_loss: 1.7219e-05\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.4144e-05 - val_loss: 1.7165e-05\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.4091e-05 - val_loss: 1.7109e-05\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.4038e-05 - val_loss: 1.7057e-05\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3985e-05 - val_loss: 1.7003e-05\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3934e-05 - val_loss: 1.6951e-05\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.3882e-05 - val_loss: 1.6898e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.3832e-05 - val_loss: 1.6848e-05\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.3781e-05 - val_loss: 1.6797e-05\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3731e-05 - val_loss: 1.6746e-05\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.3682e-05 - val_loss: 1.6697e-05\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.3633e-05 - val_loss: 1.6649e-05\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.3584e-05 - val_loss: 1.6600e-05\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.3536e-05 - val_loss: 1.6552e-05\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.3488e-05 - val_loss: 1.6506e-05\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.3440e-05 - val_loss: 1.6458e-05\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3393e-05 - val_loss: 1.6411e-05\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.3346e-05 - val_loss: 1.6366e-05\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.3299e-05 - val_loss: 1.6320e-05\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.3254e-05 - val_loss: 1.6276e-05\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.3207e-05 - val_loss: 1.6231e-05\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.3162e-05 - val_loss: 1.6188e-05\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3117e-05 - val_loss: 1.6144e-05\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.3071e-05 - val_loss: 1.6100e-05\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.3027e-05 - val_loss: 1.6057e-05\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2982e-05 - val_loss: 1.6015e-05\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.2938e-05 - val_loss: 1.5973e-05\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2894e-05 - val_loss: 1.5931e-05\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.2850e-05 - val_loss: 1.5890e-05\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.2806e-05 - val_loss: 1.5848e-05\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.2764e-05 - val_loss: 1.5809e-05\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.2720e-05 - val_loss: 1.5768e-05\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.2678e-05 - val_loss: 1.5728e-05\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2635e-05 - val_loss: 1.5688e-05\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2593e-05 - val_loss: 1.5649e-05\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2550e-05 - val_loss: 1.5609e-05\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2508e-05 - val_loss: 1.5569e-05\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.2466e-05 - val_loss: 1.5530e-05\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2425e-05 - val_loss: 1.5493e-05\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2383e-05 - val_loss: 1.5454e-05\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2342e-05 - val_loss: 1.5416e-05\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2300e-05 - val_loss: 1.5378e-05\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2260e-05 - val_loss: 1.5341e-05\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.2218e-05 - val_loss: 1.5303e-05\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.2178e-05 - val_loss: 1.5268e-05\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2137e-05 - val_loss: 1.5231e-05\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.2097e-05 - val_loss: 1.5194e-05\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2057e-05 - val_loss: 1.5157e-05\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.2016e-05 - val_loss: 1.5121e-05\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.1977e-05 - val_loss: 1.5085e-05\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 2.1420e-0 - 1s 754us/step - loss: 2.1936e-05 - val_loss: 1.5049e-05\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.1897e-05 - val_loss: 1.5015e-05\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.1857e-05 - val_loss: 1.4979e-05\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.1818e-05 - val_loss: 1.4944e-05\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.1778e-05 - val_loss: 1.4908e-05\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.1739e-05 - val_loss: 1.4874e-05\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1700e-05 - val_loss: 1.4839e-05\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.1661e-05 - val_loss: 1.4805e-05\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.1622e-05 - val_loss: 1.4770e-05\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1583e-05 - val_loss: 1.4735e-05\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1544e-05 - val_loss: 1.4702e-05\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.1506e-05 - val_loss: 1.4668e-05\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.1467e-05 - val_loss: 1.4634e-05\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.1429e-05 - val_loss: 1.4602e-05\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.1390e-05 - val_loss: 1.4567e-05\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.1352e-05 - val_loss: 1.4534e-05\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.1314e-05 - val_loss: 1.4502e-05\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 2.1276e-05 - val_loss: 1.4468e-05\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1238e-05 - val_loss: 1.4435e-05\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1200e-05 - val_loss: 1.4404e-05\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.1162e-05 - val_loss: 1.4370e-05\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1124e-05 - val_loss: 1.4338e-05\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.1086e-05 - val_loss: 1.4305e-05\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.1049e-05 - val_loss: 1.4274e-05\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.1011e-05 - val_loss: 1.4241e-05\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.0974e-05 - val_loss: 1.4210e-05\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0937e-05 - val_loss: 1.4178e-05\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.0899e-05 - val_loss: 1.4146e-05\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.0862e-05 - val_loss: 1.4115e-05\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.0825e-05 - val_loss: 1.4083e-05\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.0788e-05 - val_loss: 1.4052e-05\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0751e-05 - val_loss: 1.4020e-05\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.0714e-05 - val_loss: 1.3989e-05\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0677e-05 - val_loss: 1.3957e-05\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.0640e-05 - val_loss: 1.3927e-05\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0604e-05 - val_loss: 1.3896e-05\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.0567e-05 - val_loss: 1.3865e-05\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.0530e-05 - val_loss: 1.3835e-05\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0494e-05 - val_loss: 1.3805e-05\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0457e-05 - val_loss: 1.3774e-05\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.0421e-05 - val_loss: 1.3744e-05\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0385e-05 - val_loss: 1.3713e-05\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.0349e-05 - val_loss: 1.3684e-05\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0312e-05 - val_loss: 1.3653e-05\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0276e-05 - val_loss: 1.3622e-05\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.0240e-05 - val_loss: 1.3593e-05\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.0204e-05 - val_loss: 1.3563e-05\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0168e-05 - val_loss: 1.3533e-05\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0132e-05 - val_loss: 1.3505e-05\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0096e-05 - val_loss: 1.3474e-05\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0060e-05 - val_loss: 1.3444e-05\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.0025e-05 - val_loss: 1.3416e-05\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.9989e-05 - val_loss: 1.3385e-05\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.9954e-05 - val_loss: 1.3357e-05\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.9918e-05 - val_loss: 1.3328e-05\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.9882e-05 - val_loss: 1.3298e-05\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9847e-05 - val_loss: 1.3269e-05\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.9811e-05 - val_loss: 1.3240e-05\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.9776e-05 - val_loss: 1.3211e-05\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9740e-05 - val_loss: 1.3182e-05\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.9705e-05 - val_loss: 1.3154e-05\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9669e-05 - val_loss: 1.3124e-05\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.9634e-05 - val_loss: 1.3095e-05\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9599e-05 - val_loss: 1.3068e-05\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9563e-05 - val_loss: 1.3038e-05\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.9528e-05 - val_loss: 1.3010e-05\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9493e-05 - val_loss: 1.2982e-05\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9457e-05 - val_loss: 1.2953e-05\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.9422e-05 - val_loss: 1.2925e-05\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.9387e-05 - val_loss: 1.2897e-05\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.9352e-05 - val_loss: 1.2868e-05\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9317e-05 - val_loss: 1.2840e-05\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.9282e-05 - val_loss: 1.2812e-05\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9247e-05 - val_loss: 1.2784e-05\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.9212e-05 - val_loss: 1.2756e-05\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.9178e-05 - val_loss: 1.2728e-05\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.9143e-05 - val_loss: 1.2701e-05\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.9108e-05 - val_loss: 1.2672e-05\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.9074e-05 - val_loss: 1.2645e-05\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.9039e-05 - val_loss: 1.2617e-05\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.9005e-05 - val_loss: 1.2590e-05\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8970e-05 - val_loss: 1.2562e-05\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.8936e-05 - val_loss: 1.2535e-05\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8901e-05 - val_loss: 1.2507e-05\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8867e-05 - val_loss: 1.2480e-05\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.8833e-05 - val_loss: 1.2453e-05\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8798e-05 - val_loss: 1.2425e-05\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.8764e-05 - val_loss: 1.2398e-05\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8730e-05 - val_loss: 1.2371e-05\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.8696e-05 - val_loss: 1.2345e-05\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8662e-05 - val_loss: 1.2318e-05\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.8628e-05 - val_loss: 1.2290e-05\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.8594e-05 - val_loss: 1.2264e-05\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.8560e-05 - val_loss: 1.2236e-05\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.8526e-05 - val_loss: 1.2211e-05\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.8492e-05 - val_loss: 1.2184e-05\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.8458e-05 - val_loss: 1.2157e-05\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8425e-05 - val_loss: 1.2131e-05\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.8391e-05 - val_loss: 1.2103e-05\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.8358e-05 - val_loss: 1.2078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8324e-05 - val_loss: 1.2051e-05\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.8290e-05 - val_loss: 1.2025e-05\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.8257e-05 - val_loss: 1.1998e-05\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8224e-05 - val_loss: 1.1973e-05\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8190e-05 - val_loss: 1.1946e-05\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.8156e-05 - val_loss: 1.1920e-05\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.8124e-05 - val_loss: 1.1894e-05\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8090e-05 - val_loss: 1.1868e-05\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8057e-05 - val_loss: 1.1842e-05\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8023e-05 - val_loss: 1.1816e-05\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.7990e-05 - val_loss: 1.1790e-05\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7957e-05 - val_loss: 1.1765e-05\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.7924e-05 - val_loss: 1.1739e-05\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7891e-05 - val_loss: 1.1712e-05\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.7858e-05 - val_loss: 1.1688e-05\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7825e-05 - val_loss: 1.1661e-05\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7792e-05 - val_loss: 1.1635e-05\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7760e-05 - val_loss: 1.1612e-05\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7727e-05 - val_loss: 1.1585e-05\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7694e-05 - val_loss: 1.1561e-05\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.7661e-05 - val_loss: 1.1535e-05\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.7629e-05 - val_loss: 1.1509e-05\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.7597e-05 - val_loss: 1.1485e-05\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7563e-05 - val_loss: 1.1458e-05\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7531e-05 - val_loss: 1.1434e-05\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7499e-05 - val_loss: 1.1409e-05\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7466e-05 - val_loss: 1.1384e-05\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7434e-05 - val_loss: 1.1359e-05\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7401e-05 - val_loss: 1.1334e-05\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7369e-05 - val_loss: 1.1309e-05\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7337e-05 - val_loss: 1.1284e-05\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7305e-05 - val_loss: 1.1260e-05\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.7273e-05 - val_loss: 1.1235e-05\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7240e-05 - val_loss: 1.1210e-05\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7208e-05 - val_loss: 1.1185e-05\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.7176e-05 - val_loss: 1.1161e-05\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7144e-05 - val_loss: 1.1136e-05\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.7113e-05 - val_loss: 1.1113e-05\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7080e-05 - val_loss: 1.1087e-05\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.7049e-05 - val_loss: 1.1063e-05\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7017e-05 - val_loss: 1.1039e-05\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6985e-05 - val_loss: 1.1014e-05\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6953e-05 - val_loss: 1.0990e-05\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6922e-05 - val_loss: 1.0966e-05\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6890e-05 - val_loss: 1.0941e-05\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.6858e-05 - val_loss: 1.0918e-05\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6827e-05 - val_loss: 1.0894e-05\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6795e-05 - val_loss: 1.0870e-05\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6764e-05 - val_loss: 1.0846e-05\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6732e-05 - val_loss: 1.0822e-05\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6701e-05 - val_loss: 1.0798e-05\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6670e-05 - val_loss: 1.0774e-05\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.6638e-05 - val_loss: 1.0750e-05\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6607e-05 - val_loss: 1.0727e-05\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6576e-05 - val_loss: 1.0702e-05\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.6546e-05 - val_loss: 1.0680e-05\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.6514e-05 - val_loss: 1.0655e-05\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6482e-05 - val_loss: 1.0632e-05\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6452e-05 - val_loss: 1.0609e-05\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.6421e-05 - val_loss: 1.0585e-05\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.6390e-05 - val_loss: 1.0562e-05\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.6359e-05 - val_loss: 1.0537e-05\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6328e-05 - val_loss: 1.0514e-05\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.6297e-05 - val_loss: 1.0492e-05\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.6267e-05 - val_loss: 1.0468e-05\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.6236e-05 - val_loss: 1.0445e-05\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6205e-05 - val_loss: 1.0422e-05\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6175e-05 - val_loss: 1.0399e-05\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.6144e-05 - val_loss: 1.0376e-05\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.6113e-05 - val_loss: 1.0353e-05\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6083e-05 - val_loss: 1.0330e-05\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6052e-05 - val_loss: 1.0306e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6022e-05 - val_loss: 1.0284e-05\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5992e-05 - val_loss: 1.0261e-05\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.5961e-05 - val_loss: 1.0238e-05\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5931e-05 - val_loss: 1.0215e-05\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.5901e-05 - val_loss: 1.0193e-05\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.5871e-05 - val_loss: 1.0170e-05\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.5841e-05 - val_loss: 1.0149e-05\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.5810e-05 - val_loss: 1.0125e-05\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.5780e-05 - val_loss: 1.0103e-05\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5750e-05 - val_loss: 1.0080e-05\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.5720e-05 - val_loss: 1.0057e-05\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5690e-05 - val_loss: 1.0035e-05\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5661e-05 - val_loss: 1.0013e-05\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.5631e-05 - val_loss: 9.9913e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.5600e-05 - val_loss: 9.9678e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.5571e-05 - val_loss: 9.9454e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5542e-05 - val_loss: 9.9242e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.5512e-05 - val_loss: 9.9018e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5482e-05 - val_loss: 9.8795e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5452e-05 - val_loss: 9.8568e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5423e-05 - val_loss: 9.8353e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5393e-05 - val_loss: 9.8127e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.5363e-05 - val_loss: 9.7919e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5334e-05 - val_loss: 9.7694e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.5305e-05 - val_loss: 9.7480e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.5276e-05 - val_loss: 9.7263e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5246e-05 - val_loss: 9.7039e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5217e-05 - val_loss: 9.6832e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5188e-05 - val_loss: 9.6609e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5158e-05 - val_loss: 9.6389e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.5129e-05 - val_loss: 9.6177e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.5101e-05 - val_loss: 9.5962e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.5071e-05 - val_loss: 9.5746e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.5043e-05 - val_loss: 9.5537e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.5013e-05 - val_loss: 9.5307e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4985e-05 - val_loss: 9.5114e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4956e-05 - val_loss: 9.4892e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4927e-05 - val_loss: 9.4674e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4898e-05 - val_loss: 9.4462e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4869e-05 - val_loss: 9.4248e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.4841e-05 - val_loss: 9.4041e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4811e-05 - val_loss: 9.3819e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4784e-05 - val_loss: 9.3615e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.4755e-05 - val_loss: 9.3397e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.4727e-05 - val_loss: 9.3201e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.4698e-05 - val_loss: 9.2977e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.4669e-05 - val_loss: 9.2781e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4641e-05 - val_loss: 9.2566e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4613e-05 - val_loss: 9.2356e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.4584e-05 - val_loss: 9.2145e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.4556e-05 - val_loss: 9.1937e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.4528e-05 - val_loss: 9.1727e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.4499e-05 - val_loss: 9.1530e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4471e-05 - val_loss: 9.1326e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4443e-05 - val_loss: 9.1121e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.4416e-05 - val_loss: 9.0926e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4387e-05 - val_loss: 9.0698e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.4360e-05 - val_loss: 9.0513e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4331e-05 - val_loss: 9.0297e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4303e-05 - val_loss: 9.0097e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4275e-05 - val_loss: 8.9884e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4248e-05 - val_loss: 8.9682e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4220e-05 - val_loss: 8.9489e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.4192e-05 - val_loss: 8.9275e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4165e-05 - val_loss: 8.9088e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.4137e-05 - val_loss: 8.8882e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.4109e-05 - val_loss: 8.8674e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.4081e-05 - val_loss: 8.8476e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4053e-05 - val_loss: 8.8266e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.4025e-05 - val_loss: 8.8071e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3997e-05 - val_loss: 8.7858e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3970e-05 - val_loss: 8.7663e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.3942e-05 - val_loss: 8.7457e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.3914e-05 - val_loss: 8.7264e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3886e-05 - val_loss: 8.7052e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 1.3858e-05 - val_loss: 8.6864e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3831e-05 - val_loss: 8.6651e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3803e-05 - val_loss: 8.6461e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3776e-05 - val_loss: 8.6258e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3748e-05 - val_loss: 8.6055e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3721e-05 - val_loss: 8.5855e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3693e-05 - val_loss: 8.5665e-06\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3666e-05 - val_loss: 8.5471e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3639e-05 - val_loss: 8.5270e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.3612e-05 - val_loss: 8.5071e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.3584e-05 - val_loss: 8.4868e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.3557e-05 - val_loss: 8.4677e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.3530e-05 - val_loss: 8.4490e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.3503e-05 - val_loss: 8.4290e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.3476e-05 - val_loss: 8.4102e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3449e-05 - val_loss: 8.3896e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3422e-05 - val_loss: 8.3717e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3395e-05 - val_loss: 8.3512e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3368e-05 - val_loss: 8.3330e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3341e-05 - val_loss: 8.3128e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3314e-05 - val_loss: 8.2941e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3287e-05 - val_loss: 8.2746e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3261e-05 - val_loss: 8.2559e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3234e-05 - val_loss: 8.2368e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.3207e-05 - val_loss: 8.2176e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.3181e-05 - val_loss: 8.1986e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.3155e-05 - val_loss: 8.1804e-06\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3128e-05 - val_loss: 8.1600e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3102e-05 - val_loss: 8.1431e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.3075e-05 - val_loss: 8.1224e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3049e-05 - val_loss: 8.1062e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3022e-05 - val_loss: 8.0855e-06\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2996e-05 - val_loss: 8.0676e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2970e-05 - val_loss: 8.0479e-06\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2943e-05 - val_loss: 8.0294e-06\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2917e-05 - val_loss: 8.0112e-06\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2891e-05 - val_loss: 7.9918e-06\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2866e-05 - val_loss: 7.9753e-06\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.2839e-05 - val_loss: 7.9555e-06\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2813e-05 - val_loss: 7.9379e-06\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2787e-05 - val_loss: 7.9184e-06\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2761e-05 - val_loss: 7.9011e-06\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2735e-05 - val_loss: 7.8830e-06\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2709e-05 - val_loss: 7.8646e-06\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2684e-05 - val_loss: 7.8458e-06\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 1.2658e-05 - val_loss: 7.8275e-06\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2632e-05 - val_loss: 7.8091e-06\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.2606e-05 - val_loss: 7.7908e-06\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.2581e-05 - val_loss: 7.7740e-06\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2555e-05 - val_loss: 7.7551e-06\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2530e-05 - val_loss: 7.7381e-06\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2504e-05 - val_loss: 7.7182e-06\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2479e-05 - val_loss: 7.7016e-06\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.2453e-05 - val_loss: 7.6831e-06\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.2428e-05 - val_loss: 7.6657e-06\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2403e-05 - val_loss: 7.6471e-06\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2378e-05 - val_loss: 7.6302e-06\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.2352e-05 - val_loss: 7.6122e-06\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.2327e-05 - val_loss: 7.5948e-06\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2302e-05 - val_loss: 7.5770e-06\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2276e-05 - val_loss: 7.5589e-06\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2252e-05 - val_loss: 7.5424e-06\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2227e-05 - val_loss: 7.5241e-06\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2201e-05 - val_loss: 7.5071e-06\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2177e-05 - val_loss: 7.4890e-06\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2153e-05 - val_loss: 7.4722e-06\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2127e-05 - val_loss: 7.4547e-06\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2102e-05 - val_loss: 7.4363e-06\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2077e-05 - val_loss: 7.4191e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2052e-05 - val_loss: 7.4023e-06\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2028e-05 - val_loss: 7.3854e-06\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2003e-05 - val_loss: 7.3680e-06\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1979e-05 - val_loss: 7.3501e-06\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1954e-05 - val_loss: 7.3338e-06\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1929e-05 - val_loss: 7.3170e-06\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1905e-05 - val_loss: 7.3001e-06\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1881e-05 - val_loss: 7.2826e-06\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.1856e-05 - val_loss: 7.2652e-06\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.1832e-05 - val_loss: 7.2486e-06\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1808e-05 - val_loss: 7.2323e-06\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.1783e-05 - val_loss: 7.2155e-06\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.1759e-05 - val_loss: 7.1988e-06\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.1735e-05 - val_loss: 7.1810e-06\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1710e-05 - val_loss: 7.1640e-06\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1686e-05 - val_loss: 7.1474e-06\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.1663e-05 - val_loss: 7.1311e-06\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1639e-05 - val_loss: 7.1147e-06\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.1614e-05 - val_loss: 7.0967e-06\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1591e-05 - val_loss: 7.0805e-06\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1567e-05 - val_loss: 7.0648e-06\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1543e-05 - val_loss: 7.0486e-06\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.1519e-05 - val_loss: 7.0314e-06\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1495e-05 - val_loss: 7.0153e-06\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1471e-05 - val_loss: 6.9988e-06\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.1447e-05 - val_loss: 6.9830e-06\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1424e-05 - val_loss: 6.9658e-06\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1400e-05 - val_loss: 6.9498e-06\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1377e-05 - val_loss: 6.9329e-06\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1353e-05 - val_loss: 6.9170e-06\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1330e-05 - val_loss: 6.9008e-06\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1307e-05 - val_loss: 6.8848e-06\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.1283e-05 - val_loss: 6.8688e-06\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1259e-05 - val_loss: 6.8524e-06\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.1236e-05 - val_loss: 6.8362e-06\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.1213e-05 - val_loss: 6.8201e-06\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1189e-05 - val_loss: 6.8040e-06\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1167e-05 - val_loss: 6.7888e-06\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1143e-05 - val_loss: 6.7725e-06\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1120e-05 - val_loss: 6.7562e-06\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1097e-05 - val_loss: 6.7400e-06\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1074e-05 - val_loss: 6.7243e-06\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.1051e-05 - val_loss: 6.7083e-06\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.1028e-05 - val_loss: 6.6935e-06\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1005e-05 - val_loss: 6.6766e-06\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.0982e-05 - val_loss: 6.6618e-06\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0959e-05 - val_loss: 6.6462e-06\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.0936e-05 - val_loss: 6.6314e-06\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0914e-05 - val_loss: 6.6151e-06\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0891e-05 - val_loss: 6.5996e-06\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.0868e-05 - val_loss: 6.5832e-06\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0845e-05 - val_loss: 6.5683e-06\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0823e-05 - val_loss: 6.5533e-06\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0801e-05 - val_loss: 6.5376e-06\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0778e-05 - val_loss: 6.5226e-06\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0755e-05 - val_loss: 6.5066e-06\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.0733e-05 - val_loss: 6.4920e-06\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0711e-05 - val_loss: 6.4769e-06\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0688e-05 - val_loss: 6.4622e-06\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.0665e-05 - val_loss: 6.4459e-06\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0644e-05 - val_loss: 6.4304e-06\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.0621e-05 - val_loss: 6.4159e-06\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0599e-05 - val_loss: 6.4010e-06\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0577e-05 - val_loss: 6.3857e-06\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0555e-05 - val_loss: 6.3709e-06\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0532e-05 - val_loss: 6.3545e-06\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0510e-05 - val_loss: 6.3410e-06\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0489e-05 - val_loss: 6.3252e-06\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0467e-05 - val_loss: 6.3112e-06\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.0445e-05 - val_loss: 6.2958e-06\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0423e-05 - val_loss: 6.2805e-06\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0401e-05 - val_loss: 6.2660e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0379e-05 - val_loss: 6.2503e-06\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0358e-05 - val_loss: 6.2372e-06\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0335e-05 - val_loss: 6.2220e-06\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.0314e-05 - val_loss: 6.2074e-06\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0292e-05 - val_loss: 6.1926e-06\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0270e-05 - val_loss: 6.1783e-06\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0249e-05 - val_loss: 6.1644e-06\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0227e-05 - val_loss: 6.1490e-06\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0206e-05 - val_loss: 6.1342e-06\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.0184e-05 - val_loss: 6.1198e-06\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.0163e-05 - val_loss: 6.1059e-06\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0141e-05 - val_loss: 6.0921e-06\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.0120e-05 - val_loss: 6.0772e-06\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0098e-05 - val_loss: 6.0622e-06\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0077e-05 - val_loss: 6.0480e-06\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0056e-05 - val_loss: 6.0341e-06\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0035e-05 - val_loss: 6.0195e-06\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0014e-05 - val_loss: 6.0059e-06\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.9923e-06 - val_loss: 5.9905e-06\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.9710e-06 - val_loss: 5.9772e-06\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.9501e-06 - val_loss: 5.9620e-06\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.9293e-06 - val_loss: 5.9486e-06\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.9083e-06 - val_loss: 5.9344e-06\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.8875e-06 - val_loss: 5.9206e-06\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.8665e-06 - val_loss: 5.9064e-06\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.8455e-06 - val_loss: 5.8929e-06\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 9.8246e-06 - val_loss: 5.8788e-06\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.8038e-06 - val_loss: 5.8657e-06\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.7832e-06 - val_loss: 5.8509e-06\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.7625e-06 - val_loss: 5.8377e-06\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.7417e-06 - val_loss: 5.8227e-06\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 9.7210e-06 - val_loss: 5.8098e-06\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.7007e-06 - val_loss: 5.7968e-06\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.6797e-06 - val_loss: 5.7817e-06\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.6591e-06 - val_loss: 5.7679e-06\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.6393e-06 - val_loss: 5.7546e-06\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 9.6185e-06 - val_loss: 5.7413e-06\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.5980e-06 - val_loss: 5.7262e-06\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.5783e-06 - val_loss: 5.7143e-06\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 9.5573e-06 - val_loss: 5.7005e-06\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.5371e-06 - val_loss: 5.6867e-06\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.5164e-06 - val_loss: 5.6736e-06\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 9.4965e-06 - val_loss: 5.6599e-06\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 9.4763e-06 - val_loss: 5.6471e-06\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 9.4563e-06 - val_loss: 5.6334e-06\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.4359e-06 - val_loss: 5.6200e-06\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.4167e-06 - val_loss: 5.6070e-06\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 9.3963e-06 - val_loss: 5.5948e-06\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.3756e-06 - val_loss: 5.5795e-06\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.3556e-06 - val_loss: 5.5672e-06\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.3360e-06 - val_loss: 5.5531e-06\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.3160e-06 - val_loss: 5.5407e-06\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.2965e-06 - val_loss: 5.5267e-06\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.2764e-06 - val_loss: 5.5145e-06\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.2569e-06 - val_loss: 5.5010e-06\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.2370e-06 - val_loss: 5.4893e-06\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.2172e-06 - val_loss: 5.4748e-06\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.1975e-06 - val_loss: 5.4626e-06\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.1778e-06 - val_loss: 5.4496e-06\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.1581e-06 - val_loss: 5.4355e-06\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.1387e-06 - val_loss: 5.4240e-06\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.1194e-06 - val_loss: 5.4108e-06\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.0995e-06 - val_loss: 5.3981e-06\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.0801e-06 - val_loss: 5.3844e-06\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 9.0605e-06 - val_loss: 5.3725e-06\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.0415e-06 - val_loss: 5.3590e-06\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.0227e-06 - val_loss: 5.3474e-06\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.0026e-06 - val_loss: 5.3336e-06\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 8.9835e-06 - val_loss: 5.3213e-06\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.9640e-06 - val_loss: 5.3089e-06\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.9450e-06 - val_loss: 5.2962e-06\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.9259e-06 - val_loss: 5.2836e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.9066e-06 - val_loss: 5.2701e-06\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.8872e-06 - val_loss: 5.2581e-06\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.8694e-06 - val_loss: 5.2459e-06\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.8498e-06 - val_loss: 5.2348e-06\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.8306e-06 - val_loss: 5.2199e-06\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.8119e-06 - val_loss: 5.2093e-06\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.7927e-06 - val_loss: 5.1968e-06\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.7734e-06 - val_loss: 5.1832e-06\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.7548e-06 - val_loss: 5.1707e-06\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.7362e-06 - val_loss: 5.1600e-06\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.7173e-06 - val_loss: 5.1468e-06\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.6984e-06 - val_loss: 5.1345e-06\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.6796e-06 - val_loss: 5.1216e-06\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.6612e-06 - val_loss: 5.1106e-06\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.6425e-06 - val_loss: 5.0988e-06\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.6241e-06 - val_loss: 5.0854e-06\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.6055e-06 - val_loss: 5.0737e-06\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.5871e-06 - val_loss: 5.0616e-06\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.5685e-06 - val_loss: 5.0505e-06\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.5499e-06 - val_loss: 5.0376e-06\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.5314e-06 - val_loss: 5.0266e-06\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.5139e-06 - val_loss: 5.0155e-06\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.4948e-06 - val_loss: 5.0032e-06\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.4762e-06 - val_loss: 4.9897e-06\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.4587e-06 - val_loss: 4.9793e-06\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.4398e-06 - val_loss: 4.9677e-06\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.4218e-06 - val_loss: 4.9540e-06\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 100, 3)            60        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100, 1)            4         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1261 - val_loss: 0.1240\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.1226 - val_loss: 0.1206\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1194 - val_loss: 0.1177\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.1166 - val_loss: 0.1151\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.1141 - val_loss: 0.1128\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.1120 - val_loss: 0.1109\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.1102 - val_loss: 0.1093\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.1087 - val_loss: 0.1078\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1073 - val_loss: 0.1066\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.1061 - val_loss: 0.1055\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.1050 - val_loss: 0.1045\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.1041 - val_loss: 0.1035\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.1032 - val_loss: 0.1027\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.1023 - val_loss: 0.1019\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.1015 - val_loss: 0.1011\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.1007 - val_loss: 0.1003\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.1000 - val_loss: 0.0995\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0992 - val_loss: 0.0988\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0984 - val_loss: 0.0980\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0977 - val_loss: 0.0972\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0969 - val_loss: 0.0964\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0960 - val_loss: 0.0956\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0952 - val_loss: 0.0947\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0944 - val_loss: 0.0939\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0935 - val_loss: 0.0930\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0926 - val_loss: 0.0921\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0917 - val_loss: 0.0912\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0908 - val_loss: 0.0902\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0898 - val_loss: 0.0893\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0889 - val_loss: 0.0883\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0879 - val_loss: 0.0873\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0869 - val_loss: 0.0862\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0858 - val_loss: 0.0852\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0848 - val_loss: 0.0841\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0837 - val_loss: 0.0830\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0826 - val_loss: 0.0819\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0814 - val_loss: 0.0807\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0803 - val_loss: 0.0796\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0791 - val_loss: 0.0784\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0779 - val_loss: 0.0772\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0767 - val_loss: 0.0759\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0754 - val_loss: 0.0747\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0742 - val_loss: 0.0734\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0729 - val_loss: 0.0721\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0716 - val_loss: 0.0707\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0703 - val_loss: 0.0694\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.0689 - val_loss: 0.0680\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0675 - val_loss: 0.0667\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0662 - val_loss: 0.0653\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0648 - val_loss: 0.0639\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0633 - val_loss: 0.0624\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0619 - val_loss: 0.0610\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0605 - val_loss: 0.0595\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0590 - val_loss: 0.0581\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0575 - val_loss: 0.0566\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0561 - val_loss: 0.0551\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0546 - val_loss: 0.0536\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0531 - val_loss: 0.0521\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0516 - val_loss: 0.0506\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0501 - val_loss: 0.0491\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0486 - val_loss: 0.0476\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0471 - val_loss: 0.0461\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0456 - val_loss: 0.0446\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0441 - val_loss: 0.0431\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0426 - val_loss: 0.0416\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0411 - val_loss: 0.0401\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0396 - val_loss: 0.0386\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0381 - val_loss: 0.0372\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0367 - val_loss: 0.0358\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0353 - val_loss: 0.0344\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0339 - val_loss: 0.0330\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0326 - val_loss: 0.0317\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0313 - val_loss: 0.0305\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0301 - val_loss: 0.0292\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0288 - val_loss: 0.0280\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0276 - val_loss: 0.0268\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0264 - val_loss: 0.0256\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0253 - val_loss: 0.0245\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0241 - val_loss: 0.0234\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0230 - val_loss: 0.0223\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0220 - val_loss: 0.0212\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0210 - val_loss: 0.0202\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0190 - val_loss: 0.0183\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0180 - val_loss: 0.0174\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0171 - val_loss: 0.0165\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0163 - val_loss: 0.0156\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0154 - val_loss: 0.0148\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0027 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0012 - val_loss: 9.9824e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0011 - val_loss: 9.7061e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0011 - val_loss: 9.4432e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0011 - val_loss: 9.1930e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0011 - val_loss: 8.9545e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0010 - val_loss: 8.7272e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0010 - val_loss: 8.5104e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.9592e-04 - val_loss: 8.3034e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.7474e-04 - val_loss: 8.1059e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.5460e-04 - val_loss: 7.9172e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.3525e-04 - val_loss: 7.7369e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.1678e-04 - val_loss: 7.5643e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.9901e-04 - val_loss: 7.3993e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 8.8200e-04 - val_loss: 7.2412e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.6572e-04 - val_loss: 7.0896e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.5004e-04 - val_loss: 6.9443e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 721us/step - loss: 8.3501e-04 - val_loss: 6.8046e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.2048e-04 - val_loss: 6.6706e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0659e-04 - val_loss: 6.5415e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.9312e-04 - val_loss: 6.4174e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.8022e-04 - val_loss: 6.2978e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.6765e-04 - val_loss: 6.1826e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.5563e-04 - val_loss: 6.0713e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.4394e-04 - val_loss: 5.9639e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 7.3270e-04 - val_loss: 5.8599e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.2170e-04 - val_loss: 5.7593e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.1111e-04 - val_loss: 5.6620e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0081e-04 - val_loss: 5.5675e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.9084e-04 - val_loss: 5.4759e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8109e-04 - val_loss: 5.3869e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.7166e-04 - val_loss: 5.3004e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.6243e-04 - val_loss: 5.2163e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.5348e-04 - val_loss: 5.1344e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 6.4477e-04 - val_loss: 5.0543e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.3622e-04 - val_loss: 4.9762e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.2781e-04 - val_loss: 4.9000e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.1968e-04 - val_loss: 4.8254e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 6.1165e-04 - val_loss: 4.7524e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.0383e-04 - val_loss: 4.6807e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.9616e-04 - val_loss: 4.6104e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.8859e-04 - val_loss: 4.5414e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.8112e-04 - val_loss: 4.4737e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.7391e-04 - val_loss: 4.4071e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.6667e-04 - val_loss: 4.3416e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.5964e-04 - val_loss: 4.2770e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.5265e-04 - val_loss: 4.2133e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.4578e-04 - val_loss: 4.1505e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.3902e-04 - val_loss: 4.0886e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.3234e-04 - val_loss: 4.0277e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 5.2578e-04 - val_loss: 3.9676e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 853us/step - loss: 5.1930e-04 - val_loss: 3.9083e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 867us/step - loss: 5.1289e-04 - val_loss: 3.8498e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 850us/step - loss: 5.0661e-04 - val_loss: 3.7922e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 868us/step - loss: 5.0036e-04 - val_loss: 3.7354e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 4.9425e-04 - val_loss: 3.6794e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.8821e-04 - val_loss: 3.6241e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.8223e-04 - val_loss: 3.5696e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.7634e-04 - val_loss: 3.5158e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7055e-04 - val_loss: 3.4628e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.6482e-04 - val_loss: 3.4105e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.5917e-04 - val_loss: 3.3589e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.5359e-04 - val_loss: 3.3080e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.4813e-04 - val_loss: 3.2579e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.4271e-04 - val_loss: 3.2084e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.3736e-04 - val_loss: 3.1597e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3213e-04 - val_loss: 3.1117e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.2691e-04 - val_loss: 3.0643e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 4.2180e-04 - val_loss: 3.0177e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.1679e-04 - val_loss: 2.9718e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.1183e-04 - val_loss: 2.9265e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 4.0693e-04 - val_loss: 2.8820e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 4.0214e-04 - val_loss: 2.8382e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.9740e-04 - val_loss: 2.7950e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.9272e-04 - val_loss: 2.7525e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.8818e-04 - val_loss: 2.7108e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.8368e-04 - val_loss: 2.6698e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.7923e-04 - val_loss: 2.6294e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.7489e-04 - val_loss: 2.5898e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.7061e-04 - val_loss: 2.5508e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.6641e-04 - val_loss: 2.5124e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.6229e-04 - val_loss: 2.4748e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5823e-04 - val_loss: 2.4378e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.5426e-04 - val_loss: 2.4016e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.5032e-04 - val_loss: 2.3659e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.4650e-04 - val_loss: 2.3309e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.4274e-04 - val_loss: 2.2966e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.3906e-04 - val_loss: 2.2630e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.3543e-04 - val_loss: 2.2300e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.3188e-04 - val_loss: 2.1976e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2838e-04 - val_loss: 2.1658e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.2498e-04 - val_loss: 2.1347e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2162e-04 - val_loss: 2.1041e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.1837e-04 - val_loss: 2.0742e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.1514e-04 - val_loss: 2.0448e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.1198e-04 - val_loss: 2.0161e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.0889e-04 - val_loss: 1.9878e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.0588e-04 - val_loss: 1.9602e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.0290e-04 - val_loss: 1.9331e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.9999e-04 - val_loss: 1.9064e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.9714e-04 - val_loss: 1.8803e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.9437e-04 - val_loss: 1.8548e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.9163e-04 - val_loss: 1.8297e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.8895e-04 - val_loss: 1.8052e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.8633e-04 - val_loss: 1.7811e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.8375e-04 - val_loss: 1.7574e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.8123e-04 - val_loss: 1.7342e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.7878e-04 - val_loss: 1.7115e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.7635e-04 - val_loss: 1.6892e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.7397e-04 - val_loss: 1.6674e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.7165e-04 - val_loss: 1.6459e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.6938e-04 - val_loss: 1.6249e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6713e-04 - val_loss: 1.6042e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.6493e-04 - val_loss: 1.5838e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.6278e-04 - val_loss: 1.5639e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.6067e-04 - val_loss: 1.5442e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.5860e-04 - val_loss: 1.5250e-04\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.5656e-04 - val_loss: 1.5060e-04\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.5457e-04 - val_loss: 1.4874e-04\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.5261e-04 - val_loss: 1.4693e-04\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.5067e-04 - val_loss: 1.4513e-04\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.4878e-04 - val_loss: 1.4336e-04\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4693e-04 - val_loss: 1.4163e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.4509e-04 - val_loss: 1.3992e-04\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.4329e-04 - val_loss: 1.3823e-04\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4152e-04 - val_loss: 1.3657e-04\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.3978e-04 - val_loss: 1.3493e-04\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.3808e-04 - val_loss: 1.3334e-04\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.3639e-04 - val_loss: 1.3175e-04\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.3474e-04 - val_loss: 1.3019e-04\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.3311e-04 - val_loss: 1.2865e-04\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3150e-04 - val_loss: 1.2715e-04\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2992e-04 - val_loss: 1.2566e-04\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2837e-04 - val_loss: 1.2418e-04\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2683e-04 - val_loss: 1.2272e-04\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2533e-04 - val_loss: 1.2129e-04\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2384e-04 - val_loss: 1.1989e-04\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.2238e-04 - val_loss: 1.1850e-04\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2093e-04 - val_loss: 1.1713e-04\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.1951e-04 - val_loss: 1.1578e-04\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1811e-04 - val_loss: 1.1444e-04\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.1672e-04 - val_loss: 1.1312e-04\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.1536e-04 - val_loss: 1.1182e-04\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.1401e-04 - val_loss: 1.1054e-04\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 2.0853e-0 - 1s 777us/step - loss: 2.1268e-04 - val_loss: 1.0927e-04\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1138e-04 - val_loss: 1.0803e-04\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.1008e-04 - val_loss: 1.0679e-04\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0880e-04 - val_loss: 1.0556e-04\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0754e-04 - val_loss: 1.0437e-04\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.0630e-04 - val_loss: 1.0319e-04\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.0506e-04 - val_loss: 1.0201e-04\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.0385e-04 - val_loss: 1.0085e-04\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.0265e-04 - val_loss: 9.9697e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.0146e-04 - val_loss: 9.8565e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.0029e-04 - val_loss: 9.7442e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9913e-04 - val_loss: 9.6337e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9799e-04 - val_loss: 9.5250e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9686e-04 - val_loss: 9.4165e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9574e-04 - val_loss: 9.3091e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.9463e-04 - val_loss: 9.2035e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.9354e-04 - val_loss: 9.0996e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.9247e-04 - val_loss: 8.9976e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9139e-04 - val_loss: 8.8948e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9034e-04 - val_loss: 8.7930e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.8929e-04 - val_loss: 8.6913e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8826e-04 - val_loss: 8.5937e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.8724e-04 - val_loss: 8.4968e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.8622e-04 - val_loss: 8.4013e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8522e-04 - val_loss: 8.3061e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8423e-04 - val_loss: 8.2117e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8325e-04 - val_loss: 8.1176e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.8228e-04 - val_loss: 8.0250e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.8131e-04 - val_loss: 7.9328e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8036e-04 - val_loss: 7.8425e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.7943e-04 - val_loss: 7.7538e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7849e-04 - val_loss: 7.6655e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.7758e-04 - val_loss: 7.5792e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.7666e-04 - val_loss: 7.4941e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.7576e-04 - val_loss: 7.4071e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.7487e-04 - val_loss: 7.3227e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7399e-04 - val_loss: 7.2415e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7311e-04 - val_loss: 7.1598e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.7225e-04 - val_loss: 7.0785e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7139e-04 - val_loss: 6.9983e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.7054e-04 - val_loss: 6.9181e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.6971e-04 - val_loss: 6.8388e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6888e-04 - val_loss: 6.7622e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6806e-04 - val_loss: 6.6858e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6725e-04 - val_loss: 6.6111e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6644e-04 - val_loss: 6.5358e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.6565e-04 - val_loss: 6.4610e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.6486e-04 - val_loss: 6.3876e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6409e-04 - val_loss: 6.3175e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6332e-04 - val_loss: 6.2464e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.6255e-04 - val_loss: 6.1761e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6180e-04 - val_loss: 6.1060e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6106e-04 - val_loss: 6.0402e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6031e-04 - val_loss: 5.9712e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.5958e-04 - val_loss: 5.9033e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5886e-04 - val_loss: 5.8370e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.5815e-04 - val_loss: 5.7721e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5744e-04 - val_loss: 5.7070e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.5674e-04 - val_loss: 5.6443e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5605e-04 - val_loss: 5.5821e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.5536e-04 - val_loss: 5.5205e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5468e-04 - val_loss: 5.4582e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.5402e-04 - val_loss: 5.3995e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.5335e-04 - val_loss: 5.3394e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.5269e-04 - val_loss: 5.2809e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5205e-04 - val_loss: 5.2240e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.5140e-04 - val_loss: 5.1652e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.5077e-04 - val_loss: 5.1101e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5014e-04 - val_loss: 5.0561e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4952e-04 - val_loss: 5.0025e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4889e-04 - val_loss: 4.9469e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4829e-04 - val_loss: 4.8933e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4768e-04 - val_loss: 4.8405e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.4709e-04 - val_loss: 4.7888e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.4650e-04 - val_loss: 4.7376e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.4591e-04 - val_loss: 4.6872e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4534e-04 - val_loss: 4.6378e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4476e-04 - val_loss: 4.5873e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.4420e-04 - val_loss: 4.5400e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.4364e-04 - val_loss: 4.4929e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4308e-04 - val_loss: 4.4446e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4254e-04 - val_loss: 4.3966e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.4200e-04 - val_loss: 4.3513e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4146e-04 - val_loss: 4.3077e-05\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4093e-04 - val_loss: 4.2640e-05\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.4040e-04 - val_loss: 4.2185e-05\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3989e-04 - val_loss: 4.1767e-05\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.3938e-04 - val_loss: 4.1355e-05\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.3886e-04 - val_loss: 4.0925e-05\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3836e-04 - val_loss: 4.0513e-05\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3786e-04 - val_loss: 4.0104e-05\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3737e-04 - val_loss: 3.9712e-05\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 1.3688e-04 - val_loss: 3.9329e-05\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.3640e-04 - val_loss: 3.8944e-05\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.3592e-04 - val_loss: 3.8573e-05\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3544e-04 - val_loss: 3.8188e-05\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.3497e-04 - val_loss: 3.7800e-05\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.3452e-04 - val_loss: 3.7454e-05\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3402e-04 - val_loss: 3.7034e-05\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3353e-04 - val_loss: 3.6621e-05\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3304e-04 - val_loss: 3.6220e-05\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3255e-04 - val_loss: 3.5825e-05\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3207e-04 - val_loss: 3.5448e-05\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3158e-04 - val_loss: 3.5080e-05\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.3109e-04 - val_loss: 3.4686e-05\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3061e-04 - val_loss: 3.4306e-05\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.3014e-04 - val_loss: 3.3945e-05\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2967e-04 - val_loss: 3.3601e-05\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2919e-04 - val_loss: 3.3240e-05\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2873e-04 - val_loss: 3.2901e-05\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2827e-04 - val_loss: 3.2566e-05\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2780e-04 - val_loss: 3.2232e-05\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2735e-04 - val_loss: 3.1914e-05\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2690e-04 - val_loss: 3.1588e-05\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2645e-04 - val_loss: 3.1273e-05\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.2600e-04 - val_loss: 3.0956e-05\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2556e-04 - val_loss: 3.0643e-05\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2513e-04 - val_loss: 3.0366e-05\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2469e-04 - val_loss: 3.0067e-05\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2427e-04 - val_loss: 2.9798e-05\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2382e-04 - val_loss: 2.9489e-05\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2340e-04 - val_loss: 2.9207e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2298e-04 - val_loss: 2.8937e-05\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2256e-04 - val_loss: 2.8672e-05\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2214e-04 - val_loss: 2.8413e-05\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2172e-04 - val_loss: 2.8153e-05\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.2130e-04 - val_loss: 2.7886e-05\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2089e-04 - val_loss: 2.7616e-05\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2049e-04 - val_loss: 2.7386e-05\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2009e-04 - val_loss: 2.7152e-05\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1967e-04 - val_loss: 2.6887e-05\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1929e-04 - val_loss: 2.6670e-05\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.1888e-04 - val_loss: 2.6434e-05\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1847e-04 - val_loss: 2.6184e-05\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1808e-04 - val_loss: 2.5953e-05\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1769e-04 - val_loss: 2.5733e-05\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1730e-04 - val_loss: 2.5504e-05\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 1.1691e-04 - val_loss: 2.5287e-05\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1653e-04 - val_loss: 2.5074e-05\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.1614e-04 - val_loss: 2.4867e-05\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1575e-04 - val_loss: 2.4644e-05\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1537e-04 - val_loss: 2.4439e-05\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1499e-04 - val_loss: 2.4234e-05\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1463e-04 - val_loss: 2.4051e-05\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1423e-04 - val_loss: 2.3835e-05\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.1386e-04 - val_loss: 2.3632e-05\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1350e-04 - val_loss: 2.3456e-05\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1313e-04 - val_loss: 2.3271e-05\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.1275e-04 - val_loss: 2.3079e-05\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1238e-04 - val_loss: 2.2873e-05\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1202e-04 - val_loss: 2.2686e-05\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1166e-04 - val_loss: 2.2511e-05\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1128e-04 - val_loss: 2.2323e-05\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1095e-04 - val_loss: 2.2176e-05\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1056e-04 - val_loss: 2.1987e-05\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1020e-04 - val_loss: 2.1795e-05\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0984e-04 - val_loss: 2.1619e-05\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0949e-04 - val_loss: 2.1457e-05\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0914e-04 - val_loss: 2.1303e-05\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0879e-04 - val_loss: 2.1148e-05\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0842e-04 - val_loss: 2.0972e-05\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0807e-04 - val_loss: 2.0815e-05\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.0772e-04 - val_loss: 2.0650e-05\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.0737e-04 - val_loss: 2.0503e-05\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0701e-04 - val_loss: 2.0328e-05\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.0667e-04 - val_loss: 2.0175e-05\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0633e-04 - val_loss: 2.0036e-05\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0597e-04 - val_loss: 1.9879e-05\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0563e-04 - val_loss: 1.9733e-05\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0529e-04 - val_loss: 1.9584e-05\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.0494e-04 - val_loss: 1.9440e-05\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0460e-04 - val_loss: 1.9294e-05\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0426e-04 - val_loss: 1.9157e-05\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0392e-04 - val_loss: 1.9016e-05\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0359e-04 - val_loss: 1.8888e-05\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.0323e-04 - val_loss: 1.8737e-05\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0290e-04 - val_loss: 1.8602e-05\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0258e-04 - val_loss: 1.8485e-05\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.0222e-04 - val_loss: 1.8330e-05\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.0189e-04 - val_loss: 1.8195e-05\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0155e-04 - val_loss: 1.8054e-05\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.0122e-04 - val_loss: 1.7929e-05\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0089e-04 - val_loss: 1.7815e-05\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0055e-04 - val_loss: 1.7674e-05\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0022e-04 - val_loss: 1.7551e-05\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 9.9887e-05 - val_loss: 1.7429e-05\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.9568e-05 - val_loss: 1.7326e-05\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.9216e-05 - val_loss: 1.7182e-05\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.8894e-05 - val_loss: 1.7059e-05\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.8569e-05 - val_loss: 1.6948e-05\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.8240e-05 - val_loss: 1.6835e-05\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 9.7913e-05 - val_loss: 1.6724e-05\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.7580e-05 - val_loss: 1.6606e-05\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 9.7255e-05 - val_loss: 1.6490e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.6932e-05 - val_loss: 1.6385e-05\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.6594e-05 - val_loss: 1.6256e-05\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.6273e-05 - val_loss: 1.6144e-05\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.5947e-05 - val_loss: 1.6028e-05\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.5627e-05 - val_loss: 1.5921e-05\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 9.5314e-05 - val_loss: 1.5832e-05\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.4973e-05 - val_loss: 1.5708e-05\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.4652e-05 - val_loss: 1.5594e-05\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.4346e-05 - val_loss: 1.5512e-05\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.4002e-05 - val_loss: 1.5389e-05\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.3692e-05 - val_loss: 1.5292e-05\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.3374e-05 - val_loss: 1.5200e-05\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.3054e-05 - val_loss: 1.5109e-05\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.2736e-05 - val_loss: 1.5019e-05\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 9.2403e-05 - val_loss: 1.4910e-05\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 9.2092e-05 - val_loss: 1.4817e-05\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.1763e-05 - val_loss: 1.4711e-05\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.1451e-05 - val_loss: 1.4616e-05\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.1128e-05 - val_loss: 1.4513e-05\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.0814e-05 - val_loss: 1.4421e-05\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.0501e-05 - val_loss: 1.4333e-05\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.0188e-05 - val_loss: 1.4250e-05\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.9867e-05 - val_loss: 1.4163e-05\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.9544e-05 - val_loss: 1.4066e-05\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.9228e-05 - val_loss: 1.3970e-05\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.8901e-05 - val_loss: 1.3859e-05\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.8595e-05 - val_loss: 1.3767e-05\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.8284e-05 - val_loss: 1.3682e-05\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.7965e-05 - val_loss: 1.3588e-05\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.7662e-05 - val_loss: 1.3511e-05\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.7340e-05 - val_loss: 1.3426e-05\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.7033e-05 - val_loss: 1.3352e-05\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.6718e-05 - val_loss: 1.3273e-05\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 8.6405e-05 - val_loss: 1.3194e-05\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.6081e-05 - val_loss: 1.3097e-05\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.5771e-05 - val_loss: 1.3009e-05\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.5462e-05 - val_loss: 1.2931e-05\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.5151e-05 - val_loss: 1.2849e-05\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.4839e-05 - val_loss: 1.2764e-05\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.4541e-05 - val_loss: 1.2702e-05\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.4205e-05 - val_loss: 1.2596e-05\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.3913e-05 - val_loss: 1.2530e-05\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.3604e-05 - val_loss: 1.2465e-05\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 8.3298e-05 - val_loss: 1.2398e-05\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.2975e-05 - val_loss: 1.2310e-05\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.2668e-05 - val_loss: 1.2237e-05\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 8.2350e-05 - val_loss: 1.2149e-05\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.2041e-05 - val_loss: 1.2062e-05\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.1743e-05 - val_loss: 1.1993e-05\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.1438e-05 - val_loss: 1.1925e-05\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.1127e-05 - val_loss: 1.1854e-05\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.0814e-05 - val_loss: 1.1778e-05\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.0504e-05 - val_loss: 1.1703e-05\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.0202e-05 - val_loss: 1.1634e-05\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.9901e-05 - val_loss: 1.1570e-05\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.9576e-05 - val_loss: 1.1478e-05\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.9277e-05 - val_loss: 1.1404e-05\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.8982e-05 - val_loss: 1.1346e-05\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.8672e-05 - val_loss: 1.1283e-05\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.8369e-05 - val_loss: 1.1220e-05\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.8060e-05 - val_loss: 1.1154e-05\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.7742e-05 - val_loss: 1.1065e-05\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.7456e-05 - val_loss: 1.1013e-05\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.7133e-05 - val_loss: 1.0929e-05\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.6839e-05 - val_loss: 1.0864e-05\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 7.6533e-05 - val_loss: 1.0796e-05\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.6239e-05 - val_loss: 1.0743e-05\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.5921e-05 - val_loss: 1.0666e-05\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.5633e-05 - val_loss: 1.0616e-05\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.5335e-05 - val_loss: 1.0570e-05\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.5006e-05 - val_loss: 1.0476e-05\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.4732e-05 - val_loss: 1.0438e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.4418e-05 - val_loss: 1.0384e-05\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.4113e-05 - val_loss: 1.0318e-05\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3805e-05 - val_loss: 1.0244e-05\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 7.3503e-05 - val_loss: 1.0172e-05\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.3216e-05 - val_loss: 1.0129e-05\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.2911e-05 - val_loss: 1.0071e-05\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2603e-05 - val_loss: 9.9980e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.2318e-05 - val_loss: 9.9513e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.2022e-05 - val_loss: 9.9115e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1715e-05 - val_loss: 9.8584e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1399e-05 - val_loss: 9.7788e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.1104e-05 - val_loss: 9.7086e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.0815e-05 - val_loss: 9.6600e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0512e-05 - val_loss: 9.5991e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.0215e-05 - val_loss: 9.5404e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.9917e-05 - val_loss: 9.4832e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.9616e-05 - val_loss: 9.4200e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.9338e-05 - val_loss: 9.3893e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.9034e-05 - val_loss: 9.3439e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.8736e-05 - val_loss: 9.2917e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.8423e-05 - val_loss: 9.2125e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.8131e-05 - val_loss: 9.1513e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.7858e-05 - val_loss: 9.1225e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.7539e-05 - val_loss: 9.0494e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.7257e-05 - val_loss: 9.0000e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.6957e-05 - val_loss: 8.9458e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.6672e-05 - val_loss: 8.9077e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.6359e-05 - val_loss: 8.8320e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.6087e-05 - val_loss: 8.7959e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.5795e-05 - val_loss: 8.7603e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.5480e-05 - val_loss: 8.6847e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.5196e-05 - val_loss: 8.6324e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.4921e-05 - val_loss: 8.6071e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 6.4616e-05 - val_loss: 8.5517e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.4322e-05 - val_loss: 8.4958e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.4044e-05 - val_loss: 8.4625e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.3739e-05 - val_loss: 8.4087e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.3441e-05 - val_loss: 8.3394e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.3169e-05 - val_loss: 8.3038e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.2878e-05 - val_loss: 8.2645e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.2591e-05 - val_loss: 8.2223e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.2299e-05 - val_loss: 8.1761e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.2018e-05 - val_loss: 8.1417e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.1706e-05 - val_loss: 8.0691e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.1430e-05 - val_loss: 8.0208e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.1155e-05 - val_loss: 7.9890e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 6.0880e-05 - val_loss: 7.9661e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.0574e-05 - val_loss: 7.9126e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.0289e-05 - val_loss: 7.8689e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.9992e-05 - val_loss: 7.8083e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.9724e-05 - val_loss: 7.7738e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.9430e-05 - val_loss: 7.7220e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.9156e-05 - val_loss: 7.6850e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.8861e-05 - val_loss: 7.6338e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.8587e-05 - val_loss: 7.5974e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.8295e-05 - val_loss: 7.5471e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.8019e-05 - val_loss: 7.5051e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.7734e-05 - val_loss: 7.4599e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.7453e-05 - val_loss: 7.4141e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.7192e-05 - val_loss: 7.3959e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.6900e-05 - val_loss: 7.3604e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.6614e-05 - val_loss: 7.3143e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.6348e-05 - val_loss: 7.2900e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.6048e-05 - val_loss: 7.2326e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.5777e-05 - val_loss: 7.1894e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.5490e-05 - val_loss: 7.1285e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.5232e-05 - val_loss: 7.1036e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.4961e-05 - val_loss: 7.0808e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.4670e-05 - val_loss: 7.0344e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.4395e-05 - val_loss: 6.9954e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.4133e-05 - val_loss: 6.9780e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.3838e-05 - val_loss: 6.9251e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.3569e-05 - val_loss: 6.8800e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.3295e-05 - val_loss: 6.8395e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.3034e-05 - val_loss: 6.8162e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.2756e-05 - val_loss: 6.7823e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.2473e-05 - val_loss: 6.7311e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 5.2205e-05 - val_loss: 6.6939e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.1949e-05 - val_loss: 6.6752e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.1669e-05 - val_loss: 6.6407e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.1388e-05 - val_loss: 6.5847e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.1123e-05 - val_loss: 6.5444e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.0863e-05 - val_loss: 6.5179e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.0605e-05 - val_loss: 6.5020e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0318e-05 - val_loss: 6.4527e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.0067e-05 - val_loss: 6.4338e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.9775e-05 - val_loss: 6.3722e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.9528e-05 - val_loss: 6.3498e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.9259e-05 - val_loss: 6.3164e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.8989e-05 - val_loss: 6.2768e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.8723e-05 - val_loss: 6.2361e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.8480e-05 - val_loss: 6.2242e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.8192e-05 - val_loss: 6.1712e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.7937e-05 - val_loss: 6.1381e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.7676e-05 - val_loss: 6.1061e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.7422e-05 - val_loss: 6.0860e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 4.7164e-05 - val_loss: 6.0628e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.6901e-05 - val_loss: 6.0355e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.6626e-05 - val_loss: 5.9901e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 4.6380e-05 - val_loss: 5.9655e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.6114e-05 - val_loss: 5.9254e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.5863e-05 - val_loss: 5.8963e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.5610e-05 - val_loss: 5.8728e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.5343e-05 - val_loss: 5.8347e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.5088e-05 - val_loss: 5.7990e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.4838e-05 - val_loss: 5.7721e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 4.4581e-05 - val_loss: 5.7422e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4319e-05 - val_loss: 5.7019e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4074e-05 - val_loss: 5.6740e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.3822e-05 - val_loss: 5.6451e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.3569e-05 - val_loss: 5.6158e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.3311e-05 - val_loss: 5.5748e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.3071e-05 - val_loss: 5.5575e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2815e-05 - val_loss: 5.5246e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.2569e-05 - val_loss: 5.4992e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.2312e-05 - val_loss: 5.4629e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.2072e-05 - val_loss: 5.4397e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.1826e-05 - val_loss: 5.4171e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 4.1583e-05 - val_loss: 5.3979e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 4.1329e-05 - val_loss: 5.3676e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.1077e-05 - val_loss: 5.3276e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0827e-05 - val_loss: 5.2843e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.0603e-05 - val_loss: 5.2689e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.0359e-05 - val_loss: 5.2480e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.0104e-05 - val_loss: 5.2108e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.9860e-05 - val_loss: 5.1777e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.9628e-05 - val_loss: 5.1616e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 3.9383e-05 - val_loss: 5.1325e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.9137e-05 - val_loss: 5.0957e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.8895e-05 - val_loss: 5.0627e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.8680e-05 - val_loss: 5.0596e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.8427e-05 - val_loss: 5.0291e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.8188e-05 - val_loss: 5.0014e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.7953e-05 - val_loss: 4.9762e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.7712e-05 - val_loss: 4.9440e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.7471e-05 - val_loss: 4.9030e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.7244e-05 - val_loss: 4.8784e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7010e-05 - val_loss: 4.8517e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.6776e-05 - val_loss: 4.8238e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.6541e-05 - val_loss: 4.7971e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.6314e-05 - val_loss: 4.7733e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.6085e-05 - val_loss: 4.7539e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.5852e-05 - val_loss: 4.7305e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.5625e-05 - val_loss: 4.7097e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.5396e-05 - val_loss: 4.6885e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.5170e-05 - val_loss: 4.6684e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.4945e-05 - val_loss: 4.6483e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.4703e-05 - val_loss: 4.6088e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4479e-05 - val_loss: 4.5783e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.4252e-05 - val_loss: 4.5415e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.4033e-05 - val_loss: 4.5149e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.3816e-05 - val_loss: 4.4992e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.3586e-05 - val_loss: 4.4737e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.3359e-05 - val_loss: 4.4427e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.3139e-05 - val_loss: 4.4160e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2920e-05 - val_loss: 4.3916e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.2697e-05 - val_loss: 4.3586e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.2483e-05 - val_loss: 4.3403e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.2266e-05 - val_loss: 4.3210e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.2041e-05 - val_loss: 4.2901e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 3.1842e-05 - val_loss: 4.2848e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.1604e-05 - val_loss: 4.2462e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 3.1396e-05 - val_loss: 4.2197e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 809us/step - loss: 3.1184e-05 - val_loss: 4.2009e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 863us/step - loss: 3.0972e-05 - val_loss: 4.1803e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 830us/step - loss: 3.0749e-05 - val_loss: 4.1493e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.0547e-05 - val_loss: 4.1308e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.0326e-05 - val_loss: 4.0975e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 883us/step - loss: 3.0123e-05 - val_loss: 4.0775e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.9911e-05 - val_loss: 4.0566e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.9696e-05 - val_loss: 4.0275e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.9489e-05 - val_loss: 4.0000e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.9283e-05 - val_loss: 3.9742e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.9086e-05 - val_loss: 3.9630e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.8876e-05 - val_loss: 3.9401e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.8669e-05 - val_loss: 3.9209e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.8463e-05 - val_loss: 3.8973e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.8267e-05 - val_loss: 3.8812e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8047e-05 - val_loss: 3.8408e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.7859e-05 - val_loss: 3.8232e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.7658e-05 - val_loss: 3.8024e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.7447e-05 - val_loss: 3.7644e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.7247e-05 - val_loss: 3.7302e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.7052e-05 - val_loss: 3.7052e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.6865e-05 - val_loss: 3.6925e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.6669e-05 - val_loss: 3.6773e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.6480e-05 - val_loss: 3.6690e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.6274e-05 - val_loss: 3.6474e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.6074e-05 - val_loss: 3.6185e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.5891e-05 - val_loss: 3.6003e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 2.5687e-05 - val_loss: 3.5657e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.5506e-05 - val_loss: 3.5508e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.5315e-05 - val_loss: 3.5311e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.5124e-05 - val_loss: 3.5076e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.4933e-05 - val_loss: 3.4839e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.4744e-05 - val_loss: 3.4587e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.4573e-05 - val_loss: 3.4485e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.4368e-05 - val_loss: 3.4153e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4186e-05 - val_loss: 3.3888e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.4015e-05 - val_loss: 3.3777e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3833e-05 - val_loss: 3.3629e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.3635e-05 - val_loss: 3.3290e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.3459e-05 - val_loss: 3.3058e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.3282e-05 - val_loss: 3.2856e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.3100e-05 - val_loss: 3.2574e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2926e-05 - val_loss: 3.2405e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.2748e-05 - val_loss: 3.2232e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2575e-05 - val_loss: 3.2071e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.2404e-05 - val_loss: 3.1947e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.2220e-05 - val_loss: 3.1699e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.2053e-05 - val_loss: 3.1556e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1876e-05 - val_loss: 3.1298e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.1705e-05 - val_loss: 3.1061e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.1532e-05 - val_loss: 3.0775e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1373e-05 - val_loss: 3.0650e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.1203e-05 - val_loss: 3.0457e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1033e-05 - val_loss: 3.0241e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.0864e-05 - val_loss: 3.0028e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.0703e-05 - val_loss: 2.9860e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.0543e-05 - val_loss: 2.9697e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.0384e-05 - val_loss: 2.9569e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.0212e-05 - val_loss: 2.9327e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0054e-05 - val_loss: 2.9136e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.9902e-05 - val_loss: 2.8989e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.9740e-05 - val_loss: 2.8794e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.9577e-05 - val_loss: 2.8556e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.9426e-05 - val_loss: 2.8407e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.9267e-05 - val_loss: 2.8172e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9115e-05 - val_loss: 2.7986e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.8969e-05 - val_loss: 2.7892e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.8814e-05 - val_loss: 2.7734e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8660e-05 - val_loss: 2.7524e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.8517e-05 - val_loss: 2.7416e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.8356e-05 - val_loss: 2.7142e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8216e-05 - val_loss: 2.6972e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8071e-05 - val_loss: 2.6793e-06\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7935e-05 - val_loss: 2.6724e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.7780e-05 - val_loss: 2.6557e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.7630e-05 - val_loss: 2.6338e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7494e-05 - val_loss: 2.6217e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.7360e-05 - val_loss: 2.6136e-06\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7212e-05 - val_loss: 2.5968e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7085e-05 - val_loss: 2.5943e-06\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.6932e-05 - val_loss: 2.5725e-06\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6793e-05 - val_loss: 2.5525e-06\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6667e-05 - val_loss: 2.5405e-06\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.6523e-05 - val_loss: 2.5182e-06\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.6398e-05 - val_loss: 2.5072e-06\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6267e-05 - val_loss: 2.4965e-06\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6130e-05 - val_loss: 2.4782e-06\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6003e-05 - val_loss: 2.4661e-06\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.5876e-05 - val_loss: 2.4543e-06\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.5747e-05 - val_loss: 2.4394e-06\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.5627e-05 - val_loss: 2.4304e-06\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.5494e-05 - val_loss: 2.4105e-06\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.5366e-05 - val_loss: 2.3901e-06\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5254e-05 - val_loss: 2.3819e-06\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5130e-05 - val_loss: 2.3667e-06\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.5005e-05 - val_loss: 2.3515e-06\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4893e-05 - val_loss: 2.3435e-06\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4769e-05 - val_loss: 2.3264e-06\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.4660e-05 - val_loss: 2.3183e-06\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4540e-05 - val_loss: 2.3052e-06\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 1.4421e-05 - val_loss: 2.2876e-06\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.4313e-05 - val_loss: 2.2762e-06\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4203e-05 - val_loss: 2.2649e-06\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4089e-05 - val_loss: 2.2518e-06\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.3981e-05 - val_loss: 2.2397e-06\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3871e-05 - val_loss: 2.2258e-06\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3765e-05 - val_loss: 2.2135e-06\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3657e-05 - val_loss: 2.1991e-06\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3553e-05 - val_loss: 2.1880e-06\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3452e-05 - val_loss: 2.1776e-06\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3349e-05 - val_loss: 2.1655e-06\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.3244e-05 - val_loss: 2.1522e-06\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3149e-05 - val_loss: 2.1438e-06\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3046e-05 - val_loss: 2.1307e-06\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.2952e-05 - val_loss: 2.1225e-06\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2852e-05 - val_loss: 2.1089e-06\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.2761e-05 - val_loss: 2.1011e-06\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2661e-05 - val_loss: 2.0861e-06\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2569e-05 - val_loss: 2.0757e-06\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.2474e-05 - val_loss: 2.0636e-06\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2389e-05 - val_loss: 2.0551e-06\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2296e-05 - val_loss: 2.0439e-06\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2207e-05 - val_loss: 2.0327e-06\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2119e-05 - val_loss: 2.0231e-06\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 1.2036e-05 - val_loss: 2.0159e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.1949e-05 - val_loss: 2.0069e-06\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1860e-05 - val_loss: 1.9952e-06\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.1779e-05 - val_loss: 1.9843e-06\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.1696e-05 - val_loss: 1.9741e-06\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1615e-05 - val_loss: 1.9658e-06\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1535e-05 - val_loss: 1.9557e-06\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1457e-05 - val_loss: 1.9476e-06\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1378e-05 - val_loss: 1.9388e-06\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1298e-05 - val_loss: 1.9281e-06\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1227e-05 - val_loss: 1.9225e-06\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.1150e-05 - val_loss: 1.9133e-06\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1075e-05 - val_loss: 1.9044e-06\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.1001e-05 - val_loss: 1.8953e-06\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.0929e-05 - val_loss: 1.8873e-06\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0856e-05 - val_loss: 1.8774e-06\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0788e-05 - val_loss: 1.8694e-06\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0719e-05 - val_loss: 1.8632e-06\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0648e-05 - val_loss: 1.8548e-06\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.0582e-05 - val_loss: 1.8467e-06\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0513e-05 - val_loss: 1.8381e-06\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0445e-05 - val_loss: 1.8272e-06\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0381e-05 - val_loss: 1.8186e-06\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0319e-05 - val_loss: 1.8134e-06\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.0255e-05 - val_loss: 1.8057e-06\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0195e-05 - val_loss: 1.7996e-06\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0132e-05 - val_loss: 1.7931e-06\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0068e-05 - val_loss: 1.7845e-06\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.0009e-05 - val_loss: 1.7774e-06\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.9521e-06 - val_loss: 1.7708e-06\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.8961e-06 - val_loss: 1.7640e-06\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.8363e-06 - val_loss: 1.7569e-06\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.7761e-06 - val_loss: 1.7485e-06\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.7226e-06 - val_loss: 1.7426e-06\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.6676e-06 - val_loss: 1.7362e-06\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.6112e-06 - val_loss: 1.7286e-06\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.5569e-06 - val_loss: 1.7224e-06\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.5046e-06 - val_loss: 1.7158e-06\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.4523e-06 - val_loss: 1.7088e-06\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.4028e-06 - val_loss: 1.7036e-06\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.3508e-06 - val_loss: 1.6987e-06\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.2985e-06 - val_loss: 1.6925e-06\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.2512e-06 - val_loss: 1.6875e-06\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.2001e-06 - val_loss: 1.6801e-06\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.1540e-06 - val_loss: 1.6749e-06\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 9.1041e-06 - val_loss: 1.6677e-06\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.0599e-06 - val_loss: 1.6629e-06\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.0104e-06 - val_loss: 1.6563e-06\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.9637e-06 - val_loss: 1.6505e-06\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.9188e-06 - val_loss: 1.6453e-06\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 8.8740e-06 - val_loss: 1.6388e-06\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.8293e-06 - val_loss: 1.6320e-06\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.7867e-06 - val_loss: 1.6274e-06\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.7413e-06 - val_loss: 1.6211e-06\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.7004e-06 - val_loss: 1.6170e-06\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 8.6586e-06 - val_loss: 1.6115e-06\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.6170e-06 - val_loss: 1.6061e-06\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 8.5741e-06 - val_loss: 1.6005e-06\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.5355e-06 - val_loss: 1.5963e-06\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.4935e-06 - val_loss: 1.5904e-06\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 8.4541e-06 - val_loss: 1.5853e-06\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.4148e-06 - val_loss: 1.5813e-06\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.3792e-06 - val_loss: 1.5768e-06\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.3378e-06 - val_loss: 1.5710e-06\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.2997e-06 - val_loss: 1.5667e-06\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.2632e-06 - val_loss: 1.5611e-06\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 8.2256e-06 - val_loss: 1.5554e-06\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.1902e-06 - val_loss: 1.5519e-06\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.1531e-06 - val_loss: 1.5465e-06\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.1167e-06 - val_loss: 1.5415e-06\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.0838e-06 - val_loss: 1.5379e-06\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.0459e-06 - val_loss: 1.5321e-06\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 8.0124e-06 - val_loss: 1.5279e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.9788e-06 - val_loss: 1.5241e-06\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.9445e-06 - val_loss: 1.5194e-06\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.9105e-06 - val_loss: 1.5146e-06\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.8788e-06 - val_loss: 1.5113e-06\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 7.8442e-06 - val_loss: 1.5049e-06\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.8115e-06 - val_loss: 1.5010e-06\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.7809e-06 - val_loss: 1.4974e-06\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.7465e-06 - val_loss: 1.4918e-06\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.7152e-06 - val_loss: 1.4885e-06\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 7.6859e-06 - val_loss: 1.4849e-06\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.6527e-06 - val_loss: 1.4804e-06\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 7.6232e-06 - val_loss: 1.4764e-06\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.5915e-06 - val_loss: 1.4718e-06\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.5624e-06 - val_loss: 1.4673e-06\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.5329e-06 - val_loss: 1.4631e-06\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.5029e-06 - val_loss: 1.4590e-06\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.4737e-06 - val_loss: 1.4551e-06\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.4442e-06 - val_loss: 1.4509e-06\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.4141e-06 - val_loss: 1.4467e-06\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.3863e-06 - val_loss: 1.4428e-06\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.3581e-06 - val_loss: 1.4388e-06\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.3296e-06 - val_loss: 1.4346e-06\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3032e-06 - val_loss: 1.4313e-06\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.2736e-06 - val_loss: 1.4265e-06\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.2467e-06 - val_loss: 1.4238e-06\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.2202e-06 - val_loss: 1.4203e-06\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.1933e-06 - val_loss: 1.4165e-06\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.1646e-06 - val_loss: 1.4126e-06\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 7.1386e-06 - val_loss: 1.4090e-06\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.1126e-06 - val_loss: 1.4047e-06\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.0865e-06 - val_loss: 1.4010e-06\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.0603e-06 - val_loss: 1.3976e-06\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.0335e-06 - val_loss: 1.3937e-06\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.0088e-06 - val_loss: 1.3902e-06\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.9835e-06 - val_loss: 1.3869e-06\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.9588e-06 - val_loss: 1.3829e-06\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.9328e-06 - val_loss: 1.3791e-06\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.9075e-06 - val_loss: 1.3754e-06\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.8824e-06 - val_loss: 1.3716e-06\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.8588e-06 - val_loss: 1.3681e-06\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.8335e-06 - val_loss: 1.3642e-06\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.8092e-06 - val_loss: 1.3612e-06\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.7848e-06 - val_loss: 1.3579e-06\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.7613e-06 - val_loss: 1.3540e-06\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.7386e-06 - val_loss: 1.3505e-06\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.7139e-06 - val_loss: 1.3467e-06\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.6918e-06 - val_loss: 1.3437e-06\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.6679e-06 - val_loss: 1.3402e-06\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.6448e-06 - val_loss: 1.3373e-06\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.6198e-06 - val_loss: 1.3341e-06\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.5973e-06 - val_loss: 1.3301e-06\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.5738e-06 - val_loss: 1.3261e-06\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.5523e-06 - val_loss: 1.3232e-06\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.5293e-06 - val_loss: 1.3194e-06\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.5075e-06 - val_loss: 1.3162e-06\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.4845e-06 - val_loss: 1.3127e-06\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.4612e-06 - val_loss: 1.3100e-06\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.4398e-06 - val_loss: 1.3074e-06\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.4187e-06 - val_loss: 1.3041e-06\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.3963e-06 - val_loss: 1.3009e-06\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.3747e-06 - val_loss: 1.2972e-06\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.3526e-06 - val_loss: 1.2933e-06\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 6.3311e-06 - val_loss: 1.2898e-06\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.3098e-06 - val_loss: 1.2866e-06\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.2887e-06 - val_loss: 1.2833e-06\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.2673e-06 - val_loss: 1.2812e-06\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.2463e-06 - val_loss: 1.2777e-06\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.2256e-06 - val_loss: 1.2736e-06\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.2041e-06 - val_loss: 1.2704e-06\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 6.1828e-06 - val_loss: 1.2679e-06\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.1636e-06 - val_loss: 1.2657e-06\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.1417e-06 - val_loss: 1.2627e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.1222e-06 - val_loss: 1.2592e-06\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.1020e-06 - val_loss: 1.2548e-06\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.0812e-06 - val_loss: 1.2513e-06\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.0603e-06 - val_loss: 1.2490e-06\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.0397e-06 - val_loss: 1.2474e-06\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.0209e-06 - val_loss: 1.2438e-06\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.0008e-06 - val_loss: 1.2397e-06\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9817e-06 - val_loss: 1.2365e-06\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.9628e-06 - val_loss: 1.2335e-06\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.9415e-06 - val_loss: 1.2297e-06\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.9215e-06 - val_loss: 1.2284e-06\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.9029e-06 - val_loss: 1.2247e-06\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.8823e-06 - val_loss: 1.2205e-06\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.8630e-06 - val_loss: 1.2182e-06\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.8446e-06 - val_loss: 1.2144e-06\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.8245e-06 - val_loss: 1.2113e-06\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.8071e-06 - val_loss: 1.2093e-06\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1105 - val_loss: 0.1091\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1082 - val_loss: 0.1068\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.1060 - val_loss: 0.1048\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.1041 - val_loss: 0.1031\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.1024 - val_loss: 0.1015\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.1009 - val_loss: 0.1000\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0995 - val_loss: 0.0987\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0983 - val_loss: 0.0976\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0971 - val_loss: 0.0965\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0961 - val_loss: 0.0955\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0951 - val_loss: 0.0946\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0943 - val_loss: 0.0938\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0934 - val_loss: 0.0930\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0927 - val_loss: 0.0923\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0920 - val_loss: 0.0916\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0913 - val_loss: 0.0910\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0907 - val_loss: 0.0904\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0901 - val_loss: 0.0898\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0896 - val_loss: 0.0893\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0890 - val_loss: 0.0887\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0885 - val_loss: 0.0882\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0879 - val_loss: 0.0876\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0873 - val_loss: 0.0870\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0867 - val_loss: 0.0864\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0861 - val_loss: 0.0858\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0848 - val_loss: 0.0844\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0818 - val_loss: 0.0814\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0810 - val_loss: 0.0805\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0801 - val_loss: 0.0796\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0792 - val_loss: 0.0787\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0783 - val_loss: 0.0777\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0773 - val_loss: 0.0767\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0763 - val_loss: 0.0757\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0752 - val_loss: 0.0746\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0741 - val_loss: 0.0734\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0729 - val_loss: 0.0722\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0717 - val_loss: 0.0710\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0705 - val_loss: 0.0697\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0692 - val_loss: 0.0684\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0678 - val_loss: 0.0671\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0665 - val_loss: 0.0657\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0650 - val_loss: 0.0642\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0636 - val_loss: 0.0627\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0620 - val_loss: 0.0611\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0604 - val_loss: 0.0595\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0588 - val_loss: 0.0579\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0571 - val_loss: 0.0562\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0554 - val_loss: 0.0544\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0536 - val_loss: 0.0526\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0518 - val_loss: 0.0508\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0500 - val_loss: 0.0489\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0480 - val_loss: 0.0469\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0461 - val_loss: 0.0450\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0441 - val_loss: 0.0430\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0421 - val_loss: 0.0409\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0401 - val_loss: 0.0389\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0380 - val_loss: 0.0369\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0360 - val_loss: 0.0349\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0340 - val_loss: 0.0329\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0320 - val_loss: 0.0309\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0301 - val_loss: 0.0291\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0282 - val_loss: 0.0273\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0248 - val_loss: 0.0239\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0232 - val_loss: 0.0224\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0217 - val_loss: 0.0210\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0203 - val_loss: 0.0196\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0189 - val_loss: 0.0183\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0176 - val_loss: 0.0170\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0164 - val_loss: 0.0159\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0142 - val_loss: 0.0137\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0132 - val_loss: 0.0127\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 831us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 821us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.001 - 1s 768us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.6782e-04 - val_loss: 9.8230e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.3659e-04 - val_loss: 9.5136e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.0778e-04 - val_loss: 9.2286e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.8133e-04 - val_loss: 8.9660e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.5705e-04 - val_loss: 8.7230e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.3462e-04 - val_loss: 8.4987e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.1392e-04 - val_loss: 8.2925e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.9486e-04 - val_loss: 8.1020e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.7724e-04 - val_loss: 7.9258e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.6106e-04 - val_loss: 7.7626e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.4598e-04 - val_loss: 7.6118e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.3211e-04 - val_loss: 7.4713e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.1907e-04 - val_loss: 7.3400e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.0692e-04 - val_loss: 7.2163e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 6.9546e-04 - val_loss: 7.0993e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.8461e-04 - val_loss: 6.9886e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.7439e-04 - val_loss: 6.8843e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.6473e-04 - val_loss: 6.7858e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.5563e-04 - val_loss: 6.6922e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.4694e-04 - val_loss: 6.6026e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.3861e-04 - val_loss: 6.5159e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.3058e-04 - val_loss: 6.4309e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.2272e-04 - val_loss: 6.3488e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.1512e-04 - val_loss: 6.2687e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.0768e-04 - val_loss: 6.1904e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.0041e-04 - val_loss: 6.1138e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.9331e-04 - val_loss: 6.0385e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.8632e-04 - val_loss: 5.9639e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.7938e-04 - val_loss: 5.8906e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.7257e-04 - val_loss: 5.8183e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 5.6591e-04 - val_loss: 5.7468e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.5926e-04 - val_loss: 5.6760e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.5264e-04 - val_loss: 5.6058e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.4617e-04 - val_loss: 5.5367e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.3977e-04 - val_loss: 5.4683e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.3345e-04 - val_loss: 5.4006e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.2719e-04 - val_loss: 5.3339e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.2108e-04 - val_loss: 5.2675e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.1495e-04 - val_loss: 5.2031e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0895e-04 - val_loss: 5.1377e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.0298e-04 - val_loss: 5.0737e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.9709e-04 - val_loss: 5.0099e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.9126e-04 - val_loss: 4.9472e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.8550e-04 - val_loss: 4.8847e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7979e-04 - val_loss: 4.8224e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7408e-04 - val_loss: 4.7615e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.6847e-04 - val_loss: 4.7011e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6295e-04 - val_loss: 4.6412e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.5747e-04 - val_loss: 4.5819e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.5204e-04 - val_loss: 4.5235e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.4665e-04 - val_loss: 4.4649e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.4136e-04 - val_loss: 4.4077e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.3614e-04 - val_loss: 4.3505e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.3088e-04 - val_loss: 4.2938e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.2572e-04 - val_loss: 4.2375e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.2063e-04 - val_loss: 4.1815e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.1554e-04 - val_loss: 4.1265e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.1052e-04 - val_loss: 4.0722e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0555e-04 - val_loss: 4.0184e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.0062e-04 - val_loss: 3.9649e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.9580e-04 - val_loss: 3.9119e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.9097e-04 - val_loss: 3.8594e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.8619e-04 - val_loss: 3.8076e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.8147e-04 - val_loss: 3.7562e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.7680e-04 - val_loss: 3.7051e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.7216e-04 - val_loss: 3.6549e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.6759e-04 - val_loss: 3.6049e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.6303e-04 - val_loss: 3.5556e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.5856e-04 - val_loss: 3.5066e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.5411e-04 - val_loss: 3.4580e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.4971e-04 - val_loss: 3.4100e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.4533e-04 - val_loss: 3.3629e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.4106e-04 - val_loss: 3.3154e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.3675e-04 - val_loss: 3.2689e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.3252e-04 - val_loss: 3.2228e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.2835e-04 - val_loss: 3.1773e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.2417e-04 - val_loss: 3.1321e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.2009e-04 - val_loss: 3.0873e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.1603e-04 - val_loss: 3.0430e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.1199e-04 - val_loss: 2.9994e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.0803e-04 - val_loss: 2.9560e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.0409e-04 - val_loss: 2.9132e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.0017e-04 - val_loss: 2.8708e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.9633e-04 - val_loss: 2.8288e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.9252e-04 - val_loss: 2.7872e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.8871e-04 - val_loss: 2.7463e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.8502e-04 - val_loss: 2.7060e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.8135e-04 - val_loss: 2.6652e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.7768e-04 - val_loss: 2.6257e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.7404e-04 - val_loss: 2.5863e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.7047e-04 - val_loss: 2.5472e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.6693e-04 - val_loss: 2.5088e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.6343e-04 - val_loss: 2.4707e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.5998e-04 - val_loss: 2.4335e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.5658e-04 - val_loss: 2.3960e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5320e-04 - val_loss: 2.3592e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4987e-04 - val_loss: 2.3227e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4654e-04 - val_loss: 2.2869e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.4327e-04 - val_loss: 2.2516e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4007e-04 - val_loss: 2.2164e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.3687e-04 - val_loss: 2.1817e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.3372e-04 - val_loss: 2.1473e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3061e-04 - val_loss: 2.1137e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2752e-04 - val_loss: 2.0797e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.2446e-04 - val_loss: 2.0466e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2144e-04 - val_loss: 2.0137e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.1845e-04 - val_loss: 1.9814e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.1549e-04 - val_loss: 1.9492e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.1258e-04 - val_loss: 1.9174e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0968e-04 - val_loss: 1.8861e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.0682e-04 - val_loss: 1.8551e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0402e-04 - val_loss: 1.8242e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.0122e-04 - val_loss: 1.7938e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.9846e-04 - val_loss: 1.7637e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9573e-04 - val_loss: 1.7338e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.9301e-04 - val_loss: 1.7045e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9034e-04 - val_loss: 1.6754e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8770e-04 - val_loss: 1.6467e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.8511e-04 - val_loss: 1.6183e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.8252e-04 - val_loss: 1.5904e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.7998e-04 - val_loss: 1.5635e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.7751e-04 - val_loss: 1.5360e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7503e-04 - val_loss: 1.5096e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.7262e-04 - val_loss: 1.4834e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.7021e-04 - val_loss: 1.4577e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.6785e-04 - val_loss: 1.4324e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.6554e-04 - val_loss: 1.4074e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6328e-04 - val_loss: 1.3830e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.6103e-04 - val_loss: 1.3587e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5883e-04 - val_loss: 1.3351e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5667e-04 - val_loss: 1.3120e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.5456e-04 - val_loss: 1.2895e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.5249e-04 - val_loss: 1.2671e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.5043e-04 - val_loss: 1.2454e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4844e-04 - val_loss: 1.2238e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.4646e-04 - val_loss: 1.2027e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4451e-04 - val_loss: 1.1820e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.4260e-04 - val_loss: 1.1615e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.4070e-04 - val_loss: 1.1415e-04\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3886e-04 - val_loss: 1.1216e-04\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3704e-04 - val_loss: 1.1020e-04\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.3523e-04 - val_loss: 1.0826e-04\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.3346e-04 - val_loss: 1.0637e-04\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3172e-04 - val_loss: 1.0449e-04\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.2999e-04 - val_loss: 1.0265e-04\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2829e-04 - val_loss: 1.0083e-04\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2662e-04 - val_loss: 9.9029e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2498e-04 - val_loss: 9.7250e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2335e-04 - val_loss: 9.5494e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2175e-04 - val_loss: 9.3767e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2017e-04 - val_loss: 9.2079e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1861e-04 - val_loss: 9.0427e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 1.1902e-0 - 1s 767us/step - loss: 1.1708e-04 - val_loss: 8.8798e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1559e-04 - val_loss: 8.7202e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1412e-04 - val_loss: 8.5624e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1268e-04 - val_loss: 8.4072e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1125e-04 - val_loss: 8.2557e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0986e-04 - val_loss: 8.1076e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0849e-04 - val_loss: 7.9611e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0716e-04 - val_loss: 7.8162e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0582e-04 - val_loss: 7.6761e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0454e-04 - val_loss: 7.5382e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0327e-04 - val_loss: 7.4007e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.0201e-04 - val_loss: 7.2671e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0078e-04 - val_loss: 7.1358e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.9558e-05 - val_loss: 7.0072e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.8360e-05 - val_loss: 6.8811e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.7186e-05 - val_loss: 6.7566e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.6027e-05 - val_loss: 6.6345e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.4884e-05 - val_loss: 6.5142e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.3754e-05 - val_loss: 6.3956e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.2644e-05 - val_loss: 6.2790e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.1553e-05 - val_loss: 6.1659e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 9.0476e-05 - val_loss: 6.0530e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.9408e-05 - val_loss: 5.9413e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.8362e-05 - val_loss: 5.8323e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.7329e-05 - val_loss: 5.7264e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.6319e-05 - val_loss: 5.6218e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.5331e-05 - val_loss: 5.5197e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.4364e-05 - val_loss: 5.4208e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.3420e-05 - val_loss: 5.3219e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.2497e-05 - val_loss: 5.2256e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.1587e-05 - val_loss: 5.1313e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0691e-05 - val_loss: 5.0393e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.9817e-05 - val_loss: 4.9487e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.8964e-05 - val_loss: 4.8602e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.8123e-05 - val_loss: 4.7740e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.7303e-05 - val_loss: 4.6883e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.6489e-05 - val_loss: 4.6039e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.5690e-05 - val_loss: 4.5208e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.4898e-05 - val_loss: 4.4397e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.4117e-05 - val_loss: 4.3596e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.3336e-05 - val_loss: 4.2782e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.2554e-05 - val_loss: 4.1985e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.1791e-05 - val_loss: 4.1214e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1027e-05 - val_loss: 4.0445e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.0275e-05 - val_loss: 3.9671e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.9537e-05 - val_loss: 3.8923e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.8812e-05 - val_loss: 3.8196e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.8110e-05 - val_loss: 3.7498e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.7424e-05 - val_loss: 3.6786e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.6751e-05 - val_loss: 3.6103e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.6103e-05 - val_loss: 3.5444e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.5464e-05 - val_loss: 3.4798e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.4840e-05 - val_loss: 3.4152e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.4231e-05 - val_loss: 3.3529e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.3642e-05 - val_loss: 3.2919e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.3062e-05 - val_loss: 3.2338e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.2496e-05 - val_loss: 3.1763e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.1941e-05 - val_loss: 3.1192e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 6.1397e-05 - val_loss: 3.0645e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.0868e-05 - val_loss: 3.0116e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.0347e-05 - val_loss: 2.9599e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.9840e-05 - val_loss: 2.9078e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.9344e-05 - val_loss: 2.8576e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.8854e-05 - val_loss: 2.8087e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.8375e-05 - val_loss: 2.7612e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.7906e-05 - val_loss: 2.7144e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 5.7443e-05 - val_loss: 2.6687e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.6991e-05 - val_loss: 2.6242e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.6544e-05 - val_loss: 2.5811e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.6104e-05 - val_loss: 2.5386e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.5674e-05 - val_loss: 2.4966e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.5250e-05 - val_loss: 2.4557e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.4835e-05 - val_loss: 2.4162e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.4424e-05 - val_loss: 2.3770e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.4021e-05 - val_loss: 2.3390e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3622e-05 - val_loss: 2.3022e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 5.3230e-05 - val_loss: 2.2658e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.2845e-05 - val_loss: 2.2297e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.2468e-05 - val_loss: 2.1950e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.2094e-05 - val_loss: 2.1612e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.1723e-05 - val_loss: 2.1283e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.1362e-05 - val_loss: 2.0953e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.1003e-05 - val_loss: 2.0629e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0650e-05 - val_loss: 2.0315e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.0303e-05 - val_loss: 2.0005e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.9958e-05 - val_loss: 1.9702e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.9618e-05 - val_loss: 1.9405e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.9286e-05 - val_loss: 1.9113e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.8953e-05 - val_loss: 1.8829e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.8635e-05 - val_loss: 1.8542e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.8312e-05 - val_loss: 1.8271e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7993e-05 - val_loss: 1.8009e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.7683e-05 - val_loss: 1.7741e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.7375e-05 - val_loss: 1.7480e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 4.7069e-05 - val_loss: 1.7225e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6771e-05 - val_loss: 1.6979e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.6478e-05 - val_loss: 1.6734e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.6189e-05 - val_loss: 1.6494e-05\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.5902e-05 - val_loss: 1.6262e-05\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.5620e-05 - val_loss: 1.6038e-05\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.5341e-05 - val_loss: 1.5813e-05\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.5063e-05 - val_loss: 1.5591e-05\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.4791e-05 - val_loss: 1.5378e-05\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.4525e-05 - val_loss: 1.5164e-05\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.4261e-05 - val_loss: 1.4949e-05\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4001e-05 - val_loss: 1.4750e-05\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.3741e-05 - val_loss: 1.4557e-05\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.3491e-05 - val_loss: 1.4358e-05\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.3240e-05 - val_loss: 1.4157e-05\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.2991e-05 - val_loss: 1.3972e-05\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.2745e-05 - val_loss: 1.3801e-05\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.2503e-05 - val_loss: 1.3612e-05\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.2267e-05 - val_loss: 1.3437e-05\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.2029e-05 - val_loss: 1.3265e-05\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.1790e-05 - val_loss: 1.3095e-05\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.1564e-05 - val_loss: 1.2918e-05\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.1334e-05 - val_loss: 1.2756e-05\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.1111e-05 - val_loss: 1.2597e-05\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.0886e-05 - val_loss: 1.2439e-05\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.0668e-05 - val_loss: 1.2283e-05\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.0447e-05 - val_loss: 1.2128e-05\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.0233e-05 - val_loss: 1.1977e-05\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.0018e-05 - val_loss: 1.1829e-05\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.9813e-05 - val_loss: 1.1683e-05\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.9604e-05 - val_loss: 1.1553e-05\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 3.9396e-05 - val_loss: 1.1407e-05\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.9195e-05 - val_loss: 1.1264e-05\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.8993e-05 - val_loss: 1.1134e-05\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.8789e-05 - val_loss: 1.1007e-05\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.8597e-05 - val_loss: 1.0868e-05\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.8401e-05 - val_loss: 1.0742e-05\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.8205e-05 - val_loss: 1.0622e-05\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.8016e-05 - val_loss: 1.0501e-05\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.7827e-05 - val_loss: 1.0378e-05\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7646e-05 - val_loss: 1.0267e-05\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.7452e-05 - val_loss: 1.0166e-05\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.7268e-05 - val_loss: 1.0028e-05\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.7089e-05 - val_loss: 9.9190e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.6904e-05 - val_loss: 9.8105e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.6729e-05 - val_loss: 9.6979e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.6547e-05 - val_loss: 9.5866e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.6377e-05 - val_loss: 9.4879e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.6197e-05 - val_loss: 9.3909e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.6029e-05 - val_loss: 9.2856e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.5855e-05 - val_loss: 9.1851e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.5684e-05 - val_loss: 9.0863e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.5521e-05 - val_loss: 8.9944e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 3.5349e-05 - val_loss: 8.9009e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.5180e-05 - val_loss: 8.8053e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.5019e-05 - val_loss: 8.7107e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4856e-05 - val_loss: 8.6200e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.4696e-05 - val_loss: 8.5321e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.4535e-05 - val_loss: 8.4432e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.4375e-05 - val_loss: 8.3627e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.4219e-05 - val_loss: 8.2719e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.4058e-05 - val_loss: 8.1838e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.3907e-05 - val_loss: 8.1088e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.3750e-05 - val_loss: 8.0195e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.3599e-05 - val_loss: 7.9337e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.3449e-05 - val_loss: 7.8589e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.3296e-05 - val_loss: 7.7868e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.3147e-05 - val_loss: 7.7098e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.2997e-05 - val_loss: 7.6344e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.2852e-05 - val_loss: 7.5620e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.2708e-05 - val_loss: 7.4884e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.2562e-05 - val_loss: 7.4199e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.2416e-05 - val_loss: 7.3537e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.2272e-05 - val_loss: 7.2795e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.2129e-05 - val_loss: 7.2112e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.1989e-05 - val_loss: 7.1459e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.1852e-05 - val_loss: 7.0789e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.1708e-05 - val_loss: 7.0160e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.1573e-05 - val_loss: 6.9549e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.1438e-05 - val_loss: 6.8884e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.1298e-05 - val_loss: 6.8303e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.1165e-05 - val_loss: 6.7678e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.1026e-05 - val_loss: 6.7077e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.0895e-05 - val_loss: 6.6475e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 3.0770e-05 - val_loss: 6.5905e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.0636e-05 - val_loss: 6.5304e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.0500e-05 - val_loss: 6.4783e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.0370e-05 - val_loss: 6.4239e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.0241e-05 - val_loss: 6.3638e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.0111e-05 - val_loss: 6.3091e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.9982e-05 - val_loss: 6.2604e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.9855e-05 - val_loss: 6.2048e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.9727e-05 - val_loss: 6.1500e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.9606e-05 - val_loss: 6.0999e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.9480e-05 - val_loss: 6.0532e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9357e-05 - val_loss: 6.0056e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.9228e-05 - val_loss: 5.9568e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.9110e-05 - val_loss: 5.9033e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.8984e-05 - val_loss: 5.8564e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.8864e-05 - val_loss: 5.8089e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.8742e-05 - val_loss: 5.7601e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.8625e-05 - val_loss: 5.7205e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.8503e-05 - val_loss: 5.6726e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.8383e-05 - val_loss: 5.6234e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.8271e-05 - val_loss: 5.5820e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.8150e-05 - val_loss: 5.5424e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.8032e-05 - val_loss: 5.4992e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.7921e-05 - val_loss: 5.4518e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.7803e-05 - val_loss: 5.4088e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.7689e-05 - val_loss: 5.3688e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.7572e-05 - val_loss: 5.3382e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.7457e-05 - val_loss: 5.2909e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.7345e-05 - val_loss: 5.2499e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.7232e-05 - val_loss: 5.2145e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.7118e-05 - val_loss: 5.1763e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.7010e-05 - val_loss: 5.1307e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.6895e-05 - val_loss: 5.0950e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6788e-05 - val_loss: 5.0604e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.6675e-05 - val_loss: 5.0186e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.6570e-05 - val_loss: 4.9865e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.6455e-05 - val_loss: 4.9496e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.6350e-05 - val_loss: 4.9161e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.6243e-05 - val_loss: 4.8792e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.6138e-05 - val_loss: 4.8433e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6030e-05 - val_loss: 4.8109e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.5920e-05 - val_loss: 4.7792e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.5816e-05 - val_loss: 4.7468e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.5713e-05 - val_loss: 4.7124e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.5607e-05 - val_loss: 4.6794e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5499e-05 - val_loss: 4.6507e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.5398e-05 - val_loss: 4.6146e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.5294e-05 - val_loss: 4.5824e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5192e-05 - val_loss: 4.5522e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.5087e-05 - val_loss: 4.5229e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.4989e-05 - val_loss: 4.4920e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4885e-05 - val_loss: 4.4578e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.4787e-05 - val_loss: 4.4283e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.4683e-05 - val_loss: 4.4044e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.4582e-05 - val_loss: 4.3779e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4487e-05 - val_loss: 4.3401e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.4383e-05 - val_loss: 4.3090e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4287e-05 - val_loss: 4.2848e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.4187e-05 - val_loss: 4.2572e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.4089e-05 - val_loss: 4.2339e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.3990e-05 - val_loss: 4.2007e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.3891e-05 - val_loss: 4.1725e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.3799e-05 - val_loss: 4.1493e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.3697e-05 - val_loss: 4.1241e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.3605e-05 - val_loss: 4.0945e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3509e-05 - val_loss: 4.0671e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3413e-05 - val_loss: 4.0377e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.3322e-05 - val_loss: 4.0138e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.3222e-05 - val_loss: 3.9921e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.3131e-05 - val_loss: 3.9659e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.3037e-05 - val_loss: 3.9395e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.2941e-05 - val_loss: 3.9214e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2850e-05 - val_loss: 3.8974e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.2761e-05 - val_loss: 3.8701e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2667e-05 - val_loss: 3.8460e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.2572e-05 - val_loss: 3.8293e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.2481e-05 - val_loss: 3.8020e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2393e-05 - val_loss: 3.7780e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.2297e-05 - val_loss: 3.7616e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2209e-05 - val_loss: 3.7320e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2121e-05 - val_loss: 3.7032e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2031e-05 - val_loss: 3.6815e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.1941e-05 - val_loss: 3.6663e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.1851e-05 - val_loss: 3.6427e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.1764e-05 - val_loss: 3.6198e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1676e-05 - val_loss: 3.5977e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1585e-05 - val_loss: 3.5737e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1500e-05 - val_loss: 3.5581e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.1412e-05 - val_loss: 3.5380e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.1323e-05 - val_loss: 3.5160e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.1238e-05 - val_loss: 3.4910e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 2.1154e-05 - val_loss: 3.4735e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1067e-05 - val_loss: 3.4576e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 2.0981e-05 - val_loss: 3.4375e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0894e-05 - val_loss: 3.4154e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0805e-05 - val_loss: 3.3996e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.0725e-05 - val_loss: 3.3718e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.0644e-05 - val_loss: 3.3530e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0558e-05 - val_loss: 3.3370e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.0474e-05 - val_loss: 3.3268e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.0391e-05 - val_loss: 3.3020e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.0303e-05 - val_loss: 3.2824e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.0224e-05 - val_loss: 3.2618e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0143e-05 - val_loss: 3.2437e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.0058e-05 - val_loss: 3.2264e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.9976e-05 - val_loss: 3.2149e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9898e-05 - val_loss: 3.1886e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.9816e-05 - val_loss: 3.1704e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.9728e-05 - val_loss: 3.1559e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9650e-05 - val_loss: 3.1389e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9572e-05 - val_loss: 3.1137e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.9492e-05 - val_loss: 3.0962e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9410e-05 - val_loss: 3.0831e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9333e-05 - val_loss: 3.0727e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.9248e-05 - val_loss: 3.0528e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.9175e-05 - val_loss: 3.0329e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9096e-05 - val_loss: 3.0188e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.9018e-05 - val_loss: 3.0034e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 1.8557e-0 - 1s 736us/step - loss: 1.8933e-05 - val_loss: 2.9923e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8856e-05 - val_loss: 2.9706e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.8779e-05 - val_loss: 2.9486e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.8702e-05 - val_loss: 2.9325e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.8626e-05 - val_loss: 2.9214e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.8542e-05 - val_loss: 2.9036e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.8465e-05 - val_loss: 2.8801e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.8394e-05 - val_loss: 2.8656e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.8314e-05 - val_loss: 2.8522e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.8237e-05 - val_loss: 2.8352e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.8166e-05 - val_loss: 2.8159e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.8089e-05 - val_loss: 2.7939e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8013e-05 - val_loss: 2.8002e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7941e-05 - val_loss: 2.7661e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7861e-05 - val_loss: 2.7393e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7789e-05 - val_loss: 2.7294e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.7713e-05 - val_loss: 2.7234e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7639e-05 - val_loss: 2.7186e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.7574e-05 - val_loss: 2.6850e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7491e-05 - val_loss: 2.6662e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.7419e-05 - val_loss: 2.6588e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7345e-05 - val_loss: 2.6551e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7278e-05 - val_loss: 2.6258e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.7205e-05 - val_loss: 2.6164e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.7137e-05 - val_loss: 2.6028e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.7057e-05 - val_loss: 2.6158e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6991e-05 - val_loss: 2.5881e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6914e-05 - val_loss: 2.5565e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6842e-05 - val_loss: 2.5432e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6770e-05 - val_loss: 2.5358e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.6697e-05 - val_loss: 2.5239e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6630e-05 - val_loss: 2.5080e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6561e-05 - val_loss: 2.4933e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.6492e-05 - val_loss: 2.4826e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.6419e-05 - val_loss: 2.4707e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6350e-05 - val_loss: 2.4648e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6280e-05 - val_loss: 2.4490e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6212e-05 - val_loss: 2.4321e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6140e-05 - val_loss: 2.4207e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6073e-05 - val_loss: 2.4110e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6003e-05 - val_loss: 2.3927e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.5938e-05 - val_loss: 2.3811e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.5866e-05 - val_loss: 2.3724e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5804e-05 - val_loss: 2.3575e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.5732e-05 - val_loss: 2.3433e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5665e-05 - val_loss: 2.3411e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5600e-05 - val_loss: 2.3218e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.5532e-05 - val_loss: 2.3076e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5466e-05 - val_loss: 2.2980e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.5398e-05 - val_loss: 2.2904e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5333e-05 - val_loss: 2.2820e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5269e-05 - val_loss: 2.2639e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5201e-05 - val_loss: 2.2503e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.5135e-05 - val_loss: 2.2405e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.5071e-05 - val_loss: 2.2339e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5006e-05 - val_loss: 2.2230e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4942e-05 - val_loss: 2.2059e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4877e-05 - val_loss: 2.1960e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.4814e-05 - val_loss: 2.1876e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 1.4751e-05 - val_loss: 2.1799e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4681e-05 - val_loss: 2.1747e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.4621e-05 - val_loss: 2.1635e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4562e-05 - val_loss: 2.1438e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4495e-05 - val_loss: 2.1337e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4429e-05 - val_loss: 2.1293e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 753us/step - loss: 1.4368e-05 - val_loss: 2.1261e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4308e-05 - val_loss: 2.0997e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.4242e-05 - val_loss: 2.0891e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.4178e-05 - val_loss: 2.0836e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4117e-05 - val_loss: 2.0760e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4055e-05 - val_loss: 2.0654e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3995e-05 - val_loss: 2.0537e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.3933e-05 - val_loss: 2.0447e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3871e-05 - val_loss: 2.0352e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3807e-05 - val_loss: 2.0240e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3747e-05 - val_loss: 2.0134e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3689e-05 - val_loss: 2.0017e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3626e-05 - val_loss: 1.9984e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3570e-05 - val_loss: 1.9981e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.3510e-05 - val_loss: 1.9715e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.3447e-05 - val_loss: 1.9587e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3388e-05 - val_loss: 1.9534e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3326e-05 - val_loss: 1.9443e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3271e-05 - val_loss: 1.9369e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.3207e-05 - val_loss: 1.9303e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3152e-05 - val_loss: 1.9161e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.3093e-05 - val_loss: 1.9064e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3033e-05 - val_loss: 1.9008e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2977e-05 - val_loss: 1.8922e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.2917e-05 - val_loss: 1.8816e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2858e-05 - val_loss: 1.8794e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2800e-05 - val_loss: 1.8676e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.2744e-05 - val_loss: 1.8564e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2687e-05 - val_loss: 1.8476e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2630e-05 - val_loss: 1.8368e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.2572e-05 - val_loss: 1.8288e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2515e-05 - val_loss: 1.8247e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.2461e-05 - val_loss: 1.8175e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2403e-05 - val_loss: 1.8048e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2345e-05 - val_loss: 1.7940e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.2290e-05 - val_loss: 1.7891e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2233e-05 - val_loss: 1.7781e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2178e-05 - val_loss: 1.7682e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2122e-05 - val_loss: 1.7570e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2069e-05 - val_loss: 1.7496e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2012e-05 - val_loss: 1.7429e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1958e-05 - val_loss: 1.7349e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1902e-05 - val_loss: 1.7263e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1846e-05 - val_loss: 1.7221e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.1794e-05 - val_loss: 1.7167e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.1739e-05 - val_loss: 1.7046e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1687e-05 - val_loss: 1.6935e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1631e-05 - val_loss: 1.6849e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1579e-05 - val_loss: 1.6816e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1524e-05 - val_loss: 1.6726e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1471e-05 - val_loss: 1.6634e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1416e-05 - val_loss: 1.6579e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1366e-05 - val_loss: 1.6561e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.1315e-05 - val_loss: 1.6404e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1262e-05 - val_loss: 1.6312e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1204e-05 - val_loss: 1.6257e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.1156e-05 - val_loss: 1.6172e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.1102e-05 - val_loss: 1.6085e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1051e-05 - val_loss: 1.6044e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1001e-05 - val_loss: 1.5949e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0949e-05 - val_loss: 1.5861e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0899e-05 - val_loss: 1.5824e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0849e-05 - val_loss: 1.5745e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0793e-05 - val_loss: 1.5722e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0745e-05 - val_loss: 1.5628e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0692e-05 - val_loss: 1.5497e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0641e-05 - val_loss: 1.5426e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0595e-05 - val_loss: 1.5373e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.0542e-05 - val_loss: 1.5305e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0494e-05 - val_loss: 1.5285e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0443e-05 - val_loss: 1.5198e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.0394e-05 - val_loss: 1.5100e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0343e-05 - val_loss: 1.5021e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.0294e-05 - val_loss: 1.4943e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.0245e-05 - val_loss: 1.4921e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.0194e-05 - val_loss: 1.4903e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.0148e-05 - val_loss: 1.4735e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0097e-05 - val_loss: 1.4665e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0048e-05 - val_loss: 1.4619e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0002e-05 - val_loss: 1.4653e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.9523e-06 - val_loss: 1.4550e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.9043e-06 - val_loss: 1.4439e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.8584e-06 - val_loss: 1.4323e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.8077e-06 - val_loss: 1.4257e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.7606e-06 - val_loss: 1.4216e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.7097e-06 - val_loss: 1.4245e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.6676e-06 - val_loss: 1.4181e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.6204e-06 - val_loss: 1.4017e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.5702e-06 - val_loss: 1.3948e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.5242e-06 - val_loss: 1.3884e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.4758e-06 - val_loss: 1.3836e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.4312e-06 - val_loss: 1.3757e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.3843e-06 - val_loss: 1.3677e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.3370e-06 - val_loss: 1.3615e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.2907e-06 - val_loss: 1.3567e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.2473e-06 - val_loss: 1.3524e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.2001e-06 - val_loss: 1.3473e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.1541e-06 - val_loss: 1.3389e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.1082e-06 - val_loss: 1.3328e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.0623e-06 - val_loss: 1.3301e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 9.0178e-06 - val_loss: 1.3246e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.9751e-06 - val_loss: 1.3127e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.9284e-06 - val_loss: 1.3042e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.8838e-06 - val_loss: 1.2991e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.8393e-06 - val_loss: 1.2932e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 8.7956e-06 - val_loss: 1.2879e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 8.7508e-06 - val_loss: 1.2857e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.7105e-06 - val_loss: 1.2769e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.6661e-06 - val_loss: 1.2696e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 8.6198e-06 - val_loss: 1.2627e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.5783e-06 - val_loss: 1.2581e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.5330e-06 - val_loss: 1.2514e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 8.4919e-06 - val_loss: 1.2477e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.4476e-06 - val_loss: 1.2417e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.4051e-06 - val_loss: 1.2372e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.3615e-06 - val_loss: 1.2349e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.3249e-06 - val_loss: 1.2216e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.2808e-06 - val_loss: 1.2177e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.2365e-06 - val_loss: 1.2090e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.1945e-06 - val_loss: 1.2065e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.1518e-06 - val_loss: 1.2037e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.1103e-06 - val_loss: 1.2062e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.0734e-06 - val_loss: 1.1924e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0291e-06 - val_loss: 1.1824e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.9892e-06 - val_loss: 1.1784e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.9450e-06 - val_loss: 1.1691e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.9046e-06 - val_loss: 1.1702e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.8654e-06 - val_loss: 1.1627e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.8248e-06 - val_loss: 1.1564e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.7842e-06 - val_loss: 1.1515e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.7438e-06 - val_loss: 1.1467e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.7024e-06 - val_loss: 1.1454e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.6625e-06 - val_loss: 1.1390e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.6241e-06 - val_loss: 1.1333e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.5848e-06 - val_loss: 1.1255e-06\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.5438e-06 - val_loss: 1.1202e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.5058e-06 - val_loss: 1.1152e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.4683e-06 - val_loss: 1.1108e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.4262e-06 - val_loss: 1.1041e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3866e-06 - val_loss: 1.1018e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.3506e-06 - val_loss: 1.0954e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.3113e-06 - val_loss: 1.0896e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.2726e-06 - val_loss: 1.0870e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 7.2361e-06 - val_loss: 1.0811e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.1959e-06 - val_loss: 1.0774e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.1595e-06 - val_loss: 1.0746e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.1208e-06 - val_loss: 1.0678e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.0836e-06 - val_loss: 1.0620e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.0447e-06 - val_loss: 1.0560e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0081e-06 - val_loss: 1.0513e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.9699e-06 - val_loss: 1.0473e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.9346e-06 - val_loss: 1.0492e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.9039e-06 - val_loss: 1.0369e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.8617e-06 - val_loss: 1.0304e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.8284e-06 - val_loss: 1.0286e-06\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.7886e-06 - val_loss: 1.0233e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.7518e-06 - val_loss: 1.0193e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.7152e-06 - val_loss: 1.0137e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.6794e-06 - val_loss: 1.0135e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.6441e-06 - val_loss: 1.0091e-06\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.6088e-06 - val_loss: 1.0012e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.5742e-06 - val_loss: 9.9604e-07\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.5363e-06 - val_loss: 9.9054e-07\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.5065e-06 - val_loss: 9.8984e-07\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.4684e-06 - val_loss: 9.8437e-07\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.4317e-06 - val_loss: 9.8003e-07\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.3969e-06 - val_loss: 9.7686e-07\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.3631e-06 - val_loss: 9.7410e-07\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.3289e-06 - val_loss: 9.6757e-07\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.2946e-06 - val_loss: 9.6025e-07\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.2593e-06 - val_loss: 9.5549e-07\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.2291e-06 - val_loss: 9.5347e-07\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.1921e-06 - val_loss: 9.4659e-07\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.1597e-06 - val_loss: 9.4189e-07\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.1254e-06 - val_loss: 9.3728e-07\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.0932e-06 - val_loss: 9.3587e-07\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.0590e-06 - val_loss: 9.3307e-07\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.0258e-06 - val_loss: 9.3383e-07\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.9920e-06 - val_loss: 9.3097e-07\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.9610e-06 - val_loss: 9.2565e-07\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9263e-06 - val_loss: 9.1805e-07\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.8937e-06 - val_loss: 9.1162e-07\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.8604e-06 - val_loss: 9.0592e-07\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.8302e-06 - val_loss: 9.0370e-07\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.7979e-06 - val_loss: 9.0038e-07\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 830us/step - loss: 5.7661e-06 - val_loss: 8.9705e-07\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 834us/step - loss: 5.7335e-06 - val_loss: 8.9078e-07\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.7003e-06 - val_loss: 8.8617e-07\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.6711e-06 - val_loss: 8.8304e-07\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.6377e-06 - val_loss: 8.8375e-07\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 832us/step - loss: 5.6083e-06 - val_loss: 8.9015e-07\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 836us/step - loss: 5.5788e-06 - val_loss: 8.8715e-07\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 5.5480e-06 - val_loss: 8.8041e-07\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5183e-06 - val_loss: 8.7224e-07\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.4910e-06 - val_loss: 8.6427e-07\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.4530e-06 - val_loss: 8.5620e-07\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.4243e-06 - val_loss: 8.5380e-07\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.3919e-06 - val_loss: 8.4968e-07\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.3598e-06 - val_loss: 8.4530e-07\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 847us/step - loss: 5.3319e-06 - val_loss: 8.4212e-07\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.3036e-06 - val_loss: 8.3961e-07\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.2731e-06 - val_loss: 8.3791e-07\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 5.2421e-06 - val_loss: 8.3418e-07\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 5.2113e-06 - val_loss: 8.3288e-07\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 819us/step - loss: 5.1830e-06 - val_loss: 8.2715e-07\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 846us/step - loss: 5.1535e-06 - val_loss: 8.2057e-07\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 830us/step - loss: 5.1226e-06 - val_loss: 8.1943e-07\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 833us/step - loss: 5.0966e-06 - val_loss: 8.1426e-07\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.0662e-06 - val_loss: 8.1541e-07\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.0384e-06 - val_loss: 8.1442e-07\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.0090e-06 - val_loss: 8.1269e-07\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.9834e-06 - val_loss: 8.0529e-07\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9538e-06 - val_loss: 7.9891e-07\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.9242e-06 - val_loss: 7.9558e-07\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.8971e-06 - val_loss: 7.9068e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.8681e-06 - val_loss: 7.8733e-07\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.8419e-06 - val_loss: 7.8407e-07\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.8153e-06 - val_loss: 7.8281e-07\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.7870e-06 - val_loss: 7.7604e-07\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.7569e-06 - val_loss: 7.7155e-07\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.7305e-06 - val_loss: 7.6895e-07\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.7027e-06 - val_loss: 7.6630e-07\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.6760e-06 - val_loss: 7.6450e-07\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.6482e-06 - val_loss: 7.5972e-07\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.6219e-06 - val_loss: 7.5599e-07\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.5963e-06 - val_loss: 7.5228e-07\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.5692e-06 - val_loss: 7.5202e-07\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.5433e-06 - val_loss: 7.5033e-07\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.5161e-06 - val_loss: 7.4800e-07\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.4896e-06 - val_loss: 7.4329e-07\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 4.4643e-06 - val_loss: 7.4061e-07\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.4388e-06 - val_loss: 7.3542e-07\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.4126e-06 - val_loss: 7.3241e-07\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3855e-06 - val_loss: 7.2772e-07\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.3618e-06 - val_loss: 7.2346e-07\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.3361e-06 - val_loss: 7.2155e-07\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.3090e-06 - val_loss: 7.2230e-07\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.2856e-06 - val_loss: 7.2162e-07\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.2616e-06 - val_loss: 7.1824e-07\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 4.1876e-0 - 1s 751us/step - loss: 4.2355e-06 - val_loss: 7.1301e-07\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.2104e-06 - val_loss: 7.1208e-07\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.1858e-06 - val_loss: 7.0974e-07\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.1620e-06 - val_loss: 7.1243e-07\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.1378e-06 - val_loss: 7.0278e-07\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.1117e-06 - val_loss: 6.9689e-07\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.0859e-06 - val_loss: 6.9367e-07\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.0620e-06 - val_loss: 6.9015e-07\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.0381e-06 - val_loss: 6.8909e-07\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.0159e-06 - val_loss: 6.8568e-07\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.9921e-06 - val_loss: 6.8232e-07\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.9676e-06 - val_loss: 6.8145e-07\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.9449e-06 - val_loss: 6.7923e-07\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.9211e-06 - val_loss: 6.7631e-07\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.9001e-06 - val_loss: 6.7480e-07\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.8757e-06 - val_loss: 6.7199e-07\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.8513e-06 - val_loss: 6.7017e-07\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.8298e-06 - val_loss: 6.6470e-07\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.8062e-06 - val_loss: 6.6241e-07\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.7839e-06 - val_loss: 6.6165e-07\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.7612e-06 - val_loss: 6.5807e-07\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.7376e-06 - val_loss: 6.5678e-07\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.7168e-06 - val_loss: 6.5659e-07\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.6961e-06 - val_loss: 6.5158e-07\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.6730e-06 - val_loss: 6.5205e-07\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.6525e-06 - val_loss: 6.4642e-07\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.6291e-06 - val_loss: 6.3824e-07\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.6065e-06 - val_loss: 6.3596e-07\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.5848e-06 - val_loss: 6.3314e-07\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.5644e-06 - val_loss: 6.3165e-07\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.5424e-06 - val_loss: 6.3086e-07\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.5215e-06 - val_loss: 6.2734e-07\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5018e-06 - val_loss: 6.2377e-07\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.4813e-06 - val_loss: 6.2101e-07\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.4627e-06 - val_loss: 6.1891e-07\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.4385e-06 - val_loss: 6.1521e-07\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.4209e-06 - val_loss: 6.1398e-07\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.3988e-06 - val_loss: 6.1246e-07\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.3781e-06 - val_loss: 6.0691e-07\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.3583e-06 - val_loss: 6.0365e-07\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.3391e-06 - val_loss: 6.0250e-07\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.3180e-06 - val_loss: 5.9967e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.2965e-06 - val_loss: 5.9694e-07\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2780e-06 - val_loss: 5.9517e-07\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2567e-06 - val_loss: 5.9117e-07\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.2370e-06 - val_loss: 5.8836e-07\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.2175e-06 - val_loss: 5.8535e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.1999e-06 - val_loss: 5.8338e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.1816e-06 - val_loss: 5.8217e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.1635e-06 - val_loss: 5.8135e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.1422e-06 - val_loss: 5.7726e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.1221e-06 - val_loss: 5.7450e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.1028e-06 - val_loss: 5.7485e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.0850e-06 - val_loss: 5.7271e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.0659e-06 - val_loss: 5.6975e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.0480e-06 - val_loss: 5.7117e-07\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.0322e-06 - val_loss: 5.7249e-07\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.0111e-06 - val_loss: 5.6541e-07\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.9929e-06 - val_loss: 5.6182e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.9745e-06 - val_loss: 5.6158e-07\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.9581e-06 - val_loss: 5.5704e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9405e-06 - val_loss: 5.5296e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.9227e-06 - val_loss: 5.5052e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.9062e-06 - val_loss: 5.5087e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.8895e-06 - val_loss: 5.4673e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.8699e-06 - val_loss: 5.4369e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.8510e-06 - val_loss: 5.4173e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.8335e-06 - val_loss: 5.3979e-07\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.8169e-06 - val_loss: 5.3838e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.7996e-06 - val_loss: 5.3761e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.7833e-06 - val_loss: 5.3569e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.7673e-06 - val_loss: 5.3118e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.7501e-06 - val_loss: 5.2868e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.7329e-06 - val_loss: 5.2772e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.7163e-06 - val_loss: 5.2599e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.6998e-06 - val_loss: 5.2324e-07\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6830e-06 - val_loss: 5.2270e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.6672e-06 - val_loss: 5.1927e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 753us/step - loss: 2.6516e-06 - val_loss: 5.1656e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.6352e-06 - val_loss: 5.1580e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6190e-06 - val_loss: 5.1332e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.6037e-06 - val_loss: 5.0962e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5895e-06 - val_loss: 5.0843e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5729e-06 - val_loss: 5.0561e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.5566e-06 - val_loss: 5.0379e-07\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5421e-06 - val_loss: 5.0270e-07\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.5261e-06 - val_loss: 5.0129e-07\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5115e-06 - val_loss: 5.0023e-07\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.4947e-06 - val_loss: 4.9805e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4808e-06 - val_loss: 4.9472e-07\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4655e-06 - val_loss: 4.9248e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.4516e-06 - val_loss: 4.9260e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 2.4060e-0 - 1s 748us/step - loss: 2.4364e-06 - val_loss: 4.9508e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.4218e-06 - val_loss: 4.8969e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4071e-06 - val_loss: 4.8623e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.3920e-06 - val_loss: 4.8291e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.3779e-06 - val_loss: 4.8080e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.3640e-06 - val_loss: 4.7961e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.3483e-06 - val_loss: 4.7696e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.3346e-06 - val_loss: 4.7623e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.3208e-06 - val_loss: 4.7306e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 2.3074e-06 - val_loss: 4.7182e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.2933e-06 - val_loss: 4.6990e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.2803e-06 - val_loss: 4.6956e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2658e-06 - val_loss: 4.6775e-07\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.2524e-06 - val_loss: 4.6675e-07\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.2380e-06 - val_loss: 4.6433e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2249e-06 - val_loss: 4.6122e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2113e-06 - val_loss: 4.6150e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1981e-06 - val_loss: 4.6183e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1870e-06 - val_loss: 4.5485e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1737e-06 - val_loss: 4.5336e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.1606e-06 - val_loss: 4.5214e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1473e-06 - val_loss: 4.5101e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.1358e-06 - val_loss: 4.4974e-07\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.1218e-06 - val_loss: 4.4989e-07\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.1081e-06 - val_loss: 4.4612e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.0950e-06 - val_loss: 4.4478e-07\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.0824e-06 - val_loss: 4.4295e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.0703e-06 - val_loss: 4.4009e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0584e-06 - val_loss: 4.3791e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0461e-06 - val_loss: 4.3579e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.0337e-06 - val_loss: 4.3442e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.0218e-06 - val_loss: 4.3383e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0101e-06 - val_loss: 4.3239e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.9978e-06 - val_loss: 4.3103e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9859e-06 - val_loss: 4.2982e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.9743e-06 - val_loss: 4.3079e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.9621e-06 - val_loss: 4.2726e-07\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 100, 5)            140       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100, 1)            6         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1215 - val_loss: 0.1188\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.1171 - val_loss: 0.1146\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.1131 - val_loss: 0.1110\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.1097 - val_loss: 0.1080\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1069 - val_loss: 0.1055\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.1045 - val_loss: 0.1034\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.1027 - val_loss: 0.1018\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.1012 - val_loss: 0.1005\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.1000 - val_loss: 0.0996\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0992 - val_loss: 0.0988\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0985 - val_loss: 0.0983\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0980 - val_loss: 0.0977\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0974 - val_loss: 0.0972\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0969 - val_loss: 0.0967\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0964 - val_loss: 0.0961\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0958 - val_loss: 0.0956\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0953 - val_loss: 0.0951\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0948 - val_loss: 0.0945\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0942 - val_loss: 0.0940\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0937 - val_loss: 0.0934\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0931 - val_loss: 0.0929\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0926 - val_loss: 0.0923\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0920 - val_loss: 0.0918\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0914 - val_loss: 0.0912\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0908 - val_loss: 0.0906\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0902 - val_loss: 0.0899\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0896 - val_loss: 0.0893\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0889 - val_loss: 0.0886\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0883 - val_loss: 0.0879\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0875 - val_loss: 0.0872\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0868 - val_loss: 0.0864\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0860 - val_loss: 0.0856\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0852 - val_loss: 0.0847\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0843 - val_loss: 0.0838\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0834 - val_loss: 0.0828\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0823 - val_loss: 0.0818\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0812 - val_loss: 0.0806\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0800 - val_loss: 0.0793\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0786 - val_loss: 0.0778\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0771 - val_loss: 0.0762\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 0.0755 - val_loss: 0.0746\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0738 - val_loss: 0.0729\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0721 - val_loss: 0.0712\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.0705 - val_loss: 0.0696\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0689 - val_loss: 0.0680\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0673 - val_loss: 0.0664\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0657 - val_loss: 0.0649\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0641 - val_loss: 0.0633\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0626 - val_loss: 0.0618\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0611 - val_loss: 0.0603\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0595 - val_loss: 0.0587\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0580 - val_loss: 0.0572\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0564 - val_loss: 0.0556\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0549 - val_loss: 0.0541\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0533 - val_loss: 0.0525\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0517 - val_loss: 0.0509\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0501 - val_loss: 0.0493\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0485 - val_loss: 0.0477\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0469 - val_loss: 0.0461\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0453 - val_loss: 0.0445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0437 - val_loss: 0.0429\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0421 - val_loss: 0.0412\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0404 - val_loss: 0.0396\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0388 - val_loss: 0.0379\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0371 - val_loss: 0.0363\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0355 - val_loss: 0.0346\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0338 - val_loss: 0.0329\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0321 - val_loss: 0.0313\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0305 - val_loss: 0.0296\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0288 - val_loss: 0.0280\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0272 - val_loss: 0.0263\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0255 - val_loss: 0.0247\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0223 - val_loss: 0.0215\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0208 - val_loss: 0.0200\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0193 - val_loss: 0.0185\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0179 - val_loss: 0.0172\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 753us/step - loss: 0.0153 - val_loss: 0.0146\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0140 - val_loss: 0.0135\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0089 - val_loss: 0.0085\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.8883e-04 - val_loss: 9.9212e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.7215e-04 - val_loss: 9.7437e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.5559e-04 - val_loss: 9.5685e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.3937e-04 - val_loss: 9.3943e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.2315e-04 - val_loss: 9.2220e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.0708e-04 - val_loss: 9.0519e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.9137e-04 - val_loss: 8.8827e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.7563e-04 - val_loss: 8.7158e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.6015e-04 - val_loss: 8.5508e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.4486e-04 - val_loss: 8.3876e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.2972e-04 - val_loss: 8.2262e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.1477e-04 - val_loss: 8.0668e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.0004e-04 - val_loss: 7.9091e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.8547e-04 - val_loss: 7.7533e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.7104e-04 - val_loss: 7.5995e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.5679e-04 - val_loss: 7.4478e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.4279e-04 - val_loss: 7.2979e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.2884e-04 - val_loss: 7.1486e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.1508e-04 - val_loss: 7.0004e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.0135e-04 - val_loss: 6.8541e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.8783e-04 - val_loss: 6.7097e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.7460e-04 - val_loss: 6.5664e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.6141e-04 - val_loss: 6.4254e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.4838e-04 - val_loss: 6.2868e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.3566e-04 - val_loss: 6.1500e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.2303e-04 - val_loss: 6.0154e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.1077e-04 - val_loss: 5.8821e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.9846e-04 - val_loss: 5.7516e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.8652e-04 - val_loss: 5.6227e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.7469e-04 - val_loss: 5.4959e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.6305e-04 - val_loss: 5.3714e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.5163e-04 - val_loss: 5.2487e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.4040e-04 - val_loss: 5.1280e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.2934e-04 - val_loss: 5.0095e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.1848e-04 - val_loss: 4.8929e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.0780e-04 - val_loss: 4.7783e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9733e-04 - val_loss: 4.6656e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.8706e-04 - val_loss: 4.5547e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.7693e-04 - val_loss: 4.4459e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.6700e-04 - val_loss: 4.3391e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.5734e-04 - val_loss: 4.2338e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.4775e-04 - val_loss: 4.1305e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.3833e-04 - val_loss: 4.0292e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 4.2905e-04 - val_loss: 3.9279e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.1976e-04 - val_loss: 3.8281e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.1067e-04 - val_loss: 3.7296e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.0174e-04 - val_loss: 3.6327e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9294e-04 - val_loss: 3.5376e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.8428e-04 - val_loss: 3.4447e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.7583e-04 - val_loss: 3.3538e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.6762e-04 - val_loss: 3.2645e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.5952e-04 - val_loss: 3.1773e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.5162e-04 - val_loss: 3.0922e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.4396e-04 - val_loss: 3.0086e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.3641e-04 - val_loss: 2.9273e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 3.2905e-04 - val_loss: 2.8482e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.2194e-04 - val_loss: 2.7706e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.1496e-04 - val_loss: 2.6948e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.0811e-04 - val_loss: 2.6212e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.0150e-04 - val_loss: 2.5496e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.9514e-04 - val_loss: 2.4809e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.8899e-04 - val_loss: 2.4139e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.8298e-04 - val_loss: 2.3484e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.7710e-04 - val_loss: 2.2845e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.7138e-04 - val_loss: 2.2218e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.6573e-04 - val_loss: 2.1609e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.6025e-04 - val_loss: 2.1013e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5492e-04 - val_loss: 2.0429e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.4964e-04 - val_loss: 1.9863e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4460e-04 - val_loss: 1.9306e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.3963e-04 - val_loss: 1.8763e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3478e-04 - val_loss: 1.8232e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3002e-04 - val_loss: 1.7718e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2541e-04 - val_loss: 1.7215e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.2093e-04 - val_loss: 1.6723e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.1653e-04 - val_loss: 1.6244e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1224e-04 - val_loss: 1.5779e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.0811e-04 - val_loss: 1.5322e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0403e-04 - val_loss: 1.4880e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0009e-04 - val_loss: 1.4448e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9621e-04 - val_loss: 1.4033e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9253e-04 - val_loss: 1.3622e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.8885e-04 - val_loss: 1.3226e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8531e-04 - val_loss: 1.2840e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.8185e-04 - val_loss: 1.2464e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.7851e-04 - val_loss: 1.2098e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.7525e-04 - val_loss: 1.1739e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7207e-04 - val_loss: 1.1393e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.6897e-04 - val_loss: 1.1057e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6598e-04 - val_loss: 1.0730e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6305e-04 - val_loss: 1.0412e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6020e-04 - val_loss: 1.0103e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.5743e-04 - val_loss: 9.8023e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5475e-04 - val_loss: 9.5105e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.5213e-04 - val_loss: 9.2276e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4960e-04 - val_loss: 8.9528e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4714e-04 - val_loss: 8.6862e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.4476e-04 - val_loss: 8.4251e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.4242e-04 - val_loss: 8.1737e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.4018e-04 - val_loss: 7.9282e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3798e-04 - val_loss: 7.6917e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3586e-04 - val_loss: 7.4623e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 1.3380e-04 - val_loss: 7.2393e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 1.3180e-04 - val_loss: 7.0230e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2985e-04 - val_loss: 6.8153e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2798e-04 - val_loss: 6.6103e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2614e-04 - val_loss: 6.4141e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.2437e-04 - val_loss: 6.2240e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2265e-04 - val_loss: 6.0381e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2098e-04 - val_loss: 5.8576e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1936e-04 - val_loss: 5.6852e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1779e-04 - val_loss: 5.5165e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.1626e-04 - val_loss: 5.3525e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1478e-04 - val_loss: 5.1950e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1334e-04 - val_loss: 5.0432e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.1196e-04 - val_loss: 4.8946e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.1061e-04 - val_loss: 4.7520e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0930e-04 - val_loss: 4.6121e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0803e-04 - val_loss: 4.4774e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0679e-04 - val_loss: 4.3483e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.0560e-04 - val_loss: 4.2215e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0444e-04 - val_loss: 4.0994e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0331e-04 - val_loss: 3.9823e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0222e-04 - val_loss: 3.8701e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0115e-04 - val_loss: 3.7609e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0013e-04 - val_loss: 3.6548e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.9134e-05 - val_loss: 3.5519e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.8168e-05 - val_loss: 3.4525e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.7234e-05 - val_loss: 3.3556e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.6315e-05 - val_loss: 3.2635e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.5435e-05 - val_loss: 3.1742e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.4573e-05 - val_loss: 3.0861e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.3733e-05 - val_loss: 3.0013e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.2922e-05 - val_loss: 2.9199e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.2130e-05 - val_loss: 2.8421e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.1360e-05 - val_loss: 2.7656e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.0617e-05 - val_loss: 2.6911e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.9892e-05 - val_loss: 2.6207e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.9180e-05 - val_loss: 2.5504e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.8492e-05 - val_loss: 2.4830e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.7818e-05 - val_loss: 2.4181e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.7164e-05 - val_loss: 2.3557e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.6523e-05 - val_loss: 2.2959e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.5904e-05 - val_loss: 2.2377e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.5302e-05 - val_loss: 2.1824e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.4707e-05 - val_loss: 2.1265e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.4130e-05 - val_loss: 2.0739e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.3571e-05 - val_loss: 2.0228e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.3017e-05 - val_loss: 1.9722e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.2480e-05 - val_loss: 1.9238e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.1956e-05 - val_loss: 1.8770e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 8.1447e-05 - val_loss: 1.8325e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.0942e-05 - val_loss: 1.7882e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.0458e-05 - val_loss: 1.7468e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.9974e-05 - val_loss: 1.7057e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 7.9505e-05 - val_loss: 1.6654e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.9050e-05 - val_loss: 1.6275e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.8605e-05 - val_loss: 1.5913e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.8162e-05 - val_loss: 1.5543e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.7730e-05 - val_loss: 1.5199e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 7.7301e-05 - val_loss: 1.4849e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.6887e-05 - val_loss: 1.4519e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.6480e-05 - val_loss: 1.4203e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.6084e-05 - val_loss: 1.3897e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.5699e-05 - val_loss: 1.3617e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 7.5304e-05 - val_loss: 1.3330e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.4923e-05 - val_loss: 1.3045e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.4549e-05 - val_loss: 1.2773e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.4183e-05 - val_loss: 1.2502e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.3829e-05 - val_loss: 1.2257e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.3475e-05 - val_loss: 1.2013e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.3127e-05 - val_loss: 1.1778e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 7.2779e-05 - val_loss: 1.1534e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.2446e-05 - val_loss: 1.1305e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.2114e-05 - val_loss: 1.1085e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.1785e-05 - val_loss: 1.0873e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.1470e-05 - val_loss: 1.0672e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.1152e-05 - val_loss: 1.0484e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.0832e-05 - val_loss: 1.0276e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 7.0529e-05 - val_loss: 1.0096e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.0222e-05 - val_loss: 9.9194e-06\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.9915e-05 - val_loss: 9.7475e-06\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.9615e-05 - val_loss: 9.5735e-06\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.9310e-05 - val_loss: 9.4011e-06\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.9014e-05 - val_loss: 9.2327e-06\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.8723e-05 - val_loss: 9.0736e-06\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.8435e-05 - val_loss: 8.9145e-06\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.8155e-05 - val_loss: 8.7766e-06\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.7866e-05 - val_loss: 8.6311e-06\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.7592e-05 - val_loss: 8.4901e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.7318e-05 - val_loss: 8.3625e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.7039e-05 - val_loss: 8.2283e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.6758e-05 - val_loss: 8.0814e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.6499e-05 - val_loss: 7.9546e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.6230e-05 - val_loss: 7.8350e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.5975e-05 - val_loss: 7.7159e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 6.5719e-05 - val_loss: 7.6105e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.5458e-05 - val_loss: 7.5079e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.5207e-05 - val_loss: 7.3962e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.4938e-05 - val_loss: 7.2810e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.4698e-05 - val_loss: 7.2009e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.4443e-05 - val_loss: 7.0906e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.4193e-05 - val_loss: 6.9800e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.3949e-05 - val_loss: 6.8886e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.3703e-05 - val_loss: 6.7995e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.3465e-05 - val_loss: 6.7178e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.3217e-05 - val_loss: 6.6291e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.2972e-05 - val_loss: 6.5375e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.2735e-05 - val_loss: 6.4454e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.2500e-05 - val_loss: 6.3691e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.2264e-05 - val_loss: 6.2917e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.2026e-05 - val_loss: 6.2091e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.1796e-05 - val_loss: 6.1282e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.1570e-05 - val_loss: 6.0629e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.1333e-05 - val_loss: 5.9945e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.1105e-05 - val_loss: 5.9248e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.0877e-05 - val_loss: 5.8539e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.0648e-05 - val_loss: 5.7814e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.0426e-05 - val_loss: 5.7237e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.0197e-05 - val_loss: 5.6552e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.9986e-05 - val_loss: 5.6044e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.9760e-05 - val_loss: 5.5452e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.9534e-05 - val_loss: 5.4764e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.9328e-05 - val_loss: 5.4272e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.9104e-05 - val_loss: 5.3702e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.8880e-05 - val_loss: 5.3054e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.8666e-05 - val_loss: 5.2487e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.8452e-05 - val_loss: 5.1974e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.8243e-05 - val_loss: 5.1528e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.8023e-05 - val_loss: 5.0923e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.7814e-05 - val_loss: 5.0476e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.7613e-05 - val_loss: 5.0099e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.7401e-05 - val_loss: 4.9705e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.7183e-05 - val_loss: 4.9206e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.6979e-05 - val_loss: 4.8814e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.6774e-05 - val_loss: 4.8355e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.6558e-05 - val_loss: 4.7899e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.6362e-05 - val_loss: 4.7534e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.6143e-05 - val_loss: 4.6989e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.5945e-05 - val_loss: 4.6580e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.5741e-05 - val_loss: 4.6223e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5553e-05 - val_loss: 4.5995e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.5336e-05 - val_loss: 4.5576e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.5132e-05 - val_loss: 4.5221e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.4930e-05 - val_loss: 4.4744e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.4727e-05 - val_loss: 4.4406e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.4534e-05 - val_loss: 4.4088e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.4330e-05 - val_loss: 4.3815e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.4138e-05 - val_loss: 4.3460e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.3931e-05 - val_loss: 4.3033e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.3731e-05 - val_loss: 4.2642e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.3532e-05 - val_loss: 4.2231e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3355e-05 - val_loss: 4.2151e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.3147e-05 - val_loss: 4.1795e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.2952e-05 - val_loss: 4.1445e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.2764e-05 - val_loss: 4.1164e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.2573e-05 - val_loss: 4.1016e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.2378e-05 - val_loss: 4.0716e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.2175e-05 - val_loss: 4.0320e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.1997e-05 - val_loss: 4.0108e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.1800e-05 - val_loss: 3.9794e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.1603e-05 - val_loss: 3.9433e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.1425e-05 - val_loss: 3.9215e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.1232e-05 - val_loss: 3.8997e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.1044e-05 - val_loss: 3.8800e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.0855e-05 - val_loss: 3.8559e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.0668e-05 - val_loss: 3.8316e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.0480e-05 - val_loss: 3.8100e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.0295e-05 - val_loss: 3.7794e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.0110e-05 - val_loss: 3.7551e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.9933e-05 - val_loss: 3.7549e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.9741e-05 - val_loss: 3.7103e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 4.9555e-05 - val_loss: 3.6845e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.9379e-05 - val_loss: 3.6802e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.9188e-05 - val_loss: 3.6498e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.9008e-05 - val_loss: 3.6299e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.8831e-05 - val_loss: 3.6258e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.8642e-05 - val_loss: 3.5871e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.8458e-05 - val_loss: 3.5658e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.8276e-05 - val_loss: 3.5486e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.8095e-05 - val_loss: 3.5191e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.7919e-05 - val_loss: 3.5024e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.7738e-05 - val_loss: 3.4857e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.7552e-05 - val_loss: 3.4536e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.7378e-05 - val_loss: 3.4329e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.7203e-05 - val_loss: 3.4199e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.7025e-05 - val_loss: 3.4080e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.6850e-05 - val_loss: 3.3926e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.6673e-05 - val_loss: 3.3747e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.6500e-05 - val_loss: 3.3614e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.6327e-05 - val_loss: 3.3577e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.6135e-05 - val_loss: 3.3152e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.5970e-05 - val_loss: 3.2923e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.5789e-05 - val_loss: 3.2726e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.5622e-05 - val_loss: 3.2621e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.5448e-05 - val_loss: 3.2496e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.5279e-05 - val_loss: 3.2417e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.5098e-05 - val_loss: 3.2257e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.4918e-05 - val_loss: 3.1883e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.4753e-05 - val_loss: 3.1756e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.4589e-05 - val_loss: 3.1755e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.4420e-05 - val_loss: 3.1649e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 4.4249e-05 - val_loss: 3.1566e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.4076e-05 - val_loss: 3.1404e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 4.3904e-05 - val_loss: 3.1317e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 4.3741e-05 - val_loss: 3.1091e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.3578e-05 - val_loss: 3.0838e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.3401e-05 - val_loss: 3.0648e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.3230e-05 - val_loss: 3.0401e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.3071e-05 - val_loss: 3.0443e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.2894e-05 - val_loss: 3.0229e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2722e-05 - val_loss: 3.0234e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.2569e-05 - val_loss: 3.0180e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.2399e-05 - val_loss: 2.9836e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.2241e-05 - val_loss: 2.9711e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.2066e-05 - val_loss: 2.9525e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.1899e-05 - val_loss: 2.9458e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.1732e-05 - val_loss: 2.9363e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.1571e-05 - val_loss: 2.9153e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.1401e-05 - val_loss: 2.8966e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.1240e-05 - val_loss: 2.8980e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.1084e-05 - val_loss: 2.8772e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0919e-05 - val_loss: 2.8699e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.0753e-05 - val_loss: 2.8589e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.0589e-05 - val_loss: 2.8456e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 4.0434e-05 - val_loss: 2.8360e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.0285e-05 - val_loss: 2.8324e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.0114e-05 - val_loss: 2.8067e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.9957e-05 - val_loss: 2.7961e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9793e-05 - val_loss: 2.7948e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.9644e-05 - val_loss: 2.7758e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9476e-05 - val_loss: 2.7421e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.9326e-05 - val_loss: 2.7480e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.9157e-05 - val_loss: 2.7478e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.9010e-05 - val_loss: 2.7500e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.8839e-05 - val_loss: 2.7095e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 3.8677e-05 - val_loss: 2.6869e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.8527e-05 - val_loss: 2.6830e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.8366e-05 - val_loss: 2.6706e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.8207e-05 - val_loss: 2.6441e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8070e-05 - val_loss: 2.6513e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.7907e-05 - val_loss: 2.6658e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.7746e-05 - val_loss: 2.6462e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.7608e-05 - val_loss: 2.6522e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 3.7454e-05 - val_loss: 2.6356e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.7293e-05 - val_loss: 2.5983e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7131e-05 - val_loss: 2.5797e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.6983e-05 - val_loss: 2.5683e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.6832e-05 - val_loss: 2.5627e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.6673e-05 - val_loss: 2.5437e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.6523e-05 - val_loss: 2.5381e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.6381e-05 - val_loss: 2.5433e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.6217e-05 - val_loss: 2.5243e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.6073e-05 - val_loss: 2.5170e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.5915e-05 - val_loss: 2.5108e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.5769e-05 - val_loss: 2.4849e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.5617e-05 - val_loss: 2.4780e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.5465e-05 - val_loss: 2.4563e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 3.5317e-05 - val_loss: 2.4445e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.5169e-05 - val_loss: 2.4420e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.5023e-05 - val_loss: 2.4351e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.4873e-05 - val_loss: 2.4229e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.4722e-05 - val_loss: 2.4048e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.4581e-05 - val_loss: 2.4016e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.4431e-05 - val_loss: 2.3977e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.4287e-05 - val_loss: 2.3763e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.4151e-05 - val_loss: 2.3968e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.4002e-05 - val_loss: 2.3610e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.3854e-05 - val_loss: 2.3453e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 3.3707e-05 - val_loss: 2.3434e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.3560e-05 - val_loss: 2.3420e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.3422e-05 - val_loss: 2.3267e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.3277e-05 - val_loss: 2.3198e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.3130e-05 - val_loss: 2.3020e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.3004e-05 - val_loss: 2.3239e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.2856e-05 - val_loss: 2.3061e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.2721e-05 - val_loss: 2.2781e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.2574e-05 - val_loss: 2.2746e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.2426e-05 - val_loss: 2.2746e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.2289e-05 - val_loss: 2.2626e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.2153e-05 - val_loss: 2.2666e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.2016e-05 - val_loss: 2.2424e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.1871e-05 - val_loss: 2.2237e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.1731e-05 - val_loss: 2.2358e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.1597e-05 - val_loss: 2.2266e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.1439e-05 - val_loss: 2.2038e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.1300e-05 - val_loss: 2.1935e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.1163e-05 - val_loss: 2.1687e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.1033e-05 - val_loss: 2.1706e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.0884e-05 - val_loss: 2.1538e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.0750e-05 - val_loss: 2.1562e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.0618e-05 - val_loss: 2.1505e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.0476e-05 - val_loss: 2.1470e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.0341e-05 - val_loss: 2.1319e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 3.0210e-05 - val_loss: 2.1285e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 832us/step - loss: 3.0084e-05 - val_loss: 2.1342e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 809us/step - loss: 2.9943e-05 - val_loss: 2.1259e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 862us/step - loss: 2.9801e-05 - val_loss: 2.0991e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.9669e-05 - val_loss: 2.0881e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.9534e-05 - val_loss: 2.0754e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.9405e-05 - val_loss: 2.0747e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.9268e-05 - val_loss: 2.0633e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 2.9137e-05 - val_loss: 2.0531e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.9006e-05 - val_loss: 2.0503e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 2.8871e-05 - val_loss: 2.0566e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.8741e-05 - val_loss: 2.0288e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.8609e-05 - val_loss: 2.0278e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.8485e-05 - val_loss: 2.0174e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8357e-05 - val_loss: 2.0179e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.8227e-05 - val_loss: 2.0116e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.8102e-05 - val_loss: 2.0104e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.7967e-05 - val_loss: 1.9929e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 2.7834e-05 - val_loss: 1.9903e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 861us/step - loss: 2.7704e-05 - val_loss: 1.9713e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 811us/step - loss: 2.7577e-05 - val_loss: 1.9668e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.7449e-05 - val_loss: 1.9613e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.7322e-05 - val_loss: 1.9564e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.7194e-05 - val_loss: 1.9467e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.7069e-05 - val_loss: 1.9351e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6940e-05 - val_loss: 1.9259e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.6829e-05 - val_loss: 1.9276e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 889us/step - loss: 2.6699e-05 - val_loss: 1.9167e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 864us/step - loss: 2.6568e-05 - val_loss: 1.9049e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 2.6446e-05 - val_loss: 1.9263e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.6334e-05 - val_loss: 1.9020e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6192e-05 - val_loss: 1.8866e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6074e-05 - val_loss: 1.8812e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.5961e-05 - val_loss: 1.8756e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.5834e-05 - val_loss: 1.8712e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.5701e-05 - val_loss: 1.8473e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5590e-05 - val_loss: 1.8564e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.5461e-05 - val_loss: 1.8434e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5338e-05 - val_loss: 1.8320e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.5220e-05 - val_loss: 1.8254e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.5101e-05 - val_loss: 1.8223e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.4981e-05 - val_loss: 1.8058e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.4865e-05 - val_loss: 1.8001e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.4747e-05 - val_loss: 1.8035e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4621e-05 - val_loss: 1.7842e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.4506e-05 - val_loss: 1.7929e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.4392e-05 - val_loss: 1.7763e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.4274e-05 - val_loss: 1.7776e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.4159e-05 - val_loss: 1.7580e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.4044e-05 - val_loss: 1.7579e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3925e-05 - val_loss: 1.7586e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.3804e-05 - val_loss: 1.7530e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.3694e-05 - val_loss: 1.7563e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.3585e-05 - val_loss: 1.7316e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3468e-05 - val_loss: 1.7291e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3339e-05 - val_loss: 1.7158e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.3232e-05 - val_loss: 1.7107e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.3119e-05 - val_loss: 1.7087e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3005e-05 - val_loss: 1.7031e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2889e-05 - val_loss: 1.6917e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.2775e-05 - val_loss: 1.6796e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2664e-05 - val_loss: 1.6719e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2554e-05 - val_loss: 1.6634e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.2445e-05 - val_loss: 1.6669e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2336e-05 - val_loss: 1.6512e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2237e-05 - val_loss: 1.7315e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2167e-05 - val_loss: 1.6449e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2030e-05 - val_loss: 1.6571e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1912e-05 - val_loss: 1.6416e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.1784e-05 - val_loss: 1.6289e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.1670e-05 - val_loss: 1.6249e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.1571e-05 - val_loss: 1.6111e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.1460e-05 - val_loss: 1.6050e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.1354e-05 - val_loss: 1.5985e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.1258e-05 - val_loss: 1.6002e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.1158e-05 - val_loss: 1.5843e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.1041e-05 - val_loss: 1.5990e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0938e-05 - val_loss: 1.6035e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0843e-05 - val_loss: 1.5743e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0729e-05 - val_loss: 1.5850e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.0648e-05 - val_loss: 1.5781e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0520e-05 - val_loss: 1.5497e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0406e-05 - val_loss: 1.5507e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0302e-05 - val_loss: 1.5435e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.0217e-05 - val_loss: 1.5489e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0109e-05 - val_loss: 1.5319e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0008e-05 - val_loss: 1.5197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.9906e-05 - val_loss: 1.5232e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9804e-05 - val_loss: 1.5777e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.9728e-05 - val_loss: 1.5245e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.9605e-05 - val_loss: 1.4875e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.9519e-05 - val_loss: 1.4905e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.9407e-05 - val_loss: 1.5135e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.9304e-05 - val_loss: 1.4771e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.9196e-05 - val_loss: 1.4791e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9095e-05 - val_loss: 1.4651e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.8999e-05 - val_loss: 1.4707e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8904e-05 - val_loss: 1.4806e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8818e-05 - val_loss: 1.4765e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.8729e-05 - val_loss: 1.4436e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8631e-05 - val_loss: 1.4384e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.8522e-05 - val_loss: 1.4701e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8465e-05 - val_loss: 1.4285e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.8370e-05 - val_loss: 1.4221e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8259e-05 - val_loss: 1.4268e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.8159e-05 - val_loss: 1.4479e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.8060e-05 - val_loss: 1.4437e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.7957e-05 - val_loss: 1.3877e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7877e-05 - val_loss: 1.3865e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.7774e-05 - val_loss: 1.3878e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.7676e-05 - val_loss: 1.3848e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7590e-05 - val_loss: 1.3826e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7504e-05 - val_loss: 1.3694e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7408e-05 - val_loss: 1.3776e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.7311e-05 - val_loss: 1.3854e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7228e-05 - val_loss: 1.3658e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.7140e-05 - val_loss: 1.3486e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7046e-05 - val_loss: 1.3580e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.6972e-05 - val_loss: 1.3572e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6877e-05 - val_loss: 1.3464e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6789e-05 - val_loss: 1.3526e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6703e-05 - val_loss: 1.3418e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.6599e-05 - val_loss: 1.3130e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6504e-05 - val_loss: 1.3046e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.6415e-05 - val_loss: 1.2973e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6327e-05 - val_loss: 1.2897e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.6248e-05 - val_loss: 1.2925e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.6160e-05 - val_loss: 1.2926e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.6077e-05 - val_loss: 1.3040e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6013e-05 - val_loss: 1.3638e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.5960e-05 - val_loss: 1.3113e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.5864e-05 - val_loss: 1.2895e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5777e-05 - val_loss: 1.2763e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.5679e-05 - val_loss: 1.2598e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5574e-05 - val_loss: 1.2520e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5525e-05 - val_loss: 1.2532e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5420e-05 - val_loss: 1.2749e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.5338e-05 - val_loss: 1.2694e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.5251e-05 - val_loss: 1.2333e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.5169e-05 - val_loss: 1.2612e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5089e-05 - val_loss: 1.2300e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.5000e-05 - val_loss: 1.2163e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4927e-05 - val_loss: 1.2187e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4846e-05 - val_loss: 1.2212e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4768e-05 - val_loss: 1.2166e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.4688e-05 - val_loss: 1.2027e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4608e-05 - val_loss: 1.1931e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4536e-05 - val_loss: 1.1869e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.4454e-05 - val_loss: 1.1876e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.4372e-05 - val_loss: 1.1721e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.4303e-05 - val_loss: 1.1687e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4220e-05 - val_loss: 1.1709e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4139e-05 - val_loss: 1.1569e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4082e-05 - val_loss: 1.1534e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.4000e-05 - val_loss: 1.1617e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3926e-05 - val_loss: 1.1576e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 1.3844e-05 - val_loss: 1.1570e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.3759e-05 - val_loss: 1.1313e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3686e-05 - val_loss: 1.1308e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.3613e-05 - val_loss: 1.1312e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3550e-05 - val_loss: 1.1532e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.3475e-05 - val_loss: 1.1328e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.3410e-05 - val_loss: 1.1410e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.3339e-05 - val_loss: 1.1551e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3266e-05 - val_loss: 1.1202e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3189e-05 - val_loss: 1.1048e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3102e-05 - val_loss: 1.0944e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.3026e-05 - val_loss: 1.0931e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2949e-05 - val_loss: 1.0878e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2883e-05 - val_loss: 1.1185e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2828e-05 - val_loss: 1.0837e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2764e-05 - val_loss: 1.0979e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2707e-05 - val_loss: 1.0873e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.2637e-05 - val_loss: 1.0704e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.2533e-05 - val_loss: 1.0690e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2461e-05 - val_loss: 1.0606e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2394e-05 - val_loss: 1.0516e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.2323e-05 - val_loss: 1.0455e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.2248e-05 - val_loss: 1.0534e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2228e-05 - val_loss: 1.0353e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2149e-05 - val_loss: 1.0564e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2072e-05 - val_loss: 1.0464e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1989e-05 - val_loss: 1.0372e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1916e-05 - val_loss: 1.0175e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1860e-05 - val_loss: 1.0367e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.1806e-05 - val_loss: 1.0674e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.1754e-05 - val_loss: 1.0636e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1707e-05 - val_loss: 1.0229e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1622e-05 - val_loss: 9.9977e-07\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.1576e-05 - val_loss: 1.0311e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.1479e-05 - val_loss: 1.0331e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1416e-05 - val_loss: 1.0099e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1357e-05 - val_loss: 1.0127e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1301e-05 - val_loss: 9.8535e-07\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1225e-05 - val_loss: 9.7140e-07\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.1157e-05 - val_loss: 9.6874e-07\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1084e-05 - val_loss: 9.6594e-07\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.1026e-05 - val_loss: 9.7051e-07\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0968e-05 - val_loss: 9.7037e-07\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0903e-05 - val_loss: 9.5733e-07\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0850e-05 - val_loss: 9.6846e-07\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0792e-05 - val_loss: 9.7542e-07\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0734e-05 - val_loss: 9.4408e-07\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0661e-05 - val_loss: 9.5493e-07\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0614e-05 - val_loss: 9.5199e-07\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0563e-05 - val_loss: 9.2861e-07\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0489e-05 - val_loss: 9.2264e-07\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0425e-05 - val_loss: 9.1771e-07\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0374e-05 - val_loss: 9.2233e-07\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.0312e-05 - val_loss: 9.1123e-07\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0257e-05 - val_loss: 9.2213e-07\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.0211e-05 - val_loss: 9.2401e-07\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.0141e-05 - val_loss: 9.2292e-07\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0086e-05 - val_loss: 8.9497e-07\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0035e-05 - val_loss: 9.1223e-07\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.9758e-06 - val_loss: 8.9117e-07\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.9121e-06 - val_loss: 8.8513e-07\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.8598e-06 - val_loss: 8.9754e-07\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.8067e-06 - val_loss: 8.8556e-07\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.7437e-06 - val_loss: 8.8076e-07\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.6937e-06 - val_loss: 8.7931e-07\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.6342e-06 - val_loss: 8.6293e-07\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.5819e-06 - val_loss: 8.8503e-07\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.5311e-06 - val_loss: 8.5963e-07\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.4748e-06 - val_loss: 8.5750e-07\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.4160e-06 - val_loss: 8.6634e-07\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.3826e-06 - val_loss: 8.4741e-07\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.3235e-06 - val_loss: 8.7457e-07\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.2732e-06 - val_loss: 8.4597e-07\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.2019e-06 - val_loss: 8.3829e-07\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 9.1591e-06 - val_loss: 8.5832e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.1161e-06 - val_loss: 8.4821e-07\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.0557e-06 - val_loss: 8.2809e-07\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 8.9931e-06 - val_loss: 8.1922e-07\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.9445e-06 - val_loss: 8.2375e-07\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.8993e-06 - val_loss: 8.1505e-07\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.8532e-06 - val_loss: 8.4747e-07\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 8.8952e-06 - val_loss: 9.3668e-07\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.7838e-06 - val_loss: 8.3188e-07\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 8.7510e-06 - val_loss: 8.9461e-07\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.6941e-06 - val_loss: 8.0491e-07\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.6300e-06 - val_loss: 8.4134e-07\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.5634e-06 - val_loss: 7.9116e-07\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.5145e-06 - val_loss: 8.1754e-07\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.4652e-06 - val_loss: 7.8409e-07\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.4108e-06 - val_loss: 8.2228e-07\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.4567e-06 - val_loss: 8.8182e-07\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.3516e-06 - val_loss: 7.9981e-07\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.3483e-06 - val_loss: 9.2291e-07\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.2780e-06 - val_loss: 7.9321e-07\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.2111e-06 - val_loss: 7.7261e-07\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.1439e-06 - val_loss: 7.9719e-07\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.1063e-06 - val_loss: 7.6391e-07\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.0432e-06 - val_loss: 7.5954e-07\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.9956e-06 - val_loss: 7.6157e-07\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.9567e-06 - val_loss: 7.5312e-07\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 7.9075e-06 - val_loss: 7.5093e-07\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.8664e-06 - val_loss: 7.5866e-07\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.8275e-06 - val_loss: 7.6585e-07\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.8242e-06 - val_loss: 7.6636e-07\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.7443e-06 - val_loss: 7.6874e-07\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.7140e-06 - val_loss: 7.3656e-07\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.6521e-06 - val_loss: 7.4241e-07\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.6353e-06 - val_loss: 7.7710e-07\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.5959e-06 - val_loss: 7.4074e-07\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.5368e-06 - val_loss: 7.3583e-07\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.4911e-06 - val_loss: 7.2113e-07\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.4447e-06 - val_loss: 7.1775e-07\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.4348e-06 - val_loss: 8.3919e-07\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.4906e-06 - val_loss: 8.0514e-07\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3589e-06 - val_loss: 7.3110e-07\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.3156e-06 - val_loss: 7.2507e-07\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.2507e-06 - val_loss: 7.0815e-07\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.2133e-06 - val_loss: 7.3126e-07\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.1949e-06 - val_loss: 7.3277e-07\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1504e-06 - val_loss: 7.0177e-07\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1015e-06 - val_loss: 7.4020e-07\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.0900e-06 - val_loss: 7.2560e-07\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.0629e-06 - val_loss: 7.0848e-07\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 6.9835e-06 - val_loss: 6.8994e-07\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.9408e-06 - val_loss: 6.8879e-07\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.9325e-06 - val_loss: 7.3326e-07\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.9178e-06 - val_loss: 7.2256e-07\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.8589e-06 - val_loss: 6.8582e-07\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.8011e-06 - val_loss: 6.8676e-07\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.7862e-06 - val_loss: 7.0681e-07\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.7631e-06 - val_loss: 7.2756e-07\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.7449e-06 - val_loss: 6.8719e-07\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.6718e-06 - val_loss: 6.7845e-07\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.6334e-06 - val_loss: 6.7314e-07\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.5935e-06 - val_loss: 6.6369e-07\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.5560e-06 - val_loss: 6.7130e-07\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.5415e-06 - val_loss: 7.0825e-07\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.5320e-06 - val_loss: 7.0045e-07\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.4722e-06 - val_loss: 6.5235e-07\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.4274e-06 - val_loss: 6.8711e-07\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.4136e-06 - val_loss: 6.5729e-07\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.3607e-06 - val_loss: 6.8477e-07\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.3617e-06 - val_loss: 6.8222e-07\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.2997e-06 - val_loss: 6.4415e-07\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.2568e-06 - val_loss: 6.4618e-07\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.2454e-06 - val_loss: 7.2054e-07\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.3399e-06 - val_loss: 7.9803e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.2453e-06 - val_loss: 6.3413e-07\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.1537e-06 - val_loss: 7.0768e-07\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.1386e-06 - val_loss: 6.3185e-07\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.0773e-06 - val_loss: 6.4670e-07\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.0539e-06 - val_loss: 6.4170e-07\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.0137e-06 - val_loss: 6.5415e-07\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.0494e-06 - val_loss: 7.0531e-07\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.9851e-06 - val_loss: 6.2342e-07\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 5.9517e-06 - val_loss: 6.9916e-07\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.9469e-06 - val_loss: 6.2302e-07\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.8675e-06 - val_loss: 6.4370e-07\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.8576e-06 - val_loss: 6.1350e-07\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.8162e-06 - val_loss: 6.5868e-07\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.8126e-06 - val_loss: 6.2058e-07\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.7545e-06 - val_loss: 6.4483e-07\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.7537e-06 - val_loss: 6.0547e-07\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.7038e-06 - val_loss: 6.3245e-07\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.7003e-06 - val_loss: 6.2905e-07\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.6462e-06 - val_loss: 6.0530e-07\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.6237e-06 - val_loss: 6.2045e-07\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.5907e-06 - val_loss: 6.0162e-07\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.5695e-06 - val_loss: 6.0907e-07\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.5533e-06 - val_loss: 6.2427e-07\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.5231e-06 - val_loss: 5.9525e-07\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.4763e-06 - val_loss: 5.9384e-07\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.4608e-06 - val_loss: 6.0993e-07\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.4462e-06 - val_loss: 6.0913e-07\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.4082e-06 - val_loss: 5.8387e-07\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3874e-06 - val_loss: 6.6686e-07\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 5.4775e-06 - val_loss: 7.6025e-07\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.4674e-06 - val_loss: 6.4351e-07\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.3122e-06 - val_loss: 6.0599e-07\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.3444e-06 - val_loss: 6.7716e-07\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.2840e-06 - val_loss: 5.8660e-07\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.2517e-06 - val_loss: 6.2232e-07\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.2173e-06 - val_loss: 5.8263e-07\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.1695e-06 - val_loss: 5.7696e-07\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.1561e-06 - val_loss: 5.8689e-07\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.1306e-06 - val_loss: 5.8477e-07\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.1006e-06 - val_loss: 5.7188e-07\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.0888e-06 - val_loss: 6.0017e-07\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.0603e-06 - val_loss: 5.6563e-07\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.0295e-06 - val_loss: 5.8440e-07\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.0202e-06 - val_loss: 5.9977e-07\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.0098e-06 - val_loss: 5.9221e-07\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.9887e-06 - val_loss: 5.9421e-07\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 4.9386e-06 - val_loss: 5.7197e-07\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.9367e-06 - val_loss: 6.0824e-07\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.9549e-06 - val_loss: 6.4255e-07\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.9094e-06 - val_loss: 5.6267e-07\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 4.8429e-06 - val_loss: 5.8246e-07\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.8490e-06 - val_loss: 5.5985e-07\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.7952e-06 - val_loss: 5.5706e-07\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.7876e-06 - val_loss: 5.8643e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.7949e-06 - val_loss: 5.8070e-07\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7435e-06 - val_loss: 5.4730e-07\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.7076e-06 - val_loss: 5.4787e-07\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.6935e-06 - val_loss: 5.6752e-07\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.6829e-06 - val_loss: 5.4975e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.6480e-06 - val_loss: 5.4470e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.6357e-06 - val_loss: 5.6913e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.6389e-06 - val_loss: 5.6783e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.5944e-06 - val_loss: 5.3946e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.5918e-06 - val_loss: 6.4570e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.7089e-06 - val_loss: 7.4237e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.6819e-06 - val_loss: 5.7743e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.5158e-06 - val_loss: 5.5822e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.5154e-06 - val_loss: 5.4602e-07\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4665e-06 - val_loss: 5.3162e-07\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.4424e-06 - val_loss: 5.3518e-07\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.4391e-06 - val_loss: 5.7593e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.4511e-06 - val_loss: 5.4402e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.3935e-06 - val_loss: 5.4719e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.4268e-06 - val_loss: 6.0554e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.3954e-06 - val_loss: 5.2872e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.3335e-06 - val_loss: 5.4096e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.3376e-06 - val_loss: 5.4792e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.3131e-06 - val_loss: 5.2740e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.2794e-06 - val_loss: 5.2135e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.2586e-06 - val_loss: 5.1909e-07\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.2394e-06 - val_loss: 5.2086e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.2294e-06 - val_loss: 5.2804e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.2290e-06 - val_loss: 5.6467e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.2499e-06 - val_loss: 5.8309e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.2287e-06 - val_loss: 5.6291e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.1994e-06 - val_loss: 5.4598e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.1519e-06 - val_loss: 5.1892e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.1229e-06 - val_loss: 5.1221e-07\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.1072e-06 - val_loss: 5.2177e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0993e-06 - val_loss: 5.2647e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.0881e-06 - val_loss: 5.2449e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.0745e-06 - val_loss: 5.4512e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.0877e-06 - val_loss: 5.8193e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.1051e-06 - val_loss: 5.9062e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.0699e-06 - val_loss: 5.2533e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.9959e-06 - val_loss: 5.0186e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.9716e-06 - val_loss: 5.0292e-07\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.9599e-06 - val_loss: 5.0846e-07\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.9488e-06 - val_loss: 5.0964e-07\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.9397e-06 - val_loss: 5.1686e-07\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.9254e-06 - val_loss: 5.1087e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.9003e-06 - val_loss: 4.9898e-07\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.8809e-06 - val_loss: 4.9978e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.8677e-06 - val_loss: 4.9850e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8551e-06 - val_loss: 5.1529e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.9012e-06 - val_loss: 6.4927e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.1172e-06 - val_loss: 9.8277e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.1664e-06 - val_loss: 5.4346e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8380e-06 - val_loss: 6.3287e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.8554e-06 - val_loss: 4.9031e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.7932e-06 - val_loss: 5.3070e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.7646e-06 - val_loss: 5.0975e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.7736e-06 - val_loss: 5.1874e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.7319e-06 - val_loss: 4.9281e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.7151e-06 - val_loss: 4.9154e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.6943e-06 - val_loss: 4.8471e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.6803e-06 - val_loss: 4.9171e-07\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.6776e-06 - val_loss: 4.9791e-07\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.6594e-06 - val_loss: 4.8344e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.6443e-06 - val_loss: 4.8821e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.6307e-06 - val_loss: 4.8813e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.6173e-06 - val_loss: 4.8027e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 3.6005e-06 - val_loss: 4.8423e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.5934e-06 - val_loss: 4.9122e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.5882e-06 - val_loss: 4.9349e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.5801e-06 - val_loss: 5.1343e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.5902e-06 - val_loss: 5.2553e-07\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.5733e-06 - val_loss: 4.9155e-07\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.5294e-06 - val_loss: 4.7539e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.5262e-06 - val_loss: 5.1848e-07\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5514e-06 - val_loss: 5.2035e-07\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.5100e-06 - val_loss: 4.7577e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 3.4765e-06 - val_loss: 4.9497e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 3.5259e-06 - val_loss: 5.9422e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 3.5653e-06 - val_loss: 5.4207e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.4785e-06 - val_loss: 4.7447e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.4270e-06 - val_loss: 4.6901e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.4160e-06 - val_loss: 4.7759e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.4130e-06 - val_loss: 4.7503e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.3927e-06 - val_loss: 4.6761e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 848us/step - loss: 3.3811e-06 - val_loss: 4.6960e-07\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100, 6)            192       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100, 1)            7         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 199\n",
      "Trainable params: 199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1031 - val_loss: 0.1009\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0994 - val_loss: 0.0973\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0959 - val_loss: 0.0941\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0930 - val_loss: 0.0915\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0906 - val_loss: 0.0894\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0887 - val_loss: 0.0877\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0871 - val_loss: 0.0862\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0856 - val_loss: 0.0849\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0830 - val_loss: 0.0822\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0816 - val_loss: 0.0809\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0802 - val_loss: 0.0795\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0788 - val_loss: 0.0780\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0774 - val_loss: 0.0766\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0760 - val_loss: 0.0751\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0745 - val_loss: 0.0736\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0729 - val_loss: 0.0720\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0713 - val_loss: 0.0703\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0696 - val_loss: 0.0686\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0678 - val_loss: 0.0667\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0658 - val_loss: 0.0647\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0638 - val_loss: 0.0625\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0615 - val_loss: 0.0602\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0591 - val_loss: 0.0576\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0565 - val_loss: 0.0549\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0537 - val_loss: 0.0521\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0508 - val_loss: 0.0492\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0481 - val_loss: 0.0466\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0455 - val_loss: 0.0442\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0432 - val_loss: 0.0420\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0411 - val_loss: 0.0399\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0390 - val_loss: 0.0379\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0370 - val_loss: 0.0360\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0351 - val_loss: 0.0340\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0331 - val_loss: 0.0321\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0313 - val_loss: 0.0303\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0294 - val_loss: 0.0285\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0276 - val_loss: 0.0267\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0259 - val_loss: 0.0250\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0242 - val_loss: 0.0233\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0225 - val_loss: 0.0217\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0209 - val_loss: 0.0201\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0193 - val_loss: 0.0186\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0179 - val_loss: 0.0171\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0164 - val_loss: 0.0157\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0138 - val_loss: 0.0132\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0010 - val_loss: 9.8434e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.8850e-04 - val_loss: 9.6758e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.7295e-04 - val_loss: 9.5093e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 9.5750e-04 - val_loss: 9.3441e-04\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 781us/step - loss: 9.4209e-04 - val_loss: 9.1810e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.2700e-04 - val_loss: 9.0189e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.1192e-04 - val_loss: 8.8588e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.9709e-04 - val_loss: 8.6999e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.8226e-04 - val_loss: 8.5433e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.6780e-04 - val_loss: 8.3875e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.5333e-04 - val_loss: 8.2337e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.3904e-04 - val_loss: 8.0816e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 8.2497e-04 - val_loss: 7.9308e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.1103e-04 - val_loss: 7.7814e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.9721e-04 - val_loss: 7.6339e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.8355e-04 - val_loss: 7.4881e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.7005e-04 - val_loss: 7.3440e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.5674e-04 - val_loss: 7.2014e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.4359e-04 - val_loss: 7.0603e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 7.3054e-04 - val_loss: 6.9210e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.1768e-04 - val_loss: 6.7835e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.0490e-04 - val_loss: 6.6483e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.9242e-04 - val_loss: 6.5143e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.8000e-04 - val_loss: 6.3822e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.6792e-04 - val_loss: 6.2509e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.5580e-04 - val_loss: 6.1217e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.4387e-04 - val_loss: 5.9944e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.3217e-04 - val_loss: 5.8686e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 6.2053e-04 - val_loss: 5.7451e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.0918e-04 - val_loss: 5.6227e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.9789e-04 - val_loss: 5.5023e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.8685e-04 - val_loss: 5.3833e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.7591e-04 - val_loss: 5.2661e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.6517e-04 - val_loss: 5.1504e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.5453e-04 - val_loss: 5.0368e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.4412e-04 - val_loss: 4.9247e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.3379e-04 - val_loss: 4.8146e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.2368e-04 - val_loss: 4.7062e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.1374e-04 - val_loss: 4.5993e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.0392e-04 - val_loss: 4.4943e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.9434e-04 - val_loss: 4.3907e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.8483e-04 - val_loss: 4.2889e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.7552e-04 - val_loss: 4.1888e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.6638e-04 - val_loss: 4.0902e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.5736e-04 - val_loss: 3.9934e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.4855e-04 - val_loss: 3.8982e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.3988e-04 - val_loss: 3.8045e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.3130e-04 - val_loss: 3.7128e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.2290e-04 - val_loss: 3.6231e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.1471e-04 - val_loss: 3.5347e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.0665e-04 - val_loss: 3.4480e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.9874e-04 - val_loss: 3.3629e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.9102e-04 - val_loss: 3.2791e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.8338e-04 - val_loss: 3.1972e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.7589e-04 - val_loss: 3.1172e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.6859e-04 - val_loss: 3.0387e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.6150e-04 - val_loss: 2.9610e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.5443e-04 - val_loss: 2.8854e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.4759e-04 - val_loss: 2.8111e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.4085e-04 - val_loss: 2.7386e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.3425e-04 - val_loss: 2.6676e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.2784e-04 - val_loss: 2.5978e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.2152e-04 - val_loss: 2.5298e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.1536e-04 - val_loss: 2.4632e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.0933e-04 - val_loss: 2.3980e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 3.0675e-0 - 1s 754us/step - loss: 3.0342e-04 - val_loss: 2.3345e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 2.9769e-04 - val_loss: 2.2721e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.9205e-04 - val_loss: 2.2112e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.8656e-04 - val_loss: 2.1516e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.8119e-04 - val_loss: 2.0935e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.7592e-04 - val_loss: 2.0370e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.7080e-04 - val_loss: 1.9819e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6583e-04 - val_loss: 1.9278e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.6096e-04 - val_loss: 1.8750e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.5620e-04 - val_loss: 1.8235e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.5157e-04 - val_loss: 1.7733e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.4704e-04 - val_loss: 1.7243e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.4264e-04 - val_loss: 1.6766e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.3833e-04 - val_loss: 1.6302e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.3416e-04 - val_loss: 1.5849e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.3009e-04 - val_loss: 1.5408e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2612e-04 - val_loss: 1.4977e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2227e-04 - val_loss: 1.4555e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.1847e-04 - val_loss: 1.4148e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1482e-04 - val_loss: 1.3751e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1125e-04 - val_loss: 1.3366e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.0777e-04 - val_loss: 1.2993e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0441e-04 - val_loss: 1.2627e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.0112e-04 - val_loss: 1.2271e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.9793e-04 - val_loss: 1.1925e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.9482e-04 - val_loss: 1.1589e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.9179e-04 - val_loss: 1.1263e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.8886e-04 - val_loss: 1.0946e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.8601e-04 - val_loss: 1.0638e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.8323e-04 - val_loss: 1.0340e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8055e-04 - val_loss: 1.0047e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.7792e-04 - val_loss: 9.7638e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.7538e-04 - val_loss: 9.4899e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7291e-04 - val_loss: 9.2240e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.7050e-04 - val_loss: 8.9664e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.6818e-04 - val_loss: 8.7145e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6591e-04 - val_loss: 8.4715e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.6371e-04 - val_loss: 8.2357e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6157e-04 - val_loss: 8.0074e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5950e-04 - val_loss: 7.7876e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5750e-04 - val_loss: 7.5704e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5553e-04 - val_loss: 7.3627e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5363e-04 - val_loss: 7.1597e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5179e-04 - val_loss: 6.9626e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.5000e-04 - val_loss: 6.7720e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.4825e-04 - val_loss: 6.5891e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.4657e-04 - val_loss: 6.4110e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.4494e-04 - val_loss: 6.2369e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 1.4334e-04 - val_loss: 6.0698e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.4180e-04 - val_loss: 5.9083e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4030e-04 - val_loss: 5.7518e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3884e-04 - val_loss: 5.6000e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.3742e-04 - val_loss: 5.4538e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3604e-04 - val_loss: 5.3105e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.3470e-04 - val_loss: 5.1714e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3341e-04 - val_loss: 5.0353e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3214e-04 - val_loss: 4.9069e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.3091e-04 - val_loss: 4.7812e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2972e-04 - val_loss: 4.6603e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2856e-04 - val_loss: 4.5421e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.2743e-04 - val_loss: 4.4300e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2633e-04 - val_loss: 4.3208e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2527e-04 - val_loss: 4.2135e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2423e-04 - val_loss: 4.1104e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2321e-04 - val_loss: 4.0094e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.2223e-04 - val_loss: 3.9134e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2127e-04 - val_loss: 3.8197e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.2034e-04 - val_loss: 3.7287e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.1943e-04 - val_loss: 3.6413e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1854e-04 - val_loss: 3.5563e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1767e-04 - val_loss: 3.4738e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.1683e-04 - val_loss: 3.3926e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.1601e-04 - val_loss: 3.3166e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1521e-04 - val_loss: 3.2396e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1442e-04 - val_loss: 3.1662e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1366e-04 - val_loss: 3.0968e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.1291e-04 - val_loss: 3.0287e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1218e-04 - val_loss: 2.9633e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1147e-04 - val_loss: 2.8997e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1078e-04 - val_loss: 2.8389e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1009e-04 - val_loss: 2.7790e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0943e-04 - val_loss: 2.7219e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0877e-04 - val_loss: 2.6651e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0814e-04 - val_loss: 2.6114e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0751e-04 - val_loss: 2.5591e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0690e-04 - val_loss: 2.5078e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0630e-04 - val_loss: 2.4586e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0571e-04 - val_loss: 2.4108e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0514e-04 - val_loss: 2.3660e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0456e-04 - val_loss: 2.3198e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0401e-04 - val_loss: 2.2765e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0346e-04 - val_loss: 2.2334e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0293e-04 - val_loss: 2.1922e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 1.0240e-04 - val_loss: 2.1508e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.0188e-04 - val_loss: 2.1125e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0138e-04 - val_loss: 2.0767e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0087e-04 - val_loss: 2.0401e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0038e-04 - val_loss: 2.0058e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.9889e-05 - val_loss: 1.9698e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.9416e-05 - val_loss: 1.9367e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.8944e-05 - val_loss: 1.9046e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.8477e-05 - val_loss: 1.8727e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.8021e-05 - val_loss: 1.8419e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.7571e-05 - val_loss: 1.8122e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.7134e-05 - val_loss: 1.7840e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.6690e-05 - val_loss: 1.7561e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.6256e-05 - val_loss: 1.7284e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.5835e-05 - val_loss: 1.7028e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.5411e-05 - val_loss: 1.6779e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.4984e-05 - val_loss: 1.6512e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.4585e-05 - val_loss: 1.6280e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.4178e-05 - val_loss: 1.6057e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 9.3762e-05 - val_loss: 1.5817e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.3366e-05 - val_loss: 1.5584e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.2967e-05 - val_loss: 1.5352e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.2583e-05 - val_loss: 1.5136e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.2204e-05 - val_loss: 1.4935e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.1819e-05 - val_loss: 1.4738e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.1434e-05 - val_loss: 1.4537e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.1060e-05 - val_loss: 1.4338e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.0688e-05 - val_loss: 1.4147e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.0336e-05 - val_loss: 1.3977e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.9957e-05 - val_loss: 1.3793e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.9603e-05 - val_loss: 1.3629e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 8.9237e-05 - val_loss: 1.3455e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.8884e-05 - val_loss: 1.3290e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.8536e-05 - val_loss: 1.3139e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.8183e-05 - val_loss: 1.2984e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.7834e-05 - val_loss: 1.2827e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.7504e-05 - val_loss: 1.2693e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.7152e-05 - val_loss: 1.2551e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.6813e-05 - val_loss: 1.2412e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.6473e-05 - val_loss: 1.2272e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.6148e-05 - val_loss: 1.2148e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.5804e-05 - val_loss: 1.2009e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.5474e-05 - val_loss: 1.1877e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.5143e-05 - val_loss: 1.1742e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.4832e-05 - val_loss: 1.1630e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.4489e-05 - val_loss: 1.1492e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 8.4169e-05 - val_loss: 1.1367e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.3851e-05 - val_loss: 1.1250e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.3545e-05 - val_loss: 1.1146e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.3228e-05 - val_loss: 1.1038e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.2898e-05 - val_loss: 1.0923e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.2591e-05 - val_loss: 1.0816e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.2284e-05 - val_loss: 1.0716e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.1978e-05 - val_loss: 1.0624e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.1652e-05 - val_loss: 1.0502e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.1355e-05 - val_loss: 1.0399e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.1065e-05 - val_loss: 1.0319e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.0746e-05 - val_loss: 1.0223e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.0453e-05 - val_loss: 1.0140e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0146e-05 - val_loss: 1.0048e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 7.9852e-05 - val_loss: 9.9664e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.9549e-05 - val_loss: 9.8772e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.9254e-05 - val_loss: 9.7911e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.8954e-05 - val_loss: 9.6942e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 7.8670e-05 - val_loss: 9.6169e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.8380e-05 - val_loss: 9.5446e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 7.8086e-05 - val_loss: 9.4689e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.7794e-05 - val_loss: 9.3896e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.7504e-05 - val_loss: 9.3116e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.7213e-05 - val_loss: 9.2289e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.6936e-05 - val_loss: 9.1593e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.6647e-05 - val_loss: 9.0885e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.6361e-05 - val_loss: 9.0169e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.6081e-05 - val_loss: 8.9468e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.5803e-05 - val_loss: 8.8832e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.5519e-05 - val_loss: 8.8202e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.5244e-05 - val_loss: 8.7572e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.4955e-05 - val_loss: 8.6831e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.4683e-05 - val_loss: 8.6179e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 7.4401e-05 - val_loss: 8.5485e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.4135e-05 - val_loss: 8.4945e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.3864e-05 - val_loss: 8.4378e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3583e-05 - val_loss: 8.3778e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.3314e-05 - val_loss: 8.3227e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.3034e-05 - val_loss: 8.2559e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.2764e-05 - val_loss: 8.1889e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.2512e-05 - val_loss: 8.1463e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.2230e-05 - val_loss: 8.0878e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.1967e-05 - val_loss: 8.0343e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.1699e-05 - val_loss: 7.9837e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.1429e-05 - val_loss: 7.9233e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1179e-05 - val_loss: 7.8850e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.0904e-05 - val_loss: 7.8332e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 7.0642e-05 - val_loss: 7.7854e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.0373e-05 - val_loss: 7.7302e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.0121e-05 - val_loss: 7.6815e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.9860e-05 - val_loss: 7.6329e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.9598e-05 - val_loss: 7.5868e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.9343e-05 - val_loss: 7.5465e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.9077e-05 - val_loss: 7.4975e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.8834e-05 - val_loss: 7.4628e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8561e-05 - val_loss: 7.4108e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.8298e-05 - val_loss: 7.3517e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.8051e-05 - val_loss: 7.3033e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.7802e-05 - val_loss: 7.2650e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.7560e-05 - val_loss: 7.2372e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.7291e-05 - val_loss: 7.1913e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.7034e-05 - val_loss: 7.1418e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.6802e-05 - val_loss: 7.1098e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.6537e-05 - val_loss: 7.0685e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.6282e-05 - val_loss: 7.0146e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.6041e-05 - val_loss: 6.9775e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.5790e-05 - val_loss: 6.9335e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.5540e-05 - val_loss: 6.8882e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.5308e-05 - val_loss: 6.8646e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.5048e-05 - val_loss: 6.8244e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.4813e-05 - val_loss: 6.7987e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.4562e-05 - val_loss: 6.7644e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.4319e-05 - val_loss: 6.7295e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.4060e-05 - val_loss: 6.6751e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.3823e-05 - val_loss: 6.6246e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.3595e-05 - val_loss: 6.6009e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.3341e-05 - val_loss: 6.5625e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.3100e-05 - val_loss: 6.5273e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.2863e-05 - val_loss: 6.4989e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.2625e-05 - val_loss: 6.4673e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.2380e-05 - val_loss: 6.4270e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.2151e-05 - val_loss: 6.3944e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.1912e-05 - val_loss: 6.3670e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.1663e-05 - val_loss: 6.3262e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.1446e-05 - val_loss: 6.3093e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.1194e-05 - val_loss: 6.2713e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 6.5277e-0 - 1s 747us/step - loss: 6.0965e-05 - val_loss: 6.2433e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.0719e-05 - val_loss: 6.2056e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 6.0486e-05 - val_loss: 6.1687e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.0267e-05 - val_loss: 6.1447e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 6.0019e-05 - val_loss: 6.1042e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.9796e-05 - val_loss: 6.0797e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.9563e-05 - val_loss: 6.0530e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9322e-05 - val_loss: 6.0125e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9098e-05 - val_loss: 5.9842e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.8876e-05 - val_loss: 5.9630e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.8633e-05 - val_loss: 5.9296e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.8409e-05 - val_loss: 5.8966e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.8173e-05 - val_loss: 5.8597e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.7954e-05 - val_loss: 5.8340e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.7729e-05 - val_loss: 5.8117e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.7497e-05 - val_loss: 5.7832e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.7274e-05 - val_loss: 5.7552e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.7058e-05 - val_loss: 5.7369e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.6817e-05 - val_loss: 5.7033e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.6598e-05 - val_loss: 5.6736e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.6370e-05 - val_loss: 5.6353e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.6158e-05 - val_loss: 5.6174e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.5930e-05 - val_loss: 5.5920e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.5707e-05 - val_loss: 5.5682e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.5483e-05 - val_loss: 5.5392e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.5257e-05 - val_loss: 5.5086e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.5047e-05 - val_loss: 5.4879e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.4824e-05 - val_loss: 5.4631e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.4604e-05 - val_loss: 5.4399e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.4394e-05 - val_loss: 5.4238e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.4162e-05 - val_loss: 5.3949e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.3954e-05 - val_loss: 5.3741e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.3739e-05 - val_loss: 5.3547e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.3506e-05 - val_loss: 5.3166e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.3297e-05 - val_loss: 5.2914e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.3090e-05 - val_loss: 5.2740e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.2858e-05 - val_loss: 5.2346e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.2652e-05 - val_loss: 5.2119e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.2437e-05 - val_loss: 5.1894e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.2222e-05 - val_loss: 5.1624e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.2013e-05 - val_loss: 5.1391e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.1787e-05 - val_loss: 5.0995e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.1588e-05 - val_loss: 5.0820e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.1372e-05 - val_loss: 5.0596e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.1162e-05 - val_loss: 5.0317e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.0948e-05 - val_loss: 5.0041e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.0742e-05 - val_loss: 4.9865e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.0534e-05 - val_loss: 4.9684e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.0328e-05 - val_loss: 4.9535e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.0114e-05 - val_loss: 4.9337e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.9907e-05 - val_loss: 4.9088e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.9698e-05 - val_loss: 4.8887e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.9493e-05 - val_loss: 4.8703e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.9283e-05 - val_loss: 4.8444e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.9075e-05 - val_loss: 4.8157e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.8871e-05 - val_loss: 4.7926e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.8672e-05 - val_loss: 4.7742e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.8463e-05 - val_loss: 4.7512e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 4.8257e-05 - val_loss: 4.7248e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.8056e-05 - val_loss: 4.7032e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.7855e-05 - val_loss: 4.6841e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.7648e-05 - val_loss: 4.6619e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.7454e-05 - val_loss: 4.6473e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7244e-05 - val_loss: 4.6271e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.7057e-05 - val_loss: 4.6158e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.6849e-05 - val_loss: 4.5929e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.6645e-05 - val_loss: 4.5721e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.6446e-05 - val_loss: 4.5490e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6237e-05 - val_loss: 4.5104e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6048e-05 - val_loss: 4.4875e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.5856e-05 - val_loss: 4.4724e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.5649e-05 - val_loss: 4.4472e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.5460e-05 - val_loss: 4.4346e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.5268e-05 - val_loss: 4.4255e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.5063e-05 - val_loss: 4.4084e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.4865e-05 - val_loss: 4.3861e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.4676e-05 - val_loss: 4.3661e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.4479e-05 - val_loss: 4.3481e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.4279e-05 - val_loss: 4.3187e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.4085e-05 - val_loss: 4.2908e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.3892e-05 - val_loss: 4.2665e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.3706e-05 - val_loss: 4.2506e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.3518e-05 - val_loss: 4.2421e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.3314e-05 - val_loss: 4.2182e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.3129e-05 - val_loss: 4.1983e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.2934e-05 - val_loss: 4.1732e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.2752e-05 - val_loss: 4.1567e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.2556e-05 - val_loss: 4.1353e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.2372e-05 - val_loss: 4.1210e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.2186e-05 - val_loss: 4.1107e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.1991e-05 - val_loss: 4.0889e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.1806e-05 - val_loss: 4.0700e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.1626e-05 - val_loss: 4.0583e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.1435e-05 - val_loss: 4.0387e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.1252e-05 - val_loss: 4.0165e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.1059e-05 - val_loss: 3.9962e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.0871e-05 - val_loss: 3.9742e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.0698e-05 - val_loss: 3.9629e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.0505e-05 - val_loss: 3.9432e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.0316e-05 - val_loss: 3.9187e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.0134e-05 - val_loss: 3.8930e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.9963e-05 - val_loss: 3.8842e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9786e-05 - val_loss: 3.8791e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.9589e-05 - val_loss: 3.8609e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.9411e-05 - val_loss: 3.8377e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.9237e-05 - val_loss: 3.8211e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.9049e-05 - val_loss: 3.7981e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.8871e-05 - val_loss: 3.7829e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.8690e-05 - val_loss: 3.7678e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.8519e-05 - val_loss: 3.7515e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.8338e-05 - val_loss: 3.7343e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.8161e-05 - val_loss: 3.7194e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7980e-05 - val_loss: 3.6999e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.7804e-05 - val_loss: 3.6866e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.7629e-05 - val_loss: 3.6665e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.7449e-05 - val_loss: 3.6465e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.7280e-05 - val_loss: 3.6343e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.7100e-05 - val_loss: 3.6136e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.6923e-05 - val_loss: 3.5987e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.6768e-05 - val_loss: 3.5888e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.6571e-05 - val_loss: 3.5576e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.6421e-05 - val_loss: 3.5559e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 3.6235e-05 - val_loss: 3.5399e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.6062e-05 - val_loss: 3.5184e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5889e-05 - val_loss: 3.4958e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.5720e-05 - val_loss: 3.4770e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5553e-05 - val_loss: 3.4672e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 3.5379e-05 - val_loss: 3.4443e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.5209e-05 - val_loss: 3.4209e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.5042e-05 - val_loss: 3.4045e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.4891e-05 - val_loss: 3.4075e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.4710e-05 - val_loss: 3.3957e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.4540e-05 - val_loss: 3.3769e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.4374e-05 - val_loss: 3.3623e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.4208e-05 - val_loss: 3.3458e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.4042e-05 - val_loss: 3.3280e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.3879e-05 - val_loss: 3.3115e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.3718e-05 - val_loss: 3.3011e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.3540e-05 - val_loss: 3.2743e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.3394e-05 - val_loss: 3.2684e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.3222e-05 - val_loss: 3.2494e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.3059e-05 - val_loss: 3.2370e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.2901e-05 - val_loss: 3.2273e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2740e-05 - val_loss: 3.2153e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.2567e-05 - val_loss: 3.1906e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.2412e-05 - val_loss: 3.1746e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.2255e-05 - val_loss: 3.1611e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.2095e-05 - val_loss: 3.1476e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.1933e-05 - val_loss: 3.1307e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.1777e-05 - val_loss: 3.1202e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.1613e-05 - val_loss: 3.0983e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 3.1459e-05 - val_loss: 3.0863e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.1309e-05 - val_loss: 3.0771e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.1149e-05 - val_loss: 3.0656e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.0993e-05 - val_loss: 3.0566e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.0832e-05 - val_loss: 3.0308e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.0676e-05 - val_loss: 3.0128e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.0528e-05 - val_loss: 3.0026e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.0378e-05 - val_loss: 2.9986e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.0214e-05 - val_loss: 2.9750e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.0066e-05 - val_loss: 2.9625e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.9909e-05 - val_loss: 2.9471e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9766e-05 - val_loss: 2.9403e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.9607e-05 - val_loss: 2.9250e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.9455e-05 - val_loss: 2.9048e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.9314e-05 - val_loss: 2.9017e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.9152e-05 - val_loss: 2.8767e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.9010e-05 - val_loss: 2.8663e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.8859e-05 - val_loss: 2.8537e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.8713e-05 - val_loss: 2.8464e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.8560e-05 - val_loss: 2.8302e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.8415e-05 - val_loss: 2.8172e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.8269e-05 - val_loss: 2.8052e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.8124e-05 - val_loss: 2.7941e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.7975e-05 - val_loss: 2.7806e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.7833e-05 - val_loss: 2.7688e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.7683e-05 - val_loss: 2.7510e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.7538e-05 - val_loss: 2.7327e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.7399e-05 - val_loss: 2.7221e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.7261e-05 - val_loss: 2.7180e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.7122e-05 - val_loss: 2.7127e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.6983e-05 - val_loss: 2.7089e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.6822e-05 - val_loss: 2.6840e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6687e-05 - val_loss: 2.6635e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.6554e-05 - val_loss: 2.6586e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6397e-05 - val_loss: 2.6321e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.6267e-05 - val_loss: 2.6231e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6122e-05 - val_loss: 2.6052e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5986e-05 - val_loss: 2.5912e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.5847e-05 - val_loss: 2.5777e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.5713e-05 - val_loss: 2.5749e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5581e-05 - val_loss: 2.5632e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5438e-05 - val_loss: 2.5564e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.5310e-05 - val_loss: 2.5514e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.5168e-05 - val_loss: 2.5227e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.5035e-05 - val_loss: 2.5133e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.4903e-05 - val_loss: 2.5094e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.4768e-05 - val_loss: 2.4972e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4627e-05 - val_loss: 2.4820e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.4501e-05 - val_loss: 2.4766e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.4363e-05 - val_loss: 2.4629e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.4227e-05 - val_loss: 2.4450e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.4100e-05 - val_loss: 2.4338e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.3969e-05 - val_loss: 2.4203e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3841e-05 - val_loss: 2.4129e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3710e-05 - val_loss: 2.4031e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.3579e-05 - val_loss: 2.3897e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.3449e-05 - val_loss: 2.3777e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.3327e-05 - val_loss: 2.3692e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.3193e-05 - val_loss: 2.3572e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3065e-05 - val_loss: 2.3431e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2945e-05 - val_loss: 2.3341e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2815e-05 - val_loss: 2.3257e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.2688e-05 - val_loss: 2.3164e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2564e-05 - val_loss: 2.3042e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.2437e-05 - val_loss: 2.2927e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2319e-05 - val_loss: 2.2839e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.2193e-05 - val_loss: 2.2743e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2071e-05 - val_loss: 2.2670e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.1942e-05 - val_loss: 2.2507e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.1824e-05 - val_loss: 2.2442e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1700e-05 - val_loss: 2.2283e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.1581e-05 - val_loss: 2.2204e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1459e-05 - val_loss: 2.2091e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.1334e-05 - val_loss: 2.1939e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1226e-05 - val_loss: 2.1915e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1098e-05 - val_loss: 2.1790e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0978e-05 - val_loss: 2.1649e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0867e-05 - val_loss: 2.1577e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0745e-05 - val_loss: 2.1477e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.0627e-05 - val_loss: 2.1363e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0514e-05 - val_loss: 2.1310e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.0393e-05 - val_loss: 2.1116e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.0284e-05 - val_loss: 2.1074e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.0165e-05 - val_loss: 2.0938e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.0050e-05 - val_loss: 2.0852e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.9939e-05 - val_loss: 2.0805e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.9828e-05 - val_loss: 2.0731e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.9710e-05 - val_loss: 2.0641e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.9601e-05 - val_loss: 2.0543e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9483e-05 - val_loss: 2.0374e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.9376e-05 - val_loss: 2.0296e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9269e-05 - val_loss: 2.0267e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.9155e-05 - val_loss: 2.0121e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.9040e-05 - val_loss: 1.9999e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.8933e-05 - val_loss: 1.9876e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.8824e-05 - val_loss: 1.9772e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.8720e-05 - val_loss: 1.9726e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.8605e-05 - val_loss: 1.9604e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.8500e-05 - val_loss: 1.9512e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.8394e-05 - val_loss: 1.9463e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.8288e-05 - val_loss: 1.9319e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8183e-05 - val_loss: 1.9260e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8077e-05 - val_loss: 1.9215e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.7969e-05 - val_loss: 1.9075e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.7864e-05 - val_loss: 1.8949e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.7765e-05 - val_loss: 1.8859e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.7666e-05 - val_loss: 1.8832e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.7555e-05 - val_loss: 1.8724e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.7452e-05 - val_loss: 1.8608e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.7352e-05 - val_loss: 1.8535e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7252e-05 - val_loss: 1.8456e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7152e-05 - val_loss: 1.8396e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7045e-05 - val_loss: 1.8266e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.6947e-05 - val_loss: 1.8184e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.6849e-05 - val_loss: 1.8092e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6749e-05 - val_loss: 1.8004e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6651e-05 - val_loss: 1.7915e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.6552e-05 - val_loss: 1.7836e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.6454e-05 - val_loss: 1.7733e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6359e-05 - val_loss: 1.7663e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.6267e-05 - val_loss: 1.7621e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.6171e-05 - val_loss: 1.7558e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6072e-05 - val_loss: 1.7495e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5973e-05 - val_loss: 1.7367e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5882e-05 - val_loss: 1.7304e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5787e-05 - val_loss: 1.7195e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5696e-05 - val_loss: 1.7126e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.5601e-05 - val_loss: 1.7033e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.5505e-05 - val_loss: 1.6912e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.5413e-05 - val_loss: 1.6818e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.5329e-05 - val_loss: 1.6807e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5235e-05 - val_loss: 1.6802e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5141e-05 - val_loss: 1.6604e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.5056e-05 - val_loss: 1.6562e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4962e-05 - val_loss: 1.6461e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.4874e-05 - val_loss: 1.6403e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4786e-05 - val_loss: 1.6340e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.4696e-05 - val_loss: 1.6254e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4610e-05 - val_loss: 1.6177e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4518e-05 - val_loss: 1.6057e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.4441e-05 - val_loss: 1.6052e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.4348e-05 - val_loss: 1.5976e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.4257e-05 - val_loss: 1.5828e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4178e-05 - val_loss: 1.5797e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4091e-05 - val_loss: 1.5703e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4006e-05 - val_loss: 1.5641e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.3920e-05 - val_loss: 1.5528e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3842e-05 - val_loss: 1.5498e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3757e-05 - val_loss: 1.5458e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3671e-05 - val_loss: 1.5334e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3589e-05 - val_loss: 1.5256e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3509e-05 - val_loss: 1.5167e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3431e-05 - val_loss: 1.5142e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.3348e-05 - val_loss: 1.5085e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.3269e-05 - val_loss: 1.5048e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.3185e-05 - val_loss: 1.4947e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3105e-05 - val_loss: 1.4838e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3028e-05 - val_loss: 1.4768e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2957e-05 - val_loss: 1.4731e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2872e-05 - val_loss: 1.4634e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2793e-05 - val_loss: 1.4567e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.2720e-05 - val_loss: 1.4508e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.2641e-05 - val_loss: 1.4442e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.2565e-05 - val_loss: 1.4397e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.2492e-05 - val_loss: 1.4348e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2411e-05 - val_loss: 1.4251e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2337e-05 - val_loss: 1.4183e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2261e-05 - val_loss: 1.4075e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2187e-05 - val_loss: 1.4003e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2116e-05 - val_loss: 1.3958e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2042e-05 - val_loss: 1.3875e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1968e-05 - val_loss: 1.3805e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1898e-05 - val_loss: 1.3751e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1825e-05 - val_loss: 1.3687e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1761e-05 - val_loss: 1.3707e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.1682e-05 - val_loss: 1.3592e-06\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1609e-05 - val_loss: 1.3488e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.1542e-05 - val_loss: 1.3428e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1476e-05 - val_loss: 1.3373e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1405e-05 - val_loss: 1.3372e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.1338e-05 - val_loss: 1.3275e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1269e-05 - val_loss: 1.3290e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1200e-05 - val_loss: 1.3124e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1131e-05 - val_loss: 1.3100e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.1066e-05 - val_loss: 1.3015e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0996e-05 - val_loss: 1.2912e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0932e-05 - val_loss: 1.2872e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.0865e-05 - val_loss: 1.2817e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0802e-05 - val_loss: 1.2797e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0733e-05 - val_loss: 1.2697e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0673e-05 - val_loss: 1.2682e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0606e-05 - val_loss: 1.2610e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0539e-05 - val_loss: 1.2531e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0477e-05 - val_loss: 1.2435e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.0416e-05 - val_loss: 1.2408e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0354e-05 - val_loss: 1.2349e-06\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0294e-05 - val_loss: 1.2302e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0229e-05 - val_loss: 1.2338e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0170e-05 - val_loss: 1.2185e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0107e-05 - val_loss: 1.2108e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0046e-05 - val_loss: 1.2083e-06\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.9883e-06 - val_loss: 1.2075e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 9.9306e-06 - val_loss: 1.1965e-06\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.8666e-06 - val_loss: 1.1908e-06\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.8079e-06 - val_loss: 1.1881e-06\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.7481e-06 - val_loss: 1.1790e-06\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.6898e-06 - val_loss: 1.1723e-06\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.6357e-06 - val_loss: 1.1719e-06\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.5770e-06 - val_loss: 1.1622e-06\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.5230e-06 - val_loss: 1.1611e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.4647e-06 - val_loss: 1.1521e-06\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.4081e-06 - val_loss: 1.1449e-06\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 9.3526e-06 - val_loss: 1.1422e-06\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.2976e-06 - val_loss: 1.1405e-06\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.2406e-06 - val_loss: 1.1359e-06\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 9.1845e-06 - val_loss: 1.1252e-06\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.1282e-06 - val_loss: 1.1189e-06\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.0762e-06 - val_loss: 1.1156e-06\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.0200e-06 - val_loss: 1.1102e-06\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.9692e-06 - val_loss: 1.1047e-06\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.9168e-06 - val_loss: 1.1025e-06\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.8679e-06 - val_loss: 1.0961e-06\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.8131e-06 - val_loss: 1.0949e-06\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 8.7622e-06 - val_loss: 1.0915e-06\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.7099e-06 - val_loss: 1.0828e-06\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.6579e-06 - val_loss: 1.0742e-06\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.6073e-06 - val_loss: 1.0691e-06\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.5528e-06 - val_loss: 1.0633e-06\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.5074e-06 - val_loss: 1.0601e-06\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.4562e-06 - val_loss: 1.0525e-06\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.4097e-06 - val_loss: 1.0536e-06\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.3581e-06 - val_loss: 1.0474e-06\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.3090e-06 - val_loss: 1.0413e-06\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.2597e-06 - val_loss: 1.0335e-06\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.2111e-06 - val_loss: 1.0264e-06\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.1658e-06 - val_loss: 1.0258e-06\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.1219e-06 - val_loss: 1.0207e-06\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.0770e-06 - val_loss: 1.0153e-06\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.0277e-06 - val_loss: 1.0117e-06\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.9775e-06 - val_loss: 1.0053e-06\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.9345e-06 - val_loss: 1.0039e-06\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.8877e-06 - val_loss: 9.9917e-07\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.8425e-06 - val_loss: 9.9554e-07\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.7959e-06 - val_loss: 9.8634e-07\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.7520e-06 - val_loss: 9.8312e-07\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.7085e-06 - val_loss: 9.7835e-07\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.6648e-06 - val_loss: 9.7714e-07\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.6201e-06 - val_loss: 9.7659e-07\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.5810e-06 - val_loss: 9.6906e-07\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.5444e-06 - val_loss: 9.6310e-07\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.4924e-06 - val_loss: 9.6299e-07\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.4490e-06 - val_loss: 9.5752e-07\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 7.4085e-06 - val_loss: 9.4910e-07\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.3706e-06 - val_loss: 9.4304e-07\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3260e-06 - val_loss: 9.4557e-07\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2857e-06 - val_loss: 9.3596e-07\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.2470e-06 - val_loss: 9.3775e-07\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.2034e-06 - val_loss: 9.3420e-07\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.1620e-06 - val_loss: 9.2058e-07\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.1208e-06 - val_loss: 9.1943e-07\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.0800e-06 - val_loss: 9.1094e-07\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.0421e-06 - val_loss: 9.1045e-07\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.0039e-06 - val_loss: 9.0519e-07\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.9671e-06 - val_loss: 9.0609e-07\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.9299e-06 - val_loss: 8.9830e-07\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.8861e-06 - val_loss: 8.9769e-07\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.8643e-06 - val_loss: 9.0688e-07\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.8168e-06 - val_loss: 8.9272e-07\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.7791e-06 - val_loss: 8.8106e-07\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.7384e-06 - val_loss: 8.7986e-07\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.7047e-06 - val_loss: 8.7368e-07\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.6653e-06 - val_loss: 8.6913e-07\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.6301e-06 - val_loss: 8.7383e-07\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.5941e-06 - val_loss: 8.6166e-07\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.5576e-06 - val_loss: 8.6279e-07\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.5261e-06 - val_loss: 8.5432e-07\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.4893e-06 - val_loss: 8.5768e-07\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.4592e-06 - val_loss: 8.5222e-07\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.4196e-06 - val_loss: 8.4351e-07\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.3817e-06 - val_loss: 8.3915e-07\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.3520e-06 - val_loss: 8.3863e-07\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.3184e-06 - val_loss: 8.3698e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.2881e-06 - val_loss: 8.3308e-07\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.2506e-06 - val_loss: 8.2312e-07\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.2187e-06 - val_loss: 8.3597e-07\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.2182e-06 - val_loss: 8.7761e-07\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.2137e-06 - val_loss: 8.6225e-07\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.1492e-06 - val_loss: 8.1252e-07\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.0909e-06 - val_loss: 8.1332e-07\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.0631e-06 - val_loss: 8.0751e-07\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.0268e-06 - val_loss: 8.0254e-07\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.0042e-06 - val_loss: 8.1789e-07\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.9742e-06 - val_loss: 7.9263e-07\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.9306e-06 - val_loss: 7.8921e-07\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.9035e-06 - val_loss: 7.8877e-07\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.8832e-06 - val_loss: 8.2824e-07\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.9044e-06 - val_loss: 8.3911e-07\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.8430e-06 - val_loss: 7.7858e-07\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.7818e-06 - val_loss: 7.7371e-07\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.7620e-06 - val_loss: 7.7641e-07\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.7306e-06 - val_loss: 7.6509e-07\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.6963e-06 - val_loss: 7.6238e-07\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.6679e-06 - val_loss: 7.6632e-07\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.6615e-06 - val_loss: 7.9811e-07\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.6510e-06 - val_loss: 7.7315e-07\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.5882e-06 - val_loss: 7.5402e-07\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.5618e-06 - val_loss: 7.4750e-07\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.5342e-06 - val_loss: 7.5931e-07\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5380e-06 - val_loss: 8.2000e-07\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.5489e-06 - val_loss: 7.6404e-07\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.4609e-06 - val_loss: 7.3266e-07\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.4228e-06 - val_loss: 7.3454e-07\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.3989e-06 - val_loss: 7.2674e-07\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.3679e-06 - val_loss: 7.2199e-07\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.3427e-06 - val_loss: 7.2310e-07\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3201e-06 - val_loss: 7.1620e-07\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.2980e-06 - val_loss: 7.4156e-07\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.3255e-06 - val_loss: 8.1806e-07\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.3209e-06 - val_loss: 7.2795e-07\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 5.2237e-06 - val_loss: 7.1450e-07\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.2038e-06 - val_loss: 7.0763e-07\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.1769e-06 - val_loss: 7.0875e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.1506e-06 - val_loss: 6.9621e-07\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.1218e-06 - val_loss: 6.9911e-07\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.1118e-06 - val_loss: 7.1891e-07\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.0965e-06 - val_loss: 6.9499e-07\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.0539e-06 - val_loss: 6.9892e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.0568e-06 - val_loss: 7.2692e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.0460e-06 - val_loss: 7.1740e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.0097e-06 - val_loss: 6.9047e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.9659e-06 - val_loss: 6.7394e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.9362e-06 - val_loss: 6.6999e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.9160e-06 - val_loss: 6.7443e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.9030e-06 - val_loss: 6.7909e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.8834e-06 - val_loss: 6.7460e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.8642e-06 - val_loss: 6.8149e-07\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.8620e-06 - val_loss: 6.9073e-07\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.8281e-06 - val_loss: 6.5746e-07\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.7851e-06 - val_loss: 6.5785e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.7880e-06 - val_loss: 6.9770e-07\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.8050e-06 - val_loss: 7.1449e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 4.4708e-0 - 1s 756us/step - loss: 4.7585e-06 - val_loss: 6.5041e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.7047e-06 - val_loss: 6.4249e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.6835e-06 - val_loss: 6.4126e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.6650e-06 - val_loss: 6.4120e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.6494e-06 - val_loss: 6.4666e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.6450e-06 - val_loss: 6.6605e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.6302e-06 - val_loss: 6.4147e-07\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.5881e-06 - val_loss: 6.2672e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.5642e-06 - val_loss: 6.2503e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.5470e-06 - val_loss: 6.2274e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.5290e-06 - val_loss: 6.4287e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.5684e-06 - val_loss: 7.6539e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.6847e-06 - val_loss: 7.5231e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.5183e-06 - val_loss: 6.4568e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.5121e-06 - val_loss: 6.5360e-07\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4483e-06 - val_loss: 6.2925e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.4312e-06 - val_loss: 6.0621e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.4087e-06 - val_loss: 6.2606e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3920e-06 - val_loss: 6.0158e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.3683e-06 - val_loss: 6.1864e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.3675e-06 - val_loss: 6.0371e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.3291e-06 - val_loss: 5.9476e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.3124e-06 - val_loss: 6.0025e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.3066e-06 - val_loss: 5.9642e-07\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.2798e-06 - val_loss: 6.0041e-07\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.2726e-06 - val_loss: 5.9028e-07\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.2447e-06 - val_loss: 5.8800e-07\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.2390e-06 - val_loss: 5.9683e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.2323e-06 - val_loss: 5.9100e-07\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.1989e-06 - val_loss: 5.8407e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.1904e-06 - val_loss: 5.8447e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.1659e-06 - val_loss: 5.7165e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.1490e-06 - val_loss: 5.8678e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.1504e-06 - val_loss: 5.7863e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.1207e-06 - val_loss: 5.6598e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.1015e-06 - val_loss: 5.7210e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.0975e-06 - val_loss: 5.8185e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.0898e-06 - val_loss: 5.7544e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.0759e-06 - val_loss: 5.9047e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.0556e-06 - val_loss: 5.5643e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.0237e-06 - val_loss: 5.5337e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.0184e-06 - val_loss: 6.0546e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.0975e-06 - val_loss: 7.1542e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.0989e-06 - val_loss: 5.7179e-07\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.9726e-06 - val_loss: 5.6128e-07\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9725e-06 - val_loss: 5.7065e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.9686e-06 - val_loss: 5.6630e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.9309e-06 - val_loss: 5.4296e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.9191e-06 - val_loss: 5.4264e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.8967e-06 - val_loss: 5.4845e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.8991e-06 - val_loss: 5.5665e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.8811e-06 - val_loss: 5.3903e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.8554e-06 - val_loss: 5.2866e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.8383e-06 - val_loss: 5.2768e-07\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.8309e-06 - val_loss: 5.3969e-07\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.8275e-06 - val_loss: 5.3895e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.8159e-06 - val_loss: 5.4395e-07\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.8003e-06 - val_loss: 5.2629e-07\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.7798e-06 - val_loss: 5.2254e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 3.7635e-06 - val_loss: 5.2354e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.7509e-06 - val_loss: 5.1872e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.7356e-06 - val_loss: 5.2956e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7964e-06 - val_loss: 7.1762e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.0317e-06 - val_loss: 8.3231e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.8207e-06 - val_loss: 5.5587e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7648e-06 - val_loss: 5.1904e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.6885e-06 - val_loss: 5.3649e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.6723e-06 - val_loss: 5.0723e-07\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100, 7)            252       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100, 1)            8         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 260\n",
      "Trainable params: 260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0821 - val_loss: 0.0804\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0794 - val_loss: 0.0779\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0771 - val_loss: 0.0759\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0752 - val_loss: 0.0742\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0737 - val_loss: 0.0729\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0724 - val_loss: 0.0717\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0712 - val_loss: 0.0706\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0701 - val_loss: 0.0695\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0690 - val_loss: 0.0683\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0678 - val_loss: 0.0671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0666 - val_loss: 0.0659\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0653 - val_loss: 0.0646\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 0.0640 - val_loss: 0.0633\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 858us/step - loss: 0.0627 - val_loss: 0.0620\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 830us/step - loss: 0.0614 - val_loss: 0.0606\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 834us/step - loss: 0.0600 - val_loss: 0.0592\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 810us/step - loss: 0.0586 - val_loss: 0.0577\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0571 - val_loss: 0.0562\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0555 - val_loss: 0.0546\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0539 - val_loss: 0.0530\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0523 - val_loss: 0.0513\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0506 - val_loss: 0.0495\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0488 - val_loss: 0.0477\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0469 - val_loss: 0.0458\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0450 - val_loss: 0.0438\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0430 - val_loss: 0.0418\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0409 - val_loss: 0.0396\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0386 - val_loss: 0.0373\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0363 - val_loss: 0.0349\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0338 - val_loss: 0.0323\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0312 - val_loss: 0.0296\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0284 - val_loss: 0.0268\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0256 - val_loss: 0.0239\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0227 - val_loss: 0.0211\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0200 - val_loss: 0.0184\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0173 - val_loss: 0.0158\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0148 - val_loss: 0.0135\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.9110e-04 - val_loss: 0.0010\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.7619e-04 - val_loss: 9.9947e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.6137e-04 - val_loss: 9.8359e-04\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.4679e-04 - val_loss: 9.6791e-04\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.3248e-04 - val_loss: 9.5240e-04\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 9.1825e-04 - val_loss: 9.3703e-04\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 9.0427e-04 - val_loss: 9.2186e-04\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.9039e-04 - val_loss: 9.0692e-04\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.7668e-04 - val_loss: 8.9218e-04\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.6328e-04 - val_loss: 8.7751e-04\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.4998e-04 - val_loss: 8.6305e-04\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.3678e-04 - val_loss: 8.4879e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.2380e-04 - val_loss: 8.3465e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.1099e-04 - val_loss: 8.2070e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.9834e-04 - val_loss: 8.0694e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.8581e-04 - val_loss: 7.9330e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 7.7345e-04 - val_loss: 7.7986e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.6127e-04 - val_loss: 7.6652e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.4923e-04 - val_loss: 7.5343e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.3726e-04 - val_loss: 7.4037e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2548e-04 - val_loss: 7.2753e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.1384e-04 - val_loss: 7.1481e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.0236e-04 - val_loss: 7.0223e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.9101e-04 - val_loss: 6.8980e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.7978e-04 - val_loss: 6.7746e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.6860e-04 - val_loss: 6.6534e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.5767e-04 - val_loss: 6.5331e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.4680e-04 - val_loss: 6.4142e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.3612e-04 - val_loss: 6.2964e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.2551e-04 - val_loss: 6.1800e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.1507e-04 - val_loss: 6.0650e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.0464e-04 - val_loss: 5.9511e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.9444e-04 - val_loss: 5.8385e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.8426e-04 - val_loss: 5.7279e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.7425e-04 - val_loss: 5.6182e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.6442e-04 - val_loss: 5.5097e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.5467e-04 - val_loss: 5.4020e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.4500e-04 - val_loss: 5.2960e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3542e-04 - val_loss: 5.1915e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.2606e-04 - val_loss: 5.0881e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.1675e-04 - val_loss: 4.9858e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.0757e-04 - val_loss: 4.8850e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9851e-04 - val_loss: 4.7852e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.8958e-04 - val_loss: 4.6869e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.8073e-04 - val_loss: 4.5898e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.7207e-04 - val_loss: 4.4939e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.6342e-04 - val_loss: 4.3993e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.5500e-04 - val_loss: 4.3060e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.4661e-04 - val_loss: 4.2139e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.3831e-04 - val_loss: 4.1237e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.3028e-04 - val_loss: 4.0340e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.2225e-04 - val_loss: 3.9461e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.1436e-04 - val_loss: 3.8594e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.0663e-04 - val_loss: 3.7736e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.9899e-04 - val_loss: 3.6896e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.9142e-04 - val_loss: 3.6065e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.8401e-04 - val_loss: 3.5255e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.7672e-04 - val_loss: 3.4445e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.6957e-04 - val_loss: 3.3653e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.6245e-04 - val_loss: 3.2877e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5557e-04 - val_loss: 3.2111e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.4872e-04 - val_loss: 3.1360e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.4201e-04 - val_loss: 3.0626e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.3548e-04 - val_loss: 2.9895e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.2899e-04 - val_loss: 2.9181e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.2262e-04 - val_loss: 2.8482e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.1641e-04 - val_loss: 2.7794e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.1028e-04 - val_loss: 2.7120e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.0425e-04 - val_loss: 2.6458e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.9837e-04 - val_loss: 2.5811e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.9263e-04 - val_loss: 2.5171e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.8696e-04 - val_loss: 2.4545e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.8137e-04 - val_loss: 2.3934e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.7595e-04 - val_loss: 2.3335e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.7063e-04 - val_loss: 2.2746e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.6543e-04 - val_loss: 2.2170e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.6031e-04 - val_loss: 2.1607e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.5534e-04 - val_loss: 2.1057e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.5044e-04 - val_loss: 2.0515e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4566e-04 - val_loss: 1.9989e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.4099e-04 - val_loss: 1.9476e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.3644e-04 - val_loss: 1.8976e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.3202e-04 - val_loss: 1.8484e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2767e-04 - val_loss: 1.8007e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2344e-04 - val_loss: 1.7543e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.1932e-04 - val_loss: 1.7083e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.1526e-04 - val_loss: 1.6640e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.1134e-04 - val_loss: 1.6205e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.0750e-04 - val_loss: 1.5782e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.0377e-04 - val_loss: 1.5365e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.0009e-04 - val_loss: 1.4961e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9653e-04 - val_loss: 1.4566e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.9303e-04 - val_loss: 1.4182e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8961e-04 - val_loss: 1.3810e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8631e-04 - val_loss: 1.3445e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8310e-04 - val_loss: 1.3088e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.7995e-04 - val_loss: 1.2743e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.7690e-04 - val_loss: 1.2404e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7392e-04 - val_loss: 1.2078e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7100e-04 - val_loss: 1.1756e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6815e-04 - val_loss: 1.1445e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6540e-04 - val_loss: 1.1139e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6269e-04 - val_loss: 1.0842e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.6007e-04 - val_loss: 1.0554e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5751e-04 - val_loss: 1.0276e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.5503e-04 - val_loss: 1.0004e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.5261e-04 - val_loss: 9.7382e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.5026e-04 - val_loss: 9.4806e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4796e-04 - val_loss: 9.2300e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4573e-04 - val_loss: 8.9879e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4356e-04 - val_loss: 8.7513e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4145e-04 - val_loss: 8.5213e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3939e-04 - val_loss: 8.2983e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.3739e-04 - val_loss: 8.0787e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3544e-04 - val_loss: 7.8667e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.3354e-04 - val_loss: 7.6618e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.3170e-04 - val_loss: 7.4623e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2990e-04 - val_loss: 7.2764e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2818e-04 - val_loss: 7.0802e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2645e-04 - val_loss: 6.8974e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.2478e-04 - val_loss: 6.7206e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2316e-04 - val_loss: 6.5486e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2160e-04 - val_loss: 6.3811e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2007e-04 - val_loss: 6.2210e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.1858e-04 - val_loss: 6.0599e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1713e-04 - val_loss: 5.9059e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1572e-04 - val_loss: 5.7609e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1437e-04 - val_loss: 5.6197e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1304e-04 - val_loss: 5.4718e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1171e-04 - val_loss: 5.3358e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1043e-04 - val_loss: 5.2051e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0918e-04 - val_loss: 5.0754e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0797e-04 - val_loss: 4.9490e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0680e-04 - val_loss: 4.8295e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0565e-04 - val_loss: 4.7097e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0453e-04 - val_loss: 4.5943e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0344e-04 - val_loss: 4.4839e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0238e-04 - val_loss: 4.3790e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0136e-04 - val_loss: 4.2740e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0035e-04 - val_loss: 4.1712e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 9.9407e-05 - val_loss: 4.0732e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.8412e-05 - val_loss: 3.9747e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.7463e-05 - val_loss: 3.8887e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.6563e-05 - val_loss: 3.8104e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.5671e-05 - val_loss: 3.7068e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.4756e-05 - val_loss: 3.6211e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.3888e-05 - val_loss: 3.5359e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.3063e-05 - val_loss: 3.4577e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.2232e-05 - val_loss: 3.3771e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.1432e-05 - val_loss: 3.3024e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.0665e-05 - val_loss: 3.2352e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.9918e-05 - val_loss: 3.1614e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.9164e-05 - val_loss: 3.0923e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.8437e-05 - val_loss: 3.0200e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.7703e-05 - val_loss: 2.9516e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.6984e-05 - val_loss: 2.8882e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.6300e-05 - val_loss: 2.8282e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.5633e-05 - val_loss: 2.7699e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.4973e-05 - val_loss: 2.7076e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.4334e-05 - val_loss: 2.6572e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.3721e-05 - val_loss: 2.6005e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.3095e-05 - val_loss: 2.5456e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.2475e-05 - val_loss: 2.4895e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.1897e-05 - val_loss: 2.4402e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.1300e-05 - val_loss: 2.3919e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.0711e-05 - val_loss: 2.3410e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0122e-05 - val_loss: 2.2918e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.9580e-05 - val_loss: 2.2512e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.9033e-05 - val_loss: 2.2040e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.8488e-05 - val_loss: 2.1604e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.7968e-05 - val_loss: 2.1152e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.7452e-05 - val_loss: 2.0759e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.6935e-05 - val_loss: 2.0378e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.6440e-05 - val_loss: 1.9952e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.5921e-05 - val_loss: 1.9571e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.5454e-05 - val_loss: 1.9196e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.4970e-05 - val_loss: 1.8837e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.4506e-05 - val_loss: 1.8505e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.4062e-05 - val_loss: 1.8213e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 7.3595e-05 - val_loss: 1.7819e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 7.3134e-05 - val_loss: 1.7484e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.2690e-05 - val_loss: 1.7197e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2239e-05 - val_loss: 1.6886e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.1839e-05 - val_loss: 1.6552e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 7.1382e-05 - val_loss: 1.6267e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.0967e-05 - val_loss: 1.6002e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 7.0558e-05 - val_loss: 1.5698e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.0142e-05 - val_loss: 1.5448e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 6.9737e-05 - val_loss: 1.5203e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.9365e-05 - val_loss: 1.4893e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.8937e-05 - val_loss: 1.4649e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.8553e-05 - val_loss: 1.4441e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.8191e-05 - val_loss: 1.4164e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.7797e-05 - val_loss: 1.3939e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.7419e-05 - val_loss: 1.3708e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.7055e-05 - val_loss: 1.3456e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.6674e-05 - val_loss: 1.3235e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.6315e-05 - val_loss: 1.3014e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.5951e-05 - val_loss: 1.2814e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.5629e-05 - val_loss: 1.2621e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.5269e-05 - val_loss: 1.2477e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.4946e-05 - val_loss: 1.2211e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.4574e-05 - val_loss: 1.2055e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.4281e-05 - val_loss: 1.1833e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.3902e-05 - val_loss: 1.1650e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 6.3556e-05 - val_loss: 1.1499e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 853us/step - loss: 6.3253e-05 - val_loss: 1.1314e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.2914e-05 - val_loss: 1.1186e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.2739e-05 - val_loss: 1.1160e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.2322e-05 - val_loss: 1.0936e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.2094e-05 - val_loss: 1.0679e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.1702e-05 - val_loss: 1.0754e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.1550e-05 - val_loss: 1.0321e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.1036e-05 - val_loss: 1.0175e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.0721e-05 - val_loss: 1.0093e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.0413e-05 - val_loss: 9.9234e-06\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.0133e-05 - val_loss: 9.7250e-06\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.9828e-05 - val_loss: 9.6266e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9528e-05 - val_loss: 9.4835e-06\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.9325e-05 - val_loss: 9.3667e-06\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.8940e-05 - val_loss: 9.2014e-06\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.8639e-05 - val_loss: 9.0696e-06\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.8368e-05 - val_loss: 8.9598e-06\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.8140e-05 - val_loss: 8.9101e-06\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.7824e-05 - val_loss: 8.8040e-06\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.7615e-05 - val_loss: 8.6212e-06\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.7275e-05 - val_loss: 8.6055e-06\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.7156e-05 - val_loss: 8.4398e-06\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.6763e-05 - val_loss: 8.5594e-06\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.6561e-05 - val_loss: 8.1832e-06\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.6220e-05 - val_loss: 8.0246e-06\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.5914e-05 - val_loss: 7.9396e-06\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.5637e-05 - val_loss: 7.8197e-06\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.5389e-05 - val_loss: 7.7601e-06\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.5118e-05 - val_loss: 7.6197e-06\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.4845e-05 - val_loss: 7.5239e-06\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.4595e-05 - val_loss: 7.4367e-06\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 5.4398e-05 - val_loss: 7.5315e-06\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 5.4163e-05 - val_loss: 7.2447e-06\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.3886e-05 - val_loss: 7.1797e-06\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3608e-05 - val_loss: 7.1060e-06\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.3380e-05 - val_loss: 6.9977e-06\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.3095e-05 - val_loss: 6.9738e-06\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.3007e-05 - val_loss: 6.8942e-06\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.2654e-05 - val_loss: 6.8701e-06\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.2590e-05 - val_loss: 6.7409e-06\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.2155e-05 - val_loss: 6.6329e-06\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.1933e-05 - val_loss: 6.5070e-06\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.1672e-05 - val_loss: 6.4832e-06\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.1528e-05 - val_loss: 6.3566e-06\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.1185e-05 - val_loss: 6.3016e-06\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.0947e-05 - val_loss: 6.1897e-06\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.0709e-05 - val_loss: 6.1141e-06\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.0474e-05 - val_loss: 6.0367e-06\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.0253e-05 - val_loss: 5.9699e-06\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0058e-05 - val_loss: 5.9609e-06\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.9833e-05 - val_loss: 5.8561e-06\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.9602e-05 - val_loss: 5.7659e-06\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.9376e-05 - val_loss: 5.7997e-06\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.9236e-05 - val_loss: 5.7484e-06\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.8968e-05 - val_loss: 5.5842e-06\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.8847e-05 - val_loss: 5.9797e-06\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.8785e-05 - val_loss: 5.4518e-06\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.8361e-05 - val_loss: 5.6944e-06\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.8242e-05 - val_loss: 5.3366e-06\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.8163e-05 - val_loss: 5.8518e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7807e-05 - val_loss: 5.3695e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.7537e-05 - val_loss: 5.1653e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.7284e-05 - val_loss: 5.1943e-06\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.7043e-05 - val_loss: 5.1843e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.6831e-05 - val_loss: 5.0102e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.6569e-05 - val_loss: 4.9521e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.6366e-05 - val_loss: 4.9141e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.6160e-05 - val_loss: 4.8591e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 4.8332e-0 - 1s 747us/step - loss: 4.5955e-05 - val_loss: 4.8059e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.5759e-05 - val_loss: 4.7693e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.5558e-05 - val_loss: 4.7136e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.5375e-05 - val_loss: 4.7010e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.5162e-05 - val_loss: 4.6664e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.4999e-05 - val_loss: 4.5731e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.4752e-05 - val_loss: 4.5283e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.4573e-05 - val_loss: 4.4797e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.4356e-05 - val_loss: 4.4353e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.4214e-05 - val_loss: 4.5030e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4023e-05 - val_loss: 4.3412e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.3796e-05 - val_loss: 4.3533e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.3680e-05 - val_loss: 4.3742e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.3451e-05 - val_loss: 4.2293e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.3217e-05 - val_loss: 4.1859e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.3262e-05 - val_loss: 4.7976e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.3267e-05 - val_loss: 4.1566e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.2723e-05 - val_loss: 4.2879e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 4.2636e-05 - val_loss: 4.0308e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2317e-05 - val_loss: 4.0655e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.2108e-05 - val_loss: 3.9468e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.1942e-05 - val_loss: 4.0007e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.1790e-05 - val_loss: 3.8907e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.1552e-05 - val_loss: 3.9079e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.1436e-05 - val_loss: 3.8834e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.1219e-05 - val_loss: 3.7957e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.1051e-05 - val_loss: 3.7777e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.0829e-05 - val_loss: 3.7968e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.0718e-05 - val_loss: 3.7197e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.0484e-05 - val_loss: 3.6601e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.0397e-05 - val_loss: 3.9510e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.0330e-05 - val_loss: 3.6595e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.9972e-05 - val_loss: 3.6487e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.9851e-05 - val_loss: 3.5406e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.9605e-05 - val_loss: 3.6161e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.9506e-05 - val_loss: 3.4999e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.9264e-05 - val_loss: 3.4420e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.9104e-05 - val_loss: 3.4380e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.8923e-05 - val_loss: 3.4354e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.8784e-05 - val_loss: 3.4201e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.8657e-05 - val_loss: 3.3718e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.8426e-05 - val_loss: 3.3857e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8302e-05 - val_loss: 3.3034e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.8114e-05 - val_loss: 3.3179e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7990e-05 - val_loss: 3.3603e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.7900e-05 - val_loss: 3.3270e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7684e-05 - val_loss: 3.2263e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 3.7447e-05 - val_loss: 3.1669e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 3.7261e-05 - val_loss: 3.1712e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.7213e-05 - val_loss: 3.3727e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.7358e-05 - val_loss: 3.6072e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.7001e-05 - val_loss: 3.0909e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.6706e-05 - val_loss: 3.1777e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.6587e-05 - val_loss: 3.0566e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 3.6303e-05 - val_loss: 3.0181e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.6179e-05 - val_loss: 2.9944e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.5996e-05 - val_loss: 2.9854e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.5871e-05 - val_loss: 2.9352e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.5684e-05 - val_loss: 2.9635e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.5575e-05 - val_loss: 2.9197e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.5416e-05 - val_loss: 3.0840e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.5550e-05 - val_loss: 3.2460e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.5373e-05 - val_loss: 2.8843e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.4932e-05 - val_loss: 2.8448e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.4873e-05 - val_loss: 2.8607e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.4628e-05 - val_loss: 2.8407e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4496e-05 - val_loss: 2.7687e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 3.4377e-05 - val_loss: 2.9410e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.4364e-05 - val_loss: 2.7613e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.4067e-05 - val_loss: 2.8282e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.3898e-05 - val_loss: 2.7767e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.3872e-05 - val_loss: 2.8289e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.3641e-05 - val_loss: 2.6864e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.3491e-05 - val_loss: 2.7135e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.3304e-05 - val_loss: 2.6396e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.3147e-05 - val_loss: 2.6234e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.3019e-05 - val_loss: 2.6859e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.2892e-05 - val_loss: 2.5892e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.2732e-05 - val_loss: 2.6935e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.2803e-05 - val_loss: 2.7464e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2474e-05 - val_loss: 2.6527e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.2394e-05 - val_loss: 2.5675e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2168e-05 - val_loss: 2.6193e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.2264e-05 - val_loss: 2.8197e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.1992e-05 - val_loss: 2.5064e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.1812e-05 - val_loss: 2.5321e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.1643e-05 - val_loss: 2.4610e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.1457e-05 - val_loss: 2.4543e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.1343e-05 - val_loss: 2.5584e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.1233e-05 - val_loss: 2.4259e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.1090e-05 - val_loss: 2.5400e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.0989e-05 - val_loss: 2.4121e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.0776e-05 - val_loss: 2.3846e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.0651e-05 - val_loss: 2.4440e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.0546e-05 - val_loss: 2.3787e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.0387e-05 - val_loss: 2.3623e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.0242e-05 - val_loss: 2.3809e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.0291e-05 - val_loss: 2.7381e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.0369e-05 - val_loss: 2.4517e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.9874e-05 - val_loss: 2.3541e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.9742e-05 - val_loss: 2.3075e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.9591e-05 - val_loss: 2.2742e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.9472e-05 - val_loss: 2.3261e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.9356e-05 - val_loss: 2.2648e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.9214e-05 - val_loss: 2.4596e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.9746e-05 - val_loss: 2.9596e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.9180e-05 - val_loss: 2.4280e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.9051e-05 - val_loss: 2.2798e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.8770e-05 - val_loss: 2.4524e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.8695e-05 - val_loss: 2.2549e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.8631e-05 - val_loss: 2.2748e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.8432e-05 - val_loss: 2.6038e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.8367e-05 - val_loss: 2.1904e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.8118e-05 - val_loss: 2.1805e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.7940e-05 - val_loss: 2.1521e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.7812e-05 - val_loss: 2.1341e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.7689e-05 - val_loss: 2.1795e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.7593e-05 - val_loss: 2.1397e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.7447e-05 - val_loss: 2.0978e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.7313e-05 - val_loss: 2.0910e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.7189e-05 - val_loss: 2.0899e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.7079e-05 - val_loss: 2.0914e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.6946e-05 - val_loss: 2.0688e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.6833e-05 - val_loss: 2.0747e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6711e-05 - val_loss: 2.0794e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6638e-05 - val_loss: 2.0633e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.6485e-05 - val_loss: 2.0490e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.6369e-05 - val_loss: 2.0313e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6239e-05 - val_loss: 2.0295e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.6120e-05 - val_loss: 2.0186e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.6005e-05 - val_loss: 1.9981e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5896e-05 - val_loss: 2.0184e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 2.5774e-05 - val_loss: 1.9843e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 2.5656e-05 - val_loss: 2.0226e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.5595e-05 - val_loss: 2.0066e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.5489e-05 - val_loss: 2.0501e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.5377e-05 - val_loss: 2.0097e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.5243e-05 - val_loss: 1.9822e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.5094e-05 - val_loss: 1.9418e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.4986e-05 - val_loss: 2.0423e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5204e-05 - val_loss: 2.5696e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5147e-05 - val_loss: 2.0217e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4675e-05 - val_loss: 1.9202e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.4519e-05 - val_loss: 1.9106e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.4414e-05 - val_loss: 1.9376e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.4364e-05 - val_loss: 2.0042e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.4287e-05 - val_loss: 1.9506e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4114e-05 - val_loss: 1.8796e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.4015e-05 - val_loss: 1.9674e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.3893e-05 - val_loss: 1.8694e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.3789e-05 - val_loss: 1.9682e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.3992e-05 - val_loss: 2.4531e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.3867e-05 - val_loss: 1.8496e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3528e-05 - val_loss: 2.1013e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3486e-05 - val_loss: 1.8400e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.3234e-05 - val_loss: 1.8975e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.3156e-05 - val_loss: 1.8146e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.3009e-05 - val_loss: 1.8218e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2942e-05 - val_loss: 1.8872e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2862e-05 - val_loss: 1.8168e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.2691e-05 - val_loss: 1.8011e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.2613e-05 - val_loss: 1.8349e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.2496e-05 - val_loss: 1.7854e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.2375e-05 - val_loss: 1.8173e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.2429e-05 - val_loss: 2.0947e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.2530e-05 - val_loss: 1.9370e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.2127e-05 - val_loss: 1.7770e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2001e-05 - val_loss: 1.8171e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.1898e-05 - val_loss: 1.7520e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.1789e-05 - val_loss: 1.8171e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.1702e-05 - val_loss: 1.7456e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1565e-05 - val_loss: 1.7397e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1492e-05 - val_loss: 1.8540e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.1550e-05 - val_loss: 1.7894e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.1290e-05 - val_loss: 1.7263e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.1246e-05 - val_loss: 1.8309e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.1106e-05 - val_loss: 1.7048e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.0987e-05 - val_loss: 1.7803e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0941e-05 - val_loss: 1.6931e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.0812e-05 - val_loss: 1.7812e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.0771e-05 - val_loss: 1.7236e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0625e-05 - val_loss: 1.7111e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.0536e-05 - val_loss: 1.6852e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.0407e-05 - val_loss: 1.7793e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.0506e-05 - val_loss: 1.8881e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.0350e-05 - val_loss: 1.6499e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0135e-05 - val_loss: 1.8096e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.0139e-05 - val_loss: 1.6485e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.9947e-05 - val_loss: 1.7444e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9961e-05 - val_loss: 1.6900e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.9741e-05 - val_loss: 1.6746e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.9648e-05 - val_loss: 1.6456e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9567e-05 - val_loss: 1.6344e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9467e-05 - val_loss: 1.6285e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.9359e-05 - val_loss: 1.6055e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.9269e-05 - val_loss: 1.6158e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.9207e-05 - val_loss: 1.6217e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.9092e-05 - val_loss: 1.6481e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.9077e-05 - val_loss: 1.6853e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.8976e-05 - val_loss: 1.6372e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8959e-05 - val_loss: 1.9000e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.9254e-05 - val_loss: 2.2744e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.8986e-05 - val_loss: 1.5701e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8606e-05 - val_loss: 1.6458e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.8517e-05 - val_loss: 1.5713e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.8373e-05 - val_loss: 1.5610e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8291e-05 - val_loss: 1.5472e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8205e-05 - val_loss: 1.5504e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8127e-05 - val_loss: 1.5557e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8032e-05 - val_loss: 1.5299e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 1.7965e-05 - val_loss: 1.5548e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.7889e-05 - val_loss: 1.5247e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7771e-05 - val_loss: 1.5390e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.7768e-05 - val_loss: 1.7263e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7752e-05 - val_loss: 1.6373e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7655e-05 - val_loss: 1.5943e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 1.7668e-0 - 1s 745us/step - loss: 1.7461e-05 - val_loss: 1.5043e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7364e-05 - val_loss: 1.5480e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7330e-05 - val_loss: 1.5306e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.7189e-05 - val_loss: 1.5284e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7188e-05 - val_loss: 1.6237e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.7163e-05 - val_loss: 1.6294e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7050e-05 - val_loss: 1.4841e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6861e-05 - val_loss: 1.4834e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.6796e-05 - val_loss: 1.4759e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.6703e-05 - val_loss: 1.6591e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6955e-05 - val_loss: 1.6993e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6644e-05 - val_loss: 1.4555e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6546e-05 - val_loss: 1.7022e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6504e-05 - val_loss: 1.4636e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.6314e-05 - val_loss: 1.5517e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.6276e-05 - val_loss: 1.4579e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6263e-05 - val_loss: 1.6261e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6126e-05 - val_loss: 1.4378e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6081e-05 - val_loss: 1.5119e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5939e-05 - val_loss: 1.4159e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5862e-05 - val_loss: 1.5148e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.5803e-05 - val_loss: 1.4094e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5690e-05 - val_loss: 1.4364e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.5626e-05 - val_loss: 1.4323e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5529e-05 - val_loss: 1.3997e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5444e-05 - val_loss: 1.3951e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5371e-05 - val_loss: 1.4096e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5432e-05 - val_loss: 1.7231e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.5417e-05 - val_loss: 1.3839e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5201e-05 - val_loss: 1.5340e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.5184e-05 - val_loss: 1.3812e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5074e-05 - val_loss: 1.6372e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.5114e-05 - val_loss: 1.4116e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.4874e-05 - val_loss: 1.3590e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.4795e-05 - val_loss: 1.4377e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.4791e-05 - val_loss: 1.4126e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.4702e-05 - val_loss: 1.3995e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4589e-05 - val_loss: 1.3443e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4559e-05 - val_loss: 1.5581e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.4652e-05 - val_loss: 1.3593e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.4439e-05 - val_loss: 1.6731e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4519e-05 - val_loss: 1.3282e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4234e-05 - val_loss: 1.3495e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4144e-05 - val_loss: 1.3161e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.4065e-05 - val_loss: 1.3139e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.3997e-05 - val_loss: 1.3179e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3957e-05 - val_loss: 1.3338e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3890e-05 - val_loss: 1.3319e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.3800e-05 - val_loss: 1.2989e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.3723e-05 - val_loss: 1.2960e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3660e-05 - val_loss: 1.2963e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.3595e-05 - val_loss: 1.2980e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3520e-05 - val_loss: 1.2994e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.3532e-05 - val_loss: 1.4556e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3606e-05 - val_loss: 1.5664e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.3499e-05 - val_loss: 1.2664e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.3343e-05 - val_loss: 1.5256e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3449e-05 - val_loss: 1.4114e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.3173e-05 - val_loss: 1.3928e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.3225e-05 - val_loss: 1.3406e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.3030e-05 - val_loss: 1.2810e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2997e-05 - val_loss: 1.4044e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2962e-05 - val_loss: 1.2435e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2842e-05 - val_loss: 1.2808e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.2757e-05 - val_loss: 1.2345e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.2675e-05 - val_loss: 1.2251e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2620e-05 - val_loss: 1.2265e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2558e-05 - val_loss: 1.2276e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2488e-05 - val_loss: 1.2214e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2430e-05 - val_loss: 1.2271e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.2379e-05 - val_loss: 1.2185e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.2357e-05 - val_loss: 1.3729e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2420e-05 - val_loss: 1.3783e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2281e-05 - val_loss: 1.2086e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2125e-05 - val_loss: 1.2126e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2086e-05 - val_loss: 1.2181e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2006e-05 - val_loss: 1.1972e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1956e-05 - val_loss: 1.2104e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1945e-05 - val_loss: 1.2640e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1845e-05 - val_loss: 1.1869e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.1765e-05 - val_loss: 1.1851e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1753e-05 - val_loss: 1.3939e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.2137e-05 - val_loss: 1.8882e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.2071e-05 - val_loss: 1.2540e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1591e-05 - val_loss: 1.3227e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1658e-05 - val_loss: 1.2075e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1454e-05 - val_loss: 1.3387e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1648e-05 - val_loss: 1.4349e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.1472e-05 - val_loss: 1.1665e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1382e-05 - val_loss: 1.3624e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.1259e-05 - val_loss: 1.2073e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1225e-05 - val_loss: 1.1500e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1124e-05 - val_loss: 1.2226e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1076e-05 - val_loss: 1.1310e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0999e-05 - val_loss: 1.1785e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0947e-05 - val_loss: 1.1230e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0867e-05 - val_loss: 1.1210e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0828e-05 - val_loss: 1.1727e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.0798e-05 - val_loss: 1.1445e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0724e-05 - val_loss: 1.1141e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0668e-05 - val_loss: 1.1121e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0599e-05 - val_loss: 1.1077e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0551e-05 - val_loss: 1.1207e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.0529e-05 - val_loss: 1.1548e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.0504e-05 - val_loss: 1.0956e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0400e-05 - val_loss: 1.1254e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0374e-05 - val_loss: 1.1264e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0323e-05 - val_loss: 1.0985e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0276e-05 - val_loss: 1.2266e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0278e-05 - val_loss: 1.0930e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0141e-05 - val_loss: 1.0788e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0088e-05 - val_loss: 1.1003e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.0110e-05 - val_loss: 1.2514e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0239e-05 - val_loss: 1.2158e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.9851e-06 - val_loss: 1.2066e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0101e-05 - val_loss: 1.2646e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 9.9581e-06 - val_loss: 1.0754e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.7926e-06 - val_loss: 1.0501e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.7458e-06 - val_loss: 1.0695e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.8026e-06 - val_loss: 1.2316e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.7426e-06 - val_loss: 1.0435e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.5992e-06 - val_loss: 1.0405e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.5896e-06 - val_loss: 1.0827e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.5148e-06 - val_loss: 1.0510e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.4732e-06 - val_loss: 1.0302e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.4132e-06 - val_loss: 1.0366e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.3721e-06 - val_loss: 1.0214e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.3139e-06 - val_loss: 1.0157e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.2698e-06 - val_loss: 1.0159e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.2227e-06 - val_loss: 1.0085e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 9.1802e-06 - val_loss: 1.0106e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.1570e-06 - val_loss: 1.0434e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.1040e-06 - val_loss: 1.0097e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.0494e-06 - val_loss: 1.0004e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.9974e-06 - val_loss: 1.0138e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.0214e-06 - val_loss: 1.1066e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 9.0670e-06 - val_loss: 1.2954e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.5916e-06 - val_loss: 2.4690e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0158e-05 - val_loss: 1.1210e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.1248e-06 - val_loss: 1.6892e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.0002e-06 - val_loss: 1.2649e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.9577e-06 - val_loss: 9.8273e-07\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.7502e-06 - val_loss: 1.1415e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.6929e-06 - val_loss: 9.7267e-07\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.5934e-06 - val_loss: 9.9835e-07\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.5531e-06 - val_loss: 1.1099e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.5484e-06 - val_loss: 9.9068e-07\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.5006e-06 - val_loss: 9.5613e-07\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.4360e-06 - val_loss: 9.8260e-07\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.3820e-06 - val_loss: 9.8362e-07\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.3458e-06 - val_loss: 9.4823e-07\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 8.2915e-06 - val_loss: 9.4810e-07\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.2467e-06 - val_loss: 9.6200e-07\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.2051e-06 - val_loss: 9.4045e-07\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.1609e-06 - val_loss: 9.3551e-07\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 8.1322e-06 - val_loss: 9.4196e-07\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.0829e-06 - val_loss: 9.3635e-07\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0467e-06 - val_loss: 9.2703e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.0038e-06 - val_loss: 9.3793e-07\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.0009e-06 - val_loss: 9.5812e-07\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.9435e-06 - val_loss: 9.1885e-07\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.8951e-06 - val_loss: 9.2013e-07\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 7.8825e-06 - val_loss: 1.0966e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.0543e-06 - val_loss: 9.7906e-07\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.8188e-06 - val_loss: 1.0257e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.8060e-06 - val_loss: 9.0433e-07\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 8.1833e-0 - 1s 732us/step - loss: 7.7168e-06 - val_loss: 9.3890e-07\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.7153e-06 - val_loss: 9.4800e-07\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.6447e-06 - val_loss: 9.5183e-07\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.6773e-06 - val_loss: 9.7108e-07\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.5953e-06 - val_loss: 8.9555e-07\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.5596e-06 - val_loss: 1.0053e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.5433e-06 - val_loss: 8.8794e-07\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.4500e-06 - val_loss: 8.8593e-07\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.4130e-06 - val_loss: 8.7918e-07\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3797e-06 - val_loss: 8.9475e-07\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 7.3552e-06 - val_loss: 9.1406e-07\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.3903e-06 - val_loss: 9.4842e-07\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.2891e-06 - val_loss: 8.8599e-07\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 7.2578e-06 - val_loss: 8.9005e-07\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2314e-06 - val_loss: 8.6981e-07\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.1891e-06 - val_loss: 9.7630e-07\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3030e-06 - val_loss: 1.0562e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.2298e-06 - val_loss: 8.8853e-07\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 7.0772e-06 - val_loss: 9.4056e-07\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.2629e-06 - val_loss: 1.3318e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.4162e-06 - val_loss: 9.5627e-07\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.0027e-06 - val_loss: 9.5542e-07\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.0633e-06 - val_loss: 9.4970e-07\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.9621e-06 - val_loss: 8.4267e-07\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8724e-06 - val_loss: 8.3907e-07\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.8444e-06 - val_loss: 8.4697e-07\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.8071e-06 - val_loss: 8.3438e-07\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.8133e-06 - val_loss: 9.4552e-07\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.8095e-06 - val_loss: 8.2533e-07\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.7137e-06 - val_loss: 8.2568e-07\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.6791e-06 - val_loss: 8.2474e-07\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.6531e-06 - val_loss: 8.5637e-07\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.7278e-06 - val_loss: 1.0354e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.7965e-06 - val_loss: 8.8818e-07\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.5802e-06 - val_loss: 9.3350e-07\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.8107e-06 - val_loss: 1.1400e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.6659e-06 - val_loss: 8.0608e-07\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.4911e-06 - val_loss: 8.7562e-07\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.4549e-06 - val_loss: 8.1865e-07\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.4437e-06 - val_loss: 9.1631e-07\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.5589e-06 - val_loss: 9.7545e-07\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.4212e-06 - val_loss: 8.2581e-07\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.4140e-06 - val_loss: 8.9650e-07\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.3564e-06 - val_loss: 8.0727e-07\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.2675e-06 - val_loss: 7.8595e-07\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 6.2548e-06 - val_loss: 8.9430e-07\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.3417e-06 - val_loss: 8.8817e-07\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.2370e-06 - val_loss: 8.0832e-07\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.2022e-06 - val_loss: 8.5126e-07\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 6.1639e-06 - val_loss: 7.7564e-07\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.0915e-06 - val_loss: 7.8302e-07\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.1000e-06 - val_loss: 8.3163e-07\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.0506e-06 - val_loss: 8.1783e-07\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.1644e-06 - val_loss: 9.6937e-07\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.0610e-06 - val_loss: 7.9431e-07\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.1654e-06 - val_loss: 1.1661e-06\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.3441e-06 - val_loss: 1.2090e-06\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.2431e-06 - val_loss: 8.4160e-07\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.8970e-06 - val_loss: 8.0660e-07\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.8985e-06 - val_loss: 7.5792e-07\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.8230e-06 - val_loss: 7.5477e-07\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.7964e-06 - val_loss: 7.5767e-07\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.8006e-06 - val_loss: 8.3317e-07\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 5.8999e-06 - val_loss: 8.7096e-07\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.7549e-06 - val_loss: 7.5105e-07\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.7549e-06 - val_loss: 8.2103e-07\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.7119e-06 - val_loss: 7.5753e-07\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.6988e-06 - val_loss: 7.4745e-07\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.6217e-06 - val_loss: 7.3432e-07\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.5914e-06 - val_loss: 7.2674e-07\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.5670e-06 - val_loss: 7.3558e-07\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5672e-06 - val_loss: 7.6003e-07\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.5405e-06 - val_loss: 7.2179e-07\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.5327e-06 - val_loss: 7.7888e-07\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5511e-06 - val_loss: 8.5747e-07\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.5354e-06 - val_loss: 7.4978e-07\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.4937e-06 - val_loss: 8.7397e-07\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.5764e-06 - val_loss: 8.4660e-07\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.4634e-06 - val_loss: 7.2886e-07\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.3542e-06 - val_loss: 7.0641e-07\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 5.3435e-06 - val_loss: 7.2269e-07\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.3288e-06 - val_loss: 7.3964e-07\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.3461e-06 - val_loss: 7.8465e-07\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.3401e-06 - val_loss: 7.6606e-07\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.3367e-06 - val_loss: 8.3324e-07\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.3485e-06 - val_loss: 8.3995e-07\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.3049e-06 - val_loss: 7.4763e-07\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.2114e-06 - val_loss: 7.1086e-07\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.1519e-06 - val_loss: 6.8573e-07\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.1313e-06 - val_loss: 7.1869e-07\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.1662e-06 - val_loss: 7.7004e-07\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.1567e-06 - val_loss: 7.4920e-07\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.2171e-06 - val_loss: 1.1803e-06\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.7212e-06 - val_loss: 1.2861e-06\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.3015e-06 - val_loss: 6.8551e-07\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.1881e-06 - val_loss: 1.1093e-06\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.1759e-06 - val_loss: 7.0348e-07\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.1282e-06 - val_loss: 8.7370e-07\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0165e-06 - val_loss: 7.2592e-07\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.2296e-06 - val_loss: 1.2135e-06\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.1032e-06 - val_loss: 7.0104e-07\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.9524e-06 - val_loss: 7.1696e-07\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.8778e-06 - val_loss: 7.0960e-07\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.9607e-06 - val_loss: 8.2386e-07\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.8592e-06 - val_loss: 6.8208e-07\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.8656e-06 - val_loss: 7.3754e-07\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.8231e-06 - val_loss: 6.4927e-07\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.8791e-06 - val_loss: 9.2234e-07\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.8111e-06 - val_loss: 7.4459e-07\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.8109e-06 - val_loss: 6.5098e-07\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.7247e-06 - val_loss: 7.7650e-07\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.7565e-06 - val_loss: 6.4723e-07\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.6696e-06 - val_loss: 6.3985e-07\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.6341e-06 - val_loss: 6.5124e-07\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.6350e-06 - val_loss: 6.3544e-07\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.5981e-06 - val_loss: 6.5202e-07\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6480e-06 - val_loss: 7.8204e-07\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.6840e-06 - val_loss: 6.3946e-07\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.5681e-06 - val_loss: 7.2603e-07\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.5577e-06 - val_loss: 6.4723e-07\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.6057e-06 - val_loss: 7.8554e-07\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.6153e-06 - val_loss: 6.4306e-07\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.4896e-06 - val_loss: 7.3327e-07\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.5727e-06 - val_loss: 7.1161e-07\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.4900e-06 - val_loss: 6.1698e-07\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.4421e-06 - val_loss: 7.4325e-07\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.5377e-06 - val_loss: 6.9181e-07\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.4238e-06 - val_loss: 6.1615e-07\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4016e-06 - val_loss: 6.4703e-07\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.3607e-06 - val_loss: 6.0373e-07\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.3289e-06 - val_loss: 6.0333e-07\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.3116e-06 - val_loss: 6.2722e-07\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.3453e-06 - val_loss: 6.9454e-07\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.3882e-06 - val_loss: 7.1784e-07\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.3767e-06 - val_loss: 6.8746e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 4.2841e-06 - val_loss: 5.9486e-07\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.2694e-06 - val_loss: 6.9668e-07\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.2968e-06 - val_loss: 6.5550e-07\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.2295e-06 - val_loss: 6.1222e-07\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2114e-06 - val_loss: 6.3441e-07\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.1849e-06 - val_loss: 5.9855e-07\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2055e-06 - val_loss: 8.1721e-07\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.5965e-06 - val_loss: 1.4248e-06\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.8038e-06 - val_loss: 8.6170e-07\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.1870e-06 - val_loss: 5.8025e-07\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.1131e-06 - val_loss: 6.1601e-07\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.0806e-06 - val_loss: 5.7580e-07\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0928e-06 - val_loss: 6.4014e-07\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.0590e-06 - val_loss: 5.7415e-07\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.0198e-06 - val_loss: 5.9354e-07\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.0159e-06 - val_loss: 5.6993e-07\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.9961e-06 - val_loss: 6.2330e-07\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.1351e-06 - val_loss: 7.7967e-07\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 4.0400e-06 - val_loss: 5.6469e-07\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 3.9741e-06 - val_loss: 6.8837e-07\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.1254e-06 - val_loss: 7.3839e-07\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.9664e-06 - val_loss: 6.4367e-07\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.0958e-06 - val_loss: 8.9009e-07\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.0678e-06 - val_loss: 5.5435e-07\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.9718e-06 - val_loss: 9.9558e-07\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.3575e-06 - val_loss: 8.9707e-07\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.9769e-06 - val_loss: 5.6072e-07\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 3.9386e-06 - val_loss: 6.9231e-07\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.8540e-06 - val_loss: 5.7923e-07\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.8650e-06 - val_loss: 6.3745e-07\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.8418e-06 - val_loss: 5.5132e-07\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.7758e-06 - val_loss: 5.7329e-07\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.7612e-06 - val_loss: 5.3948e-07\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.7393e-06 - val_loss: 5.4051e-07\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.7247e-06 - val_loss: 5.3542e-07\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.7114e-06 - val_loss: 5.3841e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.6969e-06 - val_loss: 5.3392e-07\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 3.6856e-06 - val_loss: 5.3191e-07\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 3.6680e-06 - val_loss: 5.3164e-07\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.6739e-06 - val_loss: 5.9315e-07\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.6975e-06 - val_loss: 5.8544e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.7429e-06 - val_loss: 7.2187e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.7276e-06 - val_loss: 5.3401e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.6058e-06 - val_loss: 5.2413e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.5864e-06 - val_loss: 5.2212e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.5747e-06 - val_loss: 5.2691e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.5685e-06 - val_loss: 5.1747e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.5532e-06 - val_loss: 5.4347e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.5758e-06 - val_loss: 6.0486e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.7775e-06 - val_loss: 1.1115e-06\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.4077e-06 - val_loss: 1.7915e-06\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.4608e-06 - val_loss: 5.9886e-07\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.6331e-06 - val_loss: 9.0139e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.6650e-06 - val_loss: 5.0807e-07\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.5329e-06 - val_loss: 6.1493e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.5069e-06 - val_loss: 5.1173e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.5393e-06 - val_loss: 6.5597e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.4753e-06 - val_loss: 5.7063e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.4871e-06 - val_loss: 5.1242e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 3.4085e-06 - val_loss: 5.3595e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.4912e-06 - val_loss: 6.0090e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 3.4028e-06 - val_loss: 5.1359e-07\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.4118e-06 - val_loss: 5.2205e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.3658e-06 - val_loss: 5.1835e-07\n",
      "Epoch 00941: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 100, 8)            320       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100, 1)            9         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 329\n",
      "Trainable params: 329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0906 - val_loss: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0867 - val_loss: 0.0847\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0835 - val_loss: 0.0820\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0812 - val_loss: 0.0802\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.0796 - val_loss: 0.0788\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0782 - val_loss: 0.0775\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0769 - val_loss: 0.0761\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0755 - val_loss: 0.0747\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0740 - val_loss: 0.0732\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0726 - val_loss: 0.0718\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0711 - val_loss: 0.0703\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0697 - val_loss: 0.0689\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0682 - val_loss: 0.0674\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0667 - val_loss: 0.0659\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0652 - val_loss: 0.0643\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0637 - val_loss: 0.0627\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0621 - val_loss: 0.0611\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0605 - val_loss: 0.0595\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0588 - val_loss: 0.0579\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0572 - val_loss: 0.0562\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0555 - val_loss: 0.0545\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0537 - val_loss: 0.0527\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0520 - val_loss: 0.0509\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0502 - val_loss: 0.0491\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 718us/step - loss: 0.0483 - val_loss: 0.0472\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.0464 - val_loss: 0.0453\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 724us/step - loss: 0.0445 - val_loss: 0.0433\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0425 - val_loss: 0.0413\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0404 - val_loss: 0.0392\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0383 - val_loss: 0.0370\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.0360 - val_loss: 0.0346\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 0.0336 - val_loss: 0.0322\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0311 - val_loss: 0.0296\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0285 - val_loss: 0.0270\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0259 - val_loss: 0.0245\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0235 - val_loss: 0.0221\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0211 - val_loss: 0.0197\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0188 - val_loss: 0.0175\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0166 - val_loss: 0.0154\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0145 - val_loss: 0.0134\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 737us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0010 - val_loss: 9.9433e-04\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.9673e-04 - val_loss: 9.7716e-04\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.8078e-04 - val_loss: 9.6010e-04\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.6492e-04 - val_loss: 9.4325e-04\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.4918e-04 - val_loss: 9.2658e-04\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.3362e-04 - val_loss: 9.1012e-04\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.1827e-04 - val_loss: 8.9382e-04\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.0316e-04 - val_loss: 8.7763e-04\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.8809e-04 - val_loss: 8.6162e-04\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 8.7324e-04 - val_loss: 8.4577e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.5853e-04 - val_loss: 8.3012e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.4401e-04 - val_loss: 8.1460e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 8.2970e-04 - val_loss: 7.9937e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.1552e-04 - val_loss: 7.8405e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.0136e-04 - val_loss: 7.6905e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.8756e-04 - val_loss: 7.5416e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.7377e-04 - val_loss: 7.3949e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.6030e-04 - val_loss: 7.2497e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.4697e-04 - val_loss: 7.1057e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.3366e-04 - val_loss: 6.9643e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.2069e-04 - val_loss: 6.8240e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0776e-04 - val_loss: 6.6859e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.9502e-04 - val_loss: 6.5497e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.8250e-04 - val_loss: 6.4148e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.7014e-04 - val_loss: 6.2815e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.5790e-04 - val_loss: 6.1501e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.4581e-04 - val_loss: 6.0208e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.3400e-04 - val_loss: 5.8925e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.2226e-04 - val_loss: 5.7662e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.1074e-04 - val_loss: 5.6412e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.9935e-04 - val_loss: 5.5179e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.8811e-04 - val_loss: 5.3970e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.7708e-04 - val_loss: 5.2772e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.6614e-04 - val_loss: 5.1599e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.5543e-04 - val_loss: 5.0438e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.4489e-04 - val_loss: 4.9288e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.3443e-04 - val_loss: 4.8162e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.2423e-04 - val_loss: 4.7049e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.1413e-04 - val_loss: 4.5957e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.0421e-04 - val_loss: 4.4883e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.9444e-04 - val_loss: 4.3825e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 4.8492e-04 - val_loss: 4.2781e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.7543e-04 - val_loss: 4.1756e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.6615e-04 - val_loss: 4.0753e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.5707e-04 - val_loss: 3.9759e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.4810e-04 - val_loss: 3.8787e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.3932e-04 - val_loss: 3.7830e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.3066e-04 - val_loss: 3.6893e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 4.2224e-04 - val_loss: 3.5970e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.1392e-04 - val_loss: 3.5063e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.0580e-04 - val_loss: 3.4170e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.9776e-04 - val_loss: 3.3297e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.8992e-04 - val_loss: 3.2437e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.8221e-04 - val_loss: 3.1596e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7467e-04 - val_loss: 3.0778e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.6732e-04 - val_loss: 2.9964e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.6004e-04 - val_loss: 2.9172e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 842us/step - loss: 3.5300e-04 - val_loss: 2.8395e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 865us/step - loss: 3.4605e-04 - val_loss: 2.7639e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 849us/step - loss: 3.3929e-04 - val_loss: 2.6905e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.3271e-04 - val_loss: 2.6181e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.2629e-04 - val_loss: 2.5469e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.1990e-04 - val_loss: 2.4782e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.1380e-04 - val_loss: 2.4103e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.0777e-04 - val_loss: 2.3445e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.0191e-04 - val_loss: 2.2795e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.9618e-04 - val_loss: 2.2164e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.9056e-04 - val_loss: 2.1546e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8507e-04 - val_loss: 2.0943e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.7973e-04 - val_loss: 2.0356e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.7452e-04 - val_loss: 1.9780e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.6945e-04 - val_loss: 1.9221e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.6450e-04 - val_loss: 1.8673e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.5971e-04 - val_loss: 1.8135e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 2.5492e-04 - val_loss: 1.7619e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.5035e-04 - val_loss: 1.7118e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.4590e-04 - val_loss: 1.6625e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4157e-04 - val_loss: 1.6139e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3731e-04 - val_loss: 1.5673e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.3319e-04 - val_loss: 1.5221e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.2922e-04 - val_loss: 1.4778e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.2534e-04 - val_loss: 1.4348e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2155e-04 - val_loss: 1.3933e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1787e-04 - val_loss: 1.3532e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1434e-04 - val_loss: 1.3138e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1087e-04 - val_loss: 1.2752e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.0748e-04 - val_loss: 1.2383e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.0421e-04 - val_loss: 1.2021e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0105e-04 - val_loss: 1.1669e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9796e-04 - val_loss: 1.1330e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.9497e-04 - val_loss: 1.0998e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9207e-04 - val_loss: 1.0678e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.8924e-04 - val_loss: 1.0364e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8646e-04 - val_loss: 1.0062e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8384e-04 - val_loss: 9.7634e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.8124e-04 - val_loss: 9.4827e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7871e-04 - val_loss: 9.2078e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.7632e-04 - val_loss: 8.9356e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7394e-04 - val_loss: 8.6834e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7164e-04 - val_loss: 8.4265e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6940e-04 - val_loss: 8.1787e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.6721e-04 - val_loss: 7.9425e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.6510e-04 - val_loss: 7.7143e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6306e-04 - val_loss: 7.4918e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6109e-04 - val_loss: 7.2771e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.5918e-04 - val_loss: 7.0675e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5730e-04 - val_loss: 6.8706e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5550e-04 - val_loss: 6.6728e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.5375e-04 - val_loss: 6.4805e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5205e-04 - val_loss: 6.3050e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 1.5041e-04 - val_loss: 6.1236e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4878e-04 - val_loss: 5.9527e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4721e-04 - val_loss: 5.7811e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4568e-04 - val_loss: 5.6192e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4421e-04 - val_loss: 5.4629e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4277e-04 - val_loss: 5.3150e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4138e-04 - val_loss: 5.1680e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.4002e-04 - val_loss: 5.0270e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3870e-04 - val_loss: 4.8885e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.3742e-04 - val_loss: 4.7584e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3617e-04 - val_loss: 4.6284e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.3495e-04 - val_loss: 4.5019e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3377e-04 - val_loss: 4.3821e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.3261e-04 - val_loss: 4.2657e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3149e-04 - val_loss: 4.1527e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3041e-04 - val_loss: 4.0483e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2936e-04 - val_loss: 3.9406e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2833e-04 - val_loss: 3.8397e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2729e-04 - val_loss: 3.7373e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2631e-04 - val_loss: 3.6403e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2537e-04 - val_loss: 3.5487e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.2442e-04 - val_loss: 3.4604e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2351e-04 - val_loss: 3.3694e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.2260e-04 - val_loss: 3.2879e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2172e-04 - val_loss: 3.2037e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2087e-04 - val_loss: 3.1279e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2003e-04 - val_loss: 3.0494e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1922e-04 - val_loss: 2.9759e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1842e-04 - val_loss: 2.9017e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.1763e-04 - val_loss: 2.8329e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.1686e-04 - val_loss: 2.7595e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1613e-04 - val_loss: 2.6974e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.1539e-04 - val_loss: 2.6362e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.1466e-04 - val_loss: 2.5734e-05\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1396e-04 - val_loss: 2.5132e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1327e-04 - val_loss: 2.4570e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1261e-04 - val_loss: 2.3990e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.1193e-04 - val_loss: 2.3458e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1128e-04 - val_loss: 2.2929e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1061e-04 - val_loss: 2.2402e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0999e-04 - val_loss: 2.1913e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0937e-04 - val_loss: 2.1443e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.0875e-04 - val_loss: 2.0963e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0815e-04 - val_loss: 2.0501e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0756e-04 - val_loss: 2.0061e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0698e-04 - val_loss: 1.9640e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0641e-04 - val_loss: 1.9237e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0585e-04 - val_loss: 1.8840e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0531e-04 - val_loss: 1.8496e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0475e-04 - val_loss: 1.8069e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0421e-04 - val_loss: 1.7738e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0368e-04 - val_loss: 1.7356e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0314e-04 - val_loss: 1.6986e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0265e-04 - val_loss: 1.6666e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.0211e-04 - val_loss: 1.6340e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.0160e-04 - val_loss: 1.6019e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0112e-04 - val_loss: 1.5707e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0063e-04 - val_loss: 1.5419e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0015e-04 - val_loss: 1.5156e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.9663e-05 - val_loss: 1.4853e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 9.9182e-05 - val_loss: 1.4561e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 9.8710e-05 - val_loss: 1.4323e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.8242e-05 - val_loss: 1.4007e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.7775e-05 - val_loss: 1.3770e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.7326e-05 - val_loss: 1.3555e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.6887e-05 - val_loss: 1.3358e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.6409e-05 - val_loss: 1.3110e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.5983e-05 - val_loss: 1.2893e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 9.5548e-05 - val_loss: 1.2642e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.5097e-05 - val_loss: 1.2404e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 9.4676e-05 - val_loss: 1.2202e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.4240e-05 - val_loss: 1.2011e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.3815e-05 - val_loss: 1.1822e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.3400e-05 - val_loss: 1.1635e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.2974e-05 - val_loss: 1.1442e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.2566e-05 - val_loss: 1.1263e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.2140e-05 - val_loss: 1.1041e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.1752e-05 - val_loss: 1.0895e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.1345e-05 - val_loss: 1.0749e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.0923e-05 - val_loss: 1.0569e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.0539e-05 - val_loss: 1.0421e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.0144e-05 - val_loss: 1.0283e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.9775e-05 - val_loss: 1.0128e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.9359e-05 - val_loss: 9.9718e-06\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.8965e-05 - val_loss: 9.8096e-06\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.8579e-05 - val_loss: 9.6575e-06\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.8213e-05 - val_loss: 9.5547e-06\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.7811e-05 - val_loss: 9.4353e-06\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.7448e-05 - val_loss: 9.2646e-06\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.7068e-05 - val_loss: 9.1394e-06\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.6708e-05 - val_loss: 9.0360e-06\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.6324e-05 - val_loss: 8.9193e-06\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 8.5946e-05 - val_loss: 8.8099e-06\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 8.5583e-05 - val_loss: 8.6802e-06\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.5260e-05 - val_loss: 8.5821e-06\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.4880e-05 - val_loss: 8.5204e-06\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.4479e-05 - val_loss: 8.3609e-06\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.4119e-05 - val_loss: 8.2502e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.3769e-05 - val_loss: 8.1602e-06\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.3393e-05 - val_loss: 8.0314e-06\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.3042e-05 - val_loss: 7.9499e-06\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.2719e-05 - val_loss: 7.8667e-06\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.2347e-05 - val_loss: 7.7646e-06\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.1995e-05 - val_loss: 7.6743e-06\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.1637e-05 - val_loss: 7.5684e-06\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 8.1316e-05 - val_loss: 7.5310e-06\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.0961e-05 - val_loss: 7.4126e-06\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0588e-05 - val_loss: 7.3043e-06\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0266e-05 - val_loss: 7.2651e-06\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.9926e-05 - val_loss: 7.1434e-06\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.9584e-05 - val_loss: 7.0761e-06\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.9248e-05 - val_loss: 7.0088e-06\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.8902e-05 - val_loss: 6.9239e-06\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.8561e-05 - val_loss: 6.8258e-06\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.8235e-05 - val_loss: 6.7794e-06\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.7902e-05 - val_loss: 6.6941e-06\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.7581e-05 - val_loss: 6.6459e-06\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.7259e-05 - val_loss: 6.5921e-06\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.6934e-05 - val_loss: 6.5369e-06\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.6582e-05 - val_loss: 6.4564e-06\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.6248e-05 - val_loss: 6.3775e-06\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.5912e-05 - val_loss: 6.2838e-06\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.5611e-05 - val_loss: 6.2579e-06\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.5284e-05 - val_loss: 6.2159e-06\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.4957e-05 - val_loss: 6.1618e-06\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.4622e-05 - val_loss: 6.0766e-06\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.4301e-05 - val_loss: 6.0076e-06\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.3991e-05 - val_loss: 5.9577e-06\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.3669e-05 - val_loss: 5.8871e-06\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.3357e-05 - val_loss: 5.8450e-06\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3048e-05 - val_loss: 5.8234e-06\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.2734e-05 - val_loss: 5.7791e-06\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 7.2419e-05 - val_loss: 5.7356e-06\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.2112e-05 - val_loss: 5.6398e-06\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 7.1797e-05 - val_loss: 5.5991e-06\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 807us/step - loss: 7.1472e-05 - val_loss: 5.5466e-06\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 7.1163e-05 - val_loss: 5.5069e-06\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.0851e-05 - val_loss: 5.4540e-06\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 7.0553e-05 - val_loss: 5.4063e-06\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.0247e-05 - val_loss: 5.3721e-06\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.9942e-05 - val_loss: 5.3304e-06\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 6.9628e-05 - val_loss: 5.2788e-06\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 6.9323e-05 - val_loss: 5.2321e-06\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.9030e-05 - val_loss: 5.2175e-06\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 6.8727e-05 - val_loss: 5.1792e-06\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.8427e-05 - val_loss: 5.1385e-06\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.8112e-05 - val_loss: 5.0790e-06\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.7807e-05 - val_loss: 5.0066e-06\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.7521e-05 - val_loss: 4.9737e-06\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 6.7240e-05 - val_loss: 4.9480e-06\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 6.6930e-05 - val_loss: 4.8967e-06\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.6652e-05 - val_loss: 4.8695e-06\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.6348e-05 - val_loss: 4.8540e-06\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.6044e-05 - val_loss: 4.8165e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.5750e-05 - val_loss: 4.7831e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.5458e-05 - val_loss: 4.7366e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.5162e-05 - val_loss: 4.7034e-06\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.4892e-05 - val_loss: 4.6627e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.4593e-05 - val_loss: 4.6404e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.4302e-05 - val_loss: 4.5831e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.4013e-05 - val_loss: 4.5520e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.3716e-05 - val_loss: 4.5216e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.3426e-05 - val_loss: 4.4683e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.3159e-05 - val_loss: 4.4545e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.2867e-05 - val_loss: 4.4182e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 6.2598e-05 - val_loss: 4.4253e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.2312e-05 - val_loss: 4.3984e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.2042e-05 - val_loss: 4.4628e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.1772e-05 - val_loss: 4.3067e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.1463e-05 - val_loss: 4.2744e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.1185e-05 - val_loss: 4.2589e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.0904e-05 - val_loss: 4.2283e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 6.0622e-05 - val_loss: 4.2029e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.0344e-05 - val_loss: 4.1771e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.0074e-05 - val_loss: 4.1485e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.9822e-05 - val_loss: 4.1213e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.9522e-05 - val_loss: 4.1008e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.9266e-05 - val_loss: 4.0983e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.9010e-05 - val_loss: 4.0451e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 5.8706e-05 - val_loss: 4.0202e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.8438e-05 - val_loss: 3.9579e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.8172e-05 - val_loss: 3.9596e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.7893e-05 - val_loss: 3.9215e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.7638e-05 - val_loss: 3.9129e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.7358e-05 - val_loss: 3.8590e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.7106e-05 - val_loss: 3.8463e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.6820e-05 - val_loss: 3.8233e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.6544e-05 - val_loss: 3.8090e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.6288e-05 - val_loss: 3.7931e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.6016e-05 - val_loss: 3.7609e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.5758e-05 - val_loss: 3.7334e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.5486e-05 - val_loss: 3.7067e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.5247e-05 - val_loss: 3.7190e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.4976e-05 - val_loss: 3.6510e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 5.4713e-05 - val_loss: 3.6289e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.4461e-05 - val_loss: 3.6023e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.4195e-05 - val_loss: 3.6094e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.3951e-05 - val_loss: 3.6033e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.3676e-05 - val_loss: 3.5947e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.3438e-05 - val_loss: 3.5141e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.3148e-05 - val_loss: 3.4945e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.2922e-05 - val_loss: 3.4949e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.2648e-05 - val_loss: 3.4447e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.2412e-05 - val_loss: 3.4518e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.2140e-05 - val_loss: 3.4295e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.1884e-05 - val_loss: 3.3837e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 5.1639e-05 - val_loss: 3.3869e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.1390e-05 - val_loss: 3.3625e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.1170e-05 - val_loss: 3.3624e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.0879e-05 - val_loss: 3.3191e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.0629e-05 - val_loss: 3.2756e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.0404e-05 - val_loss: 3.2928e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.0143e-05 - val_loss: 3.2557e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.9885e-05 - val_loss: 3.2203e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.9643e-05 - val_loss: 3.2140e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.9422e-05 - val_loss: 3.2143e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.9156e-05 - val_loss: 3.2123e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.8928e-05 - val_loss: 3.1658e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.8705e-05 - val_loss: 3.1669e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.8452e-05 - val_loss: 3.1428e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.8177e-05 - val_loss: 3.0919e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.7954e-05 - val_loss: 3.0848e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.7723e-05 - val_loss: 3.0846e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.7471e-05 - val_loss: 3.0569e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.7234e-05 - val_loss: 3.0355e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 4.6999e-05 - val_loss: 3.0207e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 4.6756e-05 - val_loss: 3.0213e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.6524e-05 - val_loss: 2.9826e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.6287e-05 - val_loss: 2.9701e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.6048e-05 - val_loss: 2.9412e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.5826e-05 - val_loss: 2.9469e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.5585e-05 - val_loss: 2.9204e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.5362e-05 - val_loss: 2.9630e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.5134e-05 - val_loss: 2.9016e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.4892e-05 - val_loss: 2.8892e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.4657e-05 - val_loss: 2.8641e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.4420e-05 - val_loss: 2.8409e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.4225e-05 - val_loss: 2.8315e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.3980e-05 - val_loss: 2.8289e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.3751e-05 - val_loss: 2.8348e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.3540e-05 - val_loss: 2.7909e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.3303e-05 - val_loss: 2.7736e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.3074e-05 - val_loss: 2.7423e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.2846e-05 - val_loss: 2.7430e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.2620e-05 - val_loss: 2.7329e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.2387e-05 - val_loss: 2.6932e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 4.2169e-05 - val_loss: 2.6799e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.1956e-05 - val_loss: 2.6754e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.1739e-05 - val_loss: 2.6755e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.1510e-05 - val_loss: 2.6702e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.1319e-05 - val_loss: 2.7040e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.1101e-05 - val_loss: 2.6208e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.0864e-05 - val_loss: 2.6495e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.0658e-05 - val_loss: 2.6013e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 4.0439e-05 - val_loss: 2.6130e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.0216e-05 - val_loss: 2.5554e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.9984e-05 - val_loss: 2.5303e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.9778e-05 - val_loss: 2.5200e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.9562e-05 - val_loss: 2.5289e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.9348e-05 - val_loss: 2.5090e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.9153e-05 - val_loss: 2.4980e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 3.8921e-05 - val_loss: 2.4816e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.8712e-05 - val_loss: 2.4732e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.8489e-05 - val_loss: 2.4365e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.8287e-05 - val_loss: 2.4157e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.8078e-05 - val_loss: 2.4083e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.7865e-05 - val_loss: 2.3980e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.7677e-05 - val_loss: 2.4678e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.7474e-05 - val_loss: 2.3960e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7251e-05 - val_loss: 2.3738e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.7043e-05 - val_loss: 2.3576e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.6838e-05 - val_loss: 2.3411e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.6655e-05 - val_loss: 2.3397e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.6467e-05 - val_loss: 2.3396e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.6287e-05 - val_loss: 2.4514e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.6097e-05 - val_loss: 2.3078e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.5868e-05 - val_loss: 2.3105e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.5666e-05 - val_loss: 2.3512e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.5481e-05 - val_loss: 2.2759e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.5248e-05 - val_loss: 2.3343e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5081e-05 - val_loss: 2.3233e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.4882e-05 - val_loss: 2.2306e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.4645e-05 - val_loss: 2.2064e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.4441e-05 - val_loss: 2.1894e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.4248e-05 - val_loss: 2.1763e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.4057e-05 - val_loss: 2.1699e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.3854e-05 - val_loss: 2.1836e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.3708e-05 - val_loss: 2.2287e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.3518e-05 - val_loss: 2.1344e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.3296e-05 - val_loss: 2.1291e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.3098e-05 - val_loss: 2.1024e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.2916e-05 - val_loss: 2.1195e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2718e-05 - val_loss: 2.1105e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 3.2525e-05 - val_loss: 2.0930e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.2336e-05 - val_loss: 2.0663e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.2149e-05 - val_loss: 2.0507e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 3.1990e-05 - val_loss: 2.0822e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.1819e-05 - val_loss: 2.0443e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 753us/step - loss: 3.1625e-05 - val_loss: 2.0432e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.1411e-05 - val_loss: 2.0332e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.1239e-05 - val_loss: 2.0088e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.1046e-05 - val_loss: 1.9929e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.0859e-05 - val_loss: 2.0402e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.0722e-05 - val_loss: 1.9976e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.0527e-05 - val_loss: 2.0652e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.0357e-05 - val_loss: 1.9574e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.0149e-05 - val_loss: 1.9661e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.9962e-05 - val_loss: 1.9262e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.9792e-05 - val_loss: 1.9114e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.9615e-05 - val_loss: 1.9977e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.9482e-05 - val_loss: 1.9378e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.9271e-05 - val_loss: 1.9168e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.9143e-05 - val_loss: 1.9095e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.8973e-05 - val_loss: 1.9317e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.8767e-05 - val_loss: 1.9183e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8596e-05 - val_loss: 1.8422e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.8453e-05 - val_loss: 1.8890e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.8273e-05 - val_loss: 1.9742e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8158e-05 - val_loss: 1.9942e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.7955e-05 - val_loss: 1.8455e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.7719e-05 - val_loss: 1.7949e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.7544e-05 - val_loss: 1.8166e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.7378e-05 - val_loss: 1.7848e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.7198e-05 - val_loss: 1.7620e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.7057e-05 - val_loss: 1.7671e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.6885e-05 - val_loss: 1.7664e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.6725e-05 - val_loss: 1.7695e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6547e-05 - val_loss: 1.7754e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.6400e-05 - val_loss: 1.8149e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.6258e-05 - val_loss: 1.7695e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.6065e-05 - val_loss: 1.6862e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.5888e-05 - val_loss: 1.6898e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.5726e-05 - val_loss: 1.7080e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.5593e-05 - val_loss: 1.7641e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.5449e-05 - val_loss: 1.7537e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.5291e-05 - val_loss: 1.6967e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.5102e-05 - val_loss: 1.6770e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.4942e-05 - val_loss: 1.6542e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4786e-05 - val_loss: 1.6382e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.4629e-05 - val_loss: 1.6396e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4466e-05 - val_loss: 1.6270e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 2.4324e-05 - val_loss: 1.6397e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.4159e-05 - val_loss: 1.6405e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4007e-05 - val_loss: 1.5915e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.3853e-05 - val_loss: 1.5838e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3703e-05 - val_loss: 1.5747e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.3546e-05 - val_loss: 1.5735e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.3395e-05 - val_loss: 1.5580e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 2.3249e-05 - val_loss: 1.5553e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.3105e-05 - val_loss: 1.5294e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.2960e-05 - val_loss: 1.5424e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.2807e-05 - val_loss: 1.5524e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2659e-05 - val_loss: 1.5359e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2507e-05 - val_loss: 1.5177e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.2373e-05 - val_loss: 1.5159e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.2218e-05 - val_loss: 1.5080e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2084e-05 - val_loss: 1.5010e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.1945e-05 - val_loss: 1.4653e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1791e-05 - val_loss: 1.4692e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1658e-05 - val_loss: 1.4747e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.1505e-05 - val_loss: 1.4644e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.1391e-05 - val_loss: 1.4590e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.1246e-05 - val_loss: 1.4749e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.1129e-05 - val_loss: 1.4856e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0983e-05 - val_loss: 1.5109e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.0870e-05 - val_loss: 1.5321e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.0740e-05 - val_loss: 1.4192e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.0552e-05 - val_loss: 1.4292e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0410e-05 - val_loss: 1.3812e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0267e-05 - val_loss: 1.3930e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0132e-05 - val_loss: 1.3869e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.9989e-05 - val_loss: 1.3870e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.9858e-05 - val_loss: 1.3693e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9736e-05 - val_loss: 1.3564e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.9605e-05 - val_loss: 1.3624e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9474e-05 - val_loss: 1.4122e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9367e-05 - val_loss: 1.3456e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.9205e-05 - val_loss: 1.3484e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9103e-05 - val_loss: 1.3295e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.8984e-05 - val_loss: 1.3425e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.8823e-05 - val_loss: 1.3043e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8699e-05 - val_loss: 1.3031e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.8569e-05 - val_loss: 1.3074e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.8453e-05 - val_loss: 1.3442e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.8336e-05 - val_loss: 1.3589e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.8209e-05 - val_loss: 1.3197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.8089e-05 - val_loss: 1.2915e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7981e-05 - val_loss: 1.2586e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.7851e-05 - val_loss: 1.2540e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.7743e-05 - val_loss: 1.2938e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7629e-05 - val_loss: 1.3765e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7524e-05 - val_loss: 1.2844e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.7368e-05 - val_loss: 1.2461e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.7216e-05 - val_loss: 1.2371e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7161e-05 - val_loss: 1.2608e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7029e-05 - val_loss: 1.2611e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.6882e-05 - val_loss: 1.2279e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.6776e-05 - val_loss: 1.2739e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.6667e-05 - val_loss: 1.3230e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6581e-05 - val_loss: 1.2060e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6440e-05 - val_loss: 1.1822e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6388e-05 - val_loss: 1.2381e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.6255e-05 - val_loss: 1.2602e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.6129e-05 - val_loss: 1.2832e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5994e-05 - val_loss: 1.2131e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5864e-05 - val_loss: 1.2039e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5802e-05 - val_loss: 1.1571e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.5664e-05 - val_loss: 1.1454e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5527e-05 - val_loss: 1.1330e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5414e-05 - val_loss: 1.1391e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5341e-05 - val_loss: 1.1151e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.5214e-05 - val_loss: 1.1927e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.5100e-05 - val_loss: 1.1345e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.4985e-05 - val_loss: 1.1061e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.4879e-05 - val_loss: 1.0955e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4788e-05 - val_loss: 1.1373e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.4678e-05 - val_loss: 1.1585e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4597e-05 - val_loss: 1.0999e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4502e-05 - val_loss: 1.0841e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.4422e-05 - val_loss: 1.0969e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4267e-05 - val_loss: 1.1210e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4167e-05 - val_loss: 1.0558e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4045e-05 - val_loss: 1.0709e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.3985e-05 - val_loss: 1.0456e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3870e-05 - val_loss: 1.0462e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.3776e-05 - val_loss: 1.0641e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.3667e-05 - val_loss: 1.0761e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.3575e-05 - val_loss: 1.0242e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3449e-05 - val_loss: 1.0146e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.3356e-05 - val_loss: 1.0047e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.3261e-05 - val_loss: 1.0032e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.3163e-05 - val_loss: 1.0033e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3067e-05 - val_loss: 9.9337e-07\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2977e-05 - val_loss: 1.0169e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.2895e-05 - val_loss: 1.0127e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2789e-05 - val_loss: 9.7706e-07\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2703e-05 - val_loss: 9.7004e-07\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2635e-05 - val_loss: 1.0116e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2533e-05 - val_loss: 9.7720e-07\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.2461e-05 - val_loss: 9.8657e-07\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.2342e-05 - val_loss: 9.6152e-07\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.2250e-05 - val_loss: 9.5594e-07\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2160e-05 - val_loss: 9.5204e-07\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2079e-05 - val_loss: 9.4235e-07\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.1982e-05 - val_loss: 9.3386e-07\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1906e-05 - val_loss: 9.4192e-07\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1812e-05 - val_loss: 9.3239e-07\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1723e-05 - val_loss: 9.3171e-07\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1645e-05 - val_loss: 9.4886e-07\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.1585e-05 - val_loss: 9.2516e-07\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 1.1491e-05 - val_loss: 9.0600e-07\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1393e-05 - val_loss: 9.3479e-07\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1365e-05 - val_loss: 9.3069e-07\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1234e-05 - val_loss: 8.9560e-07\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.1140e-05 - val_loss: 8.9088e-07\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 1.1088e-05 - val_loss: 9.3647e-07\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1019e-05 - val_loss: 9.0091e-07\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0918e-05 - val_loss: 8.7697e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0936e-05 - val_loss: 1.1572e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.0885e-05 - val_loss: 8.6735e-07\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.0728e-05 - val_loss: 9.5336e-07\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0626e-05 - val_loss: 8.7139e-07\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0602e-05 - val_loss: 9.3807e-07\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0457e-05 - val_loss: 8.8771e-07\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0404e-05 - val_loss: 8.4253e-07\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0303e-05 - val_loss: 9.2289e-07\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0325e-05 - val_loss: 9.5608e-07\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0169e-05 - val_loss: 8.5216e-07\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0073e-05 - val_loss: 8.3442e-07\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.9909e-06 - val_loss: 8.2375e-07\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.9092e-06 - val_loss: 8.3138e-07\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.8913e-06 - val_loss: 8.9140e-07\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.8166e-06 - val_loss: 8.1024e-07\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.7004e-06 - val_loss: 8.1264e-07\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 9.6301e-06 - val_loss: 8.2605e-07\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 9.6111e-06 - val_loss: 8.3651e-07\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.4989e-06 - val_loss: 8.4647e-07\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.5268e-06 - val_loss: 8.9206e-07\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.3889e-06 - val_loss: 8.1774e-07\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.4269e-06 - val_loss: 1.0228e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.3431e-06 - val_loss: 7.7565e-07\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.2303e-06 - val_loss: 9.6890e-07\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.1877e-06 - val_loss: 7.7161e-07\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.0508e-06 - val_loss: 8.7058e-07\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.9877e-06 - val_loss: 7.9789e-07\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.9488e-06 - val_loss: 8.1551e-07\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.8476e-06 - val_loss: 7.5488e-07\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 8.7657e-06 - val_loss: 7.5045e-07\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.6963e-06 - val_loss: 7.8421e-07\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.6621e-06 - val_loss: 7.5378e-07\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.5835e-06 - val_loss: 8.0977e-07\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.5583e-06 - val_loss: 7.3055e-07\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.4525e-06 - val_loss: 7.3778e-07\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.4013e-06 - val_loss: 8.3398e-07\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.4083e-06 - val_loss: 7.3427e-07\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.3013e-06 - val_loss: 8.6799e-07\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.2910e-06 - val_loss: 7.1464e-07\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.2080e-06 - val_loss: 8.7854e-07\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.1706e-06 - val_loss: 7.0930e-07\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.0528e-06 - val_loss: 7.4851e-07\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.9892e-06 - val_loss: 7.8180e-07\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.0566e-06 - val_loss: 7.4647e-07\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.8718e-06 - val_loss: 7.4042e-07\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.8219e-06 - val_loss: 6.9039e-07\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.7846e-06 - val_loss: 7.8242e-07\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.7421e-06 - val_loss: 6.8283e-07\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.6370e-06 - val_loss: 6.8015e-07\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.5859e-06 - val_loss: 6.8193e-07\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.5286e-06 - val_loss: 6.7224e-07\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.4773e-06 - val_loss: 6.8415e-07\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.4565e-06 - val_loss: 6.9900e-07\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.3756e-06 - val_loss: 6.6402e-07\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.3399e-06 - val_loss: 7.4871e-07\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.3793e-06 - val_loss: 7.6092e-07\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.2523e-06 - val_loss: 6.6629e-07\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.2162e-06 - val_loss: 6.8022e-07\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.1149e-06 - val_loss: 6.5566e-07\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 7.0607e-06 - val_loss: 6.4030e-07\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.0272e-06 - val_loss: 6.8654e-07\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.9856e-06 - val_loss: 6.3646e-07\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.9395e-06 - val_loss: 7.3739e-07\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.9477e-06 - val_loss: 6.3848e-07\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.8488e-06 - val_loss: 8.0589e-07\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 7.0322e-06 - val_loss: 8.1078e-07\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.7947e-06 - val_loss: 6.2216e-07\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.7198e-06 - val_loss: 6.8354e-07\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 6.6505e-06 - val_loss: 6.1431e-07\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.5798e-06 - val_loss: 6.2236e-07\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.5441e-06 - val_loss: 6.1583e-07\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 6.4895e-06 - val_loss: 6.1297e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.4557e-06 - val_loss: 6.9257e-07\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.5653e-06 - val_loss: 7.4694e-07\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.4024e-06 - val_loss: 6.4272e-07\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.4199e-06 - val_loss: 7.2597e-07\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.3365e-06 - val_loss: 6.0421e-07\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.3063e-06 - val_loss: 6.9879e-07\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.2456e-06 - val_loss: 6.0207e-07\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.1446e-06 - val_loss: 5.9163e-07\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.1341e-06 - val_loss: 6.3100e-07\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.1111e-06 - val_loss: 6.3810e-07\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.0477e-06 - val_loss: 5.7208e-07\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 5.9933e-06 - val_loss: 6.5102e-07\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.9686e-06 - val_loss: 5.7390e-07\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.9048e-06 - val_loss: 5.6522e-07\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.9026e-06 - val_loss: 7.2272e-07\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.0157e-06 - val_loss: 7.1562e-07\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 5.8265e-06 - val_loss: 5.7275e-07\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 720us/step - loss: 5.7749e-06 - val_loss: 6.1672e-07\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.7440e-06 - val_loss: 5.5125e-07\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.6811e-06 - val_loss: 6.2712e-07\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.6507e-06 - val_loss: 5.5021e-07\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.6067e-06 - val_loss: 5.7076e-07\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.5559e-06 - val_loss: 5.5208e-07\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.5513e-06 - val_loss: 6.0072e-07\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.5194e-06 - val_loss: 5.5133e-07\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 5.4594e-06 - val_loss: 5.6170e-07\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.4326e-06 - val_loss: 5.3695e-07\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.3674e-06 - val_loss: 5.2640e-07\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.3351e-06 - val_loss: 5.4824e-07\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.3640e-06 - val_loss: 6.4102e-07\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.3527e-06 - val_loss: 5.3183e-07\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.2561e-06 - val_loss: 6.7931e-07\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 5.4448e-06 - val_loss: 7.2802e-07\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.2758e-06 - val_loss: 5.1437e-07\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.2307e-06 - val_loss: 7.1378e-07\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 5.2315e-06 - val_loss: 5.3010e-07\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.0762e-06 - val_loss: 5.5204e-07\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.0592e-06 - val_loss: 5.1124e-07\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.0410e-06 - val_loss: 5.4987e-07\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.9818e-06 - val_loss: 5.0745e-07\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.9401e-06 - val_loss: 5.0184e-07\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.9175e-06 - val_loss: 5.1562e-07\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.8781e-06 - val_loss: 4.9275e-07\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.8465e-06 - val_loss: 4.9002e-07\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.8115e-06 - val_loss: 4.9098e-07\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.8004e-06 - val_loss: 5.4235e-07\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.8489e-06 - val_loss: 6.0598e-07\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.8055e-06 - val_loss: 5.0693e-07\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.7007e-06 - val_loss: 4.9060e-07\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.7420e-06 - val_loss: 7.2571e-07\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.9311e-06 - val_loss: 6.2051e-07\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.6536e-06 - val_loss: 5.8338e-07\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.7296e-06 - val_loss: 5.5481e-07\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.5897e-06 - val_loss: 5.8063e-07\n",
      "Epoch 00782: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 100, 9)            396       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100, 1)            10        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0764 - val_loss: 0.0748\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0738 - val_loss: 0.0725\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0718 - val_loss: 0.0708\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0703 - val_loss: 0.0695\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0690 - val_loss: 0.0683\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0678 - val_loss: 0.0671\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0665 - val_loss: 0.0658\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0652 - val_loss: 0.0644\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0639 - val_loss: 0.0631\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0626 - val_loss: 0.0618\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0612 - val_loss: 0.0604\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0598 - val_loss: 0.0590\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0583 - val_loss: 0.0574\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0568 - val_loss: 0.0559\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0552 - val_loss: 0.0542\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0534 - val_loss: 0.0523\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0515 - val_loss: 0.0503\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0494 - val_loss: 0.0479\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0468 - val_loss: 0.0450\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0436 - val_loss: 0.0416\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0403 - val_loss: 0.0386\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0374 - val_loss: 0.0358\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0346 - val_loss: 0.0329\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0317 - val_loss: 0.0300\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0288 - val_loss: 0.0272\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0234 - val_loss: 0.0219\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0209 - val_loss: 0.0195\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0162 - val_loss: 0.0151\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 0.0142 - val_loss: 0.0131\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 741us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.8440e-04 - val_loss: 0.0010\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.6874e-04 - val_loss: 9.8451e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 9.5320e-04 - val_loss: 9.6789e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.3767e-04 - val_loss: 9.5137e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.2230e-04 - val_loss: 9.3492e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.0711e-04 - val_loss: 9.1847e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.9179e-04 - val_loss: 9.0217e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.7664e-04 - val_loss: 8.8598e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.6155e-04 - val_loss: 8.6991e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 719us/step - loss: 8.4666e-04 - val_loss: 8.5390e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.3180e-04 - val_loss: 8.3799e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 8.1709e-04 - val_loss: 8.2216e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0237e-04 - val_loss: 8.0649e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.8787e-04 - val_loss: 7.9089e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.7344e-04 - val_loss: 7.7540e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.5912e-04 - val_loss: 7.6005e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.4499e-04 - val_loss: 7.4476e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3077e-04 - val_loss: 7.2970e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.1686e-04 - val_loss: 7.1472e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.0305e-04 - val_loss: 6.9987e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.8933e-04 - val_loss: 6.8515e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.7579e-04 - val_loss: 6.7056e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.6228e-04 - val_loss: 6.5616e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.4906e-04 - val_loss: 6.4185e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.3592e-04 - val_loss: 6.2767e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.2285e-04 - val_loss: 6.1369e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.1003e-04 - val_loss: 5.9982e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.9724e-04 - val_loss: 5.8616e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.8469e-04 - val_loss: 5.7265e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.7230e-04 - val_loss: 5.5929e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.6005e-04 - val_loss: 5.4609e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.4802e-04 - val_loss: 5.3300e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.3599e-04 - val_loss: 5.2015e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 5.2421e-04 - val_loss: 5.0747e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.1265e-04 - val_loss: 4.9493e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.0117e-04 - val_loss: 4.8259e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.8988e-04 - val_loss: 4.7043e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.7880e-04 - val_loss: 4.5845e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.6788e-04 - val_loss: 4.4662e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.5707e-04 - val_loss: 4.3500e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4650e-04 - val_loss: 4.2357e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3609e-04 - val_loss: 4.1232e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.2584e-04 - val_loss: 4.0126e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.1577e-04 - val_loss: 3.9038e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.0591e-04 - val_loss: 3.7968e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.9620e-04 - val_loss: 3.6917e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.8665e-04 - val_loss: 3.5888e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.7734e-04 - val_loss: 3.4874e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 3.6810e-04 - val_loss: 3.3883e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.5911e-04 - val_loss: 3.2912e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.5034e-04 - val_loss: 3.1956e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.4169e-04 - val_loss: 3.1021e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.3324e-04 - val_loss: 3.0105e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.2495e-04 - val_loss: 2.9209e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.1685e-04 - val_loss: 2.8332e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.0896e-04 - val_loss: 2.7472e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.0120e-04 - val_loss: 2.6633e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.9362e-04 - val_loss: 2.5815e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8623e-04 - val_loss: 2.5014e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.7904e-04 - val_loss: 2.4230e-04\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 734us/step - loss: 2.7197e-04 - val_loss: 2.3466e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.6510e-04 - val_loss: 2.2720e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 722us/step - loss: 2.5841e-04 - val_loss: 2.1991e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.5188e-04 - val_loss: 2.1281e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.4549e-04 - val_loss: 2.0591e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.3932e-04 - val_loss: 1.9915e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.3323e-04 - val_loss: 1.9262e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.2738e-04 - val_loss: 1.8623e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2164e-04 - val_loss: 1.8004e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1608e-04 - val_loss: 1.7402e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.1068e-04 - val_loss: 1.6817e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.0543e-04 - val_loss: 1.6247e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.0035e-04 - val_loss: 1.5692e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9540e-04 - val_loss: 1.5153e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 723us/step - loss: 1.9059e-04 - val_loss: 1.4630e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.8593e-04 - val_loss: 1.4123e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.8137e-04 - val_loss: 1.3634e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.7699e-04 - val_loss: 1.3160e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7274e-04 - val_loss: 1.2698e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6864e-04 - val_loss: 1.2248e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6460e-04 - val_loss: 1.1819e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.6077e-04 - val_loss: 1.1400e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 1.5701e-04 - val_loss: 1.0995e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5338e-04 - val_loss: 1.0606e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.4991e-04 - val_loss: 1.0225e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.4650e-04 - val_loss: 9.8585e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.4323e-04 - val_loss: 9.5046e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4006e-04 - val_loss: 9.1654e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3700e-04 - val_loss: 8.8357e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3405e-04 - val_loss: 8.5162e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.3118e-04 - val_loss: 8.2106e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2842e-04 - val_loss: 7.9154e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2577e-04 - val_loss: 7.6284e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2321e-04 - val_loss: 7.3522e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2071e-04 - val_loss: 7.0865e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1833e-04 - val_loss: 6.8331e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1601e-04 - val_loss: 6.5852e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.1377e-04 - val_loss: 6.3495e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1163e-04 - val_loss: 6.1213e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.0955e-04 - val_loss: 5.9006e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0754e-04 - val_loss: 5.6888e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 726us/step - loss: 1.0561e-04 - val_loss: 5.4872e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.0374e-04 - val_loss: 5.2902e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0196e-04 - val_loss: 5.1020e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0022e-04 - val_loss: 4.9201e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.8543e-05 - val_loss: 4.7475e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.6931e-05 - val_loss: 4.5805e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.5379e-05 - val_loss: 4.4202e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.3874e-05 - val_loss: 4.2651e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 9.2420e-05 - val_loss: 4.1170e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 9.1027e-05 - val_loss: 3.9759e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.9682e-05 - val_loss: 3.8390e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.8385e-05 - val_loss: 3.7091e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.7119e-05 - val_loss: 3.5843e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.5912e-05 - val_loss: 3.4625e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 8.4734e-05 - val_loss: 3.3462e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.3607e-05 - val_loss: 3.2346e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.2505e-05 - val_loss: 3.1273e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.1448e-05 - val_loss: 3.0251e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0427e-05 - val_loss: 2.9281e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.9442e-05 - val_loss: 2.8334e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 7.8491e-05 - val_loss: 2.7414e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.7566e-05 - val_loss: 2.6533e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.6664e-05 - val_loss: 2.5696e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.5779e-05 - val_loss: 2.4902e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.4951e-05 - val_loss: 2.4141e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.4116e-05 - val_loss: 2.3383e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.3328e-05 - val_loss: 2.2662e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.2543e-05 - val_loss: 2.1975e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.1799e-05 - val_loss: 2.1326e-05\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.1079e-05 - val_loss: 2.0699e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 7.0361e-05 - val_loss: 2.0102e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.9693e-05 - val_loss: 1.9516e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.9024e-05 - val_loss: 1.8956e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.8346e-05 - val_loss: 1.8416e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.7730e-05 - val_loss: 1.7889e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.7109e-05 - val_loss: 1.7395e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 6.6513e-05 - val_loss: 1.6906e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.5915e-05 - val_loss: 1.6449e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.5332e-05 - val_loss: 1.6013e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.4767e-05 - val_loss: 1.5586e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 6.4206e-05 - val_loss: 1.5162e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 6.3679e-05 - val_loss: 1.4784e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.3149e-05 - val_loss: 1.4393e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.2636e-05 - val_loss: 1.4028e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.2133e-05 - val_loss: 1.3688e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.1649e-05 - val_loss: 1.3367e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.1173e-05 - val_loss: 1.3017e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.0682e-05 - val_loss: 1.2709e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.0227e-05 - val_loss: 1.2404e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.9759e-05 - val_loss: 1.2112e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.9317e-05 - val_loss: 1.1843e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.8864e-05 - val_loss: 1.1563e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.8443e-05 - val_loss: 1.1288e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.8018e-05 - val_loss: 1.1048e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.7591e-05 - val_loss: 1.0800e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.7180e-05 - val_loss: 1.0578e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.6786e-05 - val_loss: 1.0343e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.6382e-05 - val_loss: 1.0150e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5992e-05 - val_loss: 9.9105e-06\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.5599e-05 - val_loss: 9.7049e-06\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.5238e-05 - val_loss: 9.5548e-06\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.4849e-05 - val_loss: 9.3033e-06\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.4465e-05 - val_loss: 9.1807e-06\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.4132e-05 - val_loss: 8.9389e-06\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.3738e-05 - val_loss: 8.7789e-06\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.3355e-05 - val_loss: 8.6082e-06\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.3007e-05 - val_loss: 8.4973e-06\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.2712e-05 - val_loss: 8.3230e-06\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.2313e-05 - val_loss: 8.1288e-06\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.1975e-05 - val_loss: 8.0274e-06\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.1692e-05 - val_loss: 7.8938e-06\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.1296e-05 - val_loss: 7.6935e-06\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.0949e-05 - val_loss: 7.5620e-06\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.0621e-05 - val_loss: 7.4242e-06\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.0319e-05 - val_loss: 7.3736e-06\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 5.0037e-05 - val_loss: 7.2009e-06\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.9654e-05 - val_loss: 7.0540e-06\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.9347e-05 - val_loss: 6.9499e-06\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.9033e-05 - val_loss: 6.9575e-06\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.8904e-05 - val_loss: 6.9790e-06\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.8569e-05 - val_loss: 6.6060e-06\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 4.8258e-05 - val_loss: 6.9496e-06\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.8106e-05 - val_loss: 6.3921e-06\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.7640e-05 - val_loss: 6.5440e-06\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.7279e-05 - val_loss: 6.3144e-06\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6950e-05 - val_loss: 6.1054e-06\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.6604e-05 - val_loss: 6.0194e-06\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.6346e-05 - val_loss: 5.9840e-06\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.6006e-05 - val_loss: 5.8580e-06\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.5728e-05 - val_loss: 5.7614e-06\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.5471e-05 - val_loss: 5.7464e-06\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.5164e-05 - val_loss: 5.5960e-06\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 4.4868e-05 - val_loss: 5.5218e-06\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.4580e-05 - val_loss: 5.4520e-06\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.4299e-05 - val_loss: 5.3955e-06\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.4065e-05 - val_loss: 5.3588e-06\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.3771e-05 - val_loss: 5.2335e-06\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 4.3515e-05 - val_loss: 5.1981e-06\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 733us/step - loss: 4.3224e-05 - val_loss: 5.0860e-06\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.2936e-05 - val_loss: 5.0170e-06\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.2670e-05 - val_loss: 4.9600e-06\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2404e-05 - val_loss: 4.9111e-06\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.2227e-05 - val_loss: 5.0370e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.1984e-05 - val_loss: 4.7739e-06\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.1664e-05 - val_loss: 4.8286e-06\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.1414e-05 - val_loss: 4.6621e-06\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.1093e-05 - val_loss: 4.6182e-06\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.0843e-05 - val_loss: 4.5360e-06\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.0579e-05 - val_loss: 4.5119e-06\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.0355e-05 - val_loss: 4.4612e-06\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.0074e-05 - val_loss: 4.3735e-06\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.9821e-05 - val_loss: 4.3515e-06\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.9641e-05 - val_loss: 4.4364e-06\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.9405e-05 - val_loss: 4.2414e-06\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.9085e-05 - val_loss: 4.2223e-06\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.8839e-05 - val_loss: 4.1349e-06\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 3.8572e-05 - val_loss: 4.0784e-06\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.8340e-05 - val_loss: 4.0622e-06\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.8102e-05 - val_loss: 4.0037e-06\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.7853e-05 - val_loss: 3.9670e-06\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.7623e-05 - val_loss: 3.9246e-06\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.7377e-05 - val_loss: 3.9090e-06\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.7197e-05 - val_loss: 3.9621e-06\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.7084e-05 - val_loss: 4.0845e-06\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.6998e-05 - val_loss: 4.1329e-06\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.6702e-05 - val_loss: 3.7857e-06\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.6230e-05 - val_loss: 3.7770e-06\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.6112e-05 - val_loss: 3.7318e-06\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.5755e-05 - val_loss: 3.5979e-06\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.5535e-05 - val_loss: 3.6319e-06\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.5318e-05 - val_loss: 3.5398e-06\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.5119e-05 - val_loss: 3.6239e-06\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.4923e-05 - val_loss: 3.4702e-06\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.4630e-05 - val_loss: 3.5698e-06\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.4546e-05 - val_loss: 3.4667e-06\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.4190e-05 - val_loss: 3.4471e-06\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.4036e-05 - val_loss: 3.3760e-06\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.3726e-05 - val_loss: 3.2831e-06\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.3485e-05 - val_loss: 3.2455e-06\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.3282e-05 - val_loss: 3.2314e-06\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.3067e-05 - val_loss: 3.1999e-06\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2840e-05 - val_loss: 3.1720e-06\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.2676e-05 - val_loss: 3.2040e-06\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.2476e-05 - val_loss: 3.1805e-06\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.2256e-05 - val_loss: 3.0855e-06\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.1979e-05 - val_loss: 3.0718e-06\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.1833e-05 - val_loss: 3.1076e-06\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.1659e-05 - val_loss: 3.1121e-06\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.1539e-05 - val_loss: 3.1957e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.1315e-05 - val_loss: 2.9857e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.0966e-05 - val_loss: 2.9046e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 3.0761e-05 - val_loss: 2.9730e-06\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.0691e-05 - val_loss: 3.1175e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.0537e-05 - val_loss: 2.8906e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.0151e-05 - val_loss: 2.7968e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.9948e-05 - val_loss: 2.8653e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.9881e-05 - val_loss: 3.0133e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.9673e-05 - val_loss: 2.7299e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.9356e-05 - val_loss: 2.8408e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.9362e-05 - val_loss: 2.9382e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9065e-05 - val_loss: 2.6660e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.8739e-05 - val_loss: 2.6487e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.8579e-05 - val_loss: 2.6720e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.8370e-05 - val_loss: 2.5857e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.8156e-05 - val_loss: 2.5903e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.8047e-05 - val_loss: 2.6597e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.7850e-05 - val_loss: 2.5372e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.7602e-05 - val_loss: 2.5812e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.7461e-05 - val_loss: 2.5274e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.7268e-05 - val_loss: 2.5133e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.7079e-05 - val_loss: 2.4695e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.6847e-05 - val_loss: 2.4219e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.6649e-05 - val_loss: 2.4099e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.6519e-05 - val_loss: 2.4736e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6397e-05 - val_loss: 2.4620e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.6226e-05 - val_loss: 2.4844e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.6049e-05 - val_loss: 2.3771e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.5792e-05 - val_loss: 2.3482e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 2.5604e-05 - val_loss: 2.3080e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.5409e-05 - val_loss: 2.2715e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.5218e-05 - val_loss: 2.2547e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.5057e-05 - val_loss: 2.2501e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.4894e-05 - val_loss: 2.2799e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.4832e-05 - val_loss: 2.5013e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.4994e-05 - val_loss: 2.8492e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4856e-05 - val_loss: 2.2593e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4213e-05 - val_loss: 2.2597e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.4137e-05 - val_loss: 2.2129e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.3886e-05 - val_loss: 2.1061e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.3674e-05 - val_loss: 2.1369e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.3551e-05 - val_loss: 2.1064e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.3346e-05 - val_loss: 2.0567e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.3182e-05 - val_loss: 2.0932e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3056e-05 - val_loss: 2.0477e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.2850e-05 - val_loss: 2.0101e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2702e-05 - val_loss: 2.0382e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2544e-05 - val_loss: 1.9703e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.2368e-05 - val_loss: 1.9605e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2186e-05 - val_loss: 1.9343e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.2039e-05 - val_loss: 1.9235e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.1885e-05 - val_loss: 1.9149e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.1722e-05 - val_loss: 1.8973e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 2.1575e-05 - val_loss: 1.9038e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1444e-05 - val_loss: 1.9818e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1558e-05 - val_loss: 2.6987e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2517e-05 - val_loss: 3.2824e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.1522e-05 - val_loss: 2.0939e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.1342e-05 - val_loss: 1.9145e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.0822e-05 - val_loss: 2.1323e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.0626e-05 - val_loss: 1.9618e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.0476e-05 - val_loss: 1.7848e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.0315e-05 - val_loss: 1.8075e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.0093e-05 - val_loss: 1.7900e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9935e-05 - val_loss: 1.7500e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9786e-05 - val_loss: 1.7236e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9642e-05 - val_loss: 1.7002e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.9492e-05 - val_loss: 1.6863e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.9354e-05 - val_loss: 1.6813e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9210e-05 - val_loss: 1.6673e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.9075e-05 - val_loss: 1.6552e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8930e-05 - val_loss: 1.6429e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.8800e-05 - val_loss: 1.6424e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.8676e-05 - val_loss: 1.6210e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 1.8522e-05 - val_loss: 1.6045e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.8393e-05 - val_loss: 1.5936e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.8253e-05 - val_loss: 1.5801e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8120e-05 - val_loss: 1.5737e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.8002e-05 - val_loss: 1.5723e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.7865e-05 - val_loss: 1.5460e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7725e-05 - val_loss: 1.5349e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.7604e-05 - val_loss: 1.5270e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7470e-05 - val_loss: 1.5171e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.7342e-05 - val_loss: 1.5016e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.7229e-05 - val_loss: 1.5094e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7116e-05 - val_loss: 1.5198e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7057e-05 - val_loss: 1.6804e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.7204e-05 - val_loss: 2.1414e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7507e-05 - val_loss: 2.0695e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6852e-05 - val_loss: 1.4698e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.6653e-05 - val_loss: 1.6337e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6430e-05 - val_loss: 1.4262e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.6290e-05 - val_loss: 1.4756e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6156e-05 - val_loss: 1.4000e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5998e-05 - val_loss: 1.3912e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.5883e-05 - val_loss: 1.3796e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.5769e-05 - val_loss: 1.3751e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5668e-05 - val_loss: 1.3644e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5537e-05 - val_loss: 1.3554e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5431e-05 - val_loss: 1.3426e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.5310e-05 - val_loss: 1.3261e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5198e-05 - val_loss: 1.3162e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5095e-05 - val_loss: 1.3107e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4979e-05 - val_loss: 1.3036e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.4874e-05 - val_loss: 1.2970e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4768e-05 - val_loss: 1.2930e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.4662e-05 - val_loss: 1.2891e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.4591e-05 - val_loss: 1.3992e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4811e-05 - val_loss: 2.2591e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.6196e-05 - val_loss: 3.5471e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.5162e-05 - val_loss: 1.7020e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.4843e-05 - val_loss: 1.2696e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4282e-05 - val_loss: 1.5173e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.4071e-05 - val_loss: 1.4960e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.3947e-05 - val_loss: 1.2930e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.3821e-05 - val_loss: 1.1986e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3687e-05 - val_loss: 1.2157e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3552e-05 - val_loss: 1.2283e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3453e-05 - val_loss: 1.1940e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3352e-05 - val_loss: 1.1635e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3251e-05 - val_loss: 1.1601e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3153e-05 - val_loss: 1.1564e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3056e-05 - val_loss: 1.1432e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.2966e-05 - val_loss: 1.1341e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2869e-05 - val_loss: 1.1250e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2778e-05 - val_loss: 1.1191e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2689e-05 - val_loss: 1.1131e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2597e-05 - val_loss: 1.1054e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2511e-05 - val_loss: 1.1011e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.2421e-05 - val_loss: 1.0954e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.2333e-05 - val_loss: 1.0836e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.2244e-05 - val_loss: 1.0760e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2163e-05 - val_loss: 1.0763e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2077e-05 - val_loss: 1.0625e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1986e-05 - val_loss: 1.0545e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1908e-05 - val_loss: 1.0523e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1821e-05 - val_loss: 1.0425e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1737e-05 - val_loss: 1.0358e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.1656e-05 - val_loss: 1.0292e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1579e-05 - val_loss: 1.0348e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1509e-05 - val_loss: 1.0408e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1450e-05 - val_loss: 1.0617e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.1429e-05 - val_loss: 1.1894e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.1550e-05 - val_loss: 1.5204e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1900e-05 - val_loss: 1.8612e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1679e-05 - val_loss: 1.0734e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1074e-05 - val_loss: 1.1439e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.1135e-05 - val_loss: 1.0603e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 725us/step - loss: 1.0904e-05 - val_loss: 9.9170e-07\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0879e-05 - val_loss: 1.0497e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0790e-05 - val_loss: 9.6203e-07\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0658e-05 - val_loss: 9.6346e-07\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0611e-05 - val_loss: 9.7732e-07\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0535e-05 - val_loss: 9.4958e-07\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0450e-05 - val_loss: 9.3141e-07\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.0371e-05 - val_loss: 9.2590e-07\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0302e-05 - val_loss: 9.3368e-07\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.0254e-05 - val_loss: 9.4724e-07\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0208e-05 - val_loss: 9.8062e-07\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0197e-05 - val_loss: 1.0584e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.0266e-05 - val_loss: 1.3087e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0560e-05 - val_loss: 1.6991e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0605e-05 - val_loss: 1.2128e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.9410e-06 - val_loss: 9.4602e-07\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.9235e-06 - val_loss: 1.0574e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.7903e-06 - val_loss: 8.6710e-07\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.7005e-06 - val_loss: 1.0192e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 9.6970e-06 - val_loss: 8.9356e-07\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.5250e-06 - val_loss: 8.6434e-07\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.4792e-06 - val_loss: 8.8422e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.4059e-06 - val_loss: 8.4174e-07\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 9.3376e-06 - val_loss: 8.5655e-07\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.2976e-06 - val_loss: 8.6525e-07\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.2357e-06 - val_loss: 8.4157e-07\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 9.1599e-06 - val_loss: 8.2565e-07\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 9.0965e-06 - val_loss: 8.1757e-07\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.0347e-06 - val_loss: 8.1200e-07\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.9793e-06 - val_loss: 8.0979e-07\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.9319e-06 - val_loss: 8.4149e-07\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.9473e-06 - val_loss: 9.9326e-07\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.2159e-06 - val_loss: 1.7202e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.0185e-05 - val_loss: 2.3954e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 9.4889e-06 - val_loss: 8.0224e-07\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.0198e-06 - val_loss: 1.2672e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.7660e-06 - val_loss: 9.3648e-07\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.7815e-06 - val_loss: 8.5174e-07\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.5363e-06 - val_loss: 9.0432e-07\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.5398e-06 - val_loss: 7.6667e-07\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.4106e-06 - val_loss: 8.3139e-07\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.3646e-06 - val_loss: 7.5722e-07\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 8.3143e-06 - val_loss: 7.9103e-07\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.2548e-06 - val_loss: 7.4771e-07\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.2110e-06 - val_loss: 7.9959e-07\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.1628e-06 - val_loss: 7.3603e-07\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.0948e-06 - val_loss: 7.5433e-07\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.0545e-06 - val_loss: 7.4082e-07\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.9985e-06 - val_loss: 7.2281e-07\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.9438e-06 - val_loss: 7.2260e-07\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 7.9007e-06 - val_loss: 7.2447e-07\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.8553e-06 - val_loss: 7.1105e-07\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.8028e-06 - val_loss: 7.0936e-07\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.7662e-06 - val_loss: 7.1109e-07\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.7156e-06 - val_loss: 6.9843e-07\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.6745e-06 - val_loss: 7.2357e-07\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.6617e-06 - val_loss: 7.6015e-07\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 7.7188e-06 - val_loss: 1.0121e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.0478e-06 - val_loss: 1.4620e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.2657e-06 - val_loss: 1.2463e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 7.7674e-06 - val_loss: 6.9161e-07\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.4602e-06 - val_loss: 8.4108e-07\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 7.5031e-06 - val_loss: 7.0153e-07\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.3472e-06 - val_loss: 7.7269e-07\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.4665e-06 - val_loss: 8.2725e-07\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.3212e-06 - val_loss: 6.6393e-07\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.2072e-06 - val_loss: 6.8952e-07\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.2174e-06 - val_loss: 7.3170e-07\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.1863e-06 - val_loss: 6.8055e-07\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.1016e-06 - val_loss: 6.5184e-07\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.0517e-06 - val_loss: 6.4683e-07\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.0222e-06 - val_loss: 6.6969e-07\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.0159e-06 - val_loss: 7.4389e-07\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.1615e-06 - val_loss: 1.0892e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.4992e-06 - val_loss: 1.3736e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.4245e-06 - val_loss: 8.2657e-07\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8829e-06 - val_loss: 6.4730e-07\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.8790e-06 - val_loss: 7.6476e-07\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.8663e-06 - val_loss: 6.7016e-07\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.7303e-06 - val_loss: 6.0797e-07\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.6766e-06 - val_loss: 6.1993e-07\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.6574e-06 - val_loss: 6.3628e-07\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 6.6298e-06 - val_loss: 6.2056e-07\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.6075e-06 - val_loss: 6.7178e-07\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.6239e-06 - val_loss: 6.9410e-07\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.5976e-06 - val_loss: 6.7846e-07\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.5629e-06 - val_loss: 7.1090e-07\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.6181e-06 - val_loss: 8.8652e-07\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.7813e-06 - val_loss: 1.0222e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.8000e-06 - val_loss: 9.6176e-07\n",
      "Epoch 00590: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (None, 100, 10)           480       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100, 1)            11        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100, 1)            0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1215 - val_loss: 0.1177\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.1154 - val_loss: 0.1123\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.1105 - val_loss: 0.1080\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.1066 - val_loss: 0.1047\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.1036 - val_loss: 0.1023\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.1015 - val_loss: 0.1005\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0999 - val_loss: 0.0992\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0986 - val_loss: 0.0980\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0975 - val_loss: 0.0968\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0962 - val_loss: 0.0955\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0949 - val_loss: 0.0942\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0936 - val_loss: 0.0929\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0923 - val_loss: 0.0915\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0909 - val_loss: 0.0902\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0896 - val_loss: 0.0888\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0882 - val_loss: 0.0874\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0867 - val_loss: 0.0859\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0852 - val_loss: 0.0844\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0837 - val_loss: 0.0828\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 0.0821 - val_loss: 0.0812\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0804 - val_loss: 0.0795\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0787 - val_loss: 0.0777\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0770 - val_loss: 0.0759\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0751 - val_loss: 0.0740\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0732 - val_loss: 0.0721\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0712 - val_loss: 0.0700\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0691 - val_loss: 0.0678\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0669 - val_loss: 0.0656\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0646 - val_loss: 0.0631\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0621 - val_loss: 0.0605\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0594 - val_loss: 0.0577\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0564 - val_loss: 0.0546\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0532 - val_loss: 0.0511\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0496 - val_loss: 0.0473\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0456 - val_loss: 0.0433\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0416 - val_loss: 0.0394\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0379 - val_loss: 0.0361\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0348 - val_loss: 0.0332\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0321 - val_loss: 0.0306\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0296 - val_loss: 0.0282\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 0.0272 - val_loss: 0.0259\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0249 - val_loss: 0.0236\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 0.0227 - val_loss: 0.0214\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0205 - val_loss: 0.0193\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0165 - val_loss: 0.0155\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0147 - val_loss: 0.0137\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0030 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0010 - val_loss: 9.8470e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0010 - val_loss: 9.6818e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.9392e-04 - val_loss: 9.5178e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.7839e-04 - val_loss: 9.3556e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.6308e-04 - val_loss: 9.1959e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.4808e-04 - val_loss: 9.0378e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.3306e-04 - val_loss: 8.8807e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.1827e-04 - val_loss: 8.7258e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.0369e-04 - val_loss: 8.5729e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.8922e-04 - val_loss: 8.4221e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.7503e-04 - val_loss: 8.2720e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 8.6087e-04 - val_loss: 8.1250e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.4699e-04 - val_loss: 7.9798e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.3324e-04 - val_loss: 7.8357e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.1971e-04 - val_loss: 7.6941e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 8.0638e-04 - val_loss: 7.5539e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 7.9329e-04 - val_loss: 7.4140e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.8015e-04 - val_loss: 7.2772e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.6722e-04 - val_loss: 7.1426e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 7.5443e-04 - val_loss: 7.0106e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.4196e-04 - val_loss: 6.8791e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.2959e-04 - val_loss: 6.7479e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.1731e-04 - val_loss: 6.6187e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.0522e-04 - val_loss: 6.4919e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.9330e-04 - val_loss: 6.3669e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.8147e-04 - val_loss: 6.2440e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.6991e-04 - val_loss: 6.1226e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.5851e-04 - val_loss: 6.0025e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.4721e-04 - val_loss: 5.8842e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.3616e-04 - val_loss: 5.7672e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.2513e-04 - val_loss: 5.6528e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.1435e-04 - val_loss: 5.5392e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.0370e-04 - val_loss: 5.4268e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.9320e-04 - val_loss: 5.3165e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 5.8280e-04 - val_loss: 5.2078e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.7257e-04 - val_loss: 5.1011e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.6252e-04 - val_loss: 4.9957e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.5265e-04 - val_loss: 4.8917e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 5.4284e-04 - val_loss: 4.7898e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.3320e-04 - val_loss: 4.6893e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.2374e-04 - val_loss: 4.5902e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.1442e-04 - val_loss: 4.4929e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.0525e-04 - val_loss: 4.3960e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.9618e-04 - val_loss: 4.3012e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.8727e-04 - val_loss: 4.2082e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.7851e-04 - val_loss: 4.1158e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.6980e-04 - val_loss: 4.0261e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.6133e-04 - val_loss: 3.9373e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.5296e-04 - val_loss: 3.8497e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 4.4472e-04 - val_loss: 3.7635e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.3659e-04 - val_loss: 3.6793e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.2860e-04 - val_loss: 3.5956e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.2078e-04 - val_loss: 3.5136e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.1306e-04 - val_loss: 3.4330e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.0537e-04 - val_loss: 3.3531e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.9782e-04 - val_loss: 3.2747e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.9037e-04 - val_loss: 3.1972e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.8304e-04 - val_loss: 3.1207e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7578e-04 - val_loss: 3.0452e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.6863e-04 - val_loss: 2.9707e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.6160e-04 - val_loss: 2.8989e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.5470e-04 - val_loss: 2.8273e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.4801e-04 - val_loss: 2.7588e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4165e-04 - val_loss: 2.6942e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 3.3555e-04 - val_loss: 2.6309e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.2958e-04 - val_loss: 2.5693e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.2374e-04 - val_loss: 2.5088e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.1804e-04 - val_loss: 2.4500e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 3.1246e-04 - val_loss: 2.3923e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.0700e-04 - val_loss: 2.3357e-04\n",
      "Epoch 226/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 759us/step - loss: 3.0166e-04 - val_loss: 2.2805e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.9640e-04 - val_loss: 2.2266e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.9128e-04 - val_loss: 2.1740e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.8630e-04 - val_loss: 2.1220e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.8140e-04 - val_loss: 2.0718e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.7657e-04 - val_loss: 2.0224e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.7186e-04 - val_loss: 1.9740e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.6727e-04 - val_loss: 1.9271e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.6281e-04 - val_loss: 1.8813e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5841e-04 - val_loss: 1.8369e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.5410e-04 - val_loss: 1.7932e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.4987e-04 - val_loss: 1.7497e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.4573e-04 - val_loss: 1.7071e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4167e-04 - val_loss: 1.6659e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.3774e-04 - val_loss: 1.6270e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.3389e-04 - val_loss: 1.5870e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3010e-04 - val_loss: 1.5489e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.2641e-04 - val_loss: 1.5120e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.2280e-04 - val_loss: 1.4757e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1927e-04 - val_loss: 1.4399e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1583e-04 - val_loss: 1.4052e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.1245e-04 - val_loss: 1.3716e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0915e-04 - val_loss: 1.3385e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0593e-04 - val_loss: 1.3063e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0278e-04 - val_loss: 1.2750e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.9970e-04 - val_loss: 1.2446e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9669e-04 - val_loss: 1.2148e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9374e-04 - val_loss: 1.1858e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.9086e-04 - val_loss: 1.1575e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.8805e-04 - val_loss: 1.1298e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8529e-04 - val_loss: 1.1029e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.8260e-04 - val_loss: 1.0761e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.7988e-04 - val_loss: 1.0492e-04\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.7716e-04 - val_loss: 1.0220e-04\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.7446e-04 - val_loss: 9.9550e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.7178e-04 - val_loss: 9.6935e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6916e-04 - val_loss: 9.4392e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6660e-04 - val_loss: 9.1917e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.6407e-04 - val_loss: 8.9488e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.6164e-04 - val_loss: 8.7150e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5922e-04 - val_loss: 8.4852e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5689e-04 - val_loss: 8.2627e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5460e-04 - val_loss: 8.0401e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.5238e-04 - val_loss: 7.8300e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.5017e-04 - val_loss: 7.6203e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4803e-04 - val_loss: 7.4169e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.4595e-04 - val_loss: 7.2225e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4391e-04 - val_loss: 7.0341e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.4190e-04 - val_loss: 6.8477e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.3996e-04 - val_loss: 6.6674e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3805e-04 - val_loss: 6.4926e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3620e-04 - val_loss: 6.3230e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.3440e-04 - val_loss: 6.1578e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3262e-04 - val_loss: 5.9958e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3088e-04 - val_loss: 5.8390e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.2919e-04 - val_loss: 5.6868e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.2755e-04 - val_loss: 5.5398e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2593e-04 - val_loss: 5.3949e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2436e-04 - val_loss: 5.2560e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2283e-04 - val_loss: 5.1201e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.2130e-04 - val_loss: 4.9860e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1983e-04 - val_loss: 4.8599e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.1839e-04 - val_loss: 4.7344e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1699e-04 - val_loss: 4.6127e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1558e-04 - val_loss: 4.4899e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.1420e-04 - val_loss: 4.3673e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1281e-04 - val_loss: 4.2486e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.1144e-04 - val_loss: 4.1325e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1011e-04 - val_loss: 4.0198e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0880e-04 - val_loss: 3.9079e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0756e-04 - val_loss: 3.8038e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0638e-04 - val_loss: 3.7122e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.0533e-04 - val_loss: 3.6333e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0436e-04 - val_loss: 3.5571e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.0339e-04 - val_loss: 3.4811e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0246e-04 - val_loss: 3.4072e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0157e-04 - val_loss: 3.3372e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0064e-04 - val_loss: 3.2678e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.9768e-05 - val_loss: 3.2024e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.8893e-05 - val_loss: 3.1359e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.8035e-05 - val_loss: 3.0725e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.7226e-05 - val_loss: 3.0132e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.6423e-05 - val_loss: 2.9547e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.5611e-05 - val_loss: 2.8997e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.4850e-05 - val_loss: 2.8423e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.4078e-05 - val_loss: 2.7850e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.3323e-05 - val_loss: 2.7318e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.2581e-05 - val_loss: 2.6810e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.1861e-05 - val_loss: 2.6301e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.1148e-05 - val_loss: 2.5803e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.0439e-05 - val_loss: 2.5308e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.9734e-05 - val_loss: 2.4838e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 8.9066e-05 - val_loss: 2.4383e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.8379e-05 - val_loss: 2.3947e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.7745e-05 - val_loss: 2.3506e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.7063e-05 - val_loss: 2.3064e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.6444e-05 - val_loss: 2.2667e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.5802e-05 - val_loss: 2.2261e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.5192e-05 - val_loss: 2.1874e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.4570e-05 - val_loss: 2.1512e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.3950e-05 - val_loss: 2.1127e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.3385e-05 - val_loss: 2.0772e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.2785e-05 - val_loss: 2.0402e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.2179e-05 - val_loss: 2.0038e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.1613e-05 - val_loss: 1.9689e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.1056e-05 - val_loss: 1.9365e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.0486e-05 - val_loss: 1.9045e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.9919e-05 - val_loss: 1.8727e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.9389e-05 - val_loss: 1.8423e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.8833e-05 - val_loss: 1.8098e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.8314e-05 - val_loss: 1.7812e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.7766e-05 - val_loss: 1.7526e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.7254e-05 - val_loss: 1.7255e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.6724e-05 - val_loss: 1.7002e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 7.6228e-05 - val_loss: 1.6735e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.5707e-05 - val_loss: 1.6490e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.5233e-05 - val_loss: 1.6200e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.4719e-05 - val_loss: 1.5929e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.4222e-05 - val_loss: 1.5693e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.3737e-05 - val_loss: 1.5465e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.3268e-05 - val_loss: 1.5227e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.2785e-05 - val_loss: 1.4982e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.2316e-05 - val_loss: 1.4764e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.1833e-05 - val_loss: 1.4515e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.1381e-05 - val_loss: 1.4295e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.0911e-05 - val_loss: 1.4075e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 7.0456e-05 - val_loss: 1.3860e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0014e-05 - val_loss: 1.3656e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.9565e-05 - val_loss: 1.3446e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 6.9143e-05 - val_loss: 1.3246e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.8701e-05 - val_loss: 1.3044e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.8268e-05 - val_loss: 1.2864e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.7831e-05 - val_loss: 1.2688e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.7402e-05 - val_loss: 1.2500e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.6975e-05 - val_loss: 1.2322e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.6557e-05 - val_loss: 1.2143e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.6142e-05 - val_loss: 1.1972e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 6.5739e-05 - val_loss: 1.1809e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 6.5318e-05 - val_loss: 1.1640e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.4919e-05 - val_loss: 1.1476e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.4541e-05 - val_loss: 1.1335e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.4117e-05 - val_loss: 1.1165e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.3729e-05 - val_loss: 1.0999e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.3326e-05 - val_loss: 1.0843e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.2955e-05 - val_loss: 1.0702e-05\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.2564e-05 - val_loss: 1.0564e-05\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.2186e-05 - val_loss: 1.0427e-05\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.1803e-05 - val_loss: 1.0286e-05\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.1423e-05 - val_loss: 1.0143e-05\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.1055e-05 - val_loss: 1.0007e-05\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.0687e-05 - val_loss: 9.8788e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.0307e-05 - val_loss: 9.7346e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.9962e-05 - val_loss: 9.6160e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.9606e-05 - val_loss: 9.5044e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.9235e-05 - val_loss: 9.3712e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 5.8877e-05 - val_loss: 9.2483e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.8536e-05 - val_loss: 9.1397e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.8168e-05 - val_loss: 9.0209e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.7822e-05 - val_loss: 8.9165e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 5.7486e-05 - val_loss: 8.7984e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 5.7140e-05 - val_loss: 8.6848e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.6793e-05 - val_loss: 8.5713e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 5.6455e-05 - val_loss: 8.4500e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.6128e-05 - val_loss: 8.3530e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.5805e-05 - val_loss: 8.2488e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.5449e-05 - val_loss: 8.1345e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.5132e-05 - val_loss: 8.0378e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.4807e-05 - val_loss: 7.9517e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.4488e-05 - val_loss: 7.8561e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.4152e-05 - val_loss: 7.7536e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3836e-05 - val_loss: 7.6591e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.3524e-05 - val_loss: 7.5743e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.3206e-05 - val_loss: 7.4868e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.2887e-05 - val_loss: 7.3933e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.2569e-05 - val_loss: 7.3129e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 5.2276e-05 - val_loss: 7.2229e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.1958e-05 - val_loss: 7.1342e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.1665e-05 - val_loss: 7.0566e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.1352e-05 - val_loss: 6.9754e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.1058e-05 - val_loss: 6.8997e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.0749e-05 - val_loss: 6.8208e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 5.0462e-05 - val_loss: 6.7338e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 5.0165e-05 - val_loss: 6.6647e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.9874e-05 - val_loss: 6.5968e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.9572e-05 - val_loss: 6.5165e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.9284e-05 - val_loss: 6.4471e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.8986e-05 - val_loss: 6.3574e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.8708e-05 - val_loss: 6.2874e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.8429e-05 - val_loss: 6.2185e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 4.8152e-05 - val_loss: 6.1603e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 4.7855e-05 - val_loss: 6.0894e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.7585e-05 - val_loss: 6.0286e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 4.7317e-05 - val_loss: 5.9718e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.7028e-05 - val_loss: 5.8994e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.6764e-05 - val_loss: 5.8403e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.6476e-05 - val_loss: 5.7633e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6211e-05 - val_loss: 5.7175e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.5956e-05 - val_loss: 5.6482e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.5690e-05 - val_loss: 5.5997e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.5415e-05 - val_loss: 5.5383e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.5156e-05 - val_loss: 5.4788e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.4896e-05 - val_loss: 5.4561e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.4635e-05 - val_loss: 5.3816e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.4370e-05 - val_loss: 5.3080e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.4109e-05 - val_loss: 5.2523e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.3851e-05 - val_loss: 5.2080e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.3612e-05 - val_loss: 5.1550e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3348e-05 - val_loss: 5.1083e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 4.3094e-05 - val_loss: 5.0542e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 4.2843e-05 - val_loss: 4.9992e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 4.2591e-05 - val_loss: 4.9466e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.2346e-05 - val_loss: 4.9010e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.2098e-05 - val_loss: 4.8513e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.1854e-05 - val_loss: 4.8080e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.1614e-05 - val_loss: 4.7625e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.1370e-05 - val_loss: 4.7085e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.1131e-05 - val_loss: 4.6663e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.0892e-05 - val_loss: 4.6223e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 4.0656e-05 - val_loss: 4.5812e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.0414e-05 - val_loss: 4.5390e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.0182e-05 - val_loss: 4.5017e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.9952e-05 - val_loss: 4.4484e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.9728e-05 - val_loss: 4.4158e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.9487e-05 - val_loss: 4.3730e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.9270e-05 - val_loss: 4.3377e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9035e-05 - val_loss: 4.3126e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.8810e-05 - val_loss: 4.2679e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.8589e-05 - val_loss: 4.2330e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.8355e-05 - val_loss: 4.1865e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.8133e-05 - val_loss: 4.1445e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.7913e-05 - val_loss: 4.1114e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.7695e-05 - val_loss: 4.0821e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.7471e-05 - val_loss: 4.0423e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.7248e-05 - val_loss: 4.0007e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.7039e-05 - val_loss: 3.9623e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.6823e-05 - val_loss: 3.9297e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.6617e-05 - val_loss: 3.9101e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 3.6392e-05 - val_loss: 3.8681e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 3.6191e-05 - val_loss: 3.8455e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.5985e-05 - val_loss: 3.8054e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.5762e-05 - val_loss: 3.7743e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.5552e-05 - val_loss: 3.7377e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.5355e-05 - val_loss: 3.7135e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.5144e-05 - val_loss: 3.6798e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.4951e-05 - val_loss: 3.6600e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.4732e-05 - val_loss: 3.6278e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 3.4532e-05 - val_loss: 3.5958e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.4334e-05 - val_loss: 3.5700e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.4138e-05 - val_loss: 3.5424e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.3935e-05 - val_loss: 3.5148e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.3737e-05 - val_loss: 3.4856e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.3544e-05 - val_loss: 3.4612e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 3.3346e-05 - val_loss: 3.4302e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.3163e-05 - val_loss: 3.4170e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.2955e-05 - val_loss: 3.3806e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 3.2767e-05 - val_loss: 3.3529e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.2579e-05 - val_loss: 3.3303e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.2384e-05 - val_loss: 3.3310e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.2210e-05 - val_loss: 3.2837e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.2012e-05 - val_loss: 3.2584e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.1831e-05 - val_loss: 3.2430e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.1643e-05 - val_loss: 3.2208e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 3.1451e-05 - val_loss: 3.1869e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.1269e-05 - val_loss: 3.1630e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 3.1087e-05 - val_loss: 3.1444e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.0914e-05 - val_loss: 3.1202e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.0730e-05 - val_loss: 3.1026e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.0547e-05 - val_loss: 3.0797e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.0382e-05 - val_loss: 3.0636e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.0192e-05 - val_loss: 3.0396e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.0023e-05 - val_loss: 3.0213e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.9854e-05 - val_loss: 3.0224e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.9675e-05 - val_loss: 2.9822e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.9500e-05 - val_loss: 2.9583e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.9328e-05 - val_loss: 2.9554e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.9162e-05 - val_loss: 2.9226e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.8992e-05 - val_loss: 2.8975e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.8817e-05 - val_loss: 2.8797e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 2.8653e-05 - val_loss: 2.8697e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.8487e-05 - val_loss: 2.8533e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.8320e-05 - val_loss: 2.8356e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.8156e-05 - val_loss: 2.8183e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.7979e-05 - val_loss: 2.7947e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.7821e-05 - val_loss: 2.7778e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.7670e-05 - val_loss: 2.7675e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.7506e-05 - val_loss: 2.7500e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.7347e-05 - val_loss: 2.7302e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.7183e-05 - val_loss: 2.7139e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.7029e-05 - val_loss: 2.7198e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6870e-05 - val_loss: 2.6852e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.6719e-05 - val_loss: 2.6708e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6573e-05 - val_loss: 2.6588e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.6402e-05 - val_loss: 2.6522e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.6248e-05 - val_loss: 2.6428e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.6110e-05 - val_loss: 2.6064e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.5940e-05 - val_loss: 2.5901e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.5781e-05 - val_loss: 2.5755e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 727us/step - loss: 2.5642e-05 - val_loss: 2.5618e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.5493e-05 - val_loss: 2.5523e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 2.5344e-05 - val_loss: 2.5369e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 2.5199e-05 - val_loss: 2.5273e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.5049e-05 - val_loss: 2.5165e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 2.4908e-05 - val_loss: 2.4991e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.4757e-05 - val_loss: 2.4852e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.4604e-05 - val_loss: 2.4682e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4470e-05 - val_loss: 2.4558e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4333e-05 - val_loss: 2.4482e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.4198e-05 - val_loss: 2.4291e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4047e-05 - val_loss: 2.4181e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.3911e-05 - val_loss: 2.4084e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3773e-05 - val_loss: 2.4031e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3626e-05 - val_loss: 2.3844e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3496e-05 - val_loss: 2.3946e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.3372e-05 - val_loss: 2.3825e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.3238e-05 - val_loss: 2.3612e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.3091e-05 - val_loss: 2.3345e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2963e-05 - val_loss: 2.3251e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2836e-05 - val_loss: 2.3272e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2698e-05 - val_loss: 2.3134e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.2562e-05 - val_loss: 2.3025e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.2425e-05 - val_loss: 2.2886e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2294e-05 - val_loss: 2.2874e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2171e-05 - val_loss: 2.2617e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2037e-05 - val_loss: 2.2515e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.1917e-05 - val_loss: 2.2406e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.1785e-05 - val_loss: 2.2320e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.1658e-05 - val_loss: 2.2281e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1535e-05 - val_loss: 2.2133e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.1413e-05 - val_loss: 2.2076e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.1289e-05 - val_loss: 2.1936e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.1171e-05 - val_loss: 2.1901e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1047e-05 - val_loss: 2.1763e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.0919e-05 - val_loss: 2.1644e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0802e-05 - val_loss: 2.1495e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0679e-05 - val_loss: 2.1403e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 2.0556e-05 - val_loss: 2.1284e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 2.0449e-05 - val_loss: 2.1227e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.0321e-05 - val_loss: 2.1099e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 2.0211e-05 - val_loss: 2.1040e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.0097e-05 - val_loss: 2.0966e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.9978e-05 - val_loss: 2.0889e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.9861e-05 - val_loss: 2.0782e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.9750e-05 - val_loss: 2.0738e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 1.9631e-05 - val_loss: 2.0658e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.9530e-05 - val_loss: 2.0638e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.9413e-05 - val_loss: 2.0444e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 1.9299e-05 - val_loss: 2.0385e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.9187e-05 - val_loss: 2.0271e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9077e-05 - val_loss: 2.0186e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.8971e-05 - val_loss: 2.0147e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8867e-05 - val_loss: 2.0112e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8759e-05 - val_loss: 2.0096e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.8653e-05 - val_loss: 1.9872e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.8540e-05 - val_loss: 1.9848e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8445e-05 - val_loss: 1.9714e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.8333e-05 - val_loss: 1.9630e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.8227e-05 - val_loss: 1.9656e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8129e-05 - val_loss: 1.9510e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.8021e-05 - val_loss: 1.9437e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.7918e-05 - val_loss: 1.9343e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.7815e-05 - val_loss: 1.9250e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.7718e-05 - val_loss: 1.9250e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.7618e-05 - val_loss: 1.9175e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.7516e-05 - val_loss: 1.9099e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7416e-05 - val_loss: 1.8919e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.7315e-05 - val_loss: 1.8818e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.7221e-05 - val_loss: 1.8823e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7118e-05 - val_loss: 1.8696e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7022e-05 - val_loss: 1.8616e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.6925e-05 - val_loss: 1.8539e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6834e-05 - val_loss: 1.8486e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6739e-05 - val_loss: 1.8428e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6640e-05 - val_loss: 1.8363e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6545e-05 - val_loss: 1.8248e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6458e-05 - val_loss: 1.8176e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.6362e-05 - val_loss: 1.8107e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.6270e-05 - val_loss: 1.8054e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6184e-05 - val_loss: 1.8202e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.6101e-05 - val_loss: 1.7993e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.6006e-05 - val_loss: 1.7836e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5907e-05 - val_loss: 1.7784e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5818e-05 - val_loss: 1.7705e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.5731e-05 - val_loss: 1.7728e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5653e-05 - val_loss: 1.7564e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5562e-05 - val_loss: 1.7614e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.5475e-05 - val_loss: 1.7516e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.5383e-05 - val_loss: 1.7346e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.5294e-05 - val_loss: 1.7276e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5211e-05 - val_loss: 1.7247e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5124e-05 - val_loss: 1.7136e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5047e-05 - val_loss: 1.7158e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.4959e-05 - val_loss: 1.7053e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4875e-05 - val_loss: 1.6947e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.4802e-05 - val_loss: 1.6943e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4713e-05 - val_loss: 1.6916e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.4627e-05 - val_loss: 1.6804e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 1.4695e-0 - 1s 748us/step - loss: 1.4551e-05 - val_loss: 1.6701e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4466e-05 - val_loss: 1.6643e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.4389e-05 - val_loss: 1.6571e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 1.4309e-05 - val_loss: 1.6519e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.4231e-05 - val_loss: 1.6460e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4150e-05 - val_loss: 1.6382e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4074e-05 - val_loss: 1.6321e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4000e-05 - val_loss: 1.6396e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.3924e-05 - val_loss: 1.6228e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3847e-05 - val_loss: 1.6120e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3776e-05 - val_loss: 1.6111e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3694e-05 - val_loss: 1.6050e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3617e-05 - val_loss: 1.5955e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3546e-05 - val_loss: 1.5966e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3475e-05 - val_loss: 1.5832e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3402e-05 - val_loss: 1.5808e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3323e-05 - val_loss: 1.5790e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.3261e-05 - val_loss: 1.5744e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.3184e-05 - val_loss: 1.5620e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.3112e-05 - val_loss: 1.5577e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3039e-05 - val_loss: 1.5599e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.2972e-05 - val_loss: 1.5448e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2900e-05 - val_loss: 1.5404e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.2833e-05 - val_loss: 1.5320e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 1.2759e-05 - val_loss: 1.5274e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2697e-05 - val_loss: 1.5363e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2630e-05 - val_loss: 1.5215e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.2562e-05 - val_loss: 1.5142e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2504e-05 - val_loss: 1.5147e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2425e-05 - val_loss: 1.4976e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.2356e-05 - val_loss: 1.4960e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.2298e-05 - val_loss: 1.5007e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.2233e-05 - val_loss: 1.4822e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2165e-05 - val_loss: 1.4887e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2107e-05 - val_loss: 1.4863e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.2035e-05 - val_loss: 1.4725e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1967e-05 - val_loss: 1.4608e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.1906e-05 - val_loss: 1.4546e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1845e-05 - val_loss: 1.4474e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1779e-05 - val_loss: 1.4515e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1726e-05 - val_loss: 1.4480e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 1.1659e-05 - val_loss: 1.4316e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.1591e-05 - val_loss: 1.4245e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1541e-05 - val_loss: 1.4247e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 1.1484e-05 - val_loss: 1.4200e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.1421e-05 - val_loss: 1.4323e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.1371e-05 - val_loss: 1.4149e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.1304e-05 - val_loss: 1.4059e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 1.1243e-05 - val_loss: 1.3959e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1187e-05 - val_loss: 1.3915e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1126e-05 - val_loss: 1.3840e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.1068e-05 - val_loss: 1.3819e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.1008e-05 - val_loss: 1.3792e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0947e-05 - val_loss: 1.3720e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.0893e-05 - val_loss: 1.3662e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0833e-05 - val_loss: 1.3612e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0787e-05 - val_loss: 1.3734e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0730e-05 - val_loss: 1.3499e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0667e-05 - val_loss: 1.3441e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.0621e-05 - val_loss: 1.3438e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.0563e-05 - val_loss: 1.3461e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.0509e-05 - val_loss: 1.3349e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0457e-05 - val_loss: 1.3255e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0410e-05 - val_loss: 1.3239e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0360e-05 - val_loss: 1.3153e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0300e-05 - val_loss: 1.3150e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0241e-05 - val_loss: 1.3055e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.0193e-05 - val_loss: 1.3176e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.0151e-05 - val_loss: 1.3166e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0125e-05 - val_loss: 1.2899e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0041e-05 - val_loss: 1.2847e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 9.9881e-06 - val_loss: 1.2918e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.9446e-06 - val_loss: 1.2810e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 9.8979e-06 - val_loss: 1.2751e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.8359e-06 - val_loss: 1.2700e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 847us/step - loss: 9.7910e-06 - val_loss: 1.2630e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 853us/step - loss: 9.7481e-06 - val_loss: 1.2719e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 852us/step - loss: 9.7107e-06 - val_loss: 1.2891e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 858us/step - loss: 9.6532e-06 - val_loss: 1.2688e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 832us/step - loss: 9.6072e-06 - val_loss: 1.2658e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 824us/step - loss: 9.5673e-06 - val_loss: 1.2718e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 810us/step - loss: 9.5501e-06 - val_loss: 1.2374e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.4566e-06 - val_loss: 1.2346e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.4041e-06 - val_loss: 1.2251e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.3721e-06 - val_loss: 1.2218e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.3120e-06 - val_loss: 1.2191e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.2793e-06 - val_loss: 1.2148e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.2254e-06 - val_loss: 1.2124e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.1775e-06 - val_loss: 1.2098e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.1330e-06 - val_loss: 1.2004e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.0866e-06 - val_loss: 1.1917e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.0462e-06 - val_loss: 1.1985e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.0068e-06 - val_loss: 1.2088e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.0072e-06 - val_loss: 1.1896e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 8.9263e-06 - val_loss: 1.2039e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 8.8792e-06 - val_loss: 1.2198e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.8708e-06 - val_loss: 1.1796e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.7980e-06 - val_loss: 1.2096e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.7905e-06 - val_loss: 1.1735e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.7006e-06 - val_loss: 1.1595e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.6578e-06 - val_loss: 1.1617e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.6369e-06 - val_loss: 1.1704e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.5929e-06 - val_loss: 1.1479e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.5383e-06 - val_loss: 1.1590e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.5084e-06 - val_loss: 1.1328e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.4659e-06 - val_loss: 1.1871e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 8.7103e-0 - 1s 746us/step - loss: 8.4635e-06 - val_loss: 1.1559e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 8.3952e-06 - val_loss: 1.1337e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 730us/step - loss: 8.3464e-06 - val_loss: 1.1354e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.3258e-06 - val_loss: 1.2032e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.3649e-06 - val_loss: 1.3095e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 8.4561e-06 - val_loss: 1.3078e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.2678e-06 - val_loss: 1.1410e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 8.1833e-06 - val_loss: 1.1508e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.1468e-06 - val_loss: 1.1078e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.0661e-06 - val_loss: 1.0952e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.0628e-06 - val_loss: 1.1739e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.0855e-06 - val_loss: 1.2078e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.1171e-06 - val_loss: 1.2020e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.9468e-06 - val_loss: 1.0794e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.9376e-06 - val_loss: 1.1627e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.8759e-06 - val_loss: 1.0729e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.9161e-06 - val_loss: 1.3231e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.9660e-06 - val_loss: 1.1400e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.7650e-06 - val_loss: 1.0678e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.7750e-06 - val_loss: 1.2535e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.9436e-06 - val_loss: 1.3896e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.9129e-06 - val_loss: 1.1274e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.6245e-06 - val_loss: 1.1775e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.8629e-06 - val_loss: 1.3429e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.6458e-06 - val_loss: 1.0558e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.6254e-06 - val_loss: 1.1916e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.5299e-06 - val_loss: 1.0171e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.4307e-06 - val_loss: 1.0526e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.3980e-06 - val_loss: 1.0425e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.4764e-06 - val_loss: 1.2582e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 7.5316e-06 - val_loss: 1.1963e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.3995e-06 - val_loss: 9.9867e-07\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.2688e-06 - val_loss: 1.0358e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.2432e-06 - val_loss: 9.9093e-07\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.1842e-06 - val_loss: 9.9237e-07\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 7.1616e-06 - val_loss: 1.0120e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.1403e-06 - val_loss: 9.8389e-07\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 7.0886e-06 - val_loss: 9.7496e-07\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0539e-06 - val_loss: 9.7948e-07\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.0516e-06 - val_loss: 9.8707e-07\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.0032e-06 - val_loss: 1.0071e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.1746e-06 - val_loss: 1.5929e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.8167e-06 - val_loss: 1.8811e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3704e-06 - val_loss: 9.5366e-07\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.0452e-06 - val_loss: 1.3550e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0212e-06 - val_loss: 9.4892e-07\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8314e-06 - val_loss: 9.6502e-07\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.7977e-06 - val_loss: 9.4106e-07\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.7469e-06 - val_loss: 9.3423e-07\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.7741e-06 - val_loss: 1.0903e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.8394e-06 - val_loss: 9.7450e-07\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.6809e-06 - val_loss: 1.0064e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.7081e-06 - val_loss: 9.2148e-07\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.6247e-06 - val_loss: 9.8210e-07\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.6034e-06 - val_loss: 9.3192e-07\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.6416e-06 - val_loss: 1.0817e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 6.5877e-06 - val_loss: 9.1046e-07\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.5106e-06 - val_loss: 9.5505e-07\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.5324e-06 - val_loss: 9.6092e-07\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.4512e-06 - val_loss: 9.9614e-07\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.6928e-06 - val_loss: 1.3543e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.8660e-06 - val_loss: 1.1243e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.4332e-06 - val_loss: 1.1878e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 6.8570e-06 - val_loss: 1.3583e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.4752e-06 - val_loss: 9.9908e-07\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.5306e-06 - val_loss: 1.0984e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.3054e-06 - val_loss: 9.6267e-07\n",
      "Epoch 00794: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,11):\n",
    "    numOfLayers = 1\n",
    "    numOfNeurons = i \n",
    "    [model, validatoinLoss, numOfEpochs] = trainLSTM(numOfLayers, numOfNeurons)\n",
    "    modelsLoss.append(validatoinLoss)# = [modelsLoss,validatoinLoss]\n",
    "    modelsEpochs.append(numOfEpochs)\n",
    "\n",
    "plt.plot(modelsLoss)\n",
    "plt.title('Models validation loss vs. depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Depth')\n",
    "plt.xticks(np.arange(10),['1','2','3','4','5','6','7','8','9','10'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, the loss is decreasing dramatically when we get from 1 to 4 neurons and then becomes flat with a slight rise in the end. As we cannot say for sure that it will increase after 10 neurons we tried to increase the number of neurons in our next test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Models validation loss vs. Neurons count')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Neurons count')\n",
    "plt.xticks(np.arange(10),['1','2','3','4','5','6','7','8','9','10'])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsEpochs)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Training epochs vs. Neurons count')\n",
    "plt.ylabel('Epochs')\n",
    "plt.xlabel('Neurons count')\n",
    "plt.xticks(np.arange(10),['1','2','3','4','5','6','7','8','9','10'])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Neurons: \n",
    "Here we tried neurons count 10,20 ... 50 to make sure is the loss is worse with more neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 100, 10)           480       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100, 1)            11        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1204 - val_loss: 0.1165\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.1141 - val_loss: 0.1107\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.1087 - val_loss: 0.1061\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1046 - val_loss: 0.1027\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.1016 - val_loss: 0.1003\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0996 - val_loss: 0.0988\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0982 - val_loss: 0.0975\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 0.0968 - val_loss: 0.0961\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0954 - val_loss: 0.0946\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0939 - val_loss: 0.0931\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0925 - val_loss: 0.0918\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 0.0912 - val_loss: 0.0905\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0899 - val_loss: 0.0892\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0886 - val_loss: 0.0879\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0873 - val_loss: 0.0866\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0860 - val_loss: 0.0853\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0847 - val_loss: 0.0840\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0834 - val_loss: 0.0827\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0822 - val_loss: 0.0814\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0809 - val_loss: 0.0801\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0795 - val_loss: 0.0788\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0782 - val_loss: 0.0774\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0768 - val_loss: 0.0761\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0754 - val_loss: 0.0746\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0740 - val_loss: 0.0732\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0725 - val_loss: 0.0716\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0710 - val_loss: 0.0700\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0693 - val_loss: 0.0683\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0676 - val_loss: 0.0665\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0657 - val_loss: 0.0646\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0637 - val_loss: 0.0624\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0614 - val_loss: 0.0601\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0590 - val_loss: 0.0576\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0565 - val_loss: 0.0550\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0539 - val_loss: 0.0523\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 0.0511 - val_loss: 0.0495\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0482 - val_loss: 0.0465\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0453 - val_loss: 0.0436\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0424 - val_loss: 0.0407\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0395 - val_loss: 0.0379\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0367 - val_loss: 0.0351\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0339 - val_loss: 0.0324\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0313 - val_loss: 0.0298\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0287 - val_loss: 0.0273\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0263 - val_loss: 0.0250\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0241 - val_loss: 0.0229\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0220 - val_loss: 0.0209\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0201 - val_loss: 0.0190\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 0.0183 - val_loss: 0.0174\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0166 - val_loss: 0.0158\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0151 - val_loss: 0.0144\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0088 - val_loss: 0.0083\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 807us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 740us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0011 - val_loss: 9.9557e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0011 - val_loss: 9.7984e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0011 - val_loss: 9.6405e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0010 - val_loss: 9.4846e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0010 - val_loss: 9.3293e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0010 - val_loss: 9.1748e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.9392e-04 - val_loss: 9.0202e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 9.7920e-04 - val_loss: 8.8672e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 9.6459e-04 - val_loss: 8.7151e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.5006e-04 - val_loss: 8.5641e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 9.3563e-04 - val_loss: 8.4139e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 9.2131e-04 - val_loss: 8.2645e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 9.0710e-04 - val_loss: 8.1157e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.9294e-04 - val_loss: 7.9687e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.7897e-04 - val_loss: 7.8215e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 8.6500e-04 - val_loss: 7.6771e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.5117e-04 - val_loss: 7.5333e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.3746e-04 - val_loss: 7.3918e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.2390e-04 - val_loss: 7.2504e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 8.1049e-04 - val_loss: 7.1096e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.9709e-04 - val_loss: 6.9699e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.8388e-04 - val_loss: 6.8316e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.7079e-04 - val_loss: 6.6945e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.5779e-04 - val_loss: 6.5596e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.4496e-04 - val_loss: 6.4260e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.3226e-04 - val_loss: 6.2929e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.1969e-04 - val_loss: 6.1615e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.0724e-04 - val_loss: 6.0326e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.9494e-04 - val_loss: 5.9046e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.8283e-04 - val_loss: 5.7778e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.7077e-04 - val_loss: 5.6534e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 6.5892e-04 - val_loss: 5.5303e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 6.4726e-04 - val_loss: 5.4074e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.3571e-04 - val_loss: 5.2862e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 6.2427e-04 - val_loss: 5.1677e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.1305e-04 - val_loss: 5.0501e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.0192e-04 - val_loss: 4.9352e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.9096e-04 - val_loss: 4.8213e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.8019e-04 - val_loss: 4.7089e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.6958e-04 - val_loss: 4.5980e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.5907e-04 - val_loss: 4.4891e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.4876e-04 - val_loss: 4.3821e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.3862e-04 - val_loss: 4.2766e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.2864e-04 - val_loss: 4.1732e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.1883e-04 - val_loss: 4.0713e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.0917e-04 - val_loss: 3.9712e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.9971e-04 - val_loss: 3.8718e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9031e-04 - val_loss: 3.7754e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.8116e-04 - val_loss: 3.6805e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.7216e-04 - val_loss: 3.5873e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.6335e-04 - val_loss: 3.4950e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.5464e-04 - val_loss: 3.4057e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.4616e-04 - val_loss: 3.3181e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 4.3778e-04 - val_loss: 3.2318e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.2965e-04 - val_loss: 3.1463e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 4.2161e-04 - val_loss: 3.0631e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 4.1372e-04 - val_loss: 2.9823e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.0598e-04 - val_loss: 2.9036e-04\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.9843e-04 - val_loss: 2.8253e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.9105e-04 - val_loss: 2.7488e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.8380e-04 - val_loss: 2.6747e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.7674e-04 - val_loss: 2.6013e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.6979e-04 - val_loss: 2.5292e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.6299e-04 - val_loss: 2.4602e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.5636e-04 - val_loss: 2.3918e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.4983e-04 - val_loss: 2.3261e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.4354e-04 - val_loss: 2.2614e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 3.3736e-04 - val_loss: 2.1979e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.3132e-04 - val_loss: 2.1354e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.2538e-04 - val_loss: 2.0748e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.1961e-04 - val_loss: 2.0166e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.1399e-04 - val_loss: 1.9592e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.0849e-04 - val_loss: 1.9035e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.0313e-04 - val_loss: 1.8498e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.9790e-04 - val_loss: 1.7966e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.9279e-04 - val_loss: 1.7454e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.8783e-04 - val_loss: 1.6953e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8297e-04 - val_loss: 1.6465e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.7825e-04 - val_loss: 1.5994e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.7362e-04 - val_loss: 1.5531e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.6916e-04 - val_loss: 1.5081e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.6474e-04 - val_loss: 1.4645e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.6047e-04 - val_loss: 1.4222e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.5631e-04 - val_loss: 1.3811e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.5224e-04 - val_loss: 1.3406e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4831e-04 - val_loss: 1.3016e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.4442e-04 - val_loss: 1.2639e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4071e-04 - val_loss: 1.2271e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3704e-04 - val_loss: 1.1915e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.3350e-04 - val_loss: 1.1570e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.3005e-04 - val_loss: 1.1238e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.2667e-04 - val_loss: 1.0912e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.2339e-04 - val_loss: 1.0595e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.2021e-04 - val_loss: 1.0295e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1710e-04 - val_loss: 1.0002e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 2.1408e-04 - val_loss: 9.7140e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 2.1118e-04 - val_loss: 9.4356e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0827e-04 - val_loss: 9.1665e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 2.0547e-04 - val_loss: 8.9075e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.0275e-04 - val_loss: 8.6493e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0013e-04 - val_loss: 8.4115e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.9754e-04 - val_loss: 8.1691e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.9503e-04 - val_loss: 7.9402e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.9259e-04 - val_loss: 7.7206e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9019e-04 - val_loss: 7.5061e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8788e-04 - val_loss: 7.2952e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.8563e-04 - val_loss: 7.0963e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.8342e-04 - val_loss: 6.9015e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8127e-04 - val_loss: 6.7130e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7916e-04 - val_loss: 6.5271e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.7716e-04 - val_loss: 6.3519e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7518e-04 - val_loss: 6.1869e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.7322e-04 - val_loss: 6.0213e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.7133e-04 - val_loss: 5.8578e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6946e-04 - val_loss: 5.6989e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.6770e-04 - val_loss: 5.5496e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.6595e-04 - val_loss: 5.4068e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6421e-04 - val_loss: 5.2704e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6254e-04 - val_loss: 5.1385e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6090e-04 - val_loss: 5.0059e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.5929e-04 - val_loss: 4.8789e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.5772e-04 - val_loss: 4.7565e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5619e-04 - val_loss: 4.6366e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5468e-04 - val_loss: 4.5217e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.5322e-04 - val_loss: 4.4091e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5180e-04 - val_loss: 4.3037e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.5037e-04 - val_loss: 4.1993e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4901e-04 - val_loss: 4.0996e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4765e-04 - val_loss: 4.0005e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.4636e-04 - val_loss: 3.9074e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4505e-04 - val_loss: 3.8159e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.4378e-04 - val_loss: 3.7251e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.4259e-04 - val_loss: 3.6450e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.4135e-04 - val_loss: 3.5642e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.4014e-04 - val_loss: 3.4833e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.3896e-04 - val_loss: 3.4022e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.3780e-04 - val_loss: 3.3221e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.3670e-04 - val_loss: 3.2499e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.3561e-04 - val_loss: 3.1832e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.3450e-04 - val_loss: 3.1127e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.3342e-04 - val_loss: 3.0465e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.3236e-04 - val_loss: 2.9824e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3133e-04 - val_loss: 2.9192e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.3036e-04 - val_loss: 2.8627e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2933e-04 - val_loss: 2.8052e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 1.2832e-04 - val_loss: 2.7467e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2734e-04 - val_loss: 2.6914e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2644e-04 - val_loss: 2.6372e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2547e-04 - val_loss: 2.5841e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2458e-04 - val_loss: 2.5381e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.2363e-04 - val_loss: 2.4894e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.2275e-04 - val_loss: 2.4442e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.2183e-04 - val_loss: 2.3972e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2097e-04 - val_loss: 2.3524e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 1.2009e-04 - val_loss: 2.3074e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 1.1926e-04 - val_loss: 2.2664e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1843e-04 - val_loss: 2.2263e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1758e-04 - val_loss: 2.1875e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1676e-04 - val_loss: 2.1475e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1597e-04 - val_loss: 2.1113e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1515e-04 - val_loss: 2.0743e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1435e-04 - val_loss: 2.0369e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1360e-04 - val_loss: 2.0034e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1279e-04 - val_loss: 1.9676e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.1209e-04 - val_loss: 1.9377e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.1128e-04 - val_loss: 1.9045e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1055e-04 - val_loss: 1.8728e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0980e-04 - val_loss: 1.8416e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0908e-04 - val_loss: 1.8120e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0837e-04 - val_loss: 1.7844e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 728us/step - loss: 1.0765e-04 - val_loss: 1.7569e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0694e-04 - val_loss: 1.7309e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0626e-04 - val_loss: 1.7049e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0553e-04 - val_loss: 1.6748e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0485e-04 - val_loss: 1.6481e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0419e-04 - val_loss: 1.6254e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.0350e-04 - val_loss: 1.6016e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.0286e-04 - val_loss: 1.5796e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0220e-04 - val_loss: 1.5579e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0154e-04 - val_loss: 1.5389e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0089e-04 - val_loss: 1.5117e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0026e-04 - val_loss: 1.4912e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.9617e-05 - val_loss: 1.4701e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.8972e-05 - val_loss: 1.4483e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.8369e-05 - val_loss: 1.4306e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 9.7718e-05 - val_loss: 1.4103e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.7151e-05 - val_loss: 1.3933e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 9.6504e-05 - val_loss: 1.3741e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.5908e-05 - val_loss: 1.3562e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.5314e-05 - val_loss: 1.3390e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 9.4725e-05 - val_loss: 1.3216e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 9.4156e-05 - val_loss: 1.3063e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 810us/step - loss: 9.3533e-05 - val_loss: 1.2878e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.2962e-05 - val_loss: 1.2706e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 9.2405e-05 - val_loss: 1.2553e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.1801e-05 - val_loss: 1.2372e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 822us/step - loss: 9.1266e-05 - val_loss: 1.2230e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.0686e-05 - val_loss: 1.2078e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.0133e-05 - val_loss: 1.1930e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.9585e-05 - val_loss: 1.1792e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 822us/step - loss: 8.9015e-05 - val_loss: 1.1637e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.8471e-05 - val_loss: 1.1490e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.7955e-05 - val_loss: 1.1365e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.7409e-05 - val_loss: 1.1237e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.6881e-05 - val_loss: 1.1121e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.6343e-05 - val_loss: 1.0982e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.5846e-05 - val_loss: 1.0871e-05\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.5303e-05 - val_loss: 1.0746e-05\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.4790e-05 - val_loss: 1.0623e-05\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.4267e-05 - val_loss: 1.0503e-05\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 8.3789e-05 - val_loss: 1.0399e-05\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 8.3265e-05 - val_loss: 1.0282e-05\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.2757e-05 - val_loss: 1.0169e-05\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 8.2280e-05 - val_loss: 1.0075e-05\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.1770e-05 - val_loss: 9.9740e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 8.1284e-05 - val_loss: 9.8533e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.0775e-05 - val_loss: 9.7332e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 8.0325e-05 - val_loss: 9.6507e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.9824e-05 - val_loss: 9.5311e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 7.9366e-05 - val_loss: 9.4575e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 7.8874e-05 - val_loss: 9.3498e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.8405e-05 - val_loss: 9.2615e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.7969e-05 - val_loss: 9.1842e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.7494e-05 - val_loss: 9.1072e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.7008e-05 - val_loss: 9.0059e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 7.6567e-05 - val_loss: 8.9150e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.6096e-05 - val_loss: 8.8154e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.5674e-05 - val_loss: 8.7427e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.5197e-05 - val_loss: 8.6491e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 7.4752e-05 - val_loss: 8.5573e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.4319e-05 - val_loss: 8.4739e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 7.3906e-05 - val_loss: 8.4126e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.3481e-05 - val_loss: 8.3560e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2995e-05 - val_loss: 8.2570e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.2577e-05 - val_loss: 8.1717e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.2167e-05 - val_loss: 8.1018e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 814us/step - loss: 7.1738e-05 - val_loss: 8.0273e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 827us/step - loss: 7.1329e-05 - val_loss: 7.9663e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 7.0893e-05 - val_loss: 7.8900e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 7.9178e-0 - 1s 767us/step - loss: 7.0517e-05 - val_loss: 7.8415e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 7.0070e-05 - val_loss: 7.7694e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 6.9682e-05 - val_loss: 7.7059e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 817us/step - loss: 6.9262e-05 - val_loss: 7.6441e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.8864e-05 - val_loss: 7.5703e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.8460e-05 - val_loss: 7.5096e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 834us/step - loss: 6.8060e-05 - val_loss: 7.4430e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.7690e-05 - val_loss: 7.4041e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.7267e-05 - val_loss: 7.3272e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.6878e-05 - val_loss: 7.2704e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.6488e-05 - val_loss: 7.1987e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.6117e-05 - val_loss: 7.1480e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.5731e-05 - val_loss: 7.0967e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.5350e-05 - val_loss: 7.0382e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.4980e-05 - val_loss: 6.9919e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.4599e-05 - val_loss: 6.9375e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.4218e-05 - val_loss: 6.8804e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.3873e-05 - val_loss: 6.8345e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.3469e-05 - val_loss: 6.7695e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.3104e-05 - val_loss: 6.7084e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 6.2748e-05 - val_loss: 6.6534e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.2410e-05 - val_loss: 6.6203e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.2044e-05 - val_loss: 6.5733e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.1685e-05 - val_loss: 6.5294e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 6.1336e-05 - val_loss: 6.4884e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 6.0973e-05 - val_loss: 6.4377e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.0617e-05 - val_loss: 6.3835e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.0276e-05 - val_loss: 6.3347e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.9946e-05 - val_loss: 6.2955e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.9600e-05 - val_loss: 6.2563e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 743us/step - loss: 5.9258e-05 - val_loss: 6.2136e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.8903e-05 - val_loss: 6.1612e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.8596e-05 - val_loss: 6.1306e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.8243e-05 - val_loss: 6.0816e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.7917e-05 - val_loss: 6.0418e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 5.7590e-05 - val_loss: 6.0085e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 5.7281e-05 - val_loss: 5.9768e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 5.6938e-05 - val_loss: 5.9378e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.6612e-05 - val_loss: 5.8901e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.6311e-05 - val_loss: 5.8628e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 5.5971e-05 - val_loss: 5.8214e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.5675e-05 - val_loss: 5.7897e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.5333e-05 - val_loss: 5.7400e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.5040e-05 - val_loss: 5.7104e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.4734e-05 - val_loss: 5.6810e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.4411e-05 - val_loss: 5.6446e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 5.4113e-05 - val_loss: 5.6104e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 808us/step - loss: 5.3815e-05 - val_loss: 5.5808e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 5.3501e-05 - val_loss: 5.5447e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 5.3212e-05 - val_loss: 5.5177e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.2902e-05 - val_loss: 5.4829e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.2607e-05 - val_loss: 5.4492e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 848us/step - loss: 5.2322e-05 - val_loss: 5.4229e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 5.2028e-05 - val_loss: 5.3943e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 867us/step - loss: 5.1727e-05 - val_loss: 5.3582e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 5.1451e-05 - val_loss: 5.3350e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 809us/step - loss: 5.1149e-05 - val_loss: 5.3011e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.0879e-05 - val_loss: 5.2778e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.0591e-05 - val_loss: 5.2481e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.0301e-05 - val_loss: 5.2166e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.0014e-05 - val_loss: 5.1835e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.9743e-05 - val_loss: 5.1533e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.9468e-05 - val_loss: 5.1229e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.9204e-05 - val_loss: 5.1001e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 4.8931e-05 - val_loss: 5.0847e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 4.8652e-05 - val_loss: 5.0489e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.8386e-05 - val_loss: 5.0235e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.8116e-05 - val_loss: 5.0038e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.7853e-05 - val_loss: 4.9774e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 4.7588e-05 - val_loss: 4.9468e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.7355e-05 - val_loss: 4.9433e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.7085e-05 - val_loss: 4.9314e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.6823e-05 - val_loss: 4.9093e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 4.6539e-05 - val_loss: 4.8529e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.6306e-05 - val_loss: 4.8409e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6049e-05 - val_loss: 4.8344e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.5790e-05 - val_loss: 4.7928e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.5539e-05 - val_loss: 4.7758e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.5282e-05 - val_loss: 4.7612e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.5038e-05 - val_loss: 4.7271e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.4783e-05 - val_loss: 4.7029e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.4550e-05 - val_loss: 4.6848e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 4.4295e-05 - val_loss: 4.6596e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.4075e-05 - val_loss: 4.6493e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.3812e-05 - val_loss: 4.6223e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.3577e-05 - val_loss: 4.5999e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.3334e-05 - val_loss: 4.5759e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.3112e-05 - val_loss: 4.5583e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.2877e-05 - val_loss: 4.5397e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.2647e-05 - val_loss: 4.5285e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.2413e-05 - val_loss: 4.5062e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.2180e-05 - val_loss: 4.4872e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.1965e-05 - val_loss: 4.4785e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 4.1729e-05 - val_loss: 4.4571e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 4.1507e-05 - val_loss: 4.4443e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.1270e-05 - val_loss: 4.4244e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.1054e-05 - val_loss: 4.4018e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.0824e-05 - val_loss: 4.3795e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.0606e-05 - val_loss: 4.3594e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.0383e-05 - val_loss: 4.3406e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.0179e-05 - val_loss: 4.3280e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.9948e-05 - val_loss: 4.3065e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 3.9738e-05 - val_loss: 4.2910e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.9532e-05 - val_loss: 4.2830e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.9305e-05 - val_loss: 4.2654e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.9099e-05 - val_loss: 4.2432e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.8888e-05 - val_loss: 4.2282e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.8671e-05 - val_loss: 4.2086e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.8475e-05 - val_loss: 4.1969e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.8255e-05 - val_loss: 4.1775e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.8058e-05 - val_loss: 4.1675e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.7855e-05 - val_loss: 4.1505e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 3.7654e-05 - val_loss: 4.1397e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 3.7453e-05 - val_loss: 4.1202e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.7246e-05 - val_loss: 4.1059e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.7037e-05 - val_loss: 4.0852e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 3.6844e-05 - val_loss: 4.0759e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 3.6656e-05 - val_loss: 4.0576e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.6461e-05 - val_loss: 4.0464e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.6269e-05 - val_loss: 4.0291e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.6077e-05 - val_loss: 4.0194e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.5880e-05 - val_loss: 4.0043e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.5687e-05 - val_loss: 3.9895e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.5491e-05 - val_loss: 3.9757e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 3.5311e-05 - val_loss: 3.9609e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 3.5135e-05 - val_loss: 3.9539e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.4937e-05 - val_loss: 3.9340e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.4754e-05 - val_loss: 3.9247e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 3.4573e-05 - val_loss: 3.9179e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.4375e-05 - val_loss: 3.8980e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.4205e-05 - val_loss: 3.8908e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.4021e-05 - val_loss: 3.8794e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 3.3829e-05 - val_loss: 3.8667e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.3659e-05 - val_loss: 3.8462e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 3.3486e-05 - val_loss: 3.8386e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 3.3306e-05 - val_loss: 3.8203e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.3128e-05 - val_loss: 3.8107e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.2958e-05 - val_loss: 3.7996e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.2776e-05 - val_loss: 3.7842e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.2613e-05 - val_loss: 3.7734e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 3.2445e-05 - val_loss: 3.7638e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.2280e-05 - val_loss: 3.7559e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.2100e-05 - val_loss: 3.7430e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.1939e-05 - val_loss: 3.7276e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 3.1770e-05 - val_loss: 3.7175e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.1597e-05 - val_loss: 3.7131e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.1431e-05 - val_loss: 3.6920e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 3.1261e-05 - val_loss: 3.6860e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.1109e-05 - val_loss: 3.6714e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.0939e-05 - val_loss: 3.6655e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.0784e-05 - val_loss: 3.6471e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.0617e-05 - val_loss: 3.6352e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.0460e-05 - val_loss: 3.6231e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.0297e-05 - val_loss: 3.6171e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 729us/step - loss: 3.0143e-05 - val_loss: 3.6007e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.9995e-05 - val_loss: 3.6005e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.9826e-05 - val_loss: 3.5793e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.9673e-05 - val_loss: 3.5743e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 2.9530e-05 - val_loss: 3.5568e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.9387e-05 - val_loss: 3.5469e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.9234e-05 - val_loss: 3.5486e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.9081e-05 - val_loss: 3.5415e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.8932e-05 - val_loss: 3.5335e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.8766e-05 - val_loss: 3.5131e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.8614e-05 - val_loss: 3.5155e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.8467e-05 - val_loss: 3.4831e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.8319e-05 - val_loss: 3.4720e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.8175e-05 - val_loss: 3.4649e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.8026e-05 - val_loss: 3.4561e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.7882e-05 - val_loss: 3.4448e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.7742e-05 - val_loss: 3.4375e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.7600e-05 - val_loss: 3.4299e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.7446e-05 - val_loss: 3.4112e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.7314e-05 - val_loss: 3.4054e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.7164e-05 - val_loss: 3.3922e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.7024e-05 - val_loss: 3.3784e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.6889e-05 - val_loss: 3.3725e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.6752e-05 - val_loss: 3.3604e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.6616e-05 - val_loss: 3.3572e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.6483e-05 - val_loss: 3.3507e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.6337e-05 - val_loss: 3.3484e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.6211e-05 - val_loss: 3.3244e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.6068e-05 - val_loss: 3.3138e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.5938e-05 - val_loss: 3.3127e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5821e-05 - val_loss: 3.3098e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.5685e-05 - val_loss: 3.3178e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.5552e-05 - val_loss: 3.2733e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.5419e-05 - val_loss: 3.2658e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.5283e-05 - val_loss: 3.2753e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.5154e-05 - val_loss: 3.2472e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.5021e-05 - val_loss: 3.2344e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4891e-05 - val_loss: 3.2264e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.4761e-05 - val_loss: 3.2125e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.4642e-05 - val_loss: 3.2031e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4520e-05 - val_loss: 3.2267e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.4390e-05 - val_loss: 3.1855e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4264e-05 - val_loss: 3.1823e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.4143e-05 - val_loss: 3.1674e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4025e-05 - val_loss: 3.1610e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.3889e-05 - val_loss: 3.1493e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.3770e-05 - val_loss: 3.1353e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.3662e-05 - val_loss: 3.1332e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.3532e-05 - val_loss: 3.1737e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.3431e-05 - val_loss: 3.1140e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.3298e-05 - val_loss: 3.1000e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.3168e-05 - val_loss: 3.0888e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 734us/step - loss: 2.3055e-05 - val_loss: 3.0822e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2934e-05 - val_loss: 3.0683e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2817e-05 - val_loss: 3.0638e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.2705e-05 - val_loss: 3.0565e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.2587e-05 - val_loss: 3.0397e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2473e-05 - val_loss: 3.0317e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.2359e-05 - val_loss: 3.0383e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.2255e-05 - val_loss: 3.0156e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2133e-05 - val_loss: 3.0038e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.2021e-05 - val_loss: 3.0143e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.1911e-05 - val_loss: 2.9882e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.1800e-05 - val_loss: 2.9790e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.1688e-05 - val_loss: 2.9721e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1578e-05 - val_loss: 2.9626e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.1473e-05 - val_loss: 2.9736e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.1361e-05 - val_loss: 2.9413e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 2.1251e-05 - val_loss: 2.9393e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.1136e-05 - val_loss: 2.9219e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.1039e-05 - val_loss: 2.9195e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.0928e-05 - val_loss: 2.9032e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.0825e-05 - val_loss: 2.9185e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 2.0720e-05 - val_loss: 2.8846e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.0624e-05 - val_loss: 2.8865e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0518e-05 - val_loss: 2.8999e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.0414e-05 - val_loss: 2.8979e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.0312e-05 - val_loss: 2.8551e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.0208e-05 - val_loss: 2.8392e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.0108e-05 - val_loss: 2.8658e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0005e-05 - val_loss: 2.8219e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.9905e-05 - val_loss: 2.8192e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.9805e-05 - val_loss: 2.8133e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9696e-05 - val_loss: 2.7957e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.9593e-05 - val_loss: 2.7920e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.9492e-05 - val_loss: 2.7880e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.9395e-05 - val_loss: 2.7667e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.9298e-05 - val_loss: 2.7575e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.9201e-05 - val_loss: 2.7478e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.9104e-05 - val_loss: 2.7420e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.9012e-05 - val_loss: 2.7708e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.8931e-05 - val_loss: 2.7255e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.8829e-05 - val_loss: 2.7246e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.8737e-05 - val_loss: 2.7157e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.8652e-05 - val_loss: 2.7186e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8554e-05 - val_loss: 2.7054e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.8462e-05 - val_loss: 2.7025e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.8380e-05 - val_loss: 2.6969e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.8312e-05 - val_loss: 2.7125e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.8210e-05 - val_loss: 2.7034e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.8113e-05 - val_loss: 2.6783e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8029e-05 - val_loss: 2.6843e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7955e-05 - val_loss: 2.6619e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7860e-05 - val_loss: 2.6829e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.7802e-05 - val_loss: 2.7091e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.7694e-05 - val_loss: 2.6364e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7599e-05 - val_loss: 2.6309e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 735us/step - loss: 1.7517e-05 - val_loss: 2.6229e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7430e-05 - val_loss: 2.6160e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.7349e-05 - val_loss: 2.6120e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7274e-05 - val_loss: 2.6100e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.7198e-05 - val_loss: 2.5980e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.7105e-05 - val_loss: 2.5885e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.7024e-05 - val_loss: 2.5743e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6951e-05 - val_loss: 2.5719e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6863e-05 - val_loss: 2.5591e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.6776e-05 - val_loss: 2.5500e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6703e-05 - val_loss: 2.5422e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.6626e-05 - val_loss: 2.5400e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.6544e-05 - val_loss: 2.5269e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.6467e-05 - val_loss: 2.5210e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6402e-05 - val_loss: 2.5142e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.6313e-05 - val_loss: 2.5133e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.6229e-05 - val_loss: 2.4907e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.6154e-05 - val_loss: 2.4879e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.6079e-05 - val_loss: 2.4839e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.6002e-05 - val_loss: 2.4669e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.5925e-05 - val_loss: 2.4575e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.5851e-05 - val_loss: 2.4503e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5770e-05 - val_loss: 2.4532e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5703e-05 - val_loss: 2.4517e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.5630e-05 - val_loss: 2.4257e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.5550e-05 - val_loss: 2.4123e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.5489e-05 - val_loss: 2.4064e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.5416e-05 - val_loss: 2.4179e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.5345e-05 - val_loss: 2.4199e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.5281e-05 - val_loss: 2.4438e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5205e-05 - val_loss: 2.4102e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.5133e-05 - val_loss: 2.3669e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.5055e-05 - val_loss: 2.3678e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.4973e-05 - val_loss: 2.3457e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.4911e-05 - val_loss: 2.3393e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.4842e-05 - val_loss: 2.3312e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.4794e-05 - val_loss: 2.3241e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4702e-05 - val_loss: 2.3265e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.4642e-05 - val_loss: 2.3371e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4602e-05 - val_loss: 2.3012e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.4499e-05 - val_loss: 2.3140e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.4423e-05 - val_loss: 2.2789e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.4361e-05 - val_loss: 2.2857e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.4305e-05 - val_loss: 2.3049e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4240e-05 - val_loss: 2.2671e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4176e-05 - val_loss: 2.2861e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4105e-05 - val_loss: 2.2443e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.4018e-05 - val_loss: 2.2323e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.3962e-05 - val_loss: 2.2314e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.3901e-05 - val_loss: 2.2254e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.3840e-05 - val_loss: 2.2088e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.3757e-05 - val_loss: 2.1995e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.3689e-05 - val_loss: 2.2256e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.3647e-05 - val_loss: 2.1963e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.3575e-05 - val_loss: 2.1716e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.3510e-05 - val_loss: 2.1710e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.3439e-05 - val_loss: 2.1627e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.3374e-05 - val_loss: 2.1553e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3324e-05 - val_loss: 2.1489e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3245e-05 - val_loss: 2.1322e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.3195e-05 - val_loss: 2.1733e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3145e-05 - val_loss: 2.1820e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.3087e-05 - val_loss: 2.1520e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.3021e-05 - val_loss: 2.1611e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.2960e-05 - val_loss: 2.1270e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.2885e-05 - val_loss: 2.0946e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.2834e-05 - val_loss: 2.0927e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.2766e-05 - val_loss: 2.0878e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.2710e-05 - val_loss: 2.1416e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.2663e-05 - val_loss: 2.0697e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.2592e-05 - val_loss: 2.0602e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.2531e-05 - val_loss: 2.0949e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2493e-05 - val_loss: 2.1429e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.2452e-05 - val_loss: 2.0349e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2352e-05 - val_loss: 2.0219e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.2310e-05 - val_loss: 2.0108e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.2285e-05 - val_loss: 1.9961e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.2191e-05 - val_loss: 1.9902e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 814us/step - loss: 1.2121e-05 - val_loss: 1.9814e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 1.2068e-05 - val_loss: 1.9901e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.2027e-05 - val_loss: 1.9848e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.1957e-05 - val_loss: 1.9565e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.1904e-05 - val_loss: 1.9552e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.1898e-05 - val_loss: 2.0358e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1824e-05 - val_loss: 1.9419e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 731us/step - loss: 1.1741e-05 - val_loss: 1.9486e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1684e-05 - val_loss: 1.9214e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1634e-05 - val_loss: 1.9713e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1605e-05 - val_loss: 1.9143e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.1555e-05 - val_loss: 1.9033e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1467e-05 - val_loss: 1.9409e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1486e-05 - val_loss: 1.8960e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.1364e-05 - val_loss: 1.8846e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.1306e-05 - val_loss: 1.8678e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1259e-05 - val_loss: 1.8624e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.1276e-05 - val_loss: 2.0387e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1216e-05 - val_loss: 2.0648e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1193e-05 - val_loss: 1.8614e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.1084e-05 - val_loss: 1.8779e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.1018e-05 - val_loss: 1.8247e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.0946e-05 - val_loss: 1.8176e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0916e-05 - val_loss: 1.8389e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0854e-05 - val_loss: 1.8352e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0812e-05 - val_loss: 1.8018e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.0750e-05 - val_loss: 1.7897e-06\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0701e-05 - val_loss: 1.7948e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 738us/step - loss: 1.0664e-05 - val_loss: 1.7837e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 736us/step - loss: 1.0629e-05 - val_loss: 1.9030e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0630e-05 - val_loss: 1.7615e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0509e-05 - val_loss: 1.7567e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 1.0466e-05 - val_loss: 1.7869e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0563e-05 - val_loss: 2.0190e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0507e-05 - val_loss: 1.7696e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.0483e-05 - val_loss: 1.8614e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0339e-05 - val_loss: 1.8652e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0345e-05 - val_loss: 1.7202e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 1.0206e-05 - val_loss: 1.8005e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0161e-05 - val_loss: 1.7358e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.0133e-05 - val_loss: 1.7000e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0052e-05 - val_loss: 1.7169e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.0011e-05 - val_loss: 1.7061e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.9636e-06 - val_loss: 1.6690e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.9143e-06 - val_loss: 1.6866e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.8792e-06 - val_loss: 1.6602e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 9.8161e-06 - val_loss: 1.6722e-06\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.8169e-06 - val_loss: 1.6550e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.7649e-06 - val_loss: 1.7875e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.7623e-06 - val_loss: 1.6332e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 9.6660e-06 - val_loss: 1.7015e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.6364e-06 - val_loss: 1.6160e-06\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.5754e-06 - val_loss: 1.6771e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.5421e-06 - val_loss: 1.6128e-06\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.5240e-06 - val_loss: 1.6943e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.5287e-06 - val_loss: 1.7095e-06\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.4722e-06 - val_loss: 1.5866e-06\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.3905e-06 - val_loss: 1.7227e-06\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.4207e-06 - val_loss: 1.6080e-06\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.2669e-06 - val_loss: 1.5677e-06\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.2162e-06 - val_loss: 1.5581e-06\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.1856e-06 - val_loss: 1.6019e-06\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 9.3408e-06 - val_loss: 1.9554e-06\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.3426e-06 - val_loss: 1.5438e-06\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.1209e-06 - val_loss: 1.6741e-06\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 9.1436e-06 - val_loss: 1.5401e-06\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 9.0080e-06 - val_loss: 1.6879e-06\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.1775e-06 - val_loss: 1.6693e-06\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.9551e-06 - val_loss: 1.5098e-06\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.8832e-06 - val_loss: 1.6019e-06\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 8.8629e-06 - val_loss: 1.5169e-06\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.9751e-06 - val_loss: 1.8478e-06\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.9092e-06 - val_loss: 1.5244e-06\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 8.9539e-06 - val_loss: 1.7175e-06\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 8.7391e-06 - val_loss: 1.6549e-06\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.8683e-06 - val_loss: 1.5649e-06\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.6649e-06 - val_loss: 1.6317e-06\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.6344e-06 - val_loss: 1.4621e-06\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.5254e-06 - val_loss: 1.4495e-06\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.4916e-06 - val_loss: 1.4555e-06\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.4479e-06 - val_loss: 1.4474e-06\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 732us/step - loss: 8.4112e-06 - val_loss: 1.4673e-06\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 8.4971e-06 - val_loss: 1.6018e-06\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.4151e-06 - val_loss: 1.4231e-06\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 8.3307e-06 - val_loss: 1.4905e-06\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.2982e-06 - val_loss: 1.4898e-06\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.3215e-06 - val_loss: 1.4174e-06\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.2313e-06 - val_loss: 1.5240e-06\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 8.2095e-06 - val_loss: 1.4026e-06\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.1571e-06 - val_loss: 1.4431e-06\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.1099e-06 - val_loss: 1.3814e-06\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 8.0631e-06 - val_loss: 1.3985e-06\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.0245e-06 - val_loss: 1.4295e-06\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.0210e-06 - val_loss: 1.3952e-06\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 7.9622e-06 - val_loss: 1.3582e-06\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.9094e-06 - val_loss: 1.3610e-06\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.8854e-06 - val_loss: 1.3563e-06\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.8451e-06 - val_loss: 1.3460e-06\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.8086e-06 - val_loss: 1.3367e-06\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.7810e-06 - val_loss: 1.3895e-06\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.7896e-06 - val_loss: 1.3576e-06\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.7393e-06 - val_loss: 1.3251e-06\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 7.6796e-06 - val_loss: 1.3700e-06\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.7410e-06 - val_loss: 1.4481e-06\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.8123e-06 - val_loss: 1.5082e-06\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 7.6909e-06 - val_loss: 1.3298e-06\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.5658e-06 - val_loss: 1.2993e-06\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.5125e-06 - val_loss: 1.3034e-06\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.5564e-06 - val_loss: 1.4824e-06\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.6665e-06 - val_loss: 1.3970e-06\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 7.4783e-06 - val_loss: 1.3225e-06\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.4631e-06 - val_loss: 1.4345e-06\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 7.4501e-06 - val_loss: 1.2875e-06\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3371e-06 - val_loss: 1.2990e-06\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 7.3650e-06 - val_loss: 1.3105e-06\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3069e-06 - val_loss: 1.2940e-06\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.3705e-06 - val_loss: 1.4802e-06\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.3146e-06 - val_loss: 1.2423e-06\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.1719e-06 - val_loss: 1.2377e-06\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.1680e-06 - val_loss: 1.2762e-06\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.1383e-06 - val_loss: 1.2165e-06\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.1473e-06 - val_loss: 1.4432e-06\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.5009e-06 - val_loss: 1.8343e-06\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3725e-06 - val_loss: 1.2471e-06\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.0196e-06 - val_loss: 1.2976e-06\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.0931e-06 - val_loss: 1.2639e-06\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 6.9635e-06 - val_loss: 1.3130e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0091e-06 - val_loss: 1.2304e-06\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.8996e-06 - val_loss: 1.1849e-06\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.8485e-06 - val_loss: 1.2141e-06\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8468e-06 - val_loss: 1.1658e-06\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.8037e-06 - val_loss: 1.2323e-06\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 6.8867e-06 - val_loss: 1.2749e-06\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 865us/step - loss: 6.7592e-06 - val_loss: 1.1765e-06\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 842us/step - loss: 6.7451e-06 - val_loss: 1.1996e-06\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 814us/step - loss: 6.7312e-06 - val_loss: 1.1828e-06\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 6.6730e-06 - val_loss: 1.1542e-06\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.6582e-06 - val_loss: 1.1949e-06\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 6.6136e-06 - val_loss: 1.1285e-06\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 6.5893e-06 - val_loss: 1.2183e-06\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.6504e-06 - val_loss: 1.2057e-06\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.5698e-06 - val_loss: 1.1905e-06\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.6670e-06 - val_loss: 1.5206e-06\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 6.8373e-06 - val_loss: 1.2939e-06\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.5314e-06 - val_loss: 1.1037e-06\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.4939e-06 - val_loss: 1.4348e-06\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.6644e-06 - val_loss: 1.1262e-06\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 6.4486e-06 - val_loss: 1.4510e-06\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.6883e-06 - val_loss: 1.2657e-06\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.3523e-06 - val_loss: 1.1250e-06\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 6.3774e-06 - val_loss: 1.1371e-06\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 6.2746e-06 - val_loss: 1.0724e-06\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 6.2970e-06 - val_loss: 1.2018e-06\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.2454e-06 - val_loss: 1.0788e-06\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.2079e-06 - val_loss: 1.0706e-06\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 6.1545e-06 - val_loss: 1.0521e-06\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 6.1298e-06 - val_loss: 1.0630e-06\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 6.1115e-06 - val_loss: 1.0569e-06\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.0786e-06 - val_loss: 1.0450e-06\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 6.0565e-06 - val_loss: 1.0395e-06\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 6.0243e-06 - val_loss: 1.0282e-06\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.9985e-06 - val_loss: 1.0245e-06\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 6.0141e-06 - val_loss: 1.1662e-06\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 6.1112e-06 - val_loss: 1.1874e-06\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.0513e-06 - val_loss: 1.0993e-06\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.9603e-06 - val_loss: 1.0681e-06\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.9519e-06 - val_loss: 1.0481e-06\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.8670e-06 - val_loss: 1.0173e-06\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.8408e-06 - val_loss: 1.0013e-06\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.8425e-06 - val_loss: 1.1302e-06\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.9738e-06 - val_loss: 1.2299e-06\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.9679e-06 - val_loss: 1.0928e-06\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.7753e-06 - val_loss: 9.8181e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.7366e-06 - val_loss: 1.0201e-06\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.7929e-06 - val_loss: 1.1988e-06\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.0965e-06 - val_loss: 1.7503e-06\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.3981e-06 - val_loss: 1.3135e-06\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.7442e-06 - val_loss: 9.5979e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.6147e-06 - val_loss: 9.8641e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.5930e-06 - val_loss: 9.6858e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 5.6012e-06 - val_loss: 9.8733e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.5530e-06 - val_loss: 9.4453e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.5193e-06 - val_loss: 9.5514e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 5.5767e-0 - 1s 758us/step - loss: 5.5014e-06 - val_loss: 9.4696e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.4942e-06 - val_loss: 9.5091e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.4514e-06 - val_loss: 9.2806e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.4379e-06 - val_loss: 9.7174e-07\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 5.5007e-06 - val_loss: 1.0833e-06\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.5070e-06 - val_loss: 1.0187e-06\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.4637e-06 - val_loss: 9.6076e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.3714e-06 - val_loss: 1.0820e-06\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.8675e-06 - val_loss: 1.8430e-06\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.9200e-06 - val_loss: 1.0196e-06\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.3209e-06 - val_loss: 9.9251e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.3093e-06 - val_loss: 9.0152e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.2502e-06 - val_loss: 9.2005e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.2383e-06 - val_loss: 8.8753e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.2150e-06 - val_loss: 9.4464e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.3106e-06 - val_loss: 1.0500e-06\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.2695e-06 - val_loss: 9.4787e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.2152e-06 - val_loss: 9.5826e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 5.2220e-06 - val_loss: 9.5863e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 5.1374e-06 - val_loss: 9.0207e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.1382e-06 - val_loss: 9.1195e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.0810e-06 - val_loss: 8.5971e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.0468e-06 - val_loss: 8.8911e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 5.1332e-06 - val_loss: 1.1186e-06\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.1697e-06 - val_loss: 8.5737e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.0194e-06 - val_loss: 9.7693e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.0476e-06 - val_loss: 8.5715e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.9455e-06 - val_loss: 8.4296e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.9246e-06 - val_loss: 8.4019e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.9066e-06 - val_loss: 8.3409e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.8957e-06 - val_loss: 8.6392e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 4.9004e-06 - val_loss: 8.6229e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 4.9149e-06 - val_loss: 1.0022e-06\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 5.0482e-06 - val_loss: 1.0988e-06\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 5.2023e-06 - val_loss: 1.4671e-06\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.5224e-06 - val_loss: 1.2699e-06\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 4.9599e-06 - val_loss: 8.5527e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 5.0153e-06 - val_loss: 1.2548e-06\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9752e-06 - val_loss: 8.0691e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.7651e-06 - val_loss: 8.7890e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 4.8176e-06 - val_loss: 9.3614e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.7536e-06 - val_loss: 7.9164e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.6699e-06 - val_loss: 7.8982e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.6478e-06 - val_loss: 7.9384e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.6458e-06 - val_loss: 8.1259e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.6713e-06 - val_loss: 8.5941e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 4.6390e-06 - val_loss: 7.9265e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.6194e-06 - val_loss: 8.7584e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 4.6438e-06 - val_loss: 8.5237e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6238e-06 - val_loss: 8.1796e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.5444e-06 - val_loss: 7.6431e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.5172e-06 - val_loss: 7.9534e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.6145e-06 - val_loss: 1.0439e-06\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 4.8665e-06 - val_loss: 1.2338e-06\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.8311e-06 - val_loss: 9.0413e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.4876e-06 - val_loss: 7.6944e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 4.4521e-06 - val_loss: 7.5553e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 4.4139e-06 - val_loss: 7.5048e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.4197e-06 - val_loss: 8.0985e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.4590e-06 - val_loss: 8.1775e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.4324e-06 - val_loss: 7.8307e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.3671e-06 - val_loss: 7.4485e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.4543e-06 - val_loss: 1.1587e-06\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.9971e-06 - val_loss: 1.7163e-06\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.8918e-06 - val_loss: 7.3839e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 4.4334e-06 - val_loss: 1.1871e-06\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.6545e-06 - val_loss: 7.6067e-07\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.2859e-06 - val_loss: 8.0982e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.3014e-06 - val_loss: 7.1167e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.2443e-06 - val_loss: 7.6187e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 4.2121e-06 - val_loss: 7.2806e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.2276e-06 - val_loss: 7.4681e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.2051e-06 - val_loss: 7.0962e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.1588e-06 - val_loss: 7.0847e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 4.1703e-06 - val_loss: 7.8796e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.2155e-06 - val_loss: 7.7139e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.1436e-06 - val_loss: 6.9670e-07\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 100, 20)           1760      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100, 1)            21        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0888 - val_loss: 0.0858\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0841 - val_loss: 0.0819\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0808 - val_loss: 0.0794\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 769us/step - loss: 0.0785 - val_loss: 0.0774\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0765 - val_loss: 0.0752\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0741 - val_loss: 0.0727\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 0.0717 - val_loss: 0.0703\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0693 - val_loss: 0.0679\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0669 - val_loss: 0.0654\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0643 - val_loss: 0.0627\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0616 - val_loss: 0.0599\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0587 - val_loss: 0.0569\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0555 - val_loss: 0.0534\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0518 - val_loss: 0.0494\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0473 - val_loss: 0.0441\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0416 - val_loss: 0.0381\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0357 - val_loss: 0.0321\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0295 - val_loss: 0.0257\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0230 - val_loss: 0.0195\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0172 - val_loss: 0.0144\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 784us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0010 - val_loss: 9.7406e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 9.8566e-04 - val_loss: 9.4341e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.5698e-04 - val_loss: 9.1419e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.3044e-04 - val_loss: 8.8639e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.0565e-04 - val_loss: 8.6152e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 8.8192e-04 - val_loss: 8.3362e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 8.5535e-0 - 1s 745us/step - loss: 8.5634e-04 - val_loss: 8.0638e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.3085e-04 - val_loss: 7.7977e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.0762e-04 - val_loss: 7.5655e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.8803e-04 - val_loss: 7.3656e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.6748e-04 - val_loss: 7.0807e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.3876e-04 - val_loss: 6.7953e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.1603e-04 - val_loss: 6.5767e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 6.9473e-04 - val_loss: 6.3263e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.7223e-04 - val_loss: 6.1007e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.5245e-04 - val_loss: 5.9015e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.3533e-04 - val_loss: 5.7209e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.1758e-04 - val_loss: 5.4933e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.9576e-04 - val_loss: 5.2588e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.7421e-04 - val_loss: 5.0406e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.5588e-04 - val_loss: 4.8490e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.3836e-04 - val_loss: 4.6698e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.2324e-04 - val_loss: 4.5248e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.1278e-04 - val_loss: 4.4024e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.9361e-04 - val_loss: 4.1104e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.7269e-04 - val_loss: 3.9777e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.5877e-04 - val_loss: 3.7747e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.4209e-04 - val_loss: 3.6555e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.3114e-04 - val_loss: 3.4768e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.1340e-04 - val_loss: 3.3267e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.0285e-04 - val_loss: 3.2040e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.8784e-04 - val_loss: 3.0263e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.7516e-04 - val_loss: 2.9105e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.6304e-04 - val_loss: 2.7595e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.4995e-04 - val_loss: 2.6414e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.4043e-04 - val_loss: 2.5294e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 3.2931e-04 - val_loss: 2.3978e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.1734e-04 - val_loss: 2.2822e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.0750e-04 - val_loss: 2.1753e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9804e-04 - val_loss: 2.0759e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.9048e-04 - val_loss: 2.0294e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.9100e-04 - val_loss: 2.0358e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.8015e-04 - val_loss: 1.7794e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.6694e-04 - val_loss: 1.7529e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.5736e-04 - val_loss: 1.6190e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.4987e-04 - val_loss: 1.5429e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.4088e-04 - val_loss: 1.4614e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.3484e-04 - val_loss: 1.3787e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.2719e-04 - val_loss: 1.3081e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 2.2103e-04 - val_loss: 1.2388e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.1492e-04 - val_loss: 1.1750e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.0941e-04 - val_loss: 1.1244e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.0482e-04 - val_loss: 1.0666e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.9926e-04 - val_loss: 1.0021e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 1.9395e-04 - val_loss: 9.5855e-05\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.9042e-04 - val_loss: 9.1518e-05\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.8653e-04 - val_loss: 8.7347e-05\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 782us/step - loss: 1.8294e-04 - val_loss: 8.4144e-05\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.8150e-04 - val_loss: 8.3239e-05\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 1.7938e-04 - val_loss: 7.8347e-05\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7271e-04 - val_loss: 6.9104e-05\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6605e-04 - val_loss: 6.6829e-05\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.6417e-04 - val_loss: 6.2369e-05\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.5952e-04 - val_loss: 5.8598e-05\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.5698e-04 - val_loss: 5.6250e-05\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5402e-04 - val_loss: 5.2530e-05\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.5090e-04 - val_loss: 4.9726e-05\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.4854e-04 - val_loss: 4.7470e-05\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.4657e-04 - val_loss: 4.5963e-05\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.4655e-04 - val_loss: 4.8819e-05\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.4962e-04 - val_loss: 4.9123e-05\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.4617e-04 - val_loss: 4.0048e-05\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3812e-04 - val_loss: 3.7547e-05\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3862e-04 - val_loss: 3.8351e-05\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.3652e-04 - val_loss: 3.3178e-05\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3260e-04 - val_loss: 3.3101e-05\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.3403e-04 - val_loss: 3.3858e-05\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 1.3177e-04 - val_loss: 2.8383e-05\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.2803e-04 - val_loss: 2.8896e-05\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2902e-04 - val_loss: 2.8646e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2672e-04 - val_loss: 2.4369e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 838us/step - loss: 1.2368e-04 - val_loss: 2.3739e-05\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2313e-04 - val_loss: 2.2572e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.2136e-04 - val_loss: 2.1073e-05\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 1.2000e-04 - val_loss: 2.0172e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1899e-04 - val_loss: 1.9385e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.1848e-04 - val_loss: 2.0666e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.2249e-04 - val_loss: 2.9395e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2875e-04 - val_loss: 2.5371e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.1839e-04 - val_loss: 1.6783e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.1633e-04 - val_loss: 1.8180e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1449e-04 - val_loss: 1.4828e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 1.1244e-04 - val_loss: 1.4396e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.1160e-04 - val_loss: 1.3803e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1097e-04 - val_loss: 1.3713e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.1088e-04 - val_loss: 1.4419e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1090e-04 - val_loss: 1.3362e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0890e-04 - val_loss: 1.1835e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0782e-04 - val_loss: 1.1446e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 812us/step - loss: 1.0713e-04 - val_loss: 1.1134e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.0650e-04 - val_loss: 1.0859e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.0631e-04 - val_loss: 1.1805e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0817e-04 - val_loss: 1.7027e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1852e-04 - val_loss: 3.4071e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.1953e-04 - val_loss: 9.5941e-06\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0718e-04 - val_loss: 1.6325e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0543e-04 - val_loss: 1.0469e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0470e-04 - val_loss: 9.2029e-06\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0189e-04 - val_loss: 9.6594e-06\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0144e-04 - val_loss: 8.2921e-06\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0052e-04 - val_loss: 7.8707e-06\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 9.9874e-05 - val_loss: 7.9290e-06\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.9256e-05 - val_loss: 7.5648e-06\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.8888e-05 - val_loss: 7.6540e-06\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 9.8227e-05 - val_loss: 7.1454e-06\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.7800e-05 - val_loss: 7.3660e-06\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 9.7524e-05 - val_loss: 7.3967e-06\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.7025e-05 - val_loss: 6.9995e-06\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.6542e-05 - val_loss: 7.2437e-06\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 9.5911e-05 - val_loss: 6.3583e-06\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 9.5068e-05 - val_loss: 6.6530e-06\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.5311e-05 - val_loss: 7.5832e-06\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 9.6297e-05 - val_loss: 1.0191e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0001e-04 - val_loss: 1.4459e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.0018e-04 - val_loss: 8.7430e-06\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 9.3558e-05 - val_loss: 6.2361e-06\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.3959e-05 - val_loss: 8.5917e-06\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.3769e-05 - val_loss: 5.9093e-06\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.1296e-05 - val_loss: 5.8390e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 9.1340e-05 - val_loss: 5.9830e-06\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.0867e-05 - val_loss: 5.8683e-06\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.0051e-05 - val_loss: 5.1557e-06\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.9244e-05 - val_loss: 5.1666e-06\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.8991e-05 - val_loss: 5.3232e-06\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.9034e-05 - val_loss: 6.0283e-06\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.9443e-05 - val_loss: 7.7654e-06\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.3210e-05 - val_loss: 1.7263e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0368e-04 - val_loss: 2.0218e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.3386e-05 - val_loss: 5.4623e-06\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.0028e-05 - val_loss: 8.0977e-06\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.6740e-05 - val_loss: 5.7619e-06\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.6785e-05 - val_loss: 5.1163e-06\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.4969e-05 - val_loss: 4.8230e-06\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.4889e-05 - val_loss: 4.7830e-06\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 8.4076e-05 - val_loss: 4.3294e-06\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.3646e-05 - val_loss: 4.4647e-06\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.3168e-05 - val_loss: 4.2607e-06\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.2613e-05 - val_loss: 4.1645e-06\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.2201e-05 - val_loss: 4.1612e-06\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.1731e-05 - val_loss: 4.0853e-06\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.1307e-05 - val_loss: 4.0399e-06\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.0947e-05 - val_loss: 4.1349e-06\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0605e-05 - val_loss: 4.0679e-06\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.0369e-05 - val_loss: 4.5868e-06\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.0791e-05 - val_loss: 5.7801e-06\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 8.2044e-05 - val_loss: 9.1472e-06\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 8.9259e-05 - val_loss: 2.4508e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.0204e-04 - val_loss: 1.6134e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 8.2373e-05 - val_loss: 1.0942e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 8.4359e-05 - val_loss: 4.2588e-06\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 7.9084e-05 - val_loss: 7.7955e-06\n",
      "Epoch 00258: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 100, 30)           3840      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100, 1)            31        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 3,871\n",
      "Trainable params: 3,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 0.0956 - val_loss: 0.0914\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0892 - val_loss: 0.0867\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0855 - val_loss: 0.0842\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0831 - val_loss: 0.0815\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0802 - val_loss: 0.0785\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0773 - val_loss: 0.0757\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0746 - val_loss: 0.0730\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0719 - val_loss: 0.0702\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0691 - val_loss: 0.0674\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0662 - val_loss: 0.0645\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0633 - val_loss: 0.0615\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0602 - val_loss: 0.0584\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 812us/step - loss: 0.0570 - val_loss: 0.0550\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0534 - val_loss: 0.0512\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0494 - val_loss: 0.0465\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0439 - val_loss: 0.0394\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0364 - val_loss: 0.0333\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0305 - val_loss: 0.0270\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0244 - val_loss: 0.0211\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0191 - val_loss: 0.0164\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 808us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0010 - val_loss: 9.9349e-04\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0010 - val_loss: 9.5217e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.8524e-04 - val_loss: 9.2426e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.5957e-04 - val_loss: 9.0121e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 9.3569e-04 - val_loss: 8.7935e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 9.1286e-04 - val_loss: 8.5336e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 8.9023e-04 - val_loss: 8.2889e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 8.6867e-04 - val_loss: 8.0493e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.4567e-04 - val_loss: 7.8171e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 8.2430e-04 - val_loss: 7.5910e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.0339e-04 - val_loss: 7.3727e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 7.8301e-04 - val_loss: 7.1424e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 7.6172e-04 - val_loss: 6.9221e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.4216e-04 - val_loss: 6.7246e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.2342e-04 - val_loss: 6.5172e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 7.0494e-04 - val_loss: 6.3273e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.8669e-04 - val_loss: 6.1034e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.6542e-04 - val_loss: 5.8887e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 6.4554e-04 - val_loss: 5.6844e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.2774e-04 - val_loss: 5.4974e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 6.1088e-04 - val_loss: 5.3367e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.0174e-04 - val_loss: 5.3857e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 6.3362e-04 - val_loss: 5.8256e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.9591e-04 - val_loss: 4.9753e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.6379e-04 - val_loss: 4.6157e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.3746e-04 - val_loss: 4.4243e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.1628e-04 - val_loss: 4.2726e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.9920e-04 - val_loss: 4.1357e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.8399e-04 - val_loss: 3.9679e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.6948e-04 - val_loss: 3.8102e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.5606e-04 - val_loss: 3.6535e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4193e-04 - val_loss: 3.5121e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.2901e-04 - val_loss: 3.3735e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 4.1645e-04 - val_loss: 3.2410e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 4.0433e-04 - val_loss: 3.1105e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.9287e-04 - val_loss: 2.9912e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.8200e-04 - val_loss: 2.8665e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.7042e-04 - val_loss: 2.7479e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 3.6099e-04 - val_loss: 2.6555e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 3.5129e-04 - val_loss: 2.5234e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 807us/step - loss: 3.3943e-04 - val_loss: 2.4139e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.2976e-04 - val_loss: 2.3114e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.2050e-04 - val_loss: 2.2110e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 3.1183e-04 - val_loss: 2.1441e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 3.1490e-04 - val_loss: 2.4137e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 3.5536e-04 - val_loss: 2.4589e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 3.0552e-04 - val_loss: 2.0575e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.9928e-04 - val_loss: 1.7707e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.7811e-04 - val_loss: 1.7330e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 2.6783e-04 - val_loss: 1.6929e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 2.6106e-04 - val_loss: 1.5621e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.5367e-04 - val_loss: 1.4776e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.4658e-04 - val_loss: 1.4349e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 2.4030e-04 - val_loss: 1.3490e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.3402e-04 - val_loss: 1.2854e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.2845e-04 - val_loss: 1.2325e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.2336e-04 - val_loss: 1.1723e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 2.1797e-04 - val_loss: 1.1239e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 784us/step - loss: 2.1414e-04 - val_loss: 1.0706e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.0851e-04 - val_loss: 1.0195e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.0477e-04 - val_loss: 9.9238e-05\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 2.0351e-04 - val_loss: 9.9794e-05\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 2.0570e-04 - val_loss: 1.0041e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 1.9963e-04 - val_loss: 8.6269e-05\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.8870e-04 - val_loss: 8.1682e-05\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.8643e-04 - val_loss: 8.0175e-05\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.8702e-04 - val_loss: 8.3324e-05\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 1.9055e-04 - val_loss: 8.4230e-05\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.8408e-04 - val_loss: 6.8415e-05\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.7264e-04 - val_loss: 6.6971e-05\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7529e-04 - val_loss: 7.1544e-05\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.7731e-04 - val_loss: 6.6592e-05\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.6865e-04 - val_loss: 5.6276e-05\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.6206e-04 - val_loss: 5.6903e-05\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.6457e-04 - val_loss: 5.6902e-05\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.6069e-04 - val_loss: 5.0590e-05\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.5621e-04 - val_loss: 4.8293e-05\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.5451e-04 - val_loss: 4.6958e-05\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.5247e-04 - val_loss: 4.4134e-05\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.4982e-04 - val_loss: 4.1814e-05\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.4905e-04 - val_loss: 4.5819e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.5750e-04 - val_loss: 6.5753e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.8390e-04 - val_loss: 7.5970e-05\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.5936e-04 - val_loss: 3.5577e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 1.4895e-04 - val_loss: 4.3175e-05\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.4210e-04 - val_loss: 3.4539e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 1.4272e-04 - val_loss: 3.4510e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.3697e-04 - val_loss: 2.9946e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.3570e-04 - val_loss: 2.9111e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.3337e-04 - val_loss: 2.7657e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.3299e-04 - val_loss: 2.7608e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 1.3099e-04 - val_loss: 2.5522e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 1.3044e-04 - val_loss: 2.6463e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.3168e-04 - val_loss: 2.6970e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 1.2949e-04 - val_loss: 2.3238e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.2628e-04 - val_loss: 2.1866e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.2570e-04 - val_loss: 2.2753e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.2678e-04 - val_loss: 2.4789e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2808e-04 - val_loss: 2.4675e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.2589e-04 - val_loss: 2.1121e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.2383e-04 - val_loss: 2.2788e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2650e-04 - val_loss: 2.7511e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.3067e-04 - val_loss: 2.9472e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.2920e-04 - val_loss: 2.4170e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2162e-04 - val_loss: 1.6421e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1727e-04 - val_loss: 1.7740e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.1935e-04 - val_loss: 2.0137e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2155e-04 - val_loss: 2.2950e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2277e-04 - val_loss: 2.1985e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.1955e-04 - val_loss: 1.7797e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.1542e-04 - val_loss: 1.4566e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 1.1244e-04 - val_loss: 1.3720e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.1367e-04 - val_loss: 1.9221e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2133e-04 - val_loss: 3.0825e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3233e-04 - val_loss: 3.5960e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.2429e-04 - val_loss: 1.3821e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.1013e-04 - val_loss: 1.7244e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1509e-04 - val_loss: 1.6948e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.0972e-04 - val_loss: 1.1221e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 1.0739e-04 - val_loss: 1.2893e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.0773e-04 - val_loss: 1.1449e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0553e-04 - val_loss: 1.0534e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.0478e-04 - val_loss: 1.0336e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0410e-04 - val_loss: 1.0367e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0462e-04 - val_loss: 1.2816e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.0739e-04 - val_loss: 1.7582e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.1324e-04 - val_loss: 2.5145e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.1940e-04 - val_loss: 2.6301e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.1282e-04 - val_loss: 1.2515e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.0148e-04 - val_loss: 9.3607e-06\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.0152e-04 - val_loss: 1.2676e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.0286e-04 - val_loss: 1.1703e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.0201e-04 - val_loss: 1.2448e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0168e-04 - val_loss: 1.0687e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.9323e-05 - val_loss: 9.5921e-06\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.7928e-05 - val_loss: 8.7026e-06\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 9.7009e-05 - val_loss: 8.8815e-06\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.7357e-05 - val_loss: 1.0210e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 9.8586e-05 - val_loss: 1.2478e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.0196e-04 - val_loss: 2.0515e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.1201e-04 - val_loss: 3.3280e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2008e-04 - val_loss: 2.4697e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.9962e-05 - val_loss: 7.9886e-06\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 9.8985e-05 - val_loss: 2.1392e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 1.0327e-04 - val_loss: 1.0031e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 9.2635e-05 - val_loss: 1.0521e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.5862e-05 - val_loss: 9.6041e-06\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.1323e-05 - val_loss: 7.1617e-06\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.1882e-05 - val_loss: 1.0763e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 9.3023e-05 - val_loss: 7.8640e-06\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 8.9240e-05 - val_loss: 6.9344e-06\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 8.9397e-05 - val_loss: 7.6215e-06\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 8.8723e-05 - val_loss: 6.5441e-06\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 8.7387e-05 - val_loss: 6.2621e-06\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 8.7165e-05 - val_loss: 7.1328e-06\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.7644e-05 - val_loss: 8.1423e-06\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 8.9355e-05 - val_loss: 1.2608e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.6623e-05 - val_loss: 2.6692e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.1146e-04 - val_loss: 3.7326e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0643e-04 - val_loss: 1.0555e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 8.5509e-05 - val_loss: 9.0202e-06\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.7927e-05 - val_loss: 9.2314e-06\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.4285e-05 - val_loss: 5.7204e-06\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.3370e-05 - val_loss: 7.9724e-06\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.4361e-05 - val_loss: 6.4387e-06\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 8.1764e-05 - val_loss: 5.5215e-06\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 8.1345e-05 - val_loss: 5.8706e-06\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 8.0923e-05 - val_loss: 5.4237e-06\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 8.0135e-05 - val_loss: 5.2214e-06\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 7.9761e-05 - val_loss: 5.8865e-06\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.1073e-05 - val_loss: 9.7987e-06\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 8.7804e-05 - val_loss: 2.3446e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.0342e-04 - val_loss: 3.5181e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 9.9881e-05 - val_loss: 1.0894e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 7.9374e-05 - val_loss: 9.0827e-06\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.5119e-05 - val_loss: 1.4326e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 8.1469e-05 - val_loss: 4.9486e-06\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.7232e-05 - val_loss: 9.1467e-06\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.9152e-05 - val_loss: 5.7650e-06\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.5536e-05 - val_loss: 6.1348e-06\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.7918e-05 - val_loss: 9.9485e-06\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 7.9170e-05 - val_loss: 8.2052e-06\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.5846e-05 - val_loss: 5.0479e-06\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.3573e-05 - val_loss: 4.4702e-06\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.3071e-05 - val_loss: 5.0561e-06\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.3730e-05 - val_loss: 6.4559e-06\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.4720e-05 - val_loss: 8.2022e-06\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 7.7359e-05 - val_loss: 1.3433e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.3376e-05 - val_loss: 2.1989e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.8637e-05 - val_loss: 1.7411e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 7.7691e-05 - val_loss: 4.9321e-06\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 7.0713e-05 - val_loss: 7.9525e-06\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.6698e-05 - val_loss: 1.4615e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 7.8177e-05 - val_loss: 8.6992e-06\n",
      "Epoch 00290: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 100, 40)           6720      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100, 1)            41        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 6,761\n",
      "Trainable params: 6,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 0.0961 - val_loss: 0.0921\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0899 - val_loss: 0.0875\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0865 - val_loss: 0.0854\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0843 - val_loss: 0.0826\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0814 - val_loss: 0.0797\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0785 - val_loss: 0.0770\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0759 - val_loss: 0.0742\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0730 - val_loss: 0.0713\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0701 - val_loss: 0.0683\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0670 - val_loss: 0.0652\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0638 - val_loss: 0.0618\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0603 - val_loss: 0.0582\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0566 - val_loss: 0.0544\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0527 - val_loss: 0.0502\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0484 - val_loss: 0.0457\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0437 - val_loss: 0.0408\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0386 - val_loss: 0.0350\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0328 - val_loss: 0.0297\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0281 - val_loss: 0.0249\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0234 - val_loss: 0.0211\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0188 - val_loss: 0.0162\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0141 - val_loss: 0.0117\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0010 - val_loss: 9.8491e-04\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0010 - val_loss: 9.7745e-04\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 9.8569e-04 - val_loss: 9.3291e-04\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 9.5788e-04 - val_loss: 9.0798e-04\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 9.2967e-04 - val_loss: 8.8423e-04\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.1067e-04 - val_loss: 8.5808e-04\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.8229e-04 - val_loss: 8.3181e-04\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.5945e-04 - val_loss: 8.0706e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 8.3626e-04 - val_loss: 7.8534e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.1538e-04 - val_loss: 7.6076e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.9290e-04 - val_loss: 7.4195e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.7400e-04 - val_loss: 7.1507e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 7.4967e-04 - val_loss: 6.9364e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 7.2893e-04 - val_loss: 6.7117e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.0928e-04 - val_loss: 6.5103e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.8874e-04 - val_loss: 6.3058e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.7528e-04 - val_loss: 6.2354e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.7311e-04 - val_loss: 6.1330e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.4209e-04 - val_loss: 5.6921e-04\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 754us/step - loss: 6.2540e-04 - val_loss: 5.7061e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.0361e-04 - val_loss: 5.3232e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.8230e-04 - val_loss: 5.1434e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.6314e-04 - val_loss: 5.0454e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.4869e-04 - val_loss: 4.7710e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.2844e-04 - val_loss: 4.6345e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.1357e-04 - val_loss: 4.4341e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.9869e-04 - val_loss: 4.3476e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.8359e-04 - val_loss: 4.1155e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.6754e-04 - val_loss: 3.9868e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.5405e-04 - val_loss: 3.8285e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.3785e-04 - val_loss: 3.6674e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.2400e-04 - val_loss: 3.5386e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 4.1292e-04 - val_loss: 3.4044e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 3.9878e-04 - val_loss: 3.2554e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.8915e-04 - val_loss: 3.2207e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.8114e-04 - val_loss: 3.0636e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.6574e-04 - val_loss: 2.8887e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 3.5160e-04 - val_loss: 2.7643e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.3987e-04 - val_loss: 2.6584e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.3067e-04 - val_loss: 2.5570e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.1966e-04 - val_loss: 2.4319e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.0919e-04 - val_loss: 2.3313e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.9963e-04 - val_loss: 2.2316e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.9046e-04 - val_loss: 2.1494e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.9139e-04 - val_loss: 2.3711e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.5097e-04 - val_loss: 3.3986e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 3.5006e-04 - val_loss: 1.8973e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.8860e-04 - val_loss: 1.8576e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.6388e-04 - val_loss: 1.8580e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.5392e-04 - val_loss: 1.8441e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.4526e-04 - val_loss: 1.7718e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 810us/step - loss: 2.3755e-04 - val_loss: 1.6350e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.3038e-04 - val_loss: 1.4684e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 2.2062e-04 - val_loss: 1.3692e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 2.1206e-04 - val_loss: 1.3086e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.0540e-04 - val_loss: 1.2481e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.9975e-04 - val_loss: 1.1930e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 1.9470e-04 - val_loss: 1.1398e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 1.8948e-04 - val_loss: 1.0899e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.8601e-04 - val_loss: 1.0607e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.8048e-04 - val_loss: 1.0053e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7597e-04 - val_loss: 9.5711e-05\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.7216e-04 - val_loss: 9.1076e-05\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.7009e-04 - val_loss: 9.6511e-05\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.6877e-04 - val_loss: 8.3232e-05\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.6321e-04 - val_loss: 8.3823e-05\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.5800e-04 - val_loss: 7.8969e-05\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.5545e-04 - val_loss: 7.2918e-05\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.5009e-04 - val_loss: 6.9780e-05\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.4714e-04 - val_loss: 6.8335e-05\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.4618e-04 - val_loss: 6.4955e-05\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.4197e-04 - val_loss: 6.1313e-05\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.3881e-04 - val_loss: 5.9787e-05\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.3794e-04 - val_loss: 5.7593e-05\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 808us/step - loss: 1.3413e-04 - val_loss: 5.4235e-05\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.3311e-04 - val_loss: 5.6475e-05\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.3385e-04 - val_loss: 5.3037e-05\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.2819e-04 - val_loss: 4.8751e-05\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 1.2967e-04 - val_loss: 5.7117e-05\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.3657e-04 - val_loss: 6.1765e-05\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.4720e-04 - val_loss: 7.5422e-05\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.4124e-04 - val_loss: 4.2825e-05\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.1996e-04 - val_loss: 4.7433e-05\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2338e-04 - val_loss: 4.1156e-05\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.1563e-04 - val_loss: 4.0629e-05\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.2033e-04 - val_loss: 4.0751e-05\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.1415e-04 - val_loss: 3.3209e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.1070e-04 - val_loss: 3.5642e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.1191e-04 - val_loss: 3.3594e-05\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.0886e-04 - val_loss: 3.0869e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 1.0658e-04 - val_loss: 2.9425e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0501e-04 - val_loss: 3.1825e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.1240e-04 - val_loss: 4.4207e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2606e-04 - val_loss: 5.9664e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.3004e-04 - val_loss: 4.1495e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 812us/step - loss: 1.0678e-04 - val_loss: 2.4398e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.0121e-04 - val_loss: 2.8930e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.0237e-04 - val_loss: 2.5099e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 9.7551e-05 - val_loss: 2.2458e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.6587e-05 - val_loss: 2.2874e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 9.6501e-05 - val_loss: 2.2418e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 9.5232e-05 - val_loss: 2.0565e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 9.3276e-05 - val_loss: 2.0753e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 9.5951e-05 - val_loss: 2.9789e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 1.1397e-04 - val_loss: 6.2771e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 1.4736e-04 - val_loss: 6.9734e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 1.1130e-04 - val_loss: 2.0652e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.0613e-04 - val_loss: 3.9924e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.7765e-05 - val_loss: 1.8390e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.4385e-05 - val_loss: 2.1114e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 8.8692e-05 - val_loss: 2.0501e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 9.0869e-05 - val_loss: 1.8371e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 8.6526e-05 - val_loss: 1.6893e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 9.0472e-05 - val_loss: 2.1011e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 8.6911e-05 - val_loss: 1.4325e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.4687e-05 - val_loss: 1.8099e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.5693e-05 - val_loss: 1.4547e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 8.2277e-05 - val_loss: 1.3456e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.1440e-05 - val_loss: 1.3051e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.1203e-05 - val_loss: 1.5523e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.6308e-05 - val_loss: 2.4322e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.3475e-05 - val_loss: 3.1217e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 9.6964e-05 - val_loss: 2.6221e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.7465e-05 - val_loss: 1.3997e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 7.8580e-05 - val_loss: 1.3279e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 8.3719e-05 - val_loss: 2.6585e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 9.4602e-05 - val_loss: 2.7409e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.6578e-05 - val_loss: 1.2544e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 7.6218e-05 - val_loss: 1.2517e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.9330e-05 - val_loss: 1.7583e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 8.4581e-05 - val_loss: 2.5262e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.1055e-05 - val_loss: 2.7037e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.5374e-05 - val_loss: 1.4084e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 7.4289e-05 - val_loss: 9.6666e-06\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.2893e-05 - val_loss: 1.0939e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.3207e-05 - val_loss: 1.0265e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.2054e-05 - val_loss: 9.5035e-06\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 7.1052e-05 - val_loss: 9.0995e-06\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.0992e-05 - val_loss: 1.0105e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.3420e-05 - val_loss: 1.8797e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.3883e-05 - val_loss: 6.4645e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.5665e-04 - val_loss: 1.0682e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1547e-04 - val_loss: 1.0617e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.0672e-05 - val_loss: 2.8974e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 7.5795e-05 - val_loss: 2.2635e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 7.5831e-05 - val_loss: 8.7984e-06\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 7.1443e-05 - val_loss: 9.2117e-06\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 6.8011e-05 - val_loss: 1.2553e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 6.8359e-05 - val_loss: 7.8307e-06\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 6.7142e-05 - val_loss: 8.5167e-06\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 6.5307e-05 - val_loss: 7.7065e-06\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 6.4900e-05 - val_loss: 7.1615e-06\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 6.4569e-05 - val_loss: 8.7103e-06\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 6.4986e-05 - val_loss: 7.4706e-06\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 6.3374e-05 - val_loss: 6.9001e-06\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.2902e-05 - val_loss: 6.8109e-06\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 6.2371e-05 - val_loss: 6.8176e-06\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 6.2053e-05 - val_loss: 6.5130e-06\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 6.1523e-05 - val_loss: 6.4910e-06\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.1199e-05 - val_loss: 6.7219e-06\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.1809e-05 - val_loss: 8.3089e-06\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 6.3012e-05 - val_loss: 1.0059e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.4906e-05 - val_loss: 1.2430e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.7354e-05 - val_loss: 1.4945e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 6.6028e-05 - val_loss: 9.5706e-06\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.0859e-05 - val_loss: 6.2750e-06\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.8584e-05 - val_loss: 5.8293e-06\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 5.8066e-05 - val_loss: 5.9000e-06\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.7736e-05 - val_loss: 5.7166e-06\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.7343e-05 - val_loss: 5.9884e-06\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.7815e-05 - val_loss: 7.0581e-06\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 6.0694e-05 - val_loss: 2.0069e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.7489e-05 - val_loss: 1.2129e-04\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.2272e-04 - val_loss: 1.0885e-04\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.5578e-05 - val_loss: 7.8964e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 9.0186e-05 - val_loss: 2.8327e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.5823e-05 - val_loss: 1.1041e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.8277e-05 - val_loss: 5.5406e-06\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 6.2192e-05 - val_loss: 5.1570e-06\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.8917e-05 - val_loss: 6.3451e-06\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.6475e-05 - val_loss: 7.6920e-06\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 5.4621e-05 - val_loss: 7.2395e-06\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.3532e-05 - val_loss: 6.0405e-06\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.2886e-05 - val_loss: 4.9373e-06\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.2369e-05 - val_loss: 4.6649e-06\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 5.1823e-05 - val_loss: 4.5285e-06\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.1357e-05 - val_loss: 4.6469e-06\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.0937e-05 - val_loss: 4.4494e-06\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.0579e-05 - val_loss: 4.4030e-06\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 5.0259e-05 - val_loss: 4.3268e-06\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 4.9921e-05 - val_loss: 4.3507e-06\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.9665e-05 - val_loss: 4.2275e-06\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.9600e-05 - val_loss: 4.7672e-06\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.9314e-05 - val_loss: 4.1526e-06\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 4.8835e-05 - val_loss: 4.3405e-06\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.8421e-05 - val_loss: 4.1464e-06\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.8117e-05 - val_loss: 4.0252e-06\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.7868e-05 - val_loss: 4.4704e-06\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.7699e-05 - val_loss: 3.9680e-06\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.7174e-05 - val_loss: 3.9217e-06\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 4.6829e-05 - val_loss: 3.9250e-06\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.6586e-05 - val_loss: 3.8927e-06\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.6318e-05 - val_loss: 3.8602e-06\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.6077e-05 - val_loss: 3.9403e-06\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.6043e-05 - val_loss: 4.0599e-06\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.5437e-05 - val_loss: 3.7313e-06\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.5242e-05 - val_loss: 3.8436e-06\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.4898e-05 - val_loss: 3.6673e-06\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.4619e-05 - val_loss: 4.0845e-06\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 4.5678e-05 - val_loss: 7.4564e-06\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.1236e-05 - val_loss: 1.9626e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 7.6451e-05 - val_loss: 7.2567e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.3193e-04 - val_loss: 7.4046e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 7.0215e-05 - val_loss: 1.4620e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.7128e-05 - val_loss: 1.4444e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.7903e-05 - val_loss: 1.7558e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.1241e-05 - val_loss: 3.1207e-06\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 4.5864e-05 - val_loss: 8.8525e-06\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.3603e-05 - val_loss: 4.4477e-06\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 4.2850e-05 - val_loss: 3.2524e-06\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.1223e-05 - val_loss: 3.8899e-06\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 4.1554e-05 - val_loss: 3.1092e-06\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 4.0645e-05 - val_loss: 3.7075e-06\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 4.0819e-05 - val_loss: 2.8749e-06\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 4.0077e-05 - val_loss: 3.3284e-06\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 3.9916e-05 - val_loss: 2.7689e-06\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 3.9407e-05 - val_loss: 2.8861e-06\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 3.9275e-05 - val_loss: 2.7563e-06\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.9035e-05 - val_loss: 3.6949e-06\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.0123e-05 - val_loss: 4.7106e-06\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 4.0042e-05 - val_loss: 3.8293e-06\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.8844e-05 - val_loss: 2.8172e-06\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.7989e-05 - val_loss: 2.6550e-06\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 3.7660e-05 - val_loss: 2.6378e-06\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 3.7430e-05 - val_loss: 2.6316e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.7256e-05 - val_loss: 2.6903e-06\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 3.7142e-05 - val_loss: 3.0400e-06\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.7334e-05 - val_loss: 3.7109e-06\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.8848e-05 - val_loss: 8.1218e-06\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.2367e-05 - val_loss: 5.2868e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.5646e-04 - val_loss: 2.3328e-04\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 1.6693e-04 - val_loss: 1.1322e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 8.9877e-05 - val_loss: 9.5378e-06\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.9288e-05 - val_loss: 1.7713e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.8096e-05 - val_loss: 1.5155e-05\n",
      "Epoch 00335: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 100, 50)           10400     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100, 1)            51        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 0.0963 - val_loss: 0.0915\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0894 - val_loss: 0.0872\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0859 - val_loss: 0.0838\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0820 - val_loss: 0.0796\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0781 - val_loss: 0.0760\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0745 - val_loss: 0.0723\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0708 - val_loss: 0.0685\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0670 - val_loss: 0.0647\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0630 - val_loss: 0.0607\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0589 - val_loss: 0.0564\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0545 - val_loss: 0.0518\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0496 - val_loss: 0.0464\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0436 - val_loss: 0.0385\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0356 - val_loss: 0.0319\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0295 - val_loss: 0.0252\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0242 - val_loss: 0.0211\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0195 - val_loss: 0.0170\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0010 - val_loss: 9.7632e-04\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0010 - val_loss: 9.5061e-04\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0010 - val_loss: 9.2478e-04\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 9.7574e-04 - val_loss: 8.9886e-04\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 9.5166e-04 - val_loss: 8.7433e-04\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 9.2842e-04 - val_loss: 8.4854e-04\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 9.0459e-04 - val_loss: 8.2408e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 8.8161e-04 - val_loss: 8.0000e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.5884e-04 - val_loss: 7.7615e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.3688e-04 - val_loss: 7.5336e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.1465e-04 - val_loss: 7.2990e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.9296e-04 - val_loss: 7.0731e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 7.7197e-04 - val_loss: 6.8487e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.5113e-04 - val_loss: 6.6327e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 7.3115e-04 - val_loss: 6.4447e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.1251e-04 - val_loss: 6.2069e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 6.9138e-04 - val_loss: 6.0188e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.7293e-04 - val_loss: 5.8014e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.5306e-04 - val_loss: 5.6132e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.3687e-04 - val_loss: 5.4481e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.2175e-04 - val_loss: 5.3234e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.1941e-04 - val_loss: 5.4617e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.5656e-04 - val_loss: 6.0370e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 6.4909e-04 - val_loss: 4.7797e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 5.5679e-04 - val_loss: 4.7270e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.4281e-04 - val_loss: 4.3407e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.2407e-04 - val_loss: 4.2422e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.0262e-04 - val_loss: 4.0822e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 4.9371e-04 - val_loss: 3.8665e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 4.7105e-04 - val_loss: 3.7460e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.6086e-04 - val_loss: 3.5519e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4119e-04 - val_loss: 3.4104e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.2893e-04 - val_loss: 3.2510e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.1325e-04 - val_loss: 3.1037e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 3.9997e-04 - val_loss: 2.9654e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.8731e-04 - val_loss: 2.8375e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.7554e-04 - val_loss: 2.7173e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.6509e-04 - val_loss: 2.6485e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.6644e-04 - val_loss: 2.8751e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.2498e-04 - val_loss: 3.8642e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.5074e-04 - val_loss: 2.3639e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.4253e-04 - val_loss: 2.6214e-04\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 765us/step - loss: 3.2847e-04 - val_loss: 2.2224e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.2243e-04 - val_loss: 1.9500e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 3.0117e-04 - val_loss: 1.9762e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 2.8837e-04 - val_loss: 1.8720e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.8043e-04 - val_loss: 1.6805e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 2.6885e-04 - val_loss: 1.5955e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.6054e-04 - val_loss: 1.5354e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 2.5208e-04 - val_loss: 1.4543e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.4541e-04 - val_loss: 1.3650e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 2.3737e-04 - val_loss: 1.2964e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 2.3087e-04 - val_loss: 1.2331e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.2492e-04 - val_loss: 1.1675e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 2.1907e-04 - val_loss: 1.1224e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.1387e-04 - val_loss: 1.0494e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.0796e-04 - val_loss: 1.0048e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.0316e-04 - val_loss: 9.4259e-05\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9810e-04 - val_loss: 9.2033e-05\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9504e-04 - val_loss: 8.4956e-05\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.8876e-04 - val_loss: 8.1705e-05\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.8720e-04 - val_loss: 8.2489e-05\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.8991e-04 - val_loss: 8.7646e-05\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.9627e-04 - val_loss: 9.7145e-05\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 2.0626e-04 - val_loss: 1.0076e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.9262e-04 - val_loss: 6.6282e-05\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.6825e-04 - val_loss: 6.6160e-05\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.7457e-04 - val_loss: 7.2962e-05\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.7697e-04 - val_loss: 6.3506e-05\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.6288e-04 - val_loss: 5.0341e-05\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5499e-04 - val_loss: 4.8751e-05\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5313e-04 - val_loss: 4.5913e-05\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5072e-04 - val_loss: 4.5003e-05\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.5062e-04 - val_loss: 4.9325e-05\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.6204e-04 - val_loss: 8.1246e-05\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4326e-04 - val_loss: 2.5546e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.3234e-04 - val_loss: 4.7981e-05\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.8783e-04 - val_loss: 1.0298e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6608e-04 - val_loss: 8.2366e-05\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.5705e-04 - val_loss: 5.0847e-05\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.4873e-04 - val_loss: 3.3997e-05\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.3983e-04 - val_loss: 2.8632e-05\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.3738e-04 - val_loss: 2.7099e-05\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.3196e-04 - val_loss: 2.7179e-05\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.2885e-04 - val_loss: 2.5686e-05\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.2682e-04 - val_loss: 2.4542e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.2533e-04 - val_loss: 2.4121e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.2479e-04 - val_loss: 2.1734e-05\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2390e-04 - val_loss: 2.1502e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.2139e-04 - val_loss: 2.0064e-05\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.2007e-04 - val_loss: 1.8987e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.1889e-04 - val_loss: 1.8348e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.1786e-04 - val_loss: 1.7609e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.1694e-04 - val_loss: 1.7561e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1607e-04 - val_loss: 1.6370e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.1487e-04 - val_loss: 1.6177e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.1398e-04 - val_loss: 1.6001e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.1521e-04 - val_loss: 1.8865e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 1.1451e-04 - val_loss: 1.4849e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1128e-04 - val_loss: 1.4039e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.1038e-04 - val_loss: 1.3516e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 1.0937e-04 - val_loss: 1.3042e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 1.0860e-04 - val_loss: 1.2641e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 809us/step - loss: 1.0775e-04 - val_loss: 1.3011e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 810us/step - loss: 1.0958e-04 - val_loss: 1.7566e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.1549e-04 - val_loss: 2.5971e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.3073e-04 - val_loss: 5.7651e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.7210e-04 - val_loss: 1.1069e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.8988e-04 - val_loss: 3.7746e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.1325e-04 - val_loss: 3.3899e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.2520e-04 - val_loss: 1.6419e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.0454e-04 - val_loss: 1.7260e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 1.0773e-04 - val_loss: 1.0529e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.0085e-04 - val_loss: 1.1164e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.0084e-04 - val_loss: 8.9871e-06\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 9.8944e-05 - val_loss: 9.0995e-06\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.8232e-05 - val_loss: 8.7411e-06\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.7844e-05 - val_loss: 8.2774e-06\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 9.7263e-05 - val_loss: 1.0467e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 9.8018e-05 - val_loss: 8.3879e-06\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 9.5725e-05 - val_loss: 9.0335e-06\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.8404e-05 - val_loss: 1.5401e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.0391e-04 - val_loss: 2.1589e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1261e-04 - val_loss: 3.4715e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.2427e-04 - val_loss: 4.4477e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.2837e-04 - val_loss: 3.1011e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.0332e-04 - val_loss: 7.1757e-06\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 9.2382e-05 - val_loss: 1.1442e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.8342e-05 - val_loss: 1.7544e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 1.0019e-04 - val_loss: 1.3317e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 9.3591e-05 - val_loss: 8.3102e-06\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.0277e-05 - val_loss: 7.6646e-06\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 8.9868e-05 - val_loss: 9.2720e-06\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 9.2931e-05 - val_loss: 1.5780e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.0166e-04 - val_loss: 3.0323e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 1.2237e-04 - val_loss: 6.4680e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 1.5298e-04 - val_loss: 6.8749e-05\n",
      "Epoch 00228: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,6):\n",
    "    \n",
    "    numOfLayers = 1\n",
    "    numOfNeurons = i * 10 #np.power(2,i)\n",
    "    #[best_model,loss_history] = trainLSTM(numOfLayers, numOfNeurons)\n",
    "    [model, validatoinLoss, numOfEpochs,_] = trainLSTM(numOfLayers, numOfNeurons)\n",
    "    modelsLoss.append(validatoinLoss)# = [modelsLoss,validatoinLoss]\n",
    "    modelsEpochs.append(numOfEpochs)\n",
    "    #K.clear_session()\n",
    "    #del best_model\n",
    "    #gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the figure below, more neurons cause worse results. Hence we picked the best number of neurons from the range below 10, in which the best was 4 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Models validation loss vs. Neurons count')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Neurons count')\n",
    "plt.xticks(np.arange(5),['10','20','30','40','50'])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Depth\n",
    "In next step we try to pick the best Depth for LSTM layers from the range 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 0.1042 - val_loss: 0.1025\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.1014 - val_loss: 0.0999\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0990 - val_loss: 0.0979\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0973 - val_loss: 0.0965\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0960 - val_loss: 0.0955\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0952 - val_loss: 0.0948\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0945 - val_loss: 0.0942\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0939 - val_loss: 0.0936\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 0.0933 - val_loss: 0.0930\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0927 - val_loss: 0.0923\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 0.0920 - val_loss: 0.0917\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0914 - val_loss: 0.0911\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0908 - val_loss: 0.0905\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0903 - val_loss: 0.0900\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0897 - val_loss: 0.0894\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0891 - val_loss: 0.0888\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0885 - val_loss: 0.0882\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0880 - val_loss: 0.0877\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0874 - val_loss: 0.0871\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0868 - val_loss: 0.0865\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0863 - val_loss: 0.0860\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0857 - val_loss: 0.0854\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 808us/step - loss: 0.0851 - val_loss: 0.0848\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0845 - val_loss: 0.0842\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 0.0839 - val_loss: 0.0836\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 824us/step - loss: 0.0828 - val_loss: 0.0824\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0822 - val_loss: 0.0818\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0816 - val_loss: 0.0812\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0809 - val_loss: 0.0806\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 0.0803 - val_loss: 0.0800\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0797 - val_loss: 0.0793\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 0.0790 - val_loss: 0.0786\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 0.0784 - val_loss: 0.0780\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0777 - val_loss: 0.0773\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0770 - val_loss: 0.0766\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 804us/step - loss: 0.0763 - val_loss: 0.0759\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0755 - val_loss: 0.0751\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 0.0748 - val_loss: 0.0744\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0740 - val_loss: 0.0736\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0732 - val_loss: 0.0728\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0724 - val_loss: 0.0720\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0716 - val_loss: 0.0711\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0707 - val_loss: 0.0702\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0699 - val_loss: 0.0693\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0690 - val_loss: 0.0684\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0680 - val_loss: 0.0675\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 0.0671 - val_loss: 0.0665\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0661 - val_loss: 0.0655\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0650 - val_loss: 0.0644\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0640 - val_loss: 0.0633\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0629 - val_loss: 0.0622\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0618 - val_loss: 0.0611\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0606 - val_loss: 0.0599\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0594 - val_loss: 0.0587\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0582 - val_loss: 0.0574\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0569 - val_loss: 0.0561\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 0.0556 - val_loss: 0.0548\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 0.0542 - val_loss: 0.0534\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0528 - val_loss: 0.0520\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0514 - val_loss: 0.0505\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 0.0499 - val_loss: 0.0490\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 0.0484 - val_loss: 0.0475\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0469 - val_loss: 0.0459\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 0.0453 - val_loss: 0.0443\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0436 - val_loss: 0.0426\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0419 - val_loss: 0.0409\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0402 - val_loss: 0.0391\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0384 - val_loss: 0.0373\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0366 - val_loss: 0.0355\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0348 - val_loss: 0.0337\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0329 - val_loss: 0.0318\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0310 - val_loss: 0.0299\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0291 - val_loss: 0.0280\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0273 - val_loss: 0.0262\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 0.0256 - val_loss: 0.0245\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0239 - val_loss: 0.0229\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0224 - val_loss: 0.0215\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0209 - val_loss: 0.0201\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0196 - val_loss: 0.0188\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0183 - val_loss: 0.0176\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0171 - val_loss: 0.0164\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 0.0160 - val_loss: 0.0153\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 804us/step - loss: 0.0149 - val_loss: 0.0142\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 0.0138 - val_loss: 0.0131\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 766us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.9997e-04 - val_loss: 9.8950e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 9.8863e-04 - val_loss: 9.7784e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 9.7730e-04 - val_loss: 9.6626e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.6593e-04 - val_loss: 9.5467e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 9.5453e-04 - val_loss: 9.4298e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 9.4310e-04 - val_loss: 9.3127e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 9.3174e-04 - val_loss: 9.1969e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.2053e-04 - val_loss: 9.0833e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 9.0951e-04 - val_loss: 8.9737e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 809us/step - loss: 8.9888e-04 - val_loss: 8.8671e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 8.8862e-04 - val_loss: 8.7646e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.7869e-04 - val_loss: 8.6653e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 8.6899e-04 - val_loss: 8.5696e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.5955e-04 - val_loss: 8.4746e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 8.5034e-04 - val_loss: 8.3829e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 8.4134e-04 - val_loss: 8.2929e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 8.3252e-04 - val_loss: 8.2056e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 8.2390e-04 - val_loss: 8.1194e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 8.1548e-04 - val_loss: 8.0352e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 8.0723e-04 - val_loss: 7.9528e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.9914e-04 - val_loss: 7.8722e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 7.9123e-04 - val_loss: 7.7919e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 7.8342e-04 - val_loss: 7.7137e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.7576e-04 - val_loss: 7.6370e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.6822e-04 - val_loss: 7.5609e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 7.6081e-04 - val_loss: 7.4858e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 7.5345e-04 - val_loss: 7.4116e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 807us/step - loss: 7.4619e-04 - val_loss: 7.3380e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.3903e-04 - val_loss: 7.2655e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.3196e-04 - val_loss: 7.1937e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 7.2498e-04 - val_loss: 7.1229e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.1810e-04 - val_loss: 7.0532e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.1130e-04 - val_loss: 6.9840e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 7.0461e-04 - val_loss: 6.9157e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 6.9800e-04 - val_loss: 6.8486e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.9143e-04 - val_loss: 6.7810e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 6.8495e-04 - val_loss: 6.7152e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.7858e-04 - val_loss: 6.6512e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 6.7229e-04 - val_loss: 6.5850e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.6603e-04 - val_loss: 6.5218e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.5985e-04 - val_loss: 6.4585e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.5370e-04 - val_loss: 6.3952e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.4761e-04 - val_loss: 6.3328e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.4163e-04 - val_loss: 6.2711e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.3569e-04 - val_loss: 6.2098e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 6.2980e-04 - val_loss: 6.1494e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 6.2397e-04 - val_loss: 6.0894e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 6.1821e-04 - val_loss: 6.0298e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.1249e-04 - val_loss: 5.9713e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 6.0683e-04 - val_loss: 5.9123e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.0122e-04 - val_loss: 5.8543e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.9566e-04 - val_loss: 5.7966e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.9012e-04 - val_loss: 5.7393e-04\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.8465e-04 - val_loss: 5.6818e-04\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.7913e-04 - val_loss: 5.6249e-04\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.7367e-04 - val_loss: 5.5679e-04\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.6824e-04 - val_loss: 5.5112e-04\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.6284e-04 - val_loss: 5.4550e-04\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 5.5749e-04 - val_loss: 5.3989e-04\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.5215e-04 - val_loss: 5.3433e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 5.4689e-04 - val_loss: 5.2881e-04\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 5.4161e-04 - val_loss: 5.2334e-04\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.3642e-04 - val_loss: 5.1791e-04\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.3125e-04 - val_loss: 5.1248e-04\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.2612e-04 - val_loss: 5.0711e-04\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 5.2104e-04 - val_loss: 5.0178e-04\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.1596e-04 - val_loss: 4.9647e-04\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 5.1093e-04 - val_loss: 4.9120e-04\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.0598e-04 - val_loss: 4.8595e-04\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.0099e-04 - val_loss: 4.8072e-04\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.9605e-04 - val_loss: 4.7552e-04\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.9107e-04 - val_loss: 4.7026e-04\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.8609e-04 - val_loss: 4.6498e-04\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 4.8110e-04 - val_loss: 4.5970e-04\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.7611e-04 - val_loss: 4.5447e-04\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 739us/step - loss: 4.7115e-04 - val_loss: 4.4928e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.6625e-04 - val_loss: 4.4405e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.6135e-04 - val_loss: 4.3888e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.5646e-04 - val_loss: 4.3374e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.5164e-04 - val_loss: 4.2866e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4682e-04 - val_loss: 4.2355e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.4204e-04 - val_loss: 4.1850e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.3730e-04 - val_loss: 4.1348e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.3255e-04 - val_loss: 4.0843e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.2781e-04 - val_loss: 4.0329e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.2296e-04 - val_loss: 3.9816e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 4.1816e-04 - val_loss: 3.9306e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 4.1335e-04 - val_loss: 3.8796e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.0860e-04 - val_loss: 3.8285e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 4.0385e-04 - val_loss: 3.7778e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.9912e-04 - val_loss: 3.7277e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.9444e-04 - val_loss: 3.6776e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.8978e-04 - val_loss: 3.6279e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.8514e-04 - val_loss: 3.5786e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 3.8056e-04 - val_loss: 3.5294e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.7600e-04 - val_loss: 3.4805e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.7145e-04 - val_loss: 3.4321e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.6694e-04 - val_loss: 3.3839e-04\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.6247e-04 - val_loss: 3.3361e-04\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 3.5803e-04 - val_loss: 3.2886e-04\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.5364e-04 - val_loss: 3.2412e-04\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 3.4925e-04 - val_loss: 3.1942e-04\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 3.4487e-04 - val_loss: 3.1479e-04\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 3.4059e-04 - val_loss: 3.1015e-04\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 3.3632e-04 - val_loss: 3.0557e-04\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 3.3210e-04 - val_loss: 3.0103e-04\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 811us/step - loss: 3.2792e-04 - val_loss: 2.9655e-04\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 3.2378e-04 - val_loss: 2.9211e-04\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 3.1968e-04 - val_loss: 2.8770e-04\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 3.1561e-04 - val_loss: 2.8333e-04\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.1158e-04 - val_loss: 2.7899e-04\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 3.0757e-04 - val_loss: 2.7471e-04\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 3.0362e-04 - val_loss: 2.7045e-04\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 2.9971e-04 - val_loss: 2.6622e-04\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.9580e-04 - val_loss: 2.6205e-04\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.9196e-04 - val_loss: 2.5791e-04\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.8813e-04 - val_loss: 2.5382e-04\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 816us/step - loss: 2.8437e-04 - val_loss: 2.4975e-04\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.8062e-04 - val_loss: 2.4571e-04\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 2.7690e-04 - val_loss: 2.4169e-04\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 2.7320e-04 - val_loss: 2.3769e-04\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 821us/step - loss: 2.6953e-04 - val_loss: 2.3370e-04\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 2.6587e-04 - val_loss: 2.2977e-04\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 2.6227e-04 - val_loss: 2.2589e-04\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 2.5873e-04 - val_loss: 2.2209e-04\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 2.5523e-04 - val_loss: 2.1835e-04\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 2.5180e-04 - val_loss: 2.1465e-04\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 2.4839e-04 - val_loss: 2.1101e-04\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 2.4506e-04 - val_loss: 2.0738e-04\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.4172e-04 - val_loss: 2.0382e-04\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 2.3845e-04 - val_loss: 2.0029e-04\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 2.3521e-04 - val_loss: 1.9680e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.3198e-04 - val_loss: 1.9337e-04\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.2882e-04 - val_loss: 1.8997e-04\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 2.2569e-04 - val_loss: 1.8661e-04\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2259e-04 - val_loss: 1.8330e-04\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.1954e-04 - val_loss: 1.8002e-04\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 2.1653e-04 - val_loss: 1.7679e-04\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.1355e-04 - val_loss: 1.7359e-04\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.1061e-04 - val_loss: 1.7044e-04\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.0771e-04 - val_loss: 1.6731e-04\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.0482e-04 - val_loss: 1.6425e-04\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.0200e-04 - val_loss: 1.6123e-04\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.9921e-04 - val_loss: 1.5824e-04\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.9646e-04 - val_loss: 1.5528e-04\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.9373e-04 - val_loss: 1.5238e-04\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.9106e-04 - val_loss: 1.4952e-04\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.8841e-04 - val_loss: 1.4670e-04\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.8582e-04 - val_loss: 1.4392e-04\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.8325e-04 - val_loss: 1.4117e-04\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.8073e-04 - val_loss: 1.3848e-04\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.7823e-04 - val_loss: 1.3582e-04\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.7579e-04 - val_loss: 1.3319e-04\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.7336e-04 - val_loss: 1.3060e-04\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.7097e-04 - val_loss: 1.2809e-04\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.6866e-04 - val_loss: 1.2562e-04\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.6637e-04 - val_loss: 1.2320e-04\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.6414e-04 - val_loss: 1.2082e-04\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.6192e-04 - val_loss: 1.1848e-04\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.5977e-04 - val_loss: 1.1617e-04\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5762e-04 - val_loss: 1.1391e-04\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.5552e-04 - val_loss: 1.1167e-04\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.5344e-04 - val_loss: 1.0948e-04\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.5139e-04 - val_loss: 1.0729e-04\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.4936e-04 - val_loss: 1.0514e-04\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4734e-04 - val_loss: 1.0302e-04\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.4537e-04 - val_loss: 1.0092e-04\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.4341e-04 - val_loss: 9.8871e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.4149e-04 - val_loss: 9.6837e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.3961e-04 - val_loss: 9.4845e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.3775e-04 - val_loss: 9.2905e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.3592e-04 - val_loss: 9.1017e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 801us/step - loss: 1.3415e-04 - val_loss: 8.9139e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.3241e-04 - val_loss: 8.7343e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 1.3074e-04 - val_loss: 8.5632e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.2914e-04 - val_loss: 8.3976e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.2760e-04 - val_loss: 8.2351e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.2606e-04 - val_loss: 8.0729e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.2456e-04 - val_loss: 7.9142e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.2309e-04 - val_loss: 7.7602e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.2165e-04 - val_loss: 7.6082e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.2024e-04 - val_loss: 7.4604e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.1886e-04 - val_loss: 7.3148e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.1750e-04 - val_loss: 7.1714e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.1617e-04 - val_loss: 7.0322e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 1.1486e-04 - val_loss: 6.8952e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1358e-04 - val_loss: 6.7613e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.1232e-04 - val_loss: 6.6303e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.1109e-04 - val_loss: 6.5005e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 1.0989e-04 - val_loss: 6.3736e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.0870e-04 - val_loss: 6.2513e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.0754e-04 - val_loss: 6.1318e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.0640e-04 - val_loss: 6.0119e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.0528e-04 - val_loss: 5.8975e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.0419e-04 - val_loss: 5.7837e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.0312e-04 - val_loss: 5.6722e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.0207e-04 - val_loss: 5.5647e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.0104e-04 - val_loss: 5.4589e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.0004e-04 - val_loss: 5.3554e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.9043e-05 - val_loss: 5.2528e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 9.8069e-05 - val_loss: 5.1536e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 9.7120e-05 - val_loss: 5.0575e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 9.6195e-05 - val_loss: 4.9650e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 9.5302e-05 - val_loss: 4.8732e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 9.4423e-05 - val_loss: 4.7855e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 9.3572e-05 - val_loss: 4.6994e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 9.2731e-05 - val_loss: 4.6157e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 9.1910e-05 - val_loss: 4.5347e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 814us/step - loss: 9.1105e-05 - val_loss: 4.4560e-05\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 9.0317e-05 - val_loss: 4.3771e-05\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 8.9544e-05 - val_loss: 4.3001e-05\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 8.8781e-05 - val_loss: 4.2259e-05\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.8039e-05 - val_loss: 4.1519e-05\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.7314e-05 - val_loss: 4.0812e-05\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 8.6591e-05 - val_loss: 4.0134e-05\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.5891e-05 - val_loss: 3.9429e-05\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 8.5199e-05 - val_loss: 3.8766e-05\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 8.4512e-05 - val_loss: 3.8137e-05\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 8.3849e-05 - val_loss: 3.7463e-05\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 8.3190e-05 - val_loss: 3.6840e-05\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.2546e-05 - val_loss: 3.6231e-05\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 8.1913e-05 - val_loss: 3.5625e-05\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.1292e-05 - val_loss: 3.5044e-05\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0683e-05 - val_loss: 3.4477e-05\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 8.0084e-05 - val_loss: 3.3921e-05\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 7.9493e-05 - val_loss: 3.3376e-05\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.8920e-05 - val_loss: 3.2842e-05\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.8352e-05 - val_loss: 3.2332e-05\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 7.7784e-05 - val_loss: 3.1796e-05\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.7230e-05 - val_loss: 3.1298e-05\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.6681e-05 - val_loss: 3.0821e-05\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.6140e-05 - val_loss: 3.0318e-05\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 7.5613e-05 - val_loss: 2.9846e-05\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.5088e-05 - val_loss: 2.9397e-05\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.4574e-05 - val_loss: 2.8920e-05\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 7.4072e-05 - val_loss: 2.8479e-05\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 774us/step - loss: 7.3575e-05 - val_loss: 2.8062e-05\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 7.3078e-05 - val_loss: 2.7626e-05\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 7.2600e-05 - val_loss: 2.7216e-05\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 7.2118e-05 - val_loss: 2.6811e-05\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 7.1647e-05 - val_loss: 2.6396e-05\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.1189e-05 - val_loss: 2.6004e-05\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 7.0735e-05 - val_loss: 2.5631e-05\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 7.0284e-05 - val_loss: 2.5241e-05\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.9840e-05 - val_loss: 2.4870e-05\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.9407e-05 - val_loss: 2.4511e-05\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 6.8981e-05 - val_loss: 2.4165e-05\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.8554e-05 - val_loss: 2.3823e-05\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.8136e-05 - val_loss: 2.3483e-05\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.7719e-05 - val_loss: 2.3147e-05\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.7310e-05 - val_loss: 2.2824e-05\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.6905e-05 - val_loss: 2.2505e-05\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.6512e-05 - val_loss: 2.2194e-05\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.6116e-05 - val_loss: 2.1900e-05\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 6.5728e-05 - val_loss: 2.1582e-05\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.5346e-05 - val_loss: 2.1291e-05\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.4964e-05 - val_loss: 2.1010e-05\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 6.4591e-05 - val_loss: 2.0717e-05\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.4218e-05 - val_loss: 2.0435e-05\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 6.3863e-05 - val_loss: 2.0173e-05\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.3500e-05 - val_loss: 1.9914e-05\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 6.3144e-05 - val_loss: 1.9651e-05\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 6.2792e-05 - val_loss: 1.9398e-05\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.2442e-05 - val_loss: 1.9141e-05\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.2107e-05 - val_loss: 1.8889e-05\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.1773e-05 - val_loss: 1.8666e-05\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.1431e-05 - val_loss: 1.8431e-05\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.1097e-05 - val_loss: 1.8193e-05\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 6.0766e-05 - val_loss: 1.7964e-05\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.0449e-05 - val_loss: 1.7737e-05\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 6.0130e-05 - val_loss: 1.7524e-05\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.9811e-05 - val_loss: 1.7318e-05\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 5.9494e-05 - val_loss: 1.7094e-05\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.9188e-05 - val_loss: 1.6886e-05\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.8883e-05 - val_loss: 1.6700e-05\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 5.8580e-05 - val_loss: 1.6493e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.8278e-05 - val_loss: 1.6301e-05\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 5.7974e-05 - val_loss: 1.6110e-05\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.7687e-05 - val_loss: 1.5907e-05\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.7400e-05 - val_loss: 1.5737e-05\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.7109e-05 - val_loss: 1.5574e-05\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 5.6817e-05 - val_loss: 1.5387e-05\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.6534e-05 - val_loss: 1.5208e-05\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.6247e-05 - val_loss: 1.5031e-05\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.5973e-05 - val_loss: 1.4861e-05\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 5.5704e-05 - val_loss: 1.4701e-05\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.5432e-05 - val_loss: 1.4545e-05\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.5154e-05 - val_loss: 1.4380e-05\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 5.4890e-05 - val_loss: 1.4222e-05\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 5.4622e-05 - val_loss: 1.4077e-05\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 5.4359e-05 - val_loss: 1.3915e-05\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 5.4105e-05 - val_loss: 1.3775e-05\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.3845e-05 - val_loss: 1.3640e-05\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 5.3588e-05 - val_loss: 1.3492e-05\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.3330e-05 - val_loss: 1.3350e-05\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.3081e-05 - val_loss: 1.3219e-05\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 5.2821e-05 - val_loss: 1.3072e-05\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.2575e-05 - val_loss: 1.2937e-05\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 5.2329e-05 - val_loss: 1.2802e-05\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.2093e-05 - val_loss: 1.2676e-05\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.1855e-05 - val_loss: 1.2553e-05\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.1614e-05 - val_loss: 1.2431e-05\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 5.1388e-05 - val_loss: 1.2312e-05\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.1151e-05 - val_loss: 1.2199e-05\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.0924e-05 - val_loss: 1.2087e-05\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.0691e-05 - val_loss: 1.1974e-05\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 5.0468e-05 - val_loss: 1.1860e-05\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 5.0242e-05 - val_loss: 1.1756e-05\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.0023e-05 - val_loss: 1.1655e-05\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.9801e-05 - val_loss: 1.1555e-05\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 4.9574e-05 - val_loss: 1.1458e-05\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.9353e-05 - val_loss: 1.1336e-05\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.9145e-05 - val_loss: 1.1241e-05\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.8924e-05 - val_loss: 1.1149e-05\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.8711e-05 - val_loss: 1.1055e-05\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.8492e-05 - val_loss: 1.0949e-05\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.8282e-05 - val_loss: 1.0855e-05\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.8074e-05 - val_loss: 1.0767e-05\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.7863e-05 - val_loss: 1.0678e-05\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.7656e-05 - val_loss: 1.0585e-05\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.7448e-05 - val_loss: 1.0495e-05\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.7241e-05 - val_loss: 1.0406e-05\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.7036e-05 - val_loss: 1.0317e-05\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.6836e-05 - val_loss: 1.0228e-05\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 4.6631e-05 - val_loss: 1.0139e-05\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.6436e-05 - val_loss: 1.0061e-05\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 4.6235e-05 - val_loss: 9.9785e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.6040e-05 - val_loss: 9.8995e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.5840e-05 - val_loss: 9.8205e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.5644e-05 - val_loss: 9.7421e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 4.5448e-05 - val_loss: 9.6590e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.5259e-05 - val_loss: 9.5846e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.5068e-05 - val_loss: 9.5162e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.4875e-05 - val_loss: 9.4399e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.4681e-05 - val_loss: 9.3681e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.4500e-05 - val_loss: 9.2909e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4314e-05 - val_loss: 9.2234e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 4.4125e-05 - val_loss: 9.1691e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 4.3933e-05 - val_loss: 9.0769e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 4.3747e-05 - val_loss: 9.0042e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 4.3570e-05 - val_loss: 8.9421e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 4.3378e-05 - val_loss: 8.8704e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.3198e-05 - val_loss: 8.8032e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.3012e-05 - val_loss: 8.7326e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 4.2833e-05 - val_loss: 8.6670e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.2655e-05 - val_loss: 8.6010e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 4.2475e-05 - val_loss: 8.5405e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 836us/step - loss: 4.2294e-05 - val_loss: 8.4719e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.2112e-05 - val_loss: 8.4072e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 4.0624e-0 - 1s 782us/step - loss: 4.1943e-05 - val_loss: 8.3379e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.1772e-05 - val_loss: 8.2828e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 4.1589e-05 - val_loss: 8.2310e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 4.1418e-05 - val_loss: 8.1553e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 4.1253e-05 - val_loss: 8.1016e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 4.1083e-05 - val_loss: 8.0584e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.0901e-05 - val_loss: 7.9940e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.0730e-05 - val_loss: 7.9242e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.0569e-05 - val_loss: 7.8758e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.0396e-05 - val_loss: 7.8256e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0220e-05 - val_loss: 7.7650e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 4.0057e-05 - val_loss: 7.7014e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.9890e-05 - val_loss: 7.6485e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.9726e-05 - val_loss: 7.6041e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.9557e-05 - val_loss: 7.5383e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.9393e-05 - val_loss: 7.4876e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 3.9232e-05 - val_loss: 7.4322e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.9067e-05 - val_loss: 7.3798e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 3.8909e-05 - val_loss: 7.3294e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 3.8746e-05 - val_loss: 7.2846e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.8587e-05 - val_loss: 7.2298e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.8424e-05 - val_loss: 7.1731e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 3.8277e-05 - val_loss: 7.1365e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.8116e-05 - val_loss: 7.1013e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.7958e-05 - val_loss: 7.0472e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 3.7795e-05 - val_loss: 6.9952e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.7637e-05 - val_loss: 6.9481e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 3.7481e-05 - val_loss: 6.9038e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 3.7332e-05 - val_loss: 6.8553e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.7186e-05 - val_loss: 6.8147e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 3.7023e-05 - val_loss: 6.7692e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.6871e-05 - val_loss: 6.7258e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 3.6712e-05 - val_loss: 6.6757e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.6566e-05 - val_loss: 6.6281e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.6412e-05 - val_loss: 6.5857e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.6264e-05 - val_loss: 6.5456e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 3.6116e-05 - val_loss: 6.5031e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 3.5966e-05 - val_loss: 6.4566e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 3.5823e-05 - val_loss: 6.4225e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 3.5669e-05 - val_loss: 6.3845e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.5522e-05 - val_loss: 6.3427e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 3.5377e-05 - val_loss: 6.3007e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.5224e-05 - val_loss: 6.2558e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.5085e-05 - val_loss: 6.2164e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.4940e-05 - val_loss: 6.1783e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 3.4797e-05 - val_loss: 6.1442e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 3.4654e-05 - val_loss: 6.1064e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 3.4507e-05 - val_loss: 6.0714e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.4368e-05 - val_loss: 6.0272e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.4221e-05 - val_loss: 6.0009e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 3.4084e-05 - val_loss: 5.9480e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.3943e-05 - val_loss: 5.9073e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 3.3803e-05 - val_loss: 5.8735e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 3.3668e-05 - val_loss: 5.8486e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 3.3519e-05 - val_loss: 5.8076e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 3.3388e-05 - val_loss: 5.7763e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.3240e-05 - val_loss: 5.7423e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.3109e-05 - val_loss: 5.7048e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 3.2975e-05 - val_loss: 5.6663e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.2833e-05 - val_loss: 5.6326e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.2700e-05 - val_loss: 5.6034e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.2565e-05 - val_loss: 5.5718e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.2427e-05 - val_loss: 5.5387e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 3.2289e-05 - val_loss: 5.5080e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 3.2164e-05 - val_loss: 5.4690e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.2026e-05 - val_loss: 5.4378e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 3.1890e-05 - val_loss: 5.4026e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 3.1761e-05 - val_loss: 5.3742e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 3.1627e-05 - val_loss: 5.3424e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 3.1498e-05 - val_loss: 5.3088e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 3.1368e-05 - val_loss: 5.2808e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 3.1243e-05 - val_loss: 5.2557e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.1105e-05 - val_loss: 5.2428e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 3.0976e-05 - val_loss: 5.1892e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 3.0847e-05 - val_loss: 5.1492e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 813us/step - loss: 3.0719e-05 - val_loss: 5.1219e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 3.0593e-05 - val_loss: 5.1017e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 805us/step - loss: 3.0455e-05 - val_loss: 5.0654e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 3.0336e-05 - val_loss: 5.0352e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 3.0205e-05 - val_loss: 5.0086e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 3.0081e-05 - val_loss: 4.9818e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.9950e-05 - val_loss: 4.9576e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 820us/step - loss: 2.9830e-05 - val_loss: 4.9237e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.9705e-05 - val_loss: 4.8983e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 2.9576e-05 - val_loss: 4.8681e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 2.9456e-05 - val_loss: 4.8474e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.9330e-05 - val_loss: 4.8213e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.9209e-05 - val_loss: 4.7890e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.9087e-05 - val_loss: 4.7634e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.8963e-05 - val_loss: 4.7368e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.8840e-05 - val_loss: 4.7144e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.8716e-05 - val_loss: 4.6837e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.8600e-05 - val_loss: 4.6558e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.8476e-05 - val_loss: 4.6304e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.8356e-05 - val_loss: 4.6104e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.8241e-05 - val_loss: 4.5782e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.8120e-05 - val_loss: 4.5564e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.7997e-05 - val_loss: 4.5276e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.7887e-05 - val_loss: 4.5116e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.7762e-05 - val_loss: 4.4867e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.7648e-05 - val_loss: 4.4631e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.7526e-05 - val_loss: 4.4358e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 2.7413e-05 - val_loss: 4.4142e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.7295e-05 - val_loss: 4.3897e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.7183e-05 - val_loss: 4.3729e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.7059e-05 - val_loss: 4.3478e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.6947e-05 - val_loss: 4.3205e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.6834e-05 - val_loss: 4.2922e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 2.6716e-05 - val_loss: 4.2689e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 737us/step - loss: 2.6602e-05 - val_loss: 4.2486e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.6487e-05 - val_loss: 4.2238e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.6377e-05 - val_loss: 4.2023e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.6267e-05 - val_loss: 4.1856e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 2.6153e-05 - val_loss: 4.1670e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.6040e-05 - val_loss: 4.1556e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.5929e-05 - val_loss: 4.1199e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.5815e-05 - val_loss: 4.0993e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.5705e-05 - val_loss: 4.0747e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 2.5591e-05 - val_loss: 4.0613e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.5483e-05 - val_loss: 4.0359e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 2.5376e-05 - val_loss: 4.0138e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.5257e-05 - val_loss: 3.9843e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.5156e-05 - val_loss: 3.9701e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.5043e-05 - val_loss: 3.9586e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.4936e-05 - val_loss: 3.9262e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.4826e-05 - val_loss: 3.9009e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.4719e-05 - val_loss: 3.8849e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.4610e-05 - val_loss: 3.8686e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 2.4505e-05 - val_loss: 3.8481e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 745us/step - loss: 2.4398e-05 - val_loss: 3.8252e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 2.4292e-05 - val_loss: 3.8079e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 2.4184e-05 - val_loss: 3.7911e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.4080e-05 - val_loss: 3.7776e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 2.3977e-05 - val_loss: 3.7529e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.3867e-05 - val_loss: 3.7296e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 741us/step - loss: 2.3763e-05 - val_loss: 3.7095e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.3658e-05 - val_loss: 3.6911e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.3555e-05 - val_loss: 3.6731e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.3450e-05 - val_loss: 3.6563e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 2.3350e-05 - val_loss: 3.6411e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3240e-05 - val_loss: 3.6179e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 2.3144e-05 - val_loss: 3.6016e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.3035e-05 - val_loss: 3.5763e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 2.2938e-05 - val_loss: 3.5577e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.2839e-05 - val_loss: 3.5451e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 2.2737e-05 - val_loss: 3.5301e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2631e-05 - val_loss: 3.5112e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 2.2532e-05 - val_loss: 3.4948e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.2432e-05 - val_loss: 3.4785e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 2.2331e-05 - val_loss: 3.4604e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.2231e-05 - val_loss: 3.4439e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 2.2134e-05 - val_loss: 3.4243e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 2.2042e-05 - val_loss: 3.4102e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 2.1941e-05 - val_loss: 3.3961e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 2.1837e-05 - val_loss: 3.3678e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.1739e-05 - val_loss: 3.3650e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 2.1647e-05 - val_loss: 3.3425e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 2.1543e-05 - val_loss: 3.3186e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 2.1448e-05 - val_loss: 3.3017e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 2.1350e-05 - val_loss: 3.2846e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 2.1255e-05 - val_loss: 3.2731e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 2.1161e-05 - val_loss: 3.2586e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.1061e-05 - val_loss: 3.2388e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 2.0964e-05 - val_loss: 3.2221e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 2.0871e-05 - val_loss: 3.2077e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 2.0776e-05 - val_loss: 3.1933e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 2.0683e-05 - val_loss: 3.1768e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 789us/step - loss: 2.0584e-05 - val_loss: 3.1573e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 810us/step - loss: 2.0495e-05 - val_loss: 3.1433e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 2.0400e-05 - val_loss: 3.1286e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 2.0306e-05 - val_loss: 3.1117e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 817us/step - loss: 2.0215e-05 - val_loss: 3.0989e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 2.0120e-05 - val_loss: 3.0842e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 2.0031e-05 - val_loss: 3.0729e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.9938e-05 - val_loss: 3.0581e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.9846e-05 - val_loss: 3.0426e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9752e-05 - val_loss: 3.0271e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.9661e-05 - val_loss: 3.0129e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.9573e-05 - val_loss: 2.9990e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 1.9482e-05 - val_loss: 2.9794e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9395e-05 - val_loss: 2.9675e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.9301e-05 - val_loss: 2.9506e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 1.9212e-05 - val_loss: 2.9394e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.9124e-05 - val_loss: 2.9284e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.9035e-05 - val_loss: 2.9115e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.8948e-05 - val_loss: 2.8964e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.8857e-05 - val_loss: 2.8815e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.8771e-05 - val_loss: 2.8676e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.8683e-05 - val_loss: 2.8539e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.8593e-05 - val_loss: 2.8388e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 744us/step - loss: 1.8512e-05 - val_loss: 2.8292e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.8422e-05 - val_loss: 2.8153e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.8335e-05 - val_loss: 2.7980e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.8253e-05 - val_loss: 2.7912e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.8165e-05 - val_loss: 2.7851e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 1.8080e-05 - val_loss: 2.7592e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.7991e-05 - val_loss: 2.7438e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.7908e-05 - val_loss: 2.7268e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.7819e-05 - val_loss: 2.7134e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.7738e-05 - val_loss: 2.7043e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.7657e-05 - val_loss: 2.6954e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.7571e-05 - val_loss: 2.6779e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.7486e-05 - val_loss: 2.6613e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.7407e-05 - val_loss: 2.6518e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.7322e-05 - val_loss: 2.6420e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.7237e-05 - val_loss: 2.6269e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.7157e-05 - val_loss: 2.6187e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.7075e-05 - val_loss: 2.6056e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.6993e-05 - val_loss: 2.5934e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 749us/step - loss: 1.6909e-05 - val_loss: 2.5798e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.6830e-05 - val_loss: 2.5687e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.6748e-05 - val_loss: 2.5551e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.6669e-05 - val_loss: 2.5422e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.6587e-05 - val_loss: 2.5284e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 1.6508e-05 - val_loss: 2.5167e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.6430e-05 - val_loss: 2.5097e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.6349e-05 - val_loss: 2.4971e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 1.6268e-05 - val_loss: 2.4814e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.6191e-05 - val_loss: 2.4682e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.6109e-05 - val_loss: 2.4525e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.6034e-05 - val_loss: 2.4426e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 1.5956e-05 - val_loss: 2.4304e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 1.5880e-05 - val_loss: 2.4247e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 790us/step - loss: 1.5802e-05 - val_loss: 2.4116e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 888us/step - loss: 1.5729e-05 - val_loss: 2.4012e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 1.5647e-05 - val_loss: 2.3888e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.5571e-05 - val_loss: 2.3755e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 1.5492e-05 - val_loss: 2.3610e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.5417e-05 - val_loss: 2.3506e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.5344e-05 - val_loss: 2.3419e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.5269e-05 - val_loss: 2.3356e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.5194e-05 - val_loss: 2.3272e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.5120e-05 - val_loss: 2.3147e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 786us/step - loss: 1.5044e-05 - val_loss: 2.2962e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4969e-05 - val_loss: 2.2842e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.4897e-05 - val_loss: 2.2773e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4827e-05 - val_loss: 2.2708e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.4747e-05 - val_loss: 2.2566e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 743us/step - loss: 1.4674e-05 - val_loss: 2.2462e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.4605e-05 - val_loss: 2.2397e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 1.4529e-05 - val_loss: 2.2262e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.4454e-05 - val_loss: 2.2100e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.4383e-05 - val_loss: 2.1982e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.4313e-05 - val_loss: 2.1910e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.4242e-05 - val_loss: 2.1809e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 1.4169e-05 - val_loss: 2.1664e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 1.4098e-05 - val_loss: 2.1563e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 1.4028e-05 - val_loss: 2.1488e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.3961e-05 - val_loss: 2.1397e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3888e-05 - val_loss: 2.1267e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.3820e-05 - val_loss: 2.1169e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.3749e-05 - val_loss: 2.1070e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.3679e-05 - val_loss: 2.0951e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.3610e-05 - val_loss: 2.0875e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 1.3543e-05 - val_loss: 2.0798e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.3475e-05 - val_loss: 2.0695e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 1.3404e-05 - val_loss: 2.0607e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 787us/step - loss: 1.3338e-05 - val_loss: 2.0507e-06\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 792us/step - loss: 1.3268e-05 - val_loss: 2.0407e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 742us/step - loss: 1.3200e-05 - val_loss: 2.0278e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.3136e-05 - val_loss: 2.0227e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 1.3072e-05 - val_loss: 2.0176e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.3003e-05 - val_loss: 2.0058e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.2935e-05 - val_loss: 2.0003e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2874e-05 - val_loss: 1.9901e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 1.2808e-05 - val_loss: 1.9771e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.2740e-05 - val_loss: 1.9651e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.2679e-05 - val_loss: 1.9576e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.2614e-05 - val_loss: 1.9522e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 1.2553e-05 - val_loss: 1.9450e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.2486e-05 - val_loss: 1.9329e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2426e-05 - val_loss: 1.9308e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 1.2361e-05 - val_loss: 1.9204e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 1.2300e-05 - val_loss: 1.9152e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2236e-05 - val_loss: 1.9084e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 1.2176e-05 - val_loss: 1.9006e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.2114e-05 - val_loss: 1.8941e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.2051e-05 - val_loss: 1.8812e-06\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1990e-05 - val_loss: 1.8740e-06\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.1931e-05 - val_loss: 1.8683e-06\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.1869e-05 - val_loss: 1.8584e-06\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.1811e-05 - val_loss: 1.8548e-06\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 1.1749e-05 - val_loss: 1.8452e-06\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 1.1694e-05 - val_loss: 1.8409e-06\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1627e-05 - val_loss: 1.8269e-06\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 1.1571e-05 - val_loss: 1.8234e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.1513e-05 - val_loss: 1.8167e-06\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.1452e-05 - val_loss: 1.8054e-06\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 1.1392e-05 - val_loss: 1.7965e-06\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1334e-05 - val_loss: 1.7908e-06\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 1.1281e-05 - val_loss: 1.7902e-06\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.1222e-05 - val_loss: 1.7810e-06\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 1.1162e-05 - val_loss: 1.7698e-06\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1106e-05 - val_loss: 1.7654e-06\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.1048e-05 - val_loss: 1.7577e-06\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.0992e-05 - val_loss: 1.7509e-06\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 1.0935e-05 - val_loss: 1.7418e-06\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.0880e-05 - val_loss: 1.7352e-06\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0825e-05 - val_loss: 1.7291e-06\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 1.0769e-05 - val_loss: 1.7246e-06\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0713e-05 - val_loss: 1.7179e-06\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0655e-05 - val_loss: 1.7086e-06\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 1.0602e-05 - val_loss: 1.7031e-06\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 1.0547e-05 - val_loss: 1.6937e-06\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 1.0494e-05 - val_loss: 1.6878e-06\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 1.0439e-05 - val_loss: 1.6812e-06\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 1.0382e-05 - val_loss: 1.6723e-06\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 1.0331e-05 - val_loss: 1.6676e-06\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 1.0275e-05 - val_loss: 1.6601e-06\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 1.0225e-05 - val_loss: 1.6556e-06\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 1.0169e-05 - val_loss: 1.6466e-06\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 1.0115e-05 - val_loss: 1.6376e-06\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 1.0063e-05 - val_loss: 1.6270e-06\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 1.0012e-05 - val_loss: 1.6222e-06\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.9601e-06 - val_loss: 1.6162e-06\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.9096e-06 - val_loss: 1.6122e-06\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 9.8593e-06 - val_loss: 1.6053e-06\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.8042e-06 - val_loss: 1.5981e-06\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 9.7539e-06 - val_loss: 1.5910e-06\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 9.7038e-06 - val_loss: 1.5840e-06\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 9.6513e-06 - val_loss: 1.5773e-06\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 9.6020e-06 - val_loss: 1.5726e-06\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 9.5501e-06 - val_loss: 1.5671e-06\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 9.5009e-06 - val_loss: 1.5681e-06\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 9.4527e-06 - val_loss: 1.5543e-06\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.4040e-06 - val_loss: 1.5513e-06\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 9.3530e-06 - val_loss: 1.5433e-06\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 9.3026e-06 - val_loss: 1.5341e-06\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 9.2543e-06 - val_loss: 1.5278e-06\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 9.2058e-06 - val_loss: 1.5216e-06\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 9.1587e-06 - val_loss: 1.5150e-06\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 9.1103e-06 - val_loss: 1.5096e-06\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 9.0640e-06 - val_loss: 1.5030e-06\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 9.0163e-06 - val_loss: 1.4980e-06\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 8.9686e-06 - val_loss: 1.4895e-06\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 8.9173e-06 - val_loss: 1.4814e-06\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 8.8688e-06 - val_loss: 1.4687e-06\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 8.8230e-06 - val_loss: 1.4640e-06\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.7770e-06 - val_loss: 1.4593e-06\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.7342e-06 - val_loss: 1.4529e-06\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 763us/step - loss: 8.6860e-06 - val_loss: 1.4437e-06\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 8.6396e-06 - val_loss: 1.4388e-06\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 8.5947e-06 - val_loss: 1.4366e-06\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 8.5483e-06 - val_loss: 1.4297e-06\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 8.5014e-06 - val_loss: 1.4216e-06\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 8.4585e-06 - val_loss: 1.4200e-06\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 8.4122e-06 - val_loss: 1.4111e-06\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 800us/step - loss: 8.3684e-06 - val_loss: 1.4030e-06\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 8.3226e-06 - val_loss: 1.3972e-06\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.2782e-06 - val_loss: 1.3908e-06\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 796us/step - loss: 8.2349e-06 - val_loss: 1.3864e-06\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 8.1906e-06 - val_loss: 1.3778e-06\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 8.1453e-06 - val_loss: 1.3706e-06\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 8.1015e-06 - val_loss: 1.3665e-06\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 8.0572e-06 - val_loss: 1.3605e-06\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 8.0154e-06 - val_loss: 1.3547e-06\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 755us/step - loss: 7.9717e-06 - val_loss: 1.3507e-06\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.9280e-06 - val_loss: 1.3461e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.8842e-06 - val_loss: 1.3394e-06\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.8431e-06 - val_loss: 1.3353e-06\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 7.7978e-06 - val_loss: 1.3278e-06\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.7551e-06 - val_loss: 1.3203e-06\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.7136e-06 - val_loss: 1.3172e-06\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 7.6750e-06 - val_loss: 1.3147e-06\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 7.6303e-06 - val_loss: 1.3071e-06\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.5889e-06 - val_loss: 1.3006e-06\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 7.5480e-06 - val_loss: 1.2976e-06\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 7.5079e-06 - val_loss: 1.2913e-06\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 7.4653e-06 - val_loss: 1.2841e-06\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 751us/step - loss: 7.4263e-06 - val_loss: 1.2819e-06\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 746us/step - loss: 7.3850e-06 - val_loss: 1.2771e-06\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 7.3448e-06 - val_loss: 1.2721e-06\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 7.3044e-06 - val_loss: 1.2681e-06\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 7.2657e-06 - val_loss: 1.2616e-06\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 781us/step - loss: 7.2253e-06 - val_loss: 1.2540e-06\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.1842e-06 - val_loss: 1.2491e-06\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 750us/step - loss: 7.1448e-06 - val_loss: 1.2418e-06\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 7.1075e-06 - val_loss: 1.2372e-06\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 7.0688e-06 - val_loss: 1.2313e-06\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 754us/step - loss: 7.0302e-06 - val_loss: 1.2248e-06\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.9903e-06 - val_loss: 1.2185e-06\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.9515e-06 - val_loss: 1.2127e-06\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 6.9143e-06 - val_loss: 1.2068e-06\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 6.8775e-06 - val_loss: 1.2027e-06\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 6.8405e-06 - val_loss: 1.2003e-06\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.8016e-06 - val_loss: 1.1917e-06\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 6.7667e-06 - val_loss: 1.1875e-06\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 6.7266e-06 - val_loss: 1.1793e-06\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 6.6919e-06 - val_loss: 1.1765e-06\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 6.6537e-06 - val_loss: 1.1750e-06\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 6.6180e-06 - val_loss: 1.1732e-06\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 793us/step - loss: 6.5844e-06 - val_loss: 1.1628e-06\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.5444e-06 - val_loss: 1.1513e-06\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.5070e-06 - val_loss: 1.1452e-06\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 6.4720e-06 - val_loss: 1.1413e-06\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 6.4376e-06 - val_loss: 1.1392e-06\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 803us/step - loss: 6.4032e-06 - val_loss: 1.1314e-06\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 6.3681e-06 - val_loss: 1.1263e-06\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 6.3320e-06 - val_loss: 1.1213e-06\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 819us/step - loss: 6.2978e-06 - val_loss: 1.1134e-06\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 6.2629e-06 - val_loss: 1.1109e-06\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 799us/step - loss: 6.2289e-06 - val_loss: 1.1068e-06\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 6.1923e-06 - val_loss: 1.0976e-06\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 6.1604e-06 - val_loss: 1.0958e-06\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 6.1250e-06 - val_loss: 1.0891e-06\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 788us/step - loss: 6.0916e-06 - val_loss: 1.0832e-06\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 826us/step - loss: 6.0588e-06 - val_loss: 1.0790e-06\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 798us/step - loss: 6.0250e-06 - val_loss: 1.0755e-06\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.9914e-06 - val_loss: 1.0668e-06\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 5.9585e-06 - val_loss: 1.0606e-06\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 5.9259e-06 - val_loss: 1.0558e-06\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 5.8950e-06 - val_loss: 1.0521e-06\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 782us/step - loss: 5.8621e-06 - val_loss: 1.0460e-06\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 5.8300e-06 - val_loss: 1.0442e-06\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.7970e-06 - val_loss: 1.0378e-06\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 5.7648e-06 - val_loss: 1.0315e-06\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.7331e-06 - val_loss: 1.0251e-06\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 5.7022e-06 - val_loss: 1.0213e-06\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 5.6704e-06 - val_loss: 1.0149e-06\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 5.6390e-06 - val_loss: 1.0087e-06\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.6100e-06 - val_loss: 1.0060e-06\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.5778e-06 - val_loss: 9.9977e-07\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 747us/step - loss: 5.5467e-06 - val_loss: 9.9501e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 740us/step - loss: 5.5166e-06 - val_loss: 9.9006e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 748us/step - loss: 5.4867e-06 - val_loss: 9.8540e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 760us/step - loss: 5.4567e-06 - val_loss: 9.7939e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 5.4260e-06 - val_loss: 9.7473e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 5.3966e-06 - val_loss: 9.6857e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 5.3669e-06 - val_loss: 9.6420e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 5.3376e-06 - val_loss: 9.5902e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 5.3085e-06 - val_loss: 9.5393e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 5.2807e-06 - val_loss: 9.5136e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.2514e-06 - val_loss: 9.4504e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 5.2208e-06 - val_loss: 9.4115e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 771us/step - loss: 5.1934e-06 - val_loss: 9.3559e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 5.1636e-06 - val_loss: 9.2917e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 5.1355e-06 - val_loss: 9.2272e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 5.1082e-06 - val_loss: 9.1991e-07\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.0800e-06 - val_loss: 9.1465e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 5.0516e-06 - val_loss: 9.0896e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 5.0253e-06 - val_loss: 9.0850e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 4.9975e-06 - val_loss: 9.0040e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.9706e-06 - val_loss: 8.9627e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.9441e-06 - val_loss: 8.9240e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.9157e-06 - val_loss: 8.8508e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.8907e-06 - val_loss: 8.8463e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 4.8623e-06 - val_loss: 8.7685e-07\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 4.8349e-06 - val_loss: 8.7030e-07\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.8084e-06 - val_loss: 8.6649e-07\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 802us/step - loss: 4.7838e-06 - val_loss: 8.6382e-07\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 795us/step - loss: 4.7575e-06 - val_loss: 8.5785e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 820us/step - loss: 4.7305e-06 - val_loss: 8.5252e-07\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 806us/step - loss: 4.7052e-06 - val_loss: 8.5031e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 797us/step - loss: 4.6791e-06 - val_loss: 8.4319e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.6530e-06 - val_loss: 8.3801e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 4.6299e-06 - val_loss: 8.3523e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 779us/step - loss: 4.6038e-06 - val_loss: 8.2811e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.5789e-06 - val_loss: 8.2370e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 807us/step - loss: 4.5548e-06 - val_loss: 8.2204e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 780us/step - loss: 4.5286e-06 - val_loss: 8.1737e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 791us/step - loss: 4.5052e-06 - val_loss: 8.0984e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 777us/step - loss: 4.4796e-06 - val_loss: 8.0680e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 764us/step - loss: 4.4567e-06 - val_loss: 8.0209e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.4322e-06 - val_loss: 7.9731e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.4077e-06 - val_loss: 7.9281e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 4.3831e-06 - val_loss: 7.8803e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 752us/step - loss: 4.3594e-06 - val_loss: 7.8278e-07\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.3386e-06 - val_loss: 7.8197e-07\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 4.3149e-06 - val_loss: 7.7578e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 758us/step - loss: 4.2923e-06 - val_loss: 7.7037e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 778us/step - loss: 4.2659e-06 - val_loss: 7.6549e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 761us/step - loss: 4.2447e-06 - val_loss: 7.6239e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 767us/step - loss: 4.2216e-06 - val_loss: 7.5758e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.2003e-06 - val_loss: 7.5403e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 766us/step - loss: 4.1756e-06 - val_loss: 7.5019e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 775us/step - loss: 4.1552e-06 - val_loss: 7.4708e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 769us/step - loss: 4.1301e-06 - val_loss: 7.3809e-07\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 757us/step - loss: 4.1092e-06 - val_loss: 7.3811e-07\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 785us/step - loss: 4.0860e-06 - val_loss: 7.3073e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 776us/step - loss: 4.0648e-06 - val_loss: 7.2637e-07\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 756us/step - loss: 4.0424e-06 - val_loss: 7.2171e-07\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 762us/step - loss: 4.0211e-06 - val_loss: 7.2016e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 765us/step - loss: 4.0001e-06 - val_loss: 7.1281e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 768us/step - loss: 3.9791e-06 - val_loss: 7.1018e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 772us/step - loss: 3.9583e-06 - val_loss: 7.0598e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 773us/step - loss: 3.9364e-06 - val_loss: 7.0435e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.9168e-06 - val_loss: 6.9734e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 759us/step - loss: 3.8952e-06 - val_loss: 6.9444e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 770us/step - loss: 3.8738e-06 - val_loss: 6.8987e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 783us/step - loss: 3.8536e-06 - val_loss: 6.8613e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 808us/step - loss: 3.8324e-06 - val_loss: 6.8034e-07\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1031 - val_loss: 0.1012\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.1000 - val_loss: 0.0983\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0973 - val_loss: 0.0959\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0951 - val_loss: 0.0942\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0936 - val_loss: 0.0930\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0927 - val_loss: 0.0924\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0922 - val_loss: 0.0921\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0920 - val_loss: 0.0919\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0918 - val_loss: 0.0918\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0916 - val_loss: 0.0916\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0914 - val_loss: 0.0914\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0912 - val_loss: 0.0911\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0910 - val_loss: 0.0909\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0908 - val_loss: 0.0907\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0906 - val_loss: 0.0905\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0904 - val_loss: 0.0903\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0902 - val_loss: 0.0901\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0899 - val_loss: 0.0898\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0897 - val_loss: 0.0896\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0894 - val_loss: 0.0893\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0891 - val_loss: 0.0889\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0887 - val_loss: 0.0886\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0884 - val_loss: 0.0882\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0880 - val_loss: 0.0877\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0875 - val_loss: 0.0873\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0870 - val_loss: 0.0867\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0865 - val_loss: 0.0862\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0859 - val_loss: 0.0855\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0852 - val_loss: 0.0848\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0845 - val_loss: 0.0840\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0828 - val_loss: 0.0822\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0818 - val_loss: 0.0812\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0807 - val_loss: 0.0800\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0795 - val_loss: 0.0787\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0781 - val_loss: 0.0773\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0767 - val_loss: 0.0758\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0750 - val_loss: 0.0740\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0732 - val_loss: 0.0721\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0713 - val_loss: 0.0700\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0690 - val_loss: 0.0677\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0666 - val_loss: 0.0650\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0638 - val_loss: 0.0621\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0608 - val_loss: 0.0588\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0573 - val_loss: 0.0551\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0533 - val_loss: 0.0507\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0487 - val_loss: 0.0458\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0435 - val_loss: 0.0404\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0385 - val_loss: 0.0359\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0339 - val_loss: 0.0312\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0292 - val_loss: 0.0265\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0245 - val_loss: 0.0220\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0202 - val_loss: 0.0179\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0162 - val_loss: 0.0142\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 83/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8759e-04 - val_loss: 0.0010\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6256e-04 - val_loss: 9.7499e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3778e-04 - val_loss: 9.4860e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1363e-04 - val_loss: 9.2269e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8994e-04 - val_loss: 8.9726e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6661e-04 - val_loss: 8.7241e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4396e-04 - val_loss: 8.4799e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2164e-04 - val_loss: 8.2413e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9995e-04 - val_loss: 8.0072e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7866e-04 - val_loss: 7.7783e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5778e-04 - val_loss: 7.5548e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3748e-04 - val_loss: 7.3364e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1771e-04 - val_loss: 7.1226e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9842e-04 - val_loss: 6.9132e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7933e-04 - val_loss: 6.7099e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6096e-04 - val_loss: 6.5112e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4309e-04 - val_loss: 6.3168e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2546e-04 - val_loss: 6.1279e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0855e-04 - val_loss: 5.9431e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9185e-04 - val_loss: 5.7628e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7564e-04 - val_loss: 5.5877e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5981e-04 - val_loss: 5.4175e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4465e-04 - val_loss: 5.2509e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2968e-04 - val_loss: 5.0886e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1521e-04 - val_loss: 4.9306e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0098e-04 - val_loss: 4.7775e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8738e-04 - val_loss: 4.6278e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7398e-04 - val_loss: 4.4826e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6109e-04 - val_loss: 4.3410e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4851e-04 - val_loss: 4.2030e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3618e-04 - val_loss: 4.0697e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2431e-04 - val_loss: 3.9402e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1286e-04 - val_loss: 3.8132e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0157e-04 - val_loss: 3.6906e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9070e-04 - val_loss: 3.5716e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8016e-04 - val_loss: 3.4558e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6991e-04 - val_loss: 3.3433e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5998e-04 - val_loss: 3.2341e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5032e-04 - val_loss: 3.1280e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4096e-04 - val_loss: 3.0251e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3190e-04 - val_loss: 2.9252e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2308e-04 - val_loss: 2.8283e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1456e-04 - val_loss: 2.7342e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0625e-04 - val_loss: 2.6432e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9822e-04 - val_loss: 2.5551e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9041e-04 - val_loss: 2.4700e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8295e-04 - val_loss: 2.3870e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7562e-04 - val_loss: 2.3066e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6860e-04 - val_loss: 2.2288e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6175e-04 - val_loss: 2.1529e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5510e-04 - val_loss: 2.0799e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4867e-04 - val_loss: 2.0094e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4248e-04 - val_loss: 1.9411e-04\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3648e-04 - val_loss: 1.8751e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3067e-04 - val_loss: 1.8109e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2505e-04 - val_loss: 1.7491e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1963e-04 - val_loss: 1.6893e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1440e-04 - val_loss: 1.6314e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0928e-04 - val_loss: 1.5758e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0439e-04 - val_loss: 1.5218e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9968e-04 - val_loss: 1.4699e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9508e-04 - val_loss: 1.4200e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9071e-04 - val_loss: 1.3712e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8643e-04 - val_loss: 1.3245e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8233e-04 - val_loss: 1.2796e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7836e-04 - val_loss: 1.2358e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7452e-04 - val_loss: 1.1940e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7080e-04 - val_loss: 1.1542e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6725e-04 - val_loss: 1.1153e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6384e-04 - val_loss: 1.0775e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6050e-04 - val_loss: 1.0416e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5731e-04 - val_loss: 1.0069e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5427e-04 - val_loss: 9.7322e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5128e-04 - val_loss: 9.4120e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4841e-04 - val_loss: 9.1057e-05\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4567e-04 - val_loss: 8.8132e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4304e-04 - val_loss: 8.5293e-05\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4047e-04 - val_loss: 8.2576e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3801e-04 - val_loss: 7.9947e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3564e-04 - val_loss: 7.7407e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3335e-04 - val_loss: 7.4992e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3115e-04 - val_loss: 7.2667e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2901e-04 - val_loss: 7.0443e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2698e-04 - val_loss: 6.8274e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2500e-04 - val_loss: 6.6213e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2310e-04 - val_loss: 6.4248e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2127e-04 - val_loss: 6.2356e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1950e-04 - val_loss: 6.0546e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1781e-04 - val_loss: 5.8814e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1617e-04 - val_loss: 5.7161e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1458e-04 - val_loss: 5.5561e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1305e-04 - val_loss: 5.4025e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1159e-04 - val_loss: 5.2570e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1017e-04 - val_loss: 5.1177e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0878e-04 - val_loss: 4.9836e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0745e-04 - val_loss: 4.8513e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0617e-04 - val_loss: 4.7254e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0490e-04 - val_loss: 4.6041e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0369e-04 - val_loss: 4.4900e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0251e-04 - val_loss: 4.3752e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0136e-04 - val_loss: 4.2680e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0026e-04 - val_loss: 4.1665e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9188e-05 - val_loss: 4.0674e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8149e-05 - val_loss: 3.9711e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7139e-05 - val_loss: 3.8806e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6154e-05 - val_loss: 3.7933e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5208e-05 - val_loss: 3.7106e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4278e-05 - val_loss: 3.6308e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3376e-05 - val_loss: 3.5533e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2497e-05 - val_loss: 3.4773e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1632e-05 - val_loss: 3.4071e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0799e-05 - val_loss: 3.3340e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9991e-05 - val_loss: 3.2649e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9194e-05 - val_loss: 3.2005e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8434e-05 - val_loss: 3.1400e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7667e-05 - val_loss: 3.0794e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6928e-05 - val_loss: 3.0219e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6201e-05 - val_loss: 2.9676e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5514e-05 - val_loss: 2.9113e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4814e-05 - val_loss: 2.8598e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4153e-05 - val_loss: 2.8089e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3483e-05 - val_loss: 2.7630e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2817e-05 - val_loss: 2.7144e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2171e-05 - val_loss: 2.6660e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1547e-05 - val_loss: 2.6207e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0932e-05 - val_loss: 2.5775e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0320e-05 - val_loss: 2.5368e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9745e-05 - val_loss: 2.4959e-05\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9158e-05 - val_loss: 2.4571e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8586e-05 - val_loss: 2.4208e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8019e-05 - val_loss: 2.3843e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7466e-05 - val_loss: 2.3455e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6920e-05 - val_loss: 2.3108e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6399e-05 - val_loss: 2.2780e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5861e-05 - val_loss: 2.2456e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5344e-05 - val_loss: 2.2145e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4826e-05 - val_loss: 2.1838e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4317e-05 - val_loss: 2.1525e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.3817e-05 - val_loss: 2.1219e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3329e-05 - val_loss: 2.0920e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2839e-05 - val_loss: 2.0639e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2374e-05 - val_loss: 2.0382e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1880e-05 - val_loss: 2.0138e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1436e-05 - val_loss: 1.9852e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0968e-05 - val_loss: 1.9572e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0513e-05 - val_loss: 1.9339e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0067e-05 - val_loss: 1.9109e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9617e-05 - val_loss: 1.8876e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9173e-05 - val_loss: 1.8650e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8741e-05 - val_loss: 1.8425e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8304e-05 - val_loss: 1.8193e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7875e-05 - val_loss: 1.7967e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7464e-05 - val_loss: 1.7756e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7052e-05 - val_loss: 1.7556e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6643e-05 - val_loss: 1.7349e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6241e-05 - val_loss: 1.7161e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5824e-05 - val_loss: 1.7000e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5449e-05 - val_loss: 1.6775e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5039e-05 - val_loss: 1.6589e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4649e-05 - val_loss: 1.6395e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4253e-05 - val_loss: 1.6244e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3868e-05 - val_loss: 1.6091e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3519e-05 - val_loss: 1.5889e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3121e-05 - val_loss: 1.5734e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2751e-05 - val_loss: 1.5558e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2367e-05 - val_loss: 1.5406e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2000e-05 - val_loss: 1.5249e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1636e-05 - val_loss: 1.5070e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1279e-05 - val_loss: 1.4907e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0910e-05 - val_loss: 1.4761e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0568e-05 - val_loss: 1.4607e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0221e-05 - val_loss: 1.4464e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9864e-05 - val_loss: 1.4315e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9525e-05 - val_loss: 1.4191e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9180e-05 - val_loss: 1.4052e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8837e-05 - val_loss: 1.3905e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8501e-05 - val_loss: 1.3767e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8166e-05 - val_loss: 1.3635e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7838e-05 - val_loss: 1.3518e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7512e-05 - val_loss: 1.3421e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7194e-05 - val_loss: 1.3264e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6865e-05 - val_loss: 1.3127e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6542e-05 - val_loss: 1.3002e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6217e-05 - val_loss: 1.2877e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5908e-05 - val_loss: 1.2758e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5590e-05 - val_loss: 1.2684e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5284e-05 - val_loss: 1.2564e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4970e-05 - val_loss: 1.2427e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4657e-05 - val_loss: 1.2318e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4352e-05 - val_loss: 1.2210e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4045e-05 - val_loss: 1.2099e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3749e-05 - val_loss: 1.2004e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3452e-05 - val_loss: 1.1904e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3146e-05 - val_loss: 1.1791e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2868e-05 - val_loss: 1.1668e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2577e-05 - val_loss: 1.1571e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2277e-05 - val_loss: 1.1460e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1995e-05 - val_loss: 1.1374e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1703e-05 - val_loss: 1.1295e-05\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1427e-05 - val_loss: 1.1215e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1130e-05 - val_loss: 1.1121e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0865e-05 - val_loss: 1.1006e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0581e-05 - val_loss: 1.0903e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0313e-05 - val_loss: 1.0819e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0035e-05 - val_loss: 1.0742e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9763e-05 - val_loss: 1.0631e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9480e-05 - val_loss: 1.0547e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9207e-05 - val_loss: 1.0477e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8934e-05 - val_loss: 1.0381e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8666e-05 - val_loss: 1.0282e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8401e-05 - val_loss: 1.0190e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8134e-05 - val_loss: 1.0104e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7877e-05 - val_loss: 1.0025e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7613e-05 - val_loss: 9.9508e-06\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7366e-05 - val_loss: 9.8852e-06\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7091e-05 - val_loss: 9.8033e-06\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6851e-05 - val_loss: 9.7211e-06\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6593e-05 - val_loss: 9.6446e-06\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6332e-05 - val_loss: 9.5629e-06\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6089e-05 - val_loss: 9.4954e-06\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5836e-05 - val_loss: 9.4145e-06\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5602e-05 - val_loss: 9.3463e-06\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5342e-05 - val_loss: 9.2637e-06\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5092e-05 - val_loss: 9.1888e-06\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4867e-05 - val_loss: 9.1322e-06\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4613e-05 - val_loss: 9.0595e-06\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4377e-05 - val_loss: 8.9905e-06\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4130e-05 - val_loss: 8.9217e-06\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3893e-05 - val_loss: 8.8446e-06\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3658e-05 - val_loss: 8.7716e-06\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3420e-05 - val_loss: 8.7048e-06\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3196e-05 - val_loss: 8.6515e-06\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2957e-05 - val_loss: 8.5841e-06\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2730e-05 - val_loss: 8.5216e-06\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2500e-05 - val_loss: 8.4546e-06\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2283e-05 - val_loss: 8.4040e-06\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2043e-05 - val_loss: 8.3297e-06\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1812e-05 - val_loss: 8.2579e-06\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1594e-05 - val_loss: 8.2003e-06\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1370e-05 - val_loss: 8.1357e-06\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1146e-05 - val_loss: 8.0889e-06\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0931e-05 - val_loss: 8.0399e-06\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0705e-05 - val_loss: 7.9762e-06\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0484e-05 - val_loss: 7.9112e-06\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0267e-05 - val_loss: 7.8512e-06\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0051e-05 - val_loss: 7.7915e-06\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9832e-05 - val_loss: 7.7389e-06\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9630e-05 - val_loss: 7.6793e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9417e-05 - val_loss: 7.6300e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9203e-05 - val_loss: 7.5806e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8984e-05 - val_loss: 7.5179e-06\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8784e-05 - val_loss: 7.4627e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8570e-05 - val_loss: 7.4052e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8361e-05 - val_loss: 7.3454e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8159e-05 - val_loss: 7.2948e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7965e-05 - val_loss: 7.2552e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7750e-05 - val_loss: 7.1993e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7543e-05 - val_loss: 7.1388e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7345e-05 - val_loss: 7.0918e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7145e-05 - val_loss: 7.0399e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6951e-05 - val_loss: 6.9867e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6755e-05 - val_loss: 6.9514e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6549e-05 - val_loss: 6.8900e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6360e-05 - val_loss: 6.8564e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6162e-05 - val_loss: 6.8062e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5968e-05 - val_loss: 6.7620e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5770e-05 - val_loss: 6.7073e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5581e-05 - val_loss: 6.6606e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5392e-05 - val_loss: 6.6161e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5196e-05 - val_loss: 6.5689e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5019e-05 - val_loss: 6.5290e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4817e-05 - val_loss: 6.4723e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4637e-05 - val_loss: 6.4311e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4448e-05 - val_loss: 6.3821e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4274e-05 - val_loss: 6.3531e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4085e-05 - val_loss: 6.3116e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3901e-05 - val_loss: 6.2606e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3729e-05 - val_loss: 6.2297e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3545e-05 - val_loss: 6.1748e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3365e-05 - val_loss: 6.1350e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3172e-05 - val_loss: 6.0786e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2993e-05 - val_loss: 6.0290e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2820e-05 - val_loss: 5.9946e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2649e-05 - val_loss: 5.9556e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2481e-05 - val_loss: 5.9373e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2294e-05 - val_loss: 5.8997e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2120e-05 - val_loss: 5.8596e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1943e-05 - val_loss: 5.8163e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1773e-05 - val_loss: 5.7921e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1609e-05 - val_loss: 5.7419e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1434e-05 - val_loss: 5.7044e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1271e-05 - val_loss: 5.6617e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1102e-05 - val_loss: 5.6259e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0938e-05 - val_loss: 5.5959e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0765e-05 - val_loss: 5.5478e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0606e-05 - val_loss: 5.5160e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0429e-05 - val_loss: 5.4700e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0273e-05 - val_loss: 5.4365e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0109e-05 - val_loss: 5.4015e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9947e-05 - val_loss: 5.3684e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9775e-05 - val_loss: 5.3348e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9624e-05 - val_loss: 5.3091e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9465e-05 - val_loss: 5.2624e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9308e-05 - val_loss: 5.2408e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9144e-05 - val_loss: 5.2032e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8989e-05 - val_loss: 5.1696e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8830e-05 - val_loss: 5.1334e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8680e-05 - val_loss: 5.1032e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8517e-05 - val_loss: 5.0616e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8372e-05 - val_loss: 5.0355e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8221e-05 - val_loss: 5.0086e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8070e-05 - val_loss: 4.9802e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7922e-05 - val_loss: 4.9360e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7769e-05 - val_loss: 4.9017e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7610e-05 - val_loss: 4.8679e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7466e-05 - val_loss: 4.8447e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7323e-05 - val_loss: 4.8142e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7163e-05 - val_loss: 4.7761e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7016e-05 - val_loss: 4.7477e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6866e-05 - val_loss: 4.7095e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6726e-05 - val_loss: 4.6783e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6588e-05 - val_loss: 4.6616e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6449e-05 - val_loss: 4.6332e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6297e-05 - val_loss: 4.6030e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6157e-05 - val_loss: 4.5913e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6020e-05 - val_loss: 4.5604e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5871e-05 - val_loss: 4.5206e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5727e-05 - val_loss: 4.4808e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5590e-05 - val_loss: 4.4580e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5446e-05 - val_loss: 4.4333e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5315e-05 - val_loss: 4.4042e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5179e-05 - val_loss: 4.3719e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5044e-05 - val_loss: 4.3479e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4898e-05 - val_loss: 4.3070e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4769e-05 - val_loss: 4.2861e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4633e-05 - val_loss: 4.2582e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4508e-05 - val_loss: 4.2412e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4372e-05 - val_loss: 4.2162e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4235e-05 - val_loss: 4.1924e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4101e-05 - val_loss: 4.1660e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3973e-05 - val_loss: 4.1359e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3842e-05 - val_loss: 4.1060e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3716e-05 - val_loss: 4.0812e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3580e-05 - val_loss: 4.0518e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3454e-05 - val_loss: 4.0435e-06\n",
      "Epoch 450/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3335e-05 - val_loss: 4.0149e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3203e-05 - val_loss: 3.9971e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3073e-05 - val_loss: 3.9690e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2953e-05 - val_loss: 3.9427e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2823e-05 - val_loss: 3.9095e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2696e-05 - val_loss: 3.8801e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2574e-05 - val_loss: 3.8515e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2448e-05 - val_loss: 3.8296e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2330e-05 - val_loss: 3.8127e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2216e-05 - val_loss: 3.7879e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2089e-05 - val_loss: 3.7680e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1974e-05 - val_loss: 3.7550e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1851e-05 - val_loss: 3.7247e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1724e-05 - val_loss: 3.6943e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1609e-05 - val_loss: 3.6643e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1505e-05 - val_loss: 3.6562e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1379e-05 - val_loss: 3.6378e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1268e-05 - val_loss: 3.6396e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1148e-05 - val_loss: 3.6031e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1033e-05 - val_loss: 3.5700e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0921e-05 - val_loss: 3.5381e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0802e-05 - val_loss: 3.5159e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0688e-05 - val_loss: 3.4917e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0572e-05 - val_loss: 3.4720e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0467e-05 - val_loss: 3.4838e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0360e-05 - val_loss: 3.4412e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0241e-05 - val_loss: 3.4171e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0132e-05 - val_loss: 3.4029e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0014e-05 - val_loss: 3.3669e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9909e-05 - val_loss: 3.3469e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9808e-05 - val_loss: 3.3467e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9692e-05 - val_loss: 3.3165e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9589e-05 - val_loss: 3.3035e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9474e-05 - val_loss: 3.2670e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9371e-05 - val_loss: 3.2489e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9271e-05 - val_loss: 3.2439e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9162e-05 - val_loss: 3.2162e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9058e-05 - val_loss: 3.2007e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8953e-05 - val_loss: 3.1891e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8852e-05 - val_loss: 3.1905e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8761e-05 - val_loss: 3.1401e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8655e-05 - val_loss: 3.1224e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8548e-05 - val_loss: 3.0967e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8447e-05 - val_loss: 3.0769e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8343e-05 - val_loss: 3.0708e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8245e-05 - val_loss: 3.0555e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8139e-05 - val_loss: 3.0338e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8041e-05 - val_loss: 3.0224e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7951e-05 - val_loss: 2.9999e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7845e-05 - val_loss: 2.9776e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7751e-05 - val_loss: 2.9637e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7654e-05 - val_loss: 2.9455e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7555e-05 - val_loss: 2.9301e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7458e-05 - val_loss: 2.9075e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7364e-05 - val_loss: 2.8725e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7280e-05 - val_loss: 2.8726e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7173e-05 - val_loss: 2.8469e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7081e-05 - val_loss: 2.8412e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6993e-05 - val_loss: 2.8223e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6898e-05 - val_loss: 2.8042e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6808e-05 - val_loss: 2.7956e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6719e-05 - val_loss: 2.7703e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6630e-05 - val_loss: 2.7735e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6538e-05 - val_loss: 2.7540e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6444e-05 - val_loss: 2.7143e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6355e-05 - val_loss: 2.7009e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6266e-05 - val_loss: 2.6850e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6178e-05 - val_loss: 2.6705e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6090e-05 - val_loss: 2.6622e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6003e-05 - val_loss: 2.6715e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5925e-05 - val_loss: 2.6252e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5831e-05 - val_loss: 2.6062e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5745e-05 - val_loss: 2.5938e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5658e-05 - val_loss: 2.5848e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5573e-05 - val_loss: 2.5793e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5487e-05 - val_loss: 2.5585e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5403e-05 - val_loss: 2.5311e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5321e-05 - val_loss: 2.5163e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5235e-05 - val_loss: 2.5009e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5156e-05 - val_loss: 2.5035e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5076e-05 - val_loss: 2.4816e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4994e-05 - val_loss: 2.4696e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4912e-05 - val_loss: 2.4579e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4827e-05 - val_loss: 2.4436e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4749e-05 - val_loss: 2.4189e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4670e-05 - val_loss: 2.4039e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4588e-05 - val_loss: 2.3859e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4509e-05 - val_loss: 2.3697e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4433e-05 - val_loss: 2.3604e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4355e-05 - val_loss: 2.3444e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4284e-05 - val_loss: 2.3449e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4201e-05 - val_loss: 2.3331e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4123e-05 - val_loss: 2.3145e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4048e-05 - val_loss: 2.2965e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3971e-05 - val_loss: 2.2805e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3895e-05 - val_loss: 2.2676e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3823e-05 - val_loss: 2.2573e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3747e-05 - val_loss: 2.2528e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3683e-05 - val_loss: 2.2323e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3604e-05 - val_loss: 2.2171e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3533e-05 - val_loss: 2.2047e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3461e-05 - val_loss: 2.2113e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3387e-05 - val_loss: 2.1800e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3310e-05 - val_loss: 2.1665e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3242e-05 - val_loss: 2.1643e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3170e-05 - val_loss: 2.1359e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3100e-05 - val_loss: 2.1283e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3028e-05 - val_loss: 2.1140e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2960e-05 - val_loss: 2.1048e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2889e-05 - val_loss: 2.0915e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2824e-05 - val_loss: 2.0837e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2757e-05 - val_loss: 2.0853e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2690e-05 - val_loss: 2.0614e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2619e-05 - val_loss: 2.0434e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2552e-05 - val_loss: 2.0337e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2484e-05 - val_loss: 2.0238e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2420e-05 - val_loss: 2.0150e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2355e-05 - val_loss: 2.0076e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2286e-05 - val_loss: 1.9866e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2224e-05 - val_loss: 1.9753e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2162e-05 - val_loss: 1.9817e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2106e-05 - val_loss: 1.9586e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2040e-05 - val_loss: 1.9436e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1967e-05 - val_loss: 1.9304e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1904e-05 - val_loss: 1.9290e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1840e-05 - val_loss: 1.9102e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1779e-05 - val_loss: 1.9020e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1717e-05 - val_loss: 1.8901e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1654e-05 - val_loss: 1.8781e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1596e-05 - val_loss: 1.8658e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1533e-05 - val_loss: 1.8586e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1472e-05 - val_loss: 1.8476e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1413e-05 - val_loss: 1.8362e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1354e-05 - val_loss: 1.8353e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1295e-05 - val_loss: 1.8174e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1236e-05 - val_loss: 1.8014e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1177e-05 - val_loss: 1.7974e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1118e-05 - val_loss: 1.7814e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1059e-05 - val_loss: 1.7746e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1001e-05 - val_loss: 1.7678e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0953e-05 - val_loss: 1.7613e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0892e-05 - val_loss: 1.7590e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0837e-05 - val_loss: 1.7392e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0776e-05 - val_loss: 1.7267e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0722e-05 - val_loss: 1.7276e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0673e-05 - val_loss: 1.7140e-06\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0611e-05 - val_loss: 1.6934e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0558e-05 - val_loss: 1.7052e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0503e-05 - val_loss: 1.6774e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0449e-05 - val_loss: 1.6715e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0401e-05 - val_loss: 1.6631e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0342e-05 - val_loss: 1.6597e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0289e-05 - val_loss: 1.6390e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0240e-05 - val_loss: 1.6288e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0186e-05 - val_loss: 1.6343e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0134e-05 - val_loss: 1.6166e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0077e-05 - val_loss: 1.6064e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0026e-05 - val_loss: 1.6001e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9756e-06 - val_loss: 1.5823e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9250e-06 - val_loss: 1.5741e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8730e-06 - val_loss: 1.5629e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8263e-06 - val_loss: 1.5585e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7761e-06 - val_loss: 1.5519e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7269e-06 - val_loss: 1.5443e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6770e-06 - val_loss: 1.5422e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6337e-06 - val_loss: 1.5387e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5833e-06 - val_loss: 1.5345e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5376e-06 - val_loss: 1.5063e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4881e-06 - val_loss: 1.4951e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4378e-06 - val_loss: 1.4927e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3903e-06 - val_loss: 1.4830e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3425e-06 - val_loss: 1.4747e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2960e-06 - val_loss: 1.4712e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2463e-06 - val_loss: 1.4584e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2024e-06 - val_loss: 1.4485e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1577e-06 - val_loss: 1.4408e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1132e-06 - val_loss: 1.4377e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0653e-06 - val_loss: 1.4231e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0204e-06 - val_loss: 1.4206e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9764e-06 - val_loss: 1.4065e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9339e-06 - val_loss: 1.4044e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8899e-06 - val_loss: 1.3997e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8480e-06 - val_loss: 1.3939e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8079e-06 - val_loss: 1.3903e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7599e-06 - val_loss: 1.3717e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7170e-06 - val_loss: 1.3676e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6728e-06 - val_loss: 1.3567e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6295e-06 - val_loss: 1.3535e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5895e-06 - val_loss: 1.3404e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5539e-06 - val_loss: 1.3367e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5120e-06 - val_loss: 1.3318e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4652e-06 - val_loss: 1.3196e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4254e-06 - val_loss: 1.3200e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3845e-06 - val_loss: 1.3028e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.3437e-06 - val_loss: 1.3026e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3033e-06 - val_loss: 1.2936e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2657e-06 - val_loss: 1.2874e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2247e-06 - val_loss: 1.2837e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1851e-06 - val_loss: 1.2732e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1463e-06 - val_loss: 1.2810e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1120e-06 - val_loss: 1.2589e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0732e-06 - val_loss: 1.2621e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0295e-06 - val_loss: 1.2445e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9930e-06 - val_loss: 1.2466e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.9550e-06 - val_loss: 1.2311e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9180e-06 - val_loss: 1.2262e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8815e-06 - val_loss: 1.2109e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8451e-06 - val_loss: 1.2144e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8034e-06 - val_loss: 1.2068e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7711e-06 - val_loss: 1.2092e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7337e-06 - val_loss: 1.1957e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6968e-06 - val_loss: 1.1878e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6614e-06 - val_loss: 1.1867e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6273e-06 - val_loss: 1.1734e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5907e-06 - val_loss: 1.1702e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5533e-06 - val_loss: 1.1601e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5181e-06 - val_loss: 1.1558e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4836e-06 - val_loss: 1.1465e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4486e-06 - val_loss: 1.1468e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.4176e-06 - val_loss: 1.1371e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3808e-06 - val_loss: 1.1306e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3461e-06 - val_loss: 1.1233e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3124e-06 - val_loss: 1.1148e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2798e-06 - val_loss: 1.1098e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2486e-06 - val_loss: 1.1164e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2175e-06 - val_loss: 1.1037e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1842e-06 - val_loss: 1.1122e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1536e-06 - val_loss: 1.0933e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1203e-06 - val_loss: 1.0950e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0870e-06 - val_loss: 1.0793e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0549e-06 - val_loss: 1.0782e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0253e-06 - val_loss: 1.0704e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9929e-06 - val_loss: 1.0702e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9608e-06 - val_loss: 1.0542e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9260e-06 - val_loss: 1.0476e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8971e-06 - val_loss: 1.0431e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8654e-06 - val_loss: 1.0383e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8340e-06 - val_loss: 1.0327e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8062e-06 - val_loss: 1.0363e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7786e-06 - val_loss: 1.0224e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7495e-06 - val_loss: 1.0206e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7146e-06 - val_loss: 1.0090e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6850e-06 - val_loss: 1.0059e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6569e-06 - val_loss: 9.9902e-07\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6293e-06 - val_loss: 9.9546e-07\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5978e-06 - val_loss: 9.9124e-07\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5705e-06 - val_loss: 9.8533e-07\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5406e-06 - val_loss: 9.7579e-07\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5124e-06 - val_loss: 9.7231e-07\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4861e-06 - val_loss: 9.7008e-07\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4572e-06 - val_loss: 9.6759e-07\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4299e-06 - val_loss: 9.6049e-07\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4017e-06 - val_loss: 9.5328e-07\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3776e-06 - val_loss: 9.5142e-07\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3469e-06 - val_loss: 9.4571e-07\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3189e-06 - val_loss: 9.3857e-07\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2923e-06 - val_loss: 9.3201e-07\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2681e-06 - val_loss: 9.3028e-07\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2409e-06 - val_loss: 9.2225e-07\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2151e-06 - val_loss: 9.2526e-07\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1887e-06 - val_loss: 9.1694e-07\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1618e-06 - val_loss: 9.1812e-07\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1378e-06 - val_loss: 9.1016e-07\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1100e-06 - val_loss: 9.0313e-07\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0835e-06 - val_loss: 8.9590e-07\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0604e-06 - val_loss: 8.9459e-07\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0342e-06 - val_loss: 8.8891e-07\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0082e-06 - val_loss: 8.8317e-07\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9838e-06 - val_loss: 8.7876e-07\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9622e-06 - val_loss: 8.7836e-07\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9349e-06 - val_loss: 8.7131e-07\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9112e-06 - val_loss: 8.7461e-07\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8925e-06 - val_loss: 8.7265e-07\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8689e-06 - val_loss: 8.6304e-07\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8419e-06 - val_loss: 8.5831e-07\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8153e-06 - val_loss: 8.4826e-07\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7911e-06 - val_loss: 8.4893e-07\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7680e-06 - val_loss: 8.3781e-07\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7443e-06 - val_loss: 8.3656e-07\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7217e-06 - val_loss: 8.2980e-07\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6968e-06 - val_loss: 8.2735e-07\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6755e-06 - val_loss: 8.2435e-07\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6522e-06 - val_loss: 8.1730e-07\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6310e-06 - val_loss: 8.1602e-07\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6089e-06 - val_loss: 8.0912e-07\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5852e-06 - val_loss: 8.1142e-07\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5622e-06 - val_loss: 8.0142e-07\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5411e-06 - val_loss: 8.0230e-07\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5202e-06 - val_loss: 7.9884e-07\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4976e-06 - val_loss: 8.0075e-07\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4763e-06 - val_loss: 7.9010e-07\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4532e-06 - val_loss: 7.8511e-07\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4315e-06 - val_loss: 7.7898e-07\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4110e-06 - val_loss: 7.7448e-07\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.3895e-06 - val_loss: 7.7077e-07\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3704e-06 - val_loss: 7.6900e-07\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3518e-06 - val_loss: 7.7258e-07\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3290e-06 - val_loss: 7.6156e-07\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3088e-06 - val_loss: 7.5866e-07\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2893e-06 - val_loss: 7.6723e-07\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2741e-06 - val_loss: 7.5977e-07\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2505e-06 - val_loss: 7.4829e-07\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2308e-06 - val_loss: 7.4887e-07\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2097e-06 - val_loss: 7.4470e-07\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1899e-06 - val_loss: 7.4617e-07\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1689e-06 - val_loss: 7.3117e-07\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1472e-06 - val_loss: 7.3081e-07\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1288e-06 - val_loss: 7.3069e-07\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1096e-06 - val_loss: 7.1914e-07\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0892e-06 - val_loss: 7.2477e-07\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0707e-06 - val_loss: 7.1311e-07\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0495e-06 - val_loss: 7.1312e-07\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0328e-06 - val_loss: 7.1059e-07\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0131e-06 - val_loss: 7.0499e-07\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9939e-06 - val_loss: 7.0589e-07\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9762e-06 - val_loss: 6.9703e-07\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9574e-06 - val_loss: 6.9421e-07\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9393e-06 - val_loss: 6.9314e-07\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9210e-06 - val_loss: 6.8505e-07\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9019e-06 - val_loss: 6.8308e-07\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8834e-06 - val_loss: 6.8180e-07\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8653e-06 - val_loss: 6.7798e-07\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8476e-06 - val_loss: 6.7719e-07\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8296e-06 - val_loss: 6.7125e-07\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8146e-06 - val_loss: 6.7328e-07\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7994e-06 - val_loss: 6.7465e-07\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7819e-06 - val_loss: 6.6951e-07\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7637e-06 - val_loss: 6.6136e-07\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7433e-06 - val_loss: 6.6118e-07\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7284e-06 - val_loss: 6.5354e-07\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7077e-06 - val_loss: 6.5014e-07\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6910e-06 - val_loss: 6.4666e-07\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6733e-06 - val_loss: 6.4254e-07\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6564e-06 - val_loss: 6.3990e-07\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6428e-06 - val_loss: 6.4255e-07\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6302e-06 - val_loss: 6.4605e-07\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6166e-06 - val_loss: 6.3270e-07\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5986e-06 - val_loss: 6.3166e-07\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5834e-06 - val_loss: 6.3622e-07\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5656e-06 - val_loss: 6.2602e-07\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5456e-06 - val_loss: 6.2370e-07\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5273e-06 - val_loss: 6.1733e-07\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5110e-06 - val_loss: 6.1628e-07\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4953e-06 - val_loss: 6.1230e-07\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4786e-06 - val_loss: 6.0798e-07\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4658e-06 - val_loss: 6.0448e-07\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4488e-06 - val_loss: 6.0325e-07\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4350e-06 - val_loss: 5.9917e-07\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4181e-06 - val_loss: 5.9720e-07\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4031e-06 - val_loss: 5.9315e-07\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3876e-06 - val_loss: 5.9946e-07\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3734e-06 - val_loss: 5.9146e-07\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3569e-06 - val_loss: 5.8696e-07\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3414e-06 - val_loss: 5.8334e-07\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3321e-06 - val_loss: 5.8066e-07\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3180e-06 - val_loss: 5.8844e-07\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3037e-06 - val_loss: 5.8498e-07\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2889e-06 - val_loss: 5.7874e-07\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2712e-06 - val_loss: 5.7614e-07\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2541e-06 - val_loss: 5.6927e-07\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2408e-06 - val_loss: 5.7261e-07\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2271e-06 - val_loss: 5.7306e-07\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2143e-06 - val_loss: 5.6967e-07\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2011e-06 - val_loss: 5.6232e-07\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1835e-06 - val_loss: 5.5328e-07\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1662e-06 - val_loss: 5.5055e-07\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1530e-06 - val_loss: 5.4935e-07\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1374e-06 - val_loss: 5.4946e-07\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1253e-06 - val_loss: 5.4957e-07\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1120e-06 - val_loss: 5.4827e-07\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0997e-06 - val_loss: 5.5096e-07\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0872e-06 - val_loss: 5.4905e-07\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0757e-06 - val_loss: 5.3955e-07\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0562e-06 - val_loss: 5.3399e-07\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0419e-06 - val_loss: 5.3023e-07\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0353e-06 - val_loss: 5.3537e-07\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0174e-06 - val_loss: 5.4293e-07\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0107e-06 - val_loss: 5.2289e-07\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9911e-06 - val_loss: 5.2614e-07\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9805e-06 - val_loss: 5.1813e-07\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9737e-06 - val_loss: 5.2605e-07\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9546e-06 - val_loss: 5.2767e-07\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9417e-06 - val_loss: 5.2691e-07\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9272e-06 - val_loss: 5.1358e-07\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9179e-06 - val_loss: 5.1039e-07\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9005e-06 - val_loss: 5.1012e-07\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8857e-06 - val_loss: 5.1091e-07\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8730e-06 - val_loss: 5.0205e-07\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8609e-06 - val_loss: 4.9798e-07\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8461e-06 - val_loss: 4.9752e-07\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8366e-06 - val_loss: 5.0061e-07\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8226e-06 - val_loss: 4.9486e-07\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8080e-06 - val_loss: 4.9288e-07\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7982e-06 - val_loss: 4.9358e-07\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7854e-06 - val_loss: 4.9381e-07\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7747e-06 - val_loss: 4.9839e-07\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8001e-06 - val_loss: 5.0974e-07\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7581e-06 - val_loss: 5.0746e-07\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7631e-06 - val_loss: 4.7952e-07\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7414e-06 - val_loss: 5.2023e-07\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7304e-06 - val_loss: 4.7918e-07\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7210e-06 - val_loss: 5.0534e-07\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6991e-06 - val_loss: 4.7292e-07\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6776e-06 - val_loss: 4.7017e-07\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6651e-06 - val_loss: 4.7347e-07\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6529e-06 - val_loss: 4.6576e-07\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6400e-06 - val_loss: 4.6249e-07\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6296e-06 - val_loss: 4.7019e-07\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6195e-06 - val_loss: 4.6356e-07\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6058e-06 - val_loss: 4.5959e-07\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6006e-06 - val_loss: 4.7346e-07\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5905e-06 - val_loss: 4.6952e-07\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6093e-06 - val_loss: 4.9446e-07\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5870e-06 - val_loss: 4.6074e-07\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5587e-06 - val_loss: 4.6641e-07\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5518e-06 - val_loss: 4.5475e-07\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5301e-06 - val_loss: 4.4549e-07\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5190e-06 - val_loss: 4.5767e-07\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5232e-06 - val_loss: 4.6834e-07\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5209e-06 - val_loss: 4.4877e-07\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4847e-06 - val_loss: 4.5566e-07\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5166e-06 - val_loss: 5.1086e-07\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5217e-06 - val_loss: 4.6087e-07\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4618e-06 - val_loss: 4.3276e-07\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4404e-06 - val_loss: 4.3614e-07\n",
      "Epoch 875/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4330e-06 - val_loss: 4.3104e-07\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4211e-06 - val_loss: 4.3509e-07\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4170e-06 - val_loss: 4.4008e-07\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4214e-06 - val_loss: 4.6596e-07\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4298e-06 - val_loss: 4.7403e-07\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4266e-06 - val_loss: 4.6934e-07\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3984e-06 - val_loss: 4.3516e-07\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3602e-06 - val_loss: 4.4696e-07\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4118e-06 - val_loss: 4.7460e-07\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3518e-06 - val_loss: 4.2760e-07\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4181e-06 - val_loss: 6.4043e-07\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5025e-06 - val_loss: 4.5218e-07\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3205e-06 - val_loss: 4.6306e-07\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3216e-06 - val_loss: 4.0653e-07\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3058e-06 - val_loss: 4.4847e-07\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2917e-06 - val_loss: 4.0240e-07\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2672e-06 - val_loss: 4.2245e-07\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2599e-06 - val_loss: 4.0119e-07\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2501e-06 - val_loss: 4.1638e-07\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2562e-06 - val_loss: 4.3897e-07\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2444e-06 - val_loss: 3.9936e-07\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2128e-06 - val_loss: 3.9241e-07\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2020e-06 - val_loss: 3.9454e-07\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1951e-06 - val_loss: 4.0273e-07\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2090e-06 - val_loss: 4.3034e-07\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1975e-06 - val_loss: 3.9354e-07\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1692e-06 - val_loss: 3.8717e-07\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1537e-06 - val_loss: 3.8598e-07\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1459e-06 - val_loss: 3.8303e-07\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1413e-06 - val_loss: 4.2904e-07\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2221e-06 - val_loss: 5.2123e-07\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1980e-06 - val_loss: 3.8487e-07\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1168e-06 - val_loss: 4.1235e-07\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1268e-06 - val_loss: 3.8613e-07\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0958e-06 - val_loss: 4.1972e-07\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1671e-06 - val_loss: 4.9695e-07\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1379e-06 - val_loss: 3.7663e-07\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0711e-06 - val_loss: 4.3645e-07\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1111e-06 - val_loss: 3.9663e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0515e-06 - val_loss: 3.8326e-07\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0479e-06 - val_loss: 3.7158e-07\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0250e-06 - val_loss: 3.7111e-07\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0298e-06 - val_loss: 4.0192e-07\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0552e-06 - val_loss: 3.9046e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0040e-06 - val_loss: 3.7138e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0061e-06 - val_loss: 3.8645e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0009e-06 - val_loss: 3.6565e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9726e-06 - val_loss: 3.5866e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9626e-06 - val_loss: 3.6836e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9770e-06 - val_loss: 3.9384e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9773e-06 - val_loss: 3.8239e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9779e-06 - val_loss: 4.3756e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0085e-06 - val_loss: 3.8550e-07\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9335e-06 - val_loss: 3.5038e-07\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9198e-06 - val_loss: 3.6947e-07\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9068e-06 - val_loss: 3.4802e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9093e-06 - val_loss: 4.0309e-07\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9447e-06 - val_loss: 3.9010e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9026e-06 - val_loss: 3.5055e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8666e-06 - val_loss: 3.4171e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8570e-06 - val_loss: 3.4423e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8522e-06 - val_loss: 3.4927e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8667e-06 - val_loss: 3.9105e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8867e-06 - val_loss: 3.9288e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8557e-06 - val_loss: 3.4004e-07\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8152e-06 - val_loss: 3.3639e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8124e-06 - val_loss: 3.5044e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8284e-06 - val_loss: 3.8453e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8504e-06 - val_loss: 4.2191e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8872e-06 - val_loss: 4.5125e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8691e-06 - val_loss: 3.8138e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7949e-06 - val_loss: 3.3295e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7565e-06 - val_loss: 3.2643e-07\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7474e-06 - val_loss: 3.2723e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7427e-06 - val_loss: 3.2547e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7324e-06 - val_loss: 3.2154e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7253e-06 - val_loss: 3.3142e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7293e-06 - val_loss: 3.4890e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7480e-06 - val_loss: 3.8243e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7518e-06 - val_loss: 3.5497e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7197e-06 - val_loss: 3.3786e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6915e-06 - val_loss: 3.2072e-07\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7185e-06 - val_loss: 4.3636e-07\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8835e-06 - val_loss: 5.5492e-07\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8022e-06 - val_loss: 3.2403e-07\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6603e-06 - val_loss: 3.4156e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6810e-06 - val_loss: 3.2045e-07\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6437e-06 - val_loss: 3.4685e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6661e-06 - val_loss: 3.3424e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6309e-06 - val_loss: 3.0730e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6228e-06 - val_loss: 3.4320e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6465e-06 - val_loss: 3.3723e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6144e-06 - val_loss: 3.0278e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5908e-06 - val_loss: 3.1893e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6105e-06 - val_loss: 3.3372e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5983e-06 - val_loss: 3.0882e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5675e-06 - val_loss: 3.0034e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5593e-06 - val_loss: 3.0038e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5529e-06 - val_loss: 3.0448e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5664e-06 - val_loss: 3.4665e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5775e-06 - val_loss: 3.3994e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5829e-06 - val_loss: 3.5631e-07\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5662e-06 - val_loss: 3.1348e-07\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5334e-06 - val_loss: 3.2068e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5272e-06 - val_loss: 3.0317e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5065e-06 - val_loss: 2.9175e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4916e-06 - val_loss: 2.8829e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4839e-06 - val_loss: 2.9748e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5273e-06 - val_loss: 4.2899e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6926e-06 - val_loss: 5.7938e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6926e-06 - val_loss: 3.6480e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4776e-06 - val_loss: 3.0988e-07\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4875e-06 - val_loss: 3.2915e-07\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4713e-06 - val_loss: 2.9469e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4378e-06 - val_loss: 2.8189e-07\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4255e-06 - val_loss: 2.8146e-07\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4239e-06 - val_loss: 2.8845e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4416e-06 - val_loss: 3.2184e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4335e-06 - val_loss: 2.8630e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3985e-06 - val_loss: 2.7662e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3907e-06 - val_loss: 2.8058e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3841e-06 - val_loss: 2.7495e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3831e-06 - val_loss: 3.0489e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4563e-06 - val_loss: 4.5386e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6226e-06 - val_loss: 5.1917e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4713e-06 - val_loss: 2.7436e-07\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 389\n",
      "Trainable params: 389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 5s 6ms/step - loss: 0.0988 - val_loss: 0.0965\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0951 - val_loss: 0.0933\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0924 - val_loss: 0.0915\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0912 - val_loss: 0.0911\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0911 - val_loss: 0.0913\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0912 - val_loss: 0.0913\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0911 - val_loss: 0.0910\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0909 - val_loss: 0.0909\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0907 - val_loss: 0.0908\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0907 - val_loss: 0.0907\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0906 - val_loss: 0.0907\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0906 - val_loss: 0.0906\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0905 - val_loss: 0.0906\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0904 - val_loss: 0.0905\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0902 - val_loss: 0.0903\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0900 - val_loss: 0.0900\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0899 - val_loss: 0.0900\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0899 - val_loss: 0.0898\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0897 - val_loss: 0.0897\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0896 - val_loss: 0.0896\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0895 - val_loss: 0.0895\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0894 - val_loss: 0.0893\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0892 - val_loss: 0.0891\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0890 - val_loss: 0.0889\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0888 - val_loss: 0.0887\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0885 - val_loss: 0.0884\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0882 - val_loss: 0.0880\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0878 - val_loss: 0.0876\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0874 - val_loss: 0.0872\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0869 - val_loss: 0.0866\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0864 - val_loss: 0.0860\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0849 - val_loss: 0.0844\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0839 - val_loss: 0.0833\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0828 - val_loss: 0.0820\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0814 - val_loss: 0.0805\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0798 - val_loss: 0.0787\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0779 - val_loss: 0.0766\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0757 - val_loss: 0.0741\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0730 - val_loss: 0.0712\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0699 - val_loss: 0.0679\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0665 - val_loss: 0.0642\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0627 - val_loss: 0.0603\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0587 - val_loss: 0.0563\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0547 - val_loss: 0.0521\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0503 - val_loss: 0.0473\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0451 - val_loss: 0.0413\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0387 - val_loss: 0.0343\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0314 - val_loss: 0.0266\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0236 - val_loss: 0.0189\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0163 - val_loss: 0.0123\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0106 - val_loss: 0.0080\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 9.9175e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0013 - val_loss: 9.5489e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 9.1871e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 8.8296e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0012 - val_loss: 8.4813e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 8.1426e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 7.8103e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0011 - val_loss: 7.4904e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0010 - val_loss: 7.1780e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.9388e-04 - val_loss: 6.8782e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.6488e-04 - val_loss: 6.5792e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.3688e-04 - val_loss: 6.2904e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.0983e-04 - val_loss: 6.0084e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.8349e-04 - val_loss: 5.7405e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.5806e-04 - val_loss: 5.4826e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.3357e-04 - val_loss: 5.2342e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.0981e-04 - val_loss: 4.9952e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.8702e-04 - val_loss: 4.7701e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.6501e-04 - val_loss: 4.5489e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.4380e-04 - val_loss: 4.3336e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2348e-04 - val_loss: 4.1272e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.0407e-04 - val_loss: 3.9323e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.8527e-04 - val_loss: 3.7464e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.6736e-04 - val_loss: 3.5709e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.5021e-04 - val_loss: 3.4001e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.3364e-04 - val_loss: 3.2375e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1807e-04 - val_loss: 3.0916e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.0313e-04 - val_loss: 2.9469e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.8862e-04 - val_loss: 2.8102e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7489e-04 - val_loss: 2.6755e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.6167e-04 - val_loss: 2.5521e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.4925e-04 - val_loss: 2.4305e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.3729e-04 - val_loss: 2.3216e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2600e-04 - val_loss: 2.2174e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.1526e-04 - val_loss: 2.1171e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.0476e-04 - val_loss: 2.0264e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.9480e-04 - val_loss: 1.9403e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8532e-04 - val_loss: 1.8591e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7624e-04 - val_loss: 1.7784e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6763e-04 - val_loss: 1.7046e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5950e-04 - val_loss: 1.6405e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5144e-04 - val_loss: 1.5729e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4389e-04 - val_loss: 1.5146e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3668e-04 - val_loss: 1.4589e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2952e-04 - val_loss: 1.4041e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2284e-04 - val_loss: 1.3523e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1626e-04 - val_loss: 1.2997e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1011e-04 - val_loss: 1.2543e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0400e-04 - val_loss: 1.2096e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9825e-04 - val_loss: 1.1693e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9258e-04 - val_loss: 1.1305e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8725e-04 - val_loss: 1.0943e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8203e-04 - val_loss: 1.0622e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.7705e-04 - val_loss: 1.0359e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.7217e-04 - val_loss: 1.0060e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.6713e-04 - val_loss: 9.7245e-05\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.6257e-04 - val_loss: 9.4300e-05\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.5839e-04 - val_loss: 9.1652e-05\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.5393e-04 - val_loss: 8.9951e-05\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.4949e-04 - val_loss: 8.7622e-05\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.4530e-04 - val_loss: 8.4641e-05\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.4121e-04 - val_loss: 8.2656e-05\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.3729e-04 - val_loss: 8.0592e-05\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.3324e-04 - val_loss: 7.8647e-05\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.2936e-04 - val_loss: 7.7490e-05\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.2562e-04 - val_loss: 7.5189e-05\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.2199e-04 - val_loss: 7.3339e-05\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1822e-04 - val_loss: 7.1564e-05\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1473e-04 - val_loss: 7.0059e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1129e-04 - val_loss: 6.8514e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.0787e-04 - val_loss: 6.7273e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.0466e-04 - val_loss: 6.6165e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.0119e-04 - val_loss: 6.4697e-05\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9814e-04 - val_loss: 6.3144e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9517e-04 - val_loss: 6.2150e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9192e-04 - val_loss: 6.1131e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.8899e-04 - val_loss: 5.9656e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.8584e-04 - val_loss: 5.8825e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.8277e-04 - val_loss: 5.7475e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7986e-04 - val_loss: 5.6110e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7708e-04 - val_loss: 5.5303e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7418e-04 - val_loss: 5.4456e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7152e-04 - val_loss: 5.3867e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6878e-04 - val_loss: 5.2693e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6614e-04 - val_loss: 5.1913e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6328e-04 - val_loss: 5.0877e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6079e-04 - val_loss: 5.0234e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5824e-04 - val_loss: 4.9204e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5568e-04 - val_loss: 4.8583e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5310e-04 - val_loss: 4.7821e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5064e-04 - val_loss: 4.7059e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4825e-04 - val_loss: 4.6218e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4592e-04 - val_loss: 4.5662e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4344e-04 - val_loss: 4.4764e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4114e-04 - val_loss: 4.4187e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3887e-04 - val_loss: 4.3631e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3652e-04 - val_loss: 4.3089e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3432e-04 - val_loss: 4.2276e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3201e-04 - val_loss: 4.1624e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2992e-04 - val_loss: 4.1127e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2778e-04 - val_loss: 4.0483e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2561e-04 - val_loss: 4.0087e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2354e-04 - val_loss: 3.9458e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2124e-04 - val_loss: 3.8779e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1927e-04 - val_loss: 3.8300e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1719e-04 - val_loss: 3.7772e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1521e-04 - val_loss: 3.7244e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1323e-04 - val_loss: 3.6788e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1124e-04 - val_loss: 3.6389e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0943e-04 - val_loss: 3.6016e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0731e-04 - val_loss: 3.5336e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0550e-04 - val_loss: 3.4840e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0359e-04 - val_loss: 3.4489e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0172e-04 - val_loss: 3.4019e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9993e-04 - val_loss: 3.3491e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9819e-04 - val_loss: 3.3216e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9629e-04 - val_loss: 3.2950e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9455e-04 - val_loss: 3.2473e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9276e-04 - val_loss: 3.2090e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9108e-04 - val_loss: 3.1786e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8947e-04 - val_loss: 3.1514e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8759e-04 - val_loss: 3.1109e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8607e-04 - val_loss: 3.0800e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8418e-04 - val_loss: 3.0190e-05\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8267e-04 - val_loss: 2.9936e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8095e-04 - val_loss: 2.9565e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7935e-04 - val_loss: 2.9266e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7776e-04 - val_loss: 2.8713e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7619e-04 - val_loss: 2.8390e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7455e-04 - val_loss: 2.8026e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7312e-04 - val_loss: 2.7885e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7148e-04 - val_loss: 2.7529e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7000e-04 - val_loss: 2.7332e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6848e-04 - val_loss: 2.6985e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6695e-04 - val_loss: 2.6631e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6553e-04 - val_loss: 2.6268e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6403e-04 - val_loss: 2.5991e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6261e-04 - val_loss: 2.5711e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6124e-04 - val_loss: 2.5590e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5980e-04 - val_loss: 2.5424e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5831e-04 - val_loss: 2.5063e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5692e-04 - val_loss: 2.4704e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5557e-04 - val_loss: 2.4447e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5425e-04 - val_loss: 2.4227e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5290e-04 - val_loss: 2.4008e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5151e-04 - val_loss: 2.3718e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5020e-04 - val_loss: 2.3497e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4882e-04 - val_loss: 2.3343e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4772e-04 - val_loss: 2.2838e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4641e-04 - val_loss: 2.2890e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4510e-04 - val_loss: 2.2583e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4378e-04 - val_loss: 2.2629e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4260e-04 - val_loss: 2.2134e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4125e-04 - val_loss: 2.1901e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4002e-04 - val_loss: 2.1652e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3881e-04 - val_loss: 2.1600e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3759e-04 - val_loss: 2.1255e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3634e-04 - val_loss: 2.1000e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3520e-04 - val_loss: 2.0878e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3394e-04 - val_loss: 2.0585e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3286e-04 - val_loss: 2.0442e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3168e-04 - val_loss: 2.0404e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3056e-04 - val_loss: 2.0088e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2938e-04 - val_loss: 1.9870e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2827e-04 - val_loss: 1.9740e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2715e-04 - val_loss: 1.9561e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2601e-04 - val_loss: 1.9316e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2494e-04 - val_loss: 1.9204e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2382e-04 - val_loss: 1.9064e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2279e-04 - val_loss: 1.8746e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2172e-04 - val_loss: 1.8644e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2061e-04 - val_loss: 1.8441e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1956e-04 - val_loss: 1.8212e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1856e-04 - val_loss: 1.8132e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1752e-04 - val_loss: 1.8055e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1646e-04 - val_loss: 1.7836e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1542e-04 - val_loss: 1.7718e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1445e-04 - val_loss: 1.7498e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1343e-04 - val_loss: 1.7419e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1245e-04 - val_loss: 1.7140e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1147e-04 - val_loss: 1.7030e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1047e-04 - val_loss: 1.6843e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0952e-04 - val_loss: 1.6695e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0857e-04 - val_loss: 1.6557e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0766e-04 - val_loss: 1.6562e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0668e-04 - val_loss: 1.6399e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0577e-04 - val_loss: 1.6181e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0481e-04 - val_loss: 1.6080e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0390e-04 - val_loss: 1.5918e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0298e-04 - val_loss: 1.5779e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0216e-04 - val_loss: 1.5791e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0117e-04 - val_loss: 1.5557e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0033e-04 - val_loss: 1.5402e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.9392e-05 - val_loss: 1.5225e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.8516e-05 - val_loss: 1.5115e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.7653e-05 - val_loss: 1.5018e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.6827e-05 - val_loss: 1.4902e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.5923e-05 - val_loss: 1.4732e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.5099e-05 - val_loss: 1.4626e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.4250e-05 - val_loss: 1.4528e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.3430e-05 - val_loss: 1.4428e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.2606e-05 - val_loss: 1.4251e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.1751e-05 - val_loss: 1.4071e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.0984e-05 - val_loss: 1.4025e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.0201e-05 - val_loss: 1.4009e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.9398e-05 - val_loss: 1.3881e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.8631e-05 - val_loss: 1.3791e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.7799e-05 - val_loss: 1.3762e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.7046e-05 - val_loss: 1.3572e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.6293e-05 - val_loss: 1.3432e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.5490e-05 - val_loss: 1.3281e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.4754e-05 - val_loss: 1.3173e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.3953e-05 - val_loss: 1.3080e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.3211e-05 - val_loss: 1.2935e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.2480e-05 - val_loss: 1.2840e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.1735e-05 - val_loss: 1.2781e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.1038e-05 - val_loss: 1.2725e-05\n",
      "Epoch 326/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 2s 2ms/step - loss: 8.0254e-05 - val_loss: 1.2635e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.9523e-05 - val_loss: 1.2452e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.8836e-05 - val_loss: 1.2363e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.8124e-05 - val_loss: 1.2225e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.7484e-05 - val_loss: 1.2258e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.6712e-05 - val_loss: 1.2056e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.6050e-05 - val_loss: 1.1991e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.5335e-05 - val_loss: 1.1846e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.4677e-05 - val_loss: 1.1747e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.4037e-05 - val_loss: 1.1801e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.3333e-05 - val_loss: 1.1615e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2667e-05 - val_loss: 1.1553e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2021e-05 - val_loss: 1.1476e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.1350e-05 - val_loss: 1.1304e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.0732e-05 - val_loss: 1.1233e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.0138e-05 - val_loss: 1.1351e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.9478e-05 - val_loss: 1.1131e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.8803e-05 - val_loss: 1.1022e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.8183e-05 - val_loss: 1.0946e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.7582e-05 - val_loss: 1.0915e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.6940e-05 - val_loss: 1.0758e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.6354e-05 - val_loss: 1.0674e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.5741e-05 - val_loss: 1.0647e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.5156e-05 - val_loss: 1.0489e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.4573e-05 - val_loss: 1.0451e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.3962e-05 - val_loss: 1.0369e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.3423e-05 - val_loss: 1.0379e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.2797e-05 - val_loss: 1.0257e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.2221e-05 - val_loss: 1.0133e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1634e-05 - val_loss: 1.0078e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1067e-05 - val_loss: 9.9814e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.0529e-05 - val_loss: 9.9570e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.9959e-05 - val_loss: 9.8588e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.9404e-05 - val_loss: 9.7958e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.8907e-05 - val_loss: 9.9170e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.8381e-05 - val_loss: 9.5776e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7810e-05 - val_loss: 9.5613e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7248e-05 - val_loss: 9.4872e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.6708e-05 - val_loss: 9.4106e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.6202e-05 - val_loss: 9.4787e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.5707e-05 - val_loss: 9.3107e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.5232e-05 - val_loss: 9.2896e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.4675e-05 - val_loss: 9.0633e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.4138e-05 - val_loss: 9.0514e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.3708e-05 - val_loss: 9.0301e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.3160e-05 - val_loss: 8.9343e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2700e-05 - val_loss: 8.9590e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2178e-05 - val_loss: 8.8313e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.1681e-05 - val_loss: 8.8153e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.1209e-05 - val_loss: 8.6925e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.0695e-05 - val_loss: 8.6412e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.0210e-05 - val_loss: 8.5409e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.9735e-05 - val_loss: 8.4927e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.9277e-05 - val_loss: 8.3823e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8802e-05 - val_loss: 8.3140e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8363e-05 - val_loss: 8.2963e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7915e-05 - val_loss: 8.3220e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7472e-05 - val_loss: 8.1694e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7014e-05 - val_loss: 8.1596e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6540e-05 - val_loss: 8.0253e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6120e-05 - val_loss: 7.9966e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5684e-05 - val_loss: 7.9327e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5243e-05 - val_loss: 7.9031e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4837e-05 - val_loss: 7.8009e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4426e-05 - val_loss: 7.8294e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4009e-05 - val_loss: 7.7049e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3582e-05 - val_loss: 7.7493e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3185e-05 - val_loss: 7.6366e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2819e-05 - val_loss: 7.6763e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2322e-05 - val_loss: 7.4710e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1930e-05 - val_loss: 7.4464e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1568e-05 - val_loss: 7.3595e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1167e-05 - val_loss: 7.3360e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0759e-05 - val_loss: 7.1991e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0413e-05 - val_loss: 7.2364e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9994e-05 - val_loss: 7.1194e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9605e-05 - val_loss: 7.0926e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9209e-05 - val_loss: 7.1084e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8836e-05 - val_loss: 7.0035e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8448e-05 - val_loss: 6.9218e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8115e-05 - val_loss: 6.9579e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.7760e-05 - val_loss: 6.8298e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.7381e-05 - val_loss: 6.7725e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.7005e-05 - val_loss: 6.7294e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.6657e-05 - val_loss: 6.7085e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.6303e-05 - val_loss: 6.6426e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.5947e-05 - val_loss: 6.5869e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.5607e-05 - val_loss: 6.5605e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.5279e-05 - val_loss: 6.4979e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.4918e-05 - val_loss: 6.4274e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.4583e-05 - val_loss: 6.4096e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.4244e-05 - val_loss: 6.3051e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.3945e-05 - val_loss: 6.3379e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.3592e-05 - val_loss: 6.2369e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.3288e-05 - val_loss: 6.2414e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.2966e-05 - val_loss: 6.1804e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.2634e-05 - val_loss: 6.2020e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.2311e-05 - val_loss: 6.0578e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1994e-05 - val_loss: 6.0877e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1695e-05 - val_loss: 5.9727e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1362e-05 - val_loss: 5.9110e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.1069e-05 - val_loss: 5.8814e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.0765e-05 - val_loss: 5.8448e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.0466e-05 - val_loss: 5.7833e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.0212e-05 - val_loss: 5.7770e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9922e-05 - val_loss: 5.7668e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9602e-05 - val_loss: 5.6332e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9321e-05 - val_loss: 5.6496e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.9034e-05 - val_loss: 5.5883e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.8730e-05 - val_loss: 5.5198e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.8478e-05 - val_loss: 5.5374e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.8194e-05 - val_loss: 5.4500e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7904e-05 - val_loss: 5.4974e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7665e-05 - val_loss: 5.4059e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7357e-05 - val_loss: 5.3477e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.7116e-05 - val_loss: 5.3613e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6839e-05 - val_loss: 5.2698e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6562e-05 - val_loss: 5.2029e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6305e-05 - val_loss: 5.1669e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.6049e-05 - val_loss: 5.1625e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5799e-05 - val_loss: 5.0775e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5535e-05 - val_loss: 5.0628e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5307e-05 - val_loss: 5.0226e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.5060e-05 - val_loss: 4.9920e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4840e-05 - val_loss: 4.9840e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4556e-05 - val_loss: 4.8927e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4304e-05 - val_loss: 4.8723e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.4094e-05 - val_loss: 4.8050e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3850e-05 - val_loss: 4.7574e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3620e-05 - val_loss: 4.7925e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3390e-05 - val_loss: 4.6966e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.3152e-05 - val_loss: 4.6543e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2927e-05 - val_loss: 4.6480e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2701e-05 - val_loss: 4.6269e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2497e-05 - val_loss: 4.6318e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2282e-05 - val_loss: 4.5685e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.2065e-05 - val_loss: 4.5062e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1831e-05 - val_loss: 4.4488e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1615e-05 - val_loss: 4.4137e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1414e-05 - val_loss: 4.4472e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1206e-05 - val_loss: 4.3665e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.1000e-05 - val_loss: 4.3466e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0812e-05 - val_loss: 4.3069e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0586e-05 - val_loss: 4.2471e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0380e-05 - val_loss: 4.2292e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 2.0183e-05 - val_loss: 4.1868e-06\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9981e-05 - val_loss: 4.1529e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9834e-05 - val_loss: 4.1669e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9629e-05 - val_loss: 4.1791e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9428e-05 - val_loss: 4.0799e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9262e-05 - val_loss: 4.0641e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.9062e-05 - val_loss: 4.0097e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8852e-05 - val_loss: 3.9662e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8664e-05 - val_loss: 3.9559e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8510e-05 - val_loss: 3.8904e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8348e-05 - val_loss: 3.9327e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8169e-05 - val_loss: 3.8635e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.8008e-05 - val_loss: 3.9890e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7905e-05 - val_loss: 3.7951e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7761e-05 - val_loss: 3.9587e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7574e-05 - val_loss: 3.7697e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7327e-05 - val_loss: 3.7986e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.7136e-05 - val_loss: 3.6598e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6957e-05 - val_loss: 3.6269e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6794e-05 - val_loss: 3.6091e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6629e-05 - val_loss: 3.6525e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6513e-05 - val_loss: 3.6372e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6339e-05 - val_loss: 3.5137e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.6148e-05 - val_loss: 3.4951e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5990e-05 - val_loss: 3.4720e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5848e-05 - val_loss: 3.4693e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5720e-05 - val_loss: 3.4135e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5551e-05 - val_loss: 3.3961e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5410e-05 - val_loss: 3.3878e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5285e-05 - val_loss: 3.3550e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.5112e-05 - val_loss: 3.2989e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4970e-05 - val_loss: 3.2723e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4832e-05 - val_loss: 3.2546e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4673e-05 - val_loss: 3.2358e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4562e-05 - val_loss: 3.2485e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4422e-05 - val_loss: 3.1760e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4286e-05 - val_loss: 3.1601e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4162e-05 - val_loss: 3.1301e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.4025e-05 - val_loss: 3.0888e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3880e-05 - val_loss: 3.1059e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3761e-05 - val_loss: 3.0679e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3630e-05 - val_loss: 3.0281e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3487e-05 - val_loss: 2.9939e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3383e-05 - val_loss: 2.9764e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3251e-05 - val_loss: 2.9429e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3131e-05 - val_loss: 2.9773e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.3023e-05 - val_loss: 2.9205e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2880e-05 - val_loss: 2.8815e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2775e-05 - val_loss: 2.8732e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2662e-05 - val_loss: 2.8663e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2558e-05 - val_loss: 2.8135e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2449e-05 - val_loss: 2.8233e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2340e-05 - val_loss: 2.8357e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2229e-05 - val_loss: 2.8181e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2116e-05 - val_loss: 2.8497e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.2015e-05 - val_loss: 2.7411e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1888e-05 - val_loss: 2.6992e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1760e-05 - val_loss: 2.6544e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1651e-05 - val_loss: 2.6421e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1585e-05 - val_loss: 2.6103e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1449e-05 - val_loss: 2.5875e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1358e-05 - val_loss: 2.5704e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1243e-05 - val_loss: 2.5479e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1162e-05 - val_loss: 2.5805e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.1072e-05 - val_loss: 2.5790e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0969e-05 - val_loss: 2.5491e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0869e-05 - val_loss: 2.5164e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0778e-05 - val_loss: 2.5254e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0683e-05 - val_loss: 2.4625e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0584e-05 - val_loss: 2.5064e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0509e-05 - val_loss: 2.4813e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0431e-05 - val_loss: 2.4762e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0319e-05 - val_loss: 2.3753e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0220e-05 - val_loss: 2.3515e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0123e-05 - val_loss: 2.3181e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 1.0039e-05 - val_loss: 2.3273e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.9627e-06 - val_loss: 2.2692e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.8926e-06 - val_loss: 2.2846e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.8069e-06 - val_loss: 2.2849e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.7267e-06 - val_loss: 2.2687e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.6983e-06 - val_loss: 2.2124e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.6105e-06 - val_loss: 2.1998e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.5175e-06 - val_loss: 2.1815e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.3824e-06 - val_loss: 2.1613e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.3245e-06 - val_loss: 2.1568e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.2264e-06 - val_loss: 2.1255e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.1783e-06 - val_loss: 2.1730e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.1135e-06 - val_loss: 2.2350e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.0462e-06 - val_loss: 2.1701e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.9464e-06 - val_loss: 2.0644e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.8761e-06 - val_loss: 2.0562e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.7918e-06 - val_loss: 2.0344e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.7357e-06 - val_loss: 2.0600e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.6653e-06 - val_loss: 2.0216e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.6509e-06 - val_loss: 2.0278e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.5621e-06 - val_loss: 2.0580e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.4906e-06 - val_loss: 2.1529e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.4482e-06 - val_loss: 2.0069e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.3721e-06 - val_loss: 1.9153e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.2625e-06 - val_loss: 1.9550e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.1958e-06 - val_loss: 1.8975e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.1277e-06 - val_loss: 1.8700e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.0512e-06 - val_loss: 1.8648e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 8.0009e-06 - val_loss: 1.8949e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.9390e-06 - val_loss: 1.9071e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.9362e-06 - val_loss: 1.8197e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.8206e-06 - val_loss: 1.8256e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.7576e-06 - val_loss: 1.8110e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.7225e-06 - val_loss: 1.7698e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.6789e-06 - val_loss: 1.8649e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.6338e-06 - val_loss: 1.7635e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.5282e-06 - val_loss: 1.8334e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.5645e-06 - val_loss: 1.7350e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.4238e-06 - val_loss: 1.7661e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.4001e-06 - val_loss: 1.7082e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.3038e-06 - val_loss: 1.7285e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2683e-06 - val_loss: 1.6787e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2320e-06 - val_loss: 1.6735e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.1612e-06 - val_loss: 1.6440e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.1331e-06 - val_loss: 1.8138e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.2524e-06 - val_loss: 1.7419e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.0637e-06 - val_loss: 1.6258e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.9486e-06 - val_loss: 1.5955e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.8957e-06 - val_loss: 1.5876e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.8846e-06 - val_loss: 1.6059e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.8166e-06 - val_loss: 1.6852e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.0332e-06 - val_loss: 1.9534e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 7.0505e-06 - val_loss: 1.6745e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.6922e-06 - val_loss: 1.5610e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.6674e-06 - val_loss: 1.5887e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.6084e-06 - val_loss: 1.5113e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.5549e-06 - val_loss: 1.4972e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.4824e-06 - val_loss: 1.4851e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.4593e-06 - val_loss: 1.5710e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 6.4983e-06 - val_loss: 1.5336e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.4707e-06 - val_loss: 1.5783e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.3704e-06 - val_loss: 1.4575e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 2s 3ms/step - loss: 6.2792e-06 - val_loss: 1.4524e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.2728e-06 - val_loss: 1.4719e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.2676e-06 - val_loss: 1.6017e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.5739e-06 - val_loss: 1.9392e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.4420e-06 - val_loss: 1.4116e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1006e-06 - val_loss: 1.4301e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1376e-06 - val_loss: 1.4870e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.0388e-06 - val_loss: 1.5157e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1542e-06 - val_loss: 1.4321e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.9569e-06 - val_loss: 1.3561e-06\n",
      "Epoch 618/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 2s 2ms/step - loss: 5.9288e-06 - val_loss: 1.3806e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.9435e-06 - val_loss: 1.5688e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 6.1773e-06 - val_loss: 1.6943e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.9732e-06 - val_loss: 1.3084e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7689e-06 - val_loss: 1.3993e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.8055e-06 - val_loss: 1.3152e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7127e-06 - val_loss: 1.4281e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.8175e-06 - val_loss: 1.3524e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.6536e-06 - val_loss: 1.3434e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.8884e-06 - val_loss: 1.7096e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7864e-06 - val_loss: 1.2602e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.5807e-06 - val_loss: 1.4556e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7254e-06 - val_loss: 1.3813e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.5037e-06 - val_loss: 1.2258e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.4242e-06 - val_loss: 1.2617e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.6325e-06 - val_loss: 1.6730e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.7608e-06 - val_loss: 1.2871e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.4445e-06 - val_loss: 1.6744e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.6352e-06 - val_loss: 1.1934e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.3218e-06 - val_loss: 1.3129e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.3412e-06 - val_loss: 1.1778e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2184e-06 - val_loss: 1.2393e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2961e-06 - val_loss: 1.1993e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.1762e-06 - val_loss: 1.1859e-06\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2288e-06 - val_loss: 1.2223e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.1333e-06 - val_loss: 1.2864e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.3437e-06 - val_loss: 1.4587e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2132e-06 - val_loss: 1.1216e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2004e-06 - val_loss: 1.5626e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.2712e-06 - val_loss: 1.1056e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.0208e-06 - val_loss: 1.2028e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.0016e-06 - val_loss: 1.0890e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.9886e-06 - val_loss: 1.2458e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.9871e-06 - val_loss: 1.0671e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8918e-06 - val_loss: 1.1195e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8990e-06 - val_loss: 1.0728e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8254e-06 - val_loss: 1.0993e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.8387e-06 - val_loss: 1.0750e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7893e-06 - val_loss: 1.0520e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7543e-06 - val_loss: 1.0503e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7337e-06 - val_loss: 1.0317e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7031e-06 - val_loss: 1.0334e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6778e-06 - val_loss: 1.0207e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6712e-06 - val_loss: 1.0293e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6421e-06 - val_loss: 1.0068e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6630e-06 - val_loss: 1.1415e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.7531e-06 - val_loss: 1.2203e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.9684e-06 - val_loss: 1.7124e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 5.1904e-06 - val_loss: 1.2604e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6324e-06 - val_loss: 9.9841e-07\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6107e-06 - val_loss: 1.1605e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6857e-06 - val_loss: 1.1304e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5964e-06 - val_loss: 9.6300e-07\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5568e-06 - val_loss: 1.2995e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6090e-06 - val_loss: 9.9135e-07\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4149e-06 - val_loss: 9.4588e-07\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3990e-06 - val_loss: 9.4309e-07\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3693e-06 - val_loss: 1.0242e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3995e-06 - val_loss: 9.2294e-07\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3269e-06 - val_loss: 9.6138e-07\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3713e-06 - val_loss: 9.6780e-07\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2930e-06 - val_loss: 9.2137e-07\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3590e-06 - val_loss: 1.1981e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.6967e-06 - val_loss: 1.4012e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.5204e-06 - val_loss: 9.1352e-07\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2313e-06 - val_loss: 1.0008e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4363e-06 - val_loss: 1.2615e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4034e-06 - val_loss: 8.9746e-07\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1846e-06 - val_loss: 1.0149e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2968e-06 - val_loss: 1.0156e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1879e-06 - val_loss: 8.6791e-07\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1036e-06 - val_loss: 8.6919e-07\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0828e-06 - val_loss: 8.5653e-07\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0959e-06 - val_loss: 9.8616e-07\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.2064e-06 - val_loss: 9.6981e-07\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0799e-06 - val_loss: 8.3853e-07\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0085e-06 - val_loss: 8.4185e-07\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0471e-06 - val_loss: 1.0041e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1938e-06 - val_loss: 1.0529e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1364e-06 - val_loss: 8.6348e-07\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9763e-06 - val_loss: 1.0182e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.3011e-06 - val_loss: 1.3255e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.4342e-06 - val_loss: 1.2721e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1567e-06 - val_loss: 8.1318e-07\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9020e-06 - val_loss: 8.8426e-07\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9882e-06 - val_loss: 9.0354e-07\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8797e-06 - val_loss: 7.9023e-07\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8313e-06 - val_loss: 7.9312e-07\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8562e-06 - val_loss: 8.6039e-07\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8665e-06 - val_loss: 8.3328e-07\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8358e-06 - val_loss: 7.9343e-07\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.7804e-06 - val_loss: 8.2576e-07\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8200e-06 - val_loss: 8.2106e-07\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8222e-06 - val_loss: 8.8405e-07\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.8554e-06 - val_loss: 8.8749e-07\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 3.9615e-06 - val_loss: 1.2240e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.1464e-06 - val_loss: 1.0769e-06\n",
      "Epoch 00714: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 533\n",
      "Trainable params: 533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 6s 7ms/step - loss: 0.0966 - val_loss: 0.0937\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0915 - val_loss: 0.0920\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0919 - val_loss: 0.0917\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0914 - val_loss: 0.0913\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0912 - val_loss: 0.0913\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0912 - val_loss: 0.0913\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0912 - val_loss: 0.0912\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0911 - val_loss: 0.0911\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0911 - val_loss: 0.0911\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0910 - val_loss: 0.0911\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0910 - val_loss: 0.0910\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0909 - val_loss: 0.0910\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0909 - val_loss: 0.0910\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0909 - val_loss: 0.0909\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0908 - val_loss: 0.0909\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0907 - val_loss: 0.0908\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0907 - val_loss: 0.0907\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0906 - val_loss: 0.0907\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0906 - val_loss: 0.0906\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0905 - val_loss: 0.0906\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0904 - val_loss: 0.0905\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0901 - val_loss: 0.0900\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0900 - val_loss: 0.0900\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0899 - val_loss: 0.0899\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0898 - val_loss: 0.0898\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0897 - val_loss: 0.0896\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0896 - val_loss: 0.0895\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0894 - val_loss: 0.0894\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0893 - val_loss: 0.0892\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0891 - val_loss: 0.0890\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0889 - val_loss: 0.0888\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0887 - val_loss: 0.0885\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0884 - val_loss: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0880 - val_loss: 0.0878\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0876 - val_loss: 0.0873\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0871 - val_loss: 0.0867\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0864 - val_loss: 0.0859\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0833 - val_loss: 0.0825\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0819 - val_loss: 0.0809\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0803 - val_loss: 0.0792\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0785 - val_loss: 0.0774\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0767 - val_loss: 0.0757\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0751 - val_loss: 0.0744\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0740 - val_loss: 0.0738\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0735 - val_loss: 0.0735\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0733 - val_loss: 0.0733\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0731 - val_loss: 0.0730\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0728 - val_loss: 0.0728\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0726 - val_loss: 0.0725\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0724 - val_loss: 0.0723\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0722 - val_loss: 0.0721\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0718 - val_loss: 0.0717\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0716 - val_loss: 0.0715\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0714 - val_loss: 0.0712\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0711 - val_loss: 0.0710\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0709 - val_loss: 0.0708\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0707 - val_loss: 0.0705\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0704 - val_loss: 0.0702\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0701 - val_loss: 0.0699\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0698 - val_loss: 0.0695\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0694 - val_loss: 0.0691\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0690 - val_loss: 0.0687\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0685 - val_loss: 0.0681\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0679 - val_loss: 0.0675\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0673 - val_loss: 0.0668\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0665 - val_loss: 0.0660\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0656 - val_loss: 0.0650\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0646 - val_loss: 0.0638\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0633 - val_loss: 0.0623\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0617 - val_loss: 0.0607\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0600 - val_loss: 0.0588\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0581 - val_loss: 0.0569\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0563 - val_loss: 0.0551\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0545 - val_loss: 0.0535\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0530 - val_loss: 0.0521\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0517 - val_loss: 0.0508\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0504 - val_loss: 0.0495\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0493 - val_loss: 0.0485\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0482 - val_loss: 0.0471\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0469 - val_loss: 0.0462\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0457 - val_loss: 0.0446\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0443 - val_loss: 0.0432\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0429 - val_loss: 0.0418\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0414 - val_loss: 0.0402\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0399 - val_loss: 0.0388\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0383 - val_loss: 0.0371\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0367 - val_loss: 0.0354\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0349 - val_loss: 0.0336\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0331 - val_loss: 0.0318\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0313 - val_loss: 0.0299\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0293 - val_loss: 0.0279\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0274 - val_loss: 0.0259\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0253 - val_loss: 0.0240\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0234 - val_loss: 0.0218\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0214 - val_loss: 0.0200\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0196 - val_loss: 0.0182\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0180 - val_loss: 0.0167\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0165 - val_loss: 0.0153\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0151 - val_loss: 0.0140\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0139 - val_loss: 0.0129\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0092 - val_loss: 0.0086\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0036 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0018 - val_loss: 9.6927e-04\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0018 - val_loss: 9.1491e-04\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0017 - val_loss: 8.6165e-04\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0016 - val_loss: 8.0958e-04\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0016 - val_loss: 7.5922e-04\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0016 - val_loss: 7.1049e-04\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0015 - val_loss: 6.6323e-04\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0015 - val_loss: 6.1774e-04\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0014 - val_loss: 5.7423e-04\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0014 - val_loss: 5.3283e-04\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0013 - val_loss: 4.9322e-04\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0013 - val_loss: 4.5584e-04\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0012 - val_loss: 4.2045e-04\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0012 - val_loss: 3.8665e-04\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0012 - val_loss: 3.5519e-04\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0011 - val_loss: 3.2566e-04\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0011 - val_loss: 2.9851e-04\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0011 - val_loss: 2.7329e-04\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0011 - val_loss: 2.5027e-04\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0010 - val_loss: 2.2867e-04\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 0.0010 - val_loss: 2.0922e-04\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.7878e-04 - val_loss: 1.9178e-04\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.5659e-04 - val_loss: 1.7590e-04\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.3563e-04 - val_loss: 1.6165e-04\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.1594e-04 - val_loss: 1.4807e-04\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.9716e-04 - val_loss: 1.3629e-04\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.7963e-04 - val_loss: 1.2545e-04\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.6350e-04 - val_loss: 1.1608e-04\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.4796e-04 - val_loss: 1.0756e-04\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.3339e-04 - val_loss: 1.0008e-04\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.1925e-04 - val_loss: 9.3297e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.0577e-04 - val_loss: 8.7183e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.9346e-04 - val_loss: 8.2008e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.8111e-04 - val_loss: 7.7079e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.6898e-04 - val_loss: 7.2645e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.5799e-04 - val_loss: 6.8782e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.4710e-04 - val_loss: 6.5356e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.3691e-04 - val_loss: 6.2218e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.2635e-04 - val_loss: 5.9364e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.1688e-04 - val_loss: 5.6984e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.0731e-04 - val_loss: 5.4807e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.9792e-04 - val_loss: 5.2912e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.8881e-04 - val_loss: 5.0606e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.7998e-04 - val_loss: 4.8865e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.7122e-04 - val_loss: 4.7382e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.6231e-04 - val_loss: 4.5745e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.5415e-04 - val_loss: 4.4508e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.4580e-04 - val_loss: 4.3077e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.3809e-04 - val_loss: 4.1911e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.2975e-04 - val_loss: 4.0961e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.2210e-04 - val_loss: 3.9626e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.1494e-04 - val_loss: 3.8647e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.0694e-04 - val_loss: 3.7903e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.9958e-04 - val_loss: 3.6743e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.9240e-04 - val_loss: 3.5851e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.8537e-04 - val_loss: 3.5389e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.7855e-04 - val_loss: 3.4302e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.7141e-04 - val_loss: 3.3604e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.6449e-04 - val_loss: 3.2860e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.5816e-04 - val_loss: 3.2268e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.5131e-04 - val_loss: 3.1686e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.4448e-04 - val_loss: 3.0901e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.3864e-04 - val_loss: 3.0332e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.3226e-04 - val_loss: 2.9811e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.2579e-04 - val_loss: 2.9197e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.2005e-04 - val_loss: 2.8619e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.1397e-04 - val_loss: 2.8405e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.0800e-04 - val_loss: 2.7597e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.0222e-04 - val_loss: 2.7085e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.9665e-04 - val_loss: 2.6729e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.9056e-04 - val_loss: 2.6334e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.8504e-04 - val_loss: 2.5712e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.7958e-04 - val_loss: 2.5364e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.7406e-04 - val_loss: 2.4912e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.6865e-04 - val_loss: 2.4490e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.6358e-04 - val_loss: 2.4182e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.5813e-04 - val_loss: 2.3688e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.5301e-04 - val_loss: 2.3328e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4753e-04 - val_loss: 2.3076e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4299e-04 - val_loss: 2.2530e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.3785e-04 - val_loss: 2.2146e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.3292e-04 - val_loss: 2.1926e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.2793e-04 - val_loss: 2.1486e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.2320e-04 - val_loss: 2.1150e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1885e-04 - val_loss: 2.1047e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1418e-04 - val_loss: 2.0523e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0969e-04 - val_loss: 2.0186e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0493e-04 - val_loss: 2.0036e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0053e-04 - val_loss: 1.9550e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9586e-04 - val_loss: 1.9281e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9177e-04 - val_loss: 1.8944e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8721e-04 - val_loss: 1.8597e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8313e-04 - val_loss: 1.8301e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7907e-04 - val_loss: 1.8038e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7479e-04 - val_loss: 1.7828e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7070e-04 - val_loss: 1.7501e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6680e-04 - val_loss: 1.7247e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6265e-04 - val_loss: 1.7082e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5885e-04 - val_loss: 1.6743e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5495e-04 - val_loss: 1.6610e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5108e-04 - val_loss: 1.6261e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4750e-04 - val_loss: 1.6091e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4355e-04 - val_loss: 1.5943e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4009e-04 - val_loss: 1.5568e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3637e-04 - val_loss: 1.5358e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3289e-04 - val_loss: 1.5164e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2924e-04 - val_loss: 1.4893e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2575e-04 - val_loss: 1.4804e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2235e-04 - val_loss: 1.4478e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1907e-04 - val_loss: 1.4254e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1543e-04 - val_loss: 1.4173e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1220e-04 - val_loss: 1.3844e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0882e-04 - val_loss: 1.3640e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0553e-04 - val_loss: 1.3557e-05\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0259e-04 - val_loss: 1.3329e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9933e-04 - val_loss: 1.3060e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9625e-04 - val_loss: 1.2879e-05\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9302e-04 - val_loss: 1.2891e-05\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9010e-04 - val_loss: 1.2527e-05\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8688e-04 - val_loss: 1.2338e-05\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8410e-04 - val_loss: 1.2168e-05\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8103e-04 - val_loss: 1.1987e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7801e-04 - val_loss: 1.1802e-05\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7524e-04 - val_loss: 1.1646e-05\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7253e-04 - val_loss: 1.1596e-05\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6960e-04 - val_loss: 1.1368e-05\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6705e-04 - val_loss: 1.1177e-05\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6421e-04 - val_loss: 1.1080e-05\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6153e-04 - val_loss: 1.0867e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5885e-04 - val_loss: 1.0722e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5627e-04 - val_loss: 1.0654e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5362e-04 - val_loss: 1.0423e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5093e-04 - val_loss: 1.0308e-05\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4854e-04 - val_loss: 1.0220e-05\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4587e-04 - val_loss: 9.9962e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4352e-04 - val_loss: 9.8730e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4107e-04 - val_loss: 9.8272e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3863e-04 - val_loss: 9.5969e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3622e-04 - val_loss: 9.4362e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3392e-04 - val_loss: 9.3879e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3153e-04 - val_loss: 9.2021e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2918e-04 - val_loss: 9.0557e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2689e-04 - val_loss: 8.9725e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2473e-04 - val_loss: 8.8217e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2242e-04 - val_loss: 8.7265e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2030e-04 - val_loss: 8.5828e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1802e-04 - val_loss: 8.4658e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1595e-04 - val_loss: 8.3669e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1383e-04 - val_loss: 8.2374e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1167e-04 - val_loss: 8.1369e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0957e-04 - val_loss: 8.0171e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0751e-04 - val_loss: 7.9096e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0547e-04 - val_loss: 7.8139e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0350e-04 - val_loss: 7.6815e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0161e-04 - val_loss: 7.5847e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9966e-04 - val_loss: 7.5485e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9761e-04 - val_loss: 7.4023e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9574e-04 - val_loss: 7.3744e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9385e-04 - val_loss: 7.1953e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9188e-04 - val_loss: 7.0972e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9010e-04 - val_loss: 7.0326e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.8832e-04 - val_loss: 6.9159e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.8650e-04 - val_loss: 6.8251e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.8480e-04 - val_loss: 6.7583e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.8297e-04 - val_loss: 6.6558e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.8119e-04 - val_loss: 6.6000e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.7947e-04 - val_loss: 6.4864e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.7783e-04 - val_loss: 6.4097e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.7623e-04 - val_loss: 6.4468e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.7453e-04 - val_loss: 6.2951e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.7285e-04 - val_loss: 6.1956e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.7124e-04 - val_loss: 6.1415e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6967e-04 - val_loss: 6.0360e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6810e-04 - val_loss: 6.0675e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6662e-04 - val_loss: 5.9278e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6509e-04 - val_loss: 5.8656e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6346e-04 - val_loss: 5.8026e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6209e-04 - val_loss: 5.6999e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.6067e-04 - val_loss: 5.6456e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5911e-04 - val_loss: 5.6019e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5762e-04 - val_loss: 5.4850e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5629e-04 - val_loss: 5.4316e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5477e-04 - val_loss: 5.3868e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5349e-04 - val_loss: 5.3062e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5207e-04 - val_loss: 5.2935e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.5075e-04 - val_loss: 5.1750e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4938e-04 - val_loss: 5.1292e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4807e-04 - val_loss: 5.1012e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4670e-04 - val_loss: 4.9847e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4545e-04 - val_loss: 5.0433e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4418e-04 - val_loss: 4.8806e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4284e-04 - val_loss: 4.8388e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4164e-04 - val_loss: 4.7834e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.4041e-04 - val_loss: 4.7733e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3916e-04 - val_loss: 4.6762e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3801e-04 - val_loss: 4.6629e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3680e-04 - val_loss: 4.5938e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3564e-04 - val_loss: 4.5611e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3446e-04 - val_loss: 4.5457e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3334e-04 - val_loss: 4.4608e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3218e-04 - val_loss: 4.4380e-06\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.3110e-04 - val_loss: 4.3762e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2993e-04 - val_loss: 4.4155e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2891e-04 - val_loss: 4.3862e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2777e-04 - val_loss: 4.2404e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2671e-04 - val_loss: 4.2390e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2562e-04 - val_loss: 4.1606e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2461e-04 - val_loss: 4.1310e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2354e-04 - val_loss: 4.1505e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2251e-04 - val_loss: 4.0619e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2151e-04 - val_loss: 4.0299e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.2054e-04 - val_loss: 3.9835e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1951e-04 - val_loss: 3.9431e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1852e-04 - val_loss: 3.9148e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1751e-04 - val_loss: 3.8864e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1666e-04 - val_loss: 3.8406e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1568e-04 - val_loss: 3.8027e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1473e-04 - val_loss: 3.7696e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1383e-04 - val_loss: 3.7427e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1289e-04 - val_loss: 3.7230e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1200e-04 - val_loss: 3.6791e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1107e-04 - val_loss: 3.6460e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.1021e-04 - val_loss: 3.6368e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0940e-04 - val_loss: 3.6071e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0845e-04 - val_loss: 3.6269e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0763e-04 - val_loss: 3.5450e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0677e-04 - val_loss: 3.5776e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0599e-04 - val_loss: 3.4835e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0511e-04 - val_loss: 3.5154e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0428e-04 - val_loss: 3.4212e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0352e-04 - val_loss: 3.3975e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0269e-04 - val_loss: 3.4182e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0190e-04 - val_loss: 3.3450e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0112e-04 - val_loss: 3.3451e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.0036e-04 - val_loss: 3.2998e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.9588e-05 - val_loss: 3.2741e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.8807e-05 - val_loss: 3.2480e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.8107e-05 - val_loss: 3.2393e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.7322e-05 - val_loss: 3.2024e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.6589e-05 - val_loss: 3.1861e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.5902e-05 - val_loss: 3.1564e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.5188e-05 - val_loss: 3.1365e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.4462e-05 - val_loss: 3.1265e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.3841e-05 - val_loss: 3.1020e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.3102e-05 - val_loss: 3.0835e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.2416e-05 - val_loss: 3.0579e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.1731e-05 - val_loss: 3.0279e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.1121e-05 - val_loss: 3.0163e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 9.0400e-05 - val_loss: 2.9874e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.9757e-05 - val_loss: 3.0003e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.9102e-05 - val_loss: 2.9462e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.8489e-05 - val_loss: 2.9607e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.7841e-05 - val_loss: 2.9202e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.7241e-05 - val_loss: 3.0113e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.6618e-05 - val_loss: 2.8773e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.5972e-05 - val_loss: 2.8749e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.5378e-05 - val_loss: 2.8427e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.4762e-05 - val_loss: 2.8259e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.4216e-05 - val_loss: 2.8551e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.3603e-05 - val_loss: 2.8276e-06\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 3s 3ms/step - loss: 8.3010e-05 - val_loss: 2.8069e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.2462e-05 - val_loss: 2.7671e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.1870e-05 - val_loss: 2.7517e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.1300e-05 - val_loss: 2.7476e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.0765e-05 - val_loss: 2.7274e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 8.0219e-05 - val_loss: 2.7364e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.9644e-05 - val_loss: 2.7016e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.9103e-05 - val_loss: 2.6799e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.8553e-05 - val_loss: 2.6619e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.8028e-05 - val_loss: 2.6474e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.7509e-05 - val_loss: 2.6428e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.6972e-05 - val_loss: 2.6190e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.6462e-05 - val_loss: 2.6669e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.5960e-05 - val_loss: 2.5963e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.5460e-05 - val_loss: 2.5868e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.4992e-05 - val_loss: 2.5995e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.4484e-05 - val_loss: 2.6604e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.4003e-05 - val_loss: 2.5468e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.3504e-05 - val_loss: 2.5377e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.2999e-05 - val_loss: 2.6056e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.2581e-05 - val_loss: 2.5184e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.2069e-05 - val_loss: 2.5002e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.1616e-05 - val_loss: 2.5088e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.1146e-05 - val_loss: 2.4813e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.0651e-05 - val_loss: 2.4959e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 7.0208e-05 - val_loss: 2.4694e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.9755e-05 - val_loss: 2.4563e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.9318e-05 - val_loss: 2.4421e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.8885e-05 - val_loss: 2.4405e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.8446e-05 - val_loss: 2.4372e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.8012e-05 - val_loss: 2.4233e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.7596e-05 - val_loss: 2.4347e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.7163e-05 - val_loss: 2.4018e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.6720e-05 - val_loss: 2.4622e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.6316e-05 - val_loss: 2.4221e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.5901e-05 - val_loss: 2.3940e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.5476e-05 - val_loss: 2.3886e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.5071e-05 - val_loss: 2.3659e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.4708e-05 - val_loss: 2.3504e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.4263e-05 - val_loss: 2.4250e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.3871e-05 - val_loss: 2.3370e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.3469e-05 - val_loss: 2.3222e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.3054e-05 - val_loss: 2.3606e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.2707e-05 - val_loss: 2.3129e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.2316e-05 - val_loss: 2.3350e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.1916e-05 - val_loss: 2.3146e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.1562e-05 - val_loss: 2.3043e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.1165e-05 - val_loss: 2.2821e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.0815e-05 - val_loss: 2.2977e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.0439e-05 - val_loss: 2.2856e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 6.0066e-05 - val_loss: 2.2774e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.9710e-05 - val_loss: 2.2534e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.9343e-05 - val_loss: 2.2501e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.8976e-05 - val_loss: 2.2421e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.8685e-05 - val_loss: 2.2808e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.8320e-05 - val_loss: 2.2877e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.7988e-05 - val_loss: 2.2611e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.7603e-05 - val_loss: 2.2405e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.7290e-05 - val_loss: 2.2215e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.6946e-05 - val_loss: 2.2252e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.6610e-05 - val_loss: 2.2431e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.6269e-05 - val_loss: 2.2005e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.5949e-05 - val_loss: 2.2027e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.5600e-05 - val_loss: 2.2210e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.5281e-05 - val_loss: 2.1746e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.4966e-05 - val_loss: 2.1638e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.4650e-05 - val_loss: 2.1668e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.4334e-05 - val_loss: 2.1645e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.4015e-05 - val_loss: 2.1521e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.3739e-05 - val_loss: 2.1943e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.3431e-05 - val_loss: 2.1383e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.3107e-05 - val_loss: 2.2653e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.2852e-05 - val_loss: 2.1540e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.2492e-05 - val_loss: 2.1277e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.2204e-05 - val_loss: 2.1276e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.1898e-05 - val_loss: 2.1864e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.1597e-05 - val_loss: 2.1081e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.1308e-05 - val_loss: 2.1039e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.1011e-05 - val_loss: 2.1374e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.0740e-05 - val_loss: 2.0980e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.0473e-05 - val_loss: 2.0984e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 5.0184e-05 - val_loss: 2.1071e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.9881e-05 - val_loss: 2.0792e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.9594e-05 - val_loss: 2.0827e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.9323e-05 - val_loss: 2.0851e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.9051e-05 - val_loss: 2.0795e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.8816e-05 - val_loss: 2.0800e-06\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.8529e-05 - val_loss: 2.0557e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.8243e-05 - val_loss: 2.0769e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.7976e-05 - val_loss: 2.0517e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.7698e-05 - val_loss: 2.0486e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.7447e-05 - val_loss: 2.0421e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.7183e-05 - val_loss: 2.0534e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.6927e-05 - val_loss: 2.0496e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.6677e-05 - val_loss: 2.0292e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.6434e-05 - val_loss: 2.0241e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.6154e-05 - val_loss: 2.0178e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.5920e-05 - val_loss: 2.0154e-06\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.5673e-05 - val_loss: 2.0257e-06\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.5436e-05 - val_loss: 2.0045e-06\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.5184e-05 - val_loss: 2.0022e-06\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4961e-05 - val_loss: 1.9973e-06\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4728e-05 - val_loss: 2.0527e-06\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4518e-05 - val_loss: 2.0397e-06\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4262e-05 - val_loss: 2.0038e-06\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.4004e-05 - val_loss: 1.9783e-06\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.3786e-05 - val_loss: 1.9773e-06\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.3538e-05 - val_loss: 2.0047e-06\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.3316e-05 - val_loss: 1.9857e-06\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.3095e-05 - val_loss: 1.9727e-06\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.2870e-05 - val_loss: 1.9601e-06\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.2678e-05 - val_loss: 1.9534e-06\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.2418e-05 - val_loss: 1.9613e-06\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.2210e-05 - val_loss: 1.9750e-06\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1994e-05 - val_loss: 1.9436e-06\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1758e-05 - val_loss: 1.9407e-06\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1534e-05 - val_loss: 1.9383e-06\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1338e-05 - val_loss: 2.0734e-06\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.1158e-05 - val_loss: 1.9837e-06\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0935e-05 - val_loss: 1.9470e-06\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0729e-05 - val_loss: 1.9166e-06\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0503e-05 - val_loss: 1.9469e-06\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0295e-05 - val_loss: 1.9272e-06\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 4.0063e-05 - val_loss: 1.9041e-06\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9872e-05 - val_loss: 1.9022e-06\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9686e-05 - val_loss: 1.8978e-06\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9447e-05 - val_loss: 1.8935e-06\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9251e-05 - val_loss: 1.8974e-06\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.9118e-05 - val_loss: 1.8892e-06\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8873e-05 - val_loss: 1.9781e-06\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8738e-05 - val_loss: 1.9964e-06\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8541e-05 - val_loss: 1.9434e-06\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8311e-05 - val_loss: 1.8778e-06\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.8084e-05 - val_loss: 1.8866e-06\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7914e-05 - val_loss: 1.9170e-06\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7723e-05 - val_loss: 1.8854e-06\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7519e-05 - val_loss: 1.9216e-06\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7359e-05 - val_loss: 1.9166e-06\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.7152e-05 - val_loss: 1.8695e-06\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6972e-05 - val_loss: 1.8434e-06\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6856e-05 - val_loss: 1.8453e-06\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6629e-05 - val_loss: 1.8889e-06\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6509e-05 - val_loss: 1.8309e-06\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6237e-05 - val_loss: 1.8452e-06\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.6042e-05 - val_loss: 1.8232e-06\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5861e-05 - val_loss: 1.8488e-06\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5694e-05 - val_loss: 1.8433e-06\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5522e-05 - val_loss: 1.8250e-06\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5349e-05 - val_loss: 1.8293e-06\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5189e-05 - val_loss: 1.9060e-06\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.5045e-05 - val_loss: 1.9124e-06\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4873e-05 - val_loss: 1.9610e-06\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4700e-05 - val_loss: 1.8340e-06\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4511e-05 - val_loss: 1.8474e-06\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4331e-05 - val_loss: 1.8046e-06\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4163e-05 - val_loss: 1.8081e-06\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.4003e-05 - val_loss: 1.7917e-06\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3827e-05 - val_loss: 1.7728e-06\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3654e-05 - val_loss: 1.7704e-06\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3554e-05 - val_loss: 1.7652e-06\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3375e-05 - val_loss: 1.7629e-06\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3188e-05 - val_loss: 1.8189e-06\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.3037e-05 - val_loss: 1.8460e-06\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2896e-05 - val_loss: 1.8080e-06\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2713e-05 - val_loss: 1.7512e-06\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2542e-05 - val_loss: 1.7411e-06\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2390e-05 - val_loss: 1.7439e-06\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2235e-05 - val_loss: 1.7722e-06\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.2108e-05 - val_loss: 1.7767e-06\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1964e-05 - val_loss: 1.7632e-06\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1801e-05 - val_loss: 1.7283e-06\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1643e-05 - val_loss: 1.7210e-06\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1478e-05 - val_loss: 1.7152e-06\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1334e-05 - val_loss: 1.7204e-06\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1190e-05 - val_loss: 1.7537e-06\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.1047e-05 - val_loss: 1.7204e-06\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0922e-05 - val_loss: 1.7036e-06\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0769e-05 - val_loss: 1.7040e-06\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0643e-05 - val_loss: 1.7900e-06\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0504e-05 - val_loss: 1.7435e-06\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0379e-05 - val_loss: 1.8198e-06\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0420e-05 - val_loss: 1.6930e-06\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 3.0062e-05 - val_loss: 1.6947e-06\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9910e-05 - val_loss: 1.7003e-06\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9765e-05 - val_loss: 1.6675e-06\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9645e-05 - val_loss: 1.7289e-06\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9511e-05 - val_loss: 1.6769e-06\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9357e-05 - val_loss: 1.6553e-06\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9237e-05 - val_loss: 1.6880e-06\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.9093e-05 - val_loss: 1.6503e-06\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8956e-05 - val_loss: 1.7200e-06\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8858e-05 - val_loss: 1.7297e-06\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8857e-05 - val_loss: 1.6939e-06\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8582e-05 - val_loss: 1.6323e-06\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8433e-05 - val_loss: 1.6471e-06\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8390e-05 - val_loss: 1.6864e-06\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8204e-05 - val_loss: 1.6895e-06\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.8100e-05 - val_loss: 1.6113e-06\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7921e-05 - val_loss: 1.6099e-06\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7810e-05 - val_loss: 1.6776e-06\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7735e-05 - val_loss: 1.6034e-06\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7559e-05 - val_loss: 1.5959e-06\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7445e-05 - val_loss: 1.6803e-06\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7349e-05 - val_loss: 1.6353e-06\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7261e-05 - val_loss: 1.5861e-06\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.7070e-05 - val_loss: 1.5820e-06\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6976e-05 - val_loss: 1.6210e-06\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6851e-05 - val_loss: 1.6313e-06\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6761e-05 - val_loss: 1.5650e-06\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6604e-05 - val_loss: 1.5962e-06\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6543e-05 - val_loss: 1.5659e-06\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6371e-05 - val_loss: 1.5903e-06\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6302e-05 - val_loss: 1.5594e-06\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6138e-05 - val_loss: 1.5487e-06\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.6041e-05 - val_loss: 1.5493e-06\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5925e-05 - val_loss: 1.5834e-06\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5813e-05 - val_loss: 1.5827e-06\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5736e-05 - val_loss: 1.5617e-06\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5675e-05 - val_loss: 1.6271e-06\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5500e-05 - val_loss: 1.5616e-06\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5387e-05 - val_loss: 1.5092e-06\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5276e-05 - val_loss: 1.5920e-06\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5279e-05 - val_loss: 1.6502e-06\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5099e-05 - val_loss: 1.5419e-06\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4994e-05 - val_loss: 1.4946e-06\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4837e-05 - val_loss: 1.5300e-06\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4801e-05 - val_loss: 1.5019e-06\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4619e-05 - val_loss: 1.4788e-06\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4562e-05 - val_loss: 1.5867e-06\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4437e-05 - val_loss: 1.4967e-06\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4365e-05 - val_loss: 1.5264e-06\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4232e-05 - val_loss: 1.4902e-06\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4400e-05 - val_loss: 2.3011e-06\n",
      "Epoch 729/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.5015e-05 - val_loss: 2.4649e-06\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.4399e-05 - val_loss: 1.4502e-06\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3953e-05 - val_loss: 1.7228e-06\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3836e-05 - val_loss: 1.4607e-06\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3625e-05 - val_loss: 1.4852e-06\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3519e-05 - val_loss: 1.4803e-06\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3526e-05 - val_loss: 1.5646e-06\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3372e-05 - val_loss: 1.6027e-06\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3581e-05 - val_loss: 2.1056e-06\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3831e-05 - val_loss: 2.0822e-06\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3452e-05 - val_loss: 1.4467e-06\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3079e-05 - val_loss: 1.9785e-06\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.3360e-05 - val_loss: 1.5728e-06\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2813e-05 - val_loss: 1.4388e-06\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2666e-05 - val_loss: 1.4024e-06\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2609e-05 - val_loss: 1.5488e-06\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2616e-05 - val_loss: 1.3929e-06\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2446e-05 - val_loss: 1.6595e-06\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2637e-05 - val_loss: 1.7250e-06\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2367e-05 - val_loss: 1.4498e-06\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2633e-05 - val_loss: 2.6033e-06\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2842e-05 - val_loss: 1.4181e-06\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2016e-05 - val_loss: 1.5746e-06\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2148e-05 - val_loss: 1.7354e-06\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1981e-05 - val_loss: 1.4311e-06\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1704e-05 - val_loss: 1.3596e-06\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1676e-05 - val_loss: 1.7610e-06\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.2001e-05 - val_loss: 1.7858e-06\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1695e-05 - val_loss: 1.4196e-06\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1369e-05 - val_loss: 1.4060e-06\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1355e-05 - val_loss: 1.4242e-06\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1245e-05 - val_loss: 1.3719e-06\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1114e-05 - val_loss: 1.3440e-06\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1096e-05 - val_loss: 1.7036e-06\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1558e-05 - val_loss: 1.9148e-06\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1064e-05 - val_loss: 1.3280e-06\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0832e-05 - val_loss: 1.5619e-06\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1015e-05 - val_loss: 1.6751e-06\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0780e-05 - val_loss: 1.3456e-06\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0544e-05 - val_loss: 1.3126e-06\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0456e-05 - val_loss: 1.3101e-06\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0389e-05 - val_loss: 1.3613e-06\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0480e-05 - val_loss: 1.8750e-06\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1288e-05 - val_loss: 2.9091e-06\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.1500e-05 - val_loss: 1.8748e-06\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0265e-05 - val_loss: 1.3025e-06\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0074e-05 - val_loss: 1.4993e-06\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0253e-05 - val_loss: 1.6699e-06\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 2.0070e-05 - val_loss: 1.3471e-06\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9790e-05 - val_loss: 1.2764e-06\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9701e-05 - val_loss: 1.4068e-06\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9791e-05 - val_loss: 1.3968e-06\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9596e-05 - val_loss: 1.4829e-06\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9904e-05 - val_loss: 1.8678e-06\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9781e-05 - val_loss: 1.4817e-06\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9483e-05 - val_loss: 1.3805e-06\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9298e-05 - val_loss: 1.3884e-06\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9469e-05 - val_loss: 1.6204e-06\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9766e-05 - val_loss: 2.1908e-06\n",
      "Epoch 788/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 3s 3ms/step - loss: 1.9765e-05 - val_loss: 1.8063e-06\n",
      "Epoch 00788: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_29 (LSTM)               (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 677\n",
      "Trainable params: 677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 8s 9ms/step - loss: 0.0986 - val_loss: 0.0966\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0954 - val_loss: 0.0937\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0913 - val_loss: 0.0910\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0911 - val_loss: 0.0913\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0913 - val_loss: 0.0913\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0911 - val_loss: 0.0910\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0909 - val_loss: 0.0909\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0909 - val_loss: 0.0909\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0909 - val_loss: 0.0909\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0908 - val_loss: 0.0909\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0908 - val_loss: 0.0909\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0907 - val_loss: 0.0908\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0907 - val_loss: 0.0908\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0907 - val_loss: 0.0908\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0907 - val_loss: 0.0908\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0907 - val_loss: 0.0907\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0907 - val_loss: 0.0907\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0907 - val_loss: 0.0907\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0907\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0907\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0907\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0907\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0906\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0906\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0906 - val_loss: 0.0906\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0906 - val_loss: 0.0906\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0906\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0906\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0905 - val_loss: 0.0905\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0905\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0905\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0904 - val_loss: 0.0904\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0903 - val_loss: 0.0904\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0902 - val_loss: 0.0903\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0902 - val_loss: 0.0902\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0901 - val_loss: 0.0902\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0900 - val_loss: 0.0900\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0900 - val_loss: 0.0900\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0899 - val_loss: 0.0899\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0899 - val_loss: 0.0899\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0898 - val_loss: 0.0898\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0898 - val_loss: 0.0897\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0897 - val_loss: 0.0896\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0896 - val_loss: 0.0895\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0894 - val_loss: 0.0893\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0892 - val_loss: 0.0890\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0889 - val_loss: 0.0887\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0886 - val_loss: 0.0883\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0881 - val_loss: 0.0877\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0874 - val_loss: 0.0869\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0864 - val_loss: 0.0856\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0850 - val_loss: 0.0838\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0828 - val_loss: 0.0811\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0798 - val_loss: 0.0777\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0765 - val_loss: 0.0745\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0738 - val_loss: 0.0729\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0730 - val_loss: 0.0730\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0729 - val_loss: 0.0727\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0727 - val_loss: 0.0725\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0724 - val_loss: 0.0722\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0721 - val_loss: 0.0718\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0717 - val_loss: 0.0715\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0715 - val_loss: 0.0712\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0712 - val_loss: 0.0710\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0710 - val_loss: 0.0707\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0707 - val_loss: 0.0704\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0705 - val_loss: 0.0702\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0703 - val_loss: 0.0700\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0701 - val_loss: 0.0698\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0698 - val_loss: 0.0696\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0696 - val_loss: 0.0694\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0694 - val_loss: 0.0691\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0692 - val_loss: 0.0689\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0689 - val_loss: 0.0686\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0686 - val_loss: 0.0683\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0684 - val_loss: 0.0682\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0684 - val_loss: 0.0681\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0679 - val_loss: 0.0674\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0675 - val_loss: 0.0671\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0672 - val_loss: 0.0667\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0668 - val_loss: 0.0663\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0664 - val_loss: 0.0659\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0660 - val_loss: 0.0665\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0659 - val_loss: 0.0650\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0652 - val_loss: 0.0647\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0647 - val_loss: 0.0640\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0641 - val_loss: 0.0639\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0638 - val_loss: 0.0645\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0639 - val_loss: 0.0629\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0629 - val_loss: 0.0625\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0623 - val_loss: 0.0616\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0617 - val_loss: 0.0608\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0610 - val_loss: 0.0603\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0604 - val_loss: 0.0598\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0599 - val_loss: 0.0592\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0592 - val_loss: 0.0584\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0586 - val_loss: 0.0578\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0579 - val_loss: 0.0572\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0573 - val_loss: 0.0566\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0567 - val_loss: 0.0560\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0562 - val_loss: 0.0555\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0556 - val_loss: 0.0550\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0552 - val_loss: 0.0545\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0548 - val_loss: 0.0542\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0543 - val_loss: 0.0536\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0536 - val_loss: 0.0529\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0532 - val_loss: 0.0524\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0526 - val_loss: 0.0520\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0522 - val_loss: 0.0514\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0518 - val_loss: 0.0514\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0515 - val_loss: 0.0505\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0509 - val_loss: 0.0502\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0503 - val_loss: 0.0496\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0499 - val_loss: 0.0491\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0493 - val_loss: 0.0486\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0489 - val_loss: 0.0481\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0483 - val_loss: 0.0476\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0479 - val_loss: 0.0471\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0474 - val_loss: 0.0466\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0469 - val_loss: 0.0461\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0465 - val_loss: 0.0456\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0460 - val_loss: 0.0451\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0455 - val_loss: 0.0447\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0451 - val_loss: 0.0441\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0446 - val_loss: 0.0436\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0441 - val_loss: 0.0431\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0436 - val_loss: 0.0426\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0430 - val_loss: 0.0420\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0425 - val_loss: 0.0414\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0419 - val_loss: 0.0407\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0413 - val_loss: 0.0401\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0407 - val_loss: 0.0394\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0400 - val_loss: 0.0387\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0393 - val_loss: 0.0380\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0386 - val_loss: 0.0372\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0379 - val_loss: 0.0364\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0371 - val_loss: 0.0356\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0363 - val_loss: 0.0347\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0354 - val_loss: 0.0337\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0344 - val_loss: 0.0327\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0334 - val_loss: 0.0316\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0323 - val_loss: 0.0303\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0311 - val_loss: 0.0291\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0298 - val_loss: 0.0277\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0284 - val_loss: 0.0261\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0269 - val_loss: 0.0245\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0252 - val_loss: 0.0227\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0234 - val_loss: 0.0208\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0215 - val_loss: 0.0188\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0195 - val_loss: 0.0168\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0176 - val_loss: 0.0149\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0158 - val_loss: 0.0132\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0130 - val_loss: 0.0106\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0069 - val_loss: 0.0050\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0056 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0023 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0018 - val_loss: 9.8424e-04\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0017 - val_loss: 9.6679e-04\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0017 - val_loss: 9.4933e-04\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0017 - val_loss: 9.3357e-04\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0017 - val_loss: 9.1549e-04\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0016 - val_loss: 8.9850e-04\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0016 - val_loss: 8.8159e-04\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0016 - val_loss: 8.6517e-04\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0016 - val_loss: 8.4817e-04\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0015 - val_loss: 8.3153e-04\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0015 - val_loss: 8.1590e-04\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0015 - val_loss: 7.9931e-04\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0015 - val_loss: 7.8353e-04\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0015 - val_loss: 7.6815e-04\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0014 - val_loss: 7.5195e-04\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0014 - val_loss: 7.3609e-04\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0014 - val_loss: 7.2053e-04\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0014 - val_loss: 7.0512e-04\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0013 - val_loss: 6.9012e-04\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0013 - val_loss: 6.7476e-04\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0013 - val_loss: 6.6001e-04\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0013 - val_loss: 6.4527e-04\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0013 - val_loss: 6.3120e-04\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0012 - val_loss: 6.1614e-04\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0012 - val_loss: 6.0184e-04\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0012 - val_loss: 5.8848e-04\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0012 - val_loss: 5.7412e-04\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0011 - val_loss: 5.6049e-04\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0011 - val_loss: 5.4735e-04\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0011 - val_loss: 5.3392e-04\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0011 - val_loss: 5.2074e-04\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0011 - val_loss: 5.0812e-04\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0010 - val_loss: 4.9635e-04\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0010 - val_loss: 4.8525e-04\n",
      "Epoch 437/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.0010 - val_loss: 4.7444e-04\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.9154e-04 - val_loss: 4.6415e-04\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.7400e-04 - val_loss: 4.5366e-04\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.5754e-04 - val_loss: 4.4345e-04\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.4033e-04 - val_loss: 4.3337e-04\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.2465e-04 - val_loss: 4.2389e-04\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.0800e-04 - val_loss: 4.1420e-04\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.9278e-04 - val_loss: 4.0472e-04\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.7628e-04 - val_loss: 3.9543e-04\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.6098e-04 - val_loss: 3.8632e-04\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.4621e-04 - val_loss: 3.7813e-04\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.3104e-04 - val_loss: 3.6945e-04\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.1724e-04 - val_loss: 3.6013e-04\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.0274e-04 - val_loss: 3.5161e-04\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.8926e-04 - val_loss: 3.4405e-04\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.7433e-04 - val_loss: 3.3612e-04\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.6003e-04 - val_loss: 3.2747e-04\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.4717e-04 - val_loss: 3.1940e-04\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.3400e-04 - val_loss: 3.1179e-04\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.2024e-04 - val_loss: 3.0389e-04\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.0836e-04 - val_loss: 2.9637e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.9598e-04 - val_loss: 2.9066e-04\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.8267e-04 - val_loss: 2.8236e-04\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.7074e-04 - val_loss: 2.7620e-04\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.5899e-04 - val_loss: 2.6813e-04\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.4704e-04 - val_loss: 2.6518e-04\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.3717e-04 - val_loss: 2.5502e-04\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.2433e-04 - val_loss: 2.5108e-04\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.1401e-04 - val_loss: 2.4233e-04\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.0219e-04 - val_loss: 2.3708e-04\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.9217e-04 - val_loss: 2.3066e-04\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.8095e-04 - val_loss: 2.2450e-04\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.7077e-04 - val_loss: 2.1967e-04\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.6218e-04 - val_loss: 2.1713e-04\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.5219e-04 - val_loss: 2.0805e-04\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.4306e-04 - val_loss: 2.0750e-04\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 5.3448e-04 - val_loss: 1.9833e-04\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 5.2397e-04 - val_loss: 1.9514e-04\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.1528e-04 - val_loss: 1.8951e-04\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 5.0547e-04 - val_loss: 1.8449e-04\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 4.9640e-04 - val_loss: 1.7891e-04\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.8761e-04 - val_loss: 1.7405e-04\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 4.7931e-04 - val_loss: 1.6972e-04\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.7168e-04 - val_loss: 1.6595e-04\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 4.6375e-04 - val_loss: 1.6380e-04\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.5712e-04 - val_loss: 1.6067e-04\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.4920e-04 - val_loss: 1.5439e-04\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 4.4155e-04 - val_loss: 1.4966e-04\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.3445e-04 - val_loss: 1.4572e-04\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 4.2595e-04 - val_loss: 1.4209e-04\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.1862e-04 - val_loss: 1.3849e-04\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 4.1196e-04 - val_loss: 1.3894e-04\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.0728e-04 - val_loss: 1.3505e-04\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.9978e-04 - val_loss: 1.2895e-04\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.9443e-04 - val_loss: 1.2632e-04\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.8611e-04 - val_loss: 1.2275e-04\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.7925e-04 - val_loss: 1.1975e-04\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.7310e-04 - val_loss: 1.1606e-04\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.6682e-04 - val_loss: 1.1324e-04\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.6172e-04 - val_loss: 1.1140e-04\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.5572e-04 - val_loss: 1.0806e-04\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.5072e-04 - val_loss: 1.0543e-04\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.4641e-04 - val_loss: 1.0300e-04\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.3952e-04 - val_loss: 1.0058e-04\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.3805e-04 - val_loss: 9.8258e-05\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.2873e-04 - val_loss: 9.5716e-05\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.2394e-04 - val_loss: 9.4012e-05\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.1919e-04 - val_loss: 9.1248e-05\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.1327e-04 - val_loss: 8.9187e-05\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.0847e-04 - val_loss: 8.6941e-05\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 3.0370e-04 - val_loss: 8.4959e-05\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.9931e-04 - val_loss: 8.4216e-05\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.9735e-04 - val_loss: 8.4310e-05\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.9230e-04 - val_loss: 8.5380e-05\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.8780e-04 - val_loss: 7.7971e-05\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.8539e-04 - val_loss: 7.9208e-05\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.8081e-04 - val_loss: 8.3815e-05\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.7687e-04 - val_loss: 7.2732e-05\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.6987e-04 - val_loss: 7.1652e-05\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.6645e-04 - val_loss: 7.2212e-05\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.6385e-04 - val_loss: 6.9327e-05\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.5931e-04 - val_loss: 6.7145e-05\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.5527e-04 - val_loss: 6.8319e-05\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.5711e-04 - val_loss: 6.5154e-05\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.4851e-04 - val_loss: 6.3005e-05\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.4488e-04 - val_loss: 6.2278e-05\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.4290e-04 - val_loss: 6.0825e-05\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.3827e-04 - val_loss: 5.9352e-05\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.3617e-04 - val_loss: 5.8777e-05\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.3445e-04 - val_loss: 6.4135e-05\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.3635e-04 - val_loss: 5.7153e-05\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.2622e-04 - val_loss: 5.5591e-05\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.3030e-04 - val_loss: 6.4348e-05\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.2470e-04 - val_loss: 6.4550e-05\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.3056e-04 - val_loss: 5.2447e-05\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 2.1732e-04 - val_loss: 5.1345e-05\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.1280e-04 - val_loss: 5.1489e-05\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.1156e-04 - val_loss: 6.2053e-05\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.1393e-04 - val_loss: 5.6130e-05\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.1382e-04 - val_loss: 5.0623e-05\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.0994e-04 - val_loss: 4.7471e-05\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.0434e-04 - val_loss: 4.6968e-05\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.0553e-04 - val_loss: 4.7189e-05\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.9685e-04 - val_loss: 4.5207e-05\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.9483e-04 - val_loss: 4.4568e-05\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.9113e-04 - val_loss: 4.3823e-05\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.8832e-04 - val_loss: 4.3746e-05\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.8809e-04 - val_loss: 4.2781e-05\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.8391e-04 - val_loss: 4.1893e-05\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.8231e-04 - val_loss: 4.2355e-05\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.8164e-04 - val_loss: 4.9092e-05\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.8184e-04 - val_loss: 4.9961e-05\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.8287e-04 - val_loss: 4.4079e-05\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.7815e-04 - val_loss: 4.2311e-05\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.7449e-04 - val_loss: 3.8497e-05\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.7149e-04 - val_loss: 3.7997e-05\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.7015e-04 - val_loss: 3.7170e-05\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6667e-04 - val_loss: 3.6884e-05\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6726e-04 - val_loss: 4.0695e-05\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6451e-04 - val_loss: 3.9000e-05\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6293e-04 - val_loss: 3.5205e-05\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6295e-04 - val_loss: 3.5808e-05\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6036e-04 - val_loss: 3.4767e-05\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.5880e-04 - val_loss: 3.7675e-05\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.5628e-04 - val_loss: 3.4771e-05\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.5430e-04 - val_loss: 3.7202e-05\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.5316e-04 - val_loss: 3.3529e-05\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.5086e-04 - val_loss: 3.2576e-05\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.4916e-04 - val_loss: 3.2435e-05\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.4780e-04 - val_loss: 3.1939e-05\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.4832e-04 - val_loss: 3.3919e-05\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.5018e-04 - val_loss: 3.2776e-05\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.4533e-04 - val_loss: 3.0768e-05\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.4441e-04 - val_loss: 3.0541e-05\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.4414e-04 - val_loss: 3.0261e-05\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.4134e-04 - val_loss: 2.9974e-05\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3955e-04 - val_loss: 2.9648e-05\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3812e-04 - val_loss: 2.9507e-05\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3627e-04 - val_loss: 2.9545e-05\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3636e-04 - val_loss: 2.9493e-05\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3442e-04 - val_loss: 2.9399e-05\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.3313e-04 - val_loss: 2.8472e-05\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3257e-04 - val_loss: 3.0459e-05\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3213e-04 - val_loss: 2.9536e-05\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.3154e-04 - val_loss: 3.0133e-05\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.3259e-04 - val_loss: 3.2415e-05\n",
      "Epoch 583/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.3046e-04 - val_loss: 3.1603e-05\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2848e-04 - val_loss: 2.8787e-05\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2625e-04 - val_loss: 2.7386e-05\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2514e-04 - val_loss: 3.0191e-05\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2532e-04 - val_loss: 2.7526e-05\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.2330e-04 - val_loss: 2.6581e-05\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2215e-04 - val_loss: 2.6031e-05\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2094e-04 - val_loss: 2.7477e-05\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.2113e-04 - val_loss: 2.6364e-05\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1952e-04 - val_loss: 2.5768e-05\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1883e-04 - val_loss: 2.5323e-05\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1739e-04 - val_loss: 2.7261e-05\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1786e-04 - val_loss: 2.6027e-05\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1727e-04 - val_loss: 2.5169e-05\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1687e-04 - val_loss: 2.7286e-05\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1456e-04 - val_loss: 2.4585e-05\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1346e-04 - val_loss: 2.4348e-05\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1339e-04 - val_loss: 2.6333e-05\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1354e-04 - val_loss: 2.9653e-05\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1331e-04 - val_loss: 3.0797e-05\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1280e-04 - val_loss: 3.0001e-05\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 3s 4ms/step - loss: 1.1332e-04 - val_loss: 2.4584e-05\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1097e-04 - val_loss: 2.4523e-05\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0797e-04 - val_loss: 2.3342e-05\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0685e-04 - val_loss: 2.3806e-05\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.0634e-04 - val_loss: 2.3282e-05\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0551e-04 - val_loss: 2.2896e-05\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0482e-04 - val_loss: 2.3254e-05\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0453e-04 - val_loss: 2.4311e-05\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.0445e-04 - val_loss: 2.3519e-05\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.0302e-04 - val_loss: 2.2576e-05\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.0218e-04 - val_loss: 2.2222e-05\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0133e-04 - val_loss: 2.2261e-05\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0116e-04 - val_loss: 2.2088e-05\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0156e-04 - val_loss: 2.1849e-05\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.0444e-04 - val_loss: 2.5824e-05\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 1.0169e-04 - val_loss: 2.6347e-05\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.9899e-05 - val_loss: 2.4757e-05\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.9153e-05 - val_loss: 2.1503e-05\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.6964e-05 - val_loss: 2.1348e-05\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.7179e-05 - val_loss: 2.2956e-05\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.5878e-05 - val_loss: 2.1328e-05\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.7737e-05 - val_loss: 2.2377e-05\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.6487e-05 - val_loss: 2.4715e-05\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.5709e-05 - val_loss: 2.6354e-05\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.5845e-05 - val_loss: 2.2400e-05\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.3927e-05 - val_loss: 2.1015e-05\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.2110e-05 - val_loss: 2.0718e-05\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.2600e-05 - val_loss: 2.1147e-05\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.1249e-05 - val_loss: 2.0474e-05\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.0639e-05 - val_loss: 2.0801e-05\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.0575e-05 - val_loss: 2.5997e-05\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 9.4392e-05 - val_loss: 2.1520e-05\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.3733e-05 - val_loss: 2.0013e-05\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.1335e-05 - val_loss: 2.3356e-05\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.9940e-05 - val_loss: 2.8138e-05\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.1605e-05 - val_loss: 2.0313e-05\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.8575e-05 - val_loss: 2.0552e-05\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.7703e-05 - val_loss: 2.1851e-05\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.8767e-05 - val_loss: 3.1420e-05\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.9949e-05 - val_loss: 2.6791e-05\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.7461e-05 - val_loss: 2.3035e-05\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.6056e-05 - val_loss: 1.9698e-05\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.5399e-05 - val_loss: 2.0450e-05\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.3599e-05 - val_loss: 1.9157e-05\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.2686e-05 - val_loss: 1.9848e-05\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.3694e-05 - val_loss: 1.8890e-05\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.2081e-05 - val_loss: 1.8789e-05\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.1192e-05 - val_loss: 1.9628e-05\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.1376e-05 - val_loss: 2.0671e-05\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.5471e-05 - val_loss: 2.1233e-05\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.0707e-05 - val_loss: 1.9248e-05\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.9892e-05 - val_loss: 1.9642e-05\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 8.1439e-05 - val_loss: 1.9246e-05\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.9538e-05 - val_loss: 2.0847e-05\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.9182e-05 - val_loss: 1.8966e-05\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.9638e-05 - val_loss: 1.8715e-05\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.7849e-05 - val_loss: 1.9209e-05\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.7451e-05 - val_loss: 1.9749e-05\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.7178e-05 - val_loss: 2.0189e-05\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.7141e-05 - val_loss: 1.8027e-05\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.5628e-05 - val_loss: 1.8274e-05\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.5613e-05 - val_loss: 1.7859e-05\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.4769e-05 - val_loss: 1.8183e-05\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.4396e-05 - val_loss: 1.7884e-05\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.3895e-05 - val_loss: 1.7904e-05\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.3569e-05 - val_loss: 1.9449e-05\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 7.4693e-05 - val_loss: 1.7485e-05\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.2698e-05 - val_loss: 1.9166e-05\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.3688e-05 - val_loss: 1.8373e-05\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.3083e-05 - val_loss: 1.7807e-05\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.1533e-05 - val_loss: 1.7391e-05\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.1027e-05 - val_loss: 1.7351e-05\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.3053e-05 - val_loss: 2.0656e-05\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.1678e-05 - val_loss: 1.7397e-05\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.1140e-05 - val_loss: 2.0564e-05\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.1088e-05 - val_loss: 2.2273e-05\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.6056e-05 - val_loss: 1.8862e-05\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.9213e-05 - val_loss: 1.7123e-05\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.9228e-05 - val_loss: 1.8183e-05\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.8365e-05 - val_loss: 1.6765e-05\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.9362e-05 - val_loss: 1.9561e-05\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.0261e-05 - val_loss: 2.2273e-05\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.9376e-05 - val_loss: 1.6606e-05\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.6591e-05 - val_loss: 1.7061e-05\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.6274e-05 - val_loss: 1.7455e-05\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.8159e-05 - val_loss: 2.1272e-05\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.8999e-05 - val_loss: 1.6436e-05\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.8224e-05 - val_loss: 2.3095e-05\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.7389e-05 - val_loss: 2.3986e-05\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.2555e-05 - val_loss: 1.6466e-05\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.5731e-05 - val_loss: 1.9247e-05\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 6.4951e-05 - val_loss: 1.7641e-05\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.5434e-05 - val_loss: 1.6096e-05\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3845e-05 - val_loss: 1.7184e-05\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3567e-05 - val_loss: 1.8186e-05\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.2934e-05 - val_loss: 1.6558e-05\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3378e-05 - val_loss: 1.7413e-05\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3453e-05 - val_loss: 1.7378e-05\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3207e-05 - val_loss: 1.8345e-05\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.2037e-05 - val_loss: 1.8357e-05\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.6622e-05 - val_loss: 1.8005e-05\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.2256e-05 - val_loss: 2.2862e-05\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3253e-05 - val_loss: 1.6430e-05\n",
      "Epoch 00706: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,6):\n",
    "    numOfLayers = i\n",
    "    numOfNeurons = 4\n",
    "    [model, validatoinLoss, numOfEpochs,_] = trainLSTM(numOfLayers, numOfNeurons)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Models validation loss vs. depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Depth')\n",
    "plt.xticks(np.arange(5), [1,2,3,4,5])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the figure above, we had the best performance with 2 LSTM layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final LSTM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the final LSTM architecture with 2 LSTM layers each with 4 neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_38 (LSTM)               (None, 100, 4)            96        \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100, 1)            5         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.0937 - val_loss: 0.0932\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0932 - val_loss: 0.0932\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0929 - val_loss: 0.0927\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0926 - val_loss: 0.0926\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0924 - val_loss: 0.0923\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0921 - val_loss: 0.0921\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0919 - val_loss: 0.0919\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0917 - val_loss: 0.0917\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0915 - val_loss: 0.0915\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0913 - val_loss: 0.0913\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0912 - val_loss: 0.0911\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0910 - val_loss: 0.0909\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0908 - val_loss: 0.0908\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0907 - val_loss: 0.0906\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0905 - val_loss: 0.0904\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0903 - val_loss: 0.0903\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0901 - val_loss: 0.0901\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0900 - val_loss: 0.0899\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0898 - val_loss: 0.0897\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0896 - val_loss: 0.0895\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0894 - val_loss: 0.0893\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0892 - val_loss: 0.0891\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0890 - val_loss: 0.0888\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0887 - val_loss: 0.0886\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0884 - val_loss: 0.0883\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0882 - val_loss: 0.0880\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0878 - val_loss: 0.0877\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0875 - val_loss: 0.0873\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0871 - val_loss: 0.0869\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0867 - val_loss: 0.0864\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0862 - val_loss: 0.0859\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0857 - val_loss: 0.0854\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0851 - val_loss: 0.0847\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0845 - val_loss: 0.0841\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0837 - val_loss: 0.0833\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0830 - val_loss: 0.0825\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0821 - val_loss: 0.0816\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0811 - val_loss: 0.0805\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0801 - val_loss: 0.0794\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0790 - val_loss: 0.0782\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0777 - val_loss: 0.0769\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0763 - val_loss: 0.0755\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0749 - val_loss: 0.0739\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0732 - val_loss: 0.0722\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0715 - val_loss: 0.0704\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0696 - val_loss: 0.0684\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0676 - val_loss: 0.0663\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0655 - val_loss: 0.0641\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0632 - val_loss: 0.0618\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0609 - val_loss: 0.0593\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0584 - val_loss: 0.0568\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0558 - val_loss: 0.0542\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0532 - val_loss: 0.0515\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0505 - val_loss: 0.0489\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0478 - val_loss: 0.0462\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0452 - val_loss: 0.0436\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0427 - val_loss: 0.0411\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0402 - val_loss: 0.0387\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0379 - val_loss: 0.0364\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0355 - val_loss: 0.0341\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0333 - val_loss: 0.0319\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0310 - val_loss: 0.0296\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.0274\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0265 - val_loss: 0.0252\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0221 - val_loss: 0.0208\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0200 - val_loss: 0.0187\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0166\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0010 - val_loss: 9.5549e-04\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2179e-04 - val_loss: 8.8013e-04\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4935e-04 - val_loss: 8.1627e-04\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8754e-04 - val_loss: 7.6171e-04\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3451e-04 - val_loss: 7.1471e-04\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8859e-04 - val_loss: 6.7397e-04\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4869e-04 - val_loss: 6.3843e-04\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1381e-04 - val_loss: 6.0723e-04\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8313e-04 - val_loss: 5.7969e-04\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5609e-04 - val_loss: 5.5521e-04\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3189e-04 - val_loss: 5.3336e-04\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1035e-04 - val_loss: 5.1374e-04\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9101e-04 - val_loss: 4.9601e-04\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7355e-04 - val_loss: 4.7991e-04\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5767e-04 - val_loss: 4.6519e-04\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4320e-04 - val_loss: 4.5167e-04\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2990e-04 - val_loss: 4.3919e-04\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1767e-04 - val_loss: 4.2760e-04\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0630e-04 - val_loss: 4.1678e-04\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9575e-04 - val_loss: 4.0662e-04\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8584e-04 - val_loss: 3.9707e-04\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7654e-04 - val_loss: 3.8802e-04\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6777e-04 - val_loss: 3.7943e-04\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5946e-04 - val_loss: 3.7124e-04\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5154e-04 - val_loss: 3.6341e-04\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4398e-04 - val_loss: 3.5589e-04\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3677e-04 - val_loss: 3.4866e-04\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2983e-04 - val_loss: 3.4168e-04\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2315e-04 - val_loss: 3.3494e-04\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1672e-04 - val_loss: 3.2840e-04\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1049e-04 - val_loss: 3.2207e-04\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0446e-04 - val_loss: 3.1591e-04\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9861e-04 - val_loss: 3.0993e-04\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9294e-04 - val_loss: 3.0409e-04\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8742e-04 - val_loss: 2.9840e-04\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8206e-04 - val_loss: 2.9285e-04\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7682e-04 - val_loss: 2.8743e-04\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 2.7172e-04 - val_loss: 2.8213e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6674e-04 - val_loss: 2.7695e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6187e-04 - val_loss: 2.7189e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5713e-04 - val_loss: 2.6694e-04\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5247e-04 - val_loss: 2.6210e-04\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4794e-04 - val_loss: 2.5736e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4351e-04 - val_loss: 2.5271e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3915e-04 - val_loss: 2.4817e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3491e-04 - val_loss: 2.4371e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3074e-04 - val_loss: 2.3935e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2667e-04 - val_loss: 2.3507e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2268e-04 - val_loss: 2.3088e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1878e-04 - val_loss: 2.2678e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1497e-04 - val_loss: 2.2274e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1119e-04 - val_loss: 2.1880e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0753e-04 - val_loss: 2.1493e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0393e-04 - val_loss: 2.1115e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0040e-04 - val_loss: 2.0743e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9695e-04 - val_loss: 2.0379e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9357e-04 - val_loss: 2.0021e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9023e-04 - val_loss: 1.9672e-04\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8700e-04 - val_loss: 1.9328e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8380e-04 - val_loss: 1.8992e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8067e-04 - val_loss: 1.8662e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7760e-04 - val_loss: 1.8339e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7461e-04 - val_loss: 1.8021e-04\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7165e-04 - val_loss: 1.7710e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6876e-04 - val_loss: 1.7405e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6594e-04 - val_loss: 1.7105e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6316e-04 - val_loss: 1.6811e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6043e-04 - val_loss: 1.6524e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5776e-04 - val_loss: 1.6241e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5514e-04 - val_loss: 1.5964e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5257e-04 - val_loss: 1.5692e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5004e-04 - val_loss: 1.5426e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4757e-04 - val_loss: 1.5166e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4515e-04 - val_loss: 1.4909e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4277e-04 - val_loss: 1.4658e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4043e-04 - val_loss: 1.4411e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3814e-04 - val_loss: 1.4170e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3590e-04 - val_loss: 1.3932e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3370e-04 - val_loss: 1.3699e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3153e-04 - val_loss: 1.3470e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2941e-04 - val_loss: 1.3246e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2733e-04 - val_loss: 1.3026e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2529e-04 - val_loss: 1.2810e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2328e-04 - val_loss: 1.2598e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2131e-04 - val_loss: 1.2391e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1938e-04 - val_loss: 1.2187e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1749e-04 - val_loss: 1.1986e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1563e-04 - val_loss: 1.1789e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1380e-04 - val_loss: 1.1596e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1201e-04 - val_loss: 1.1407e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1025e-04 - val_loss: 1.1221e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0852e-04 - val_loss: 1.1038e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0683e-04 - val_loss: 1.0859e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0516e-04 - val_loss: 1.0683e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0353e-04 - val_loss: 1.0511e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0192e-04 - val_loss: 1.0342e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0035e-04 - val_loss: 1.0175e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8800e-05 - val_loss: 1.0012e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7289e-05 - val_loss: 9.8514e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5798e-05 - val_loss: 9.6934e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4326e-05 - val_loss: 9.5392e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2894e-05 - val_loss: 9.3872e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1479e-05 - val_loss: 9.2380e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0096e-05 - val_loss: 9.0912e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8730e-05 - val_loss: 8.9475e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7399e-05 - val_loss: 8.8057e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6077e-05 - val_loss: 8.6671e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4786e-05 - val_loss: 8.5311e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3519e-05 - val_loss: 8.3973e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2277e-05 - val_loss: 8.2656e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1049e-05 - val_loss: 8.1365e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9851e-05 - val_loss: 8.0094e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8667e-05 - val_loss: 7.8847e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7505e-05 - val_loss: 7.7625e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6366e-05 - val_loss: 7.6423e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5250e-05 - val_loss: 7.5237e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4144e-05 - val_loss: 7.4076e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3061e-05 - val_loss: 7.2938e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2001e-05 - val_loss: 7.1816e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0955e-05 - val_loss: 7.0715e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9927e-05 - val_loss: 6.9633e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8919e-05 - val_loss: 6.8570e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7927e-05 - val_loss: 6.7523e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6952e-05 - val_loss: 6.6496e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5994e-05 - val_loss: 6.5486e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5051e-05 - val_loss: 6.4494e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4127e-05 - val_loss: 6.3517e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3216e-05 - val_loss: 6.2558e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2323e-05 - val_loss: 6.1611e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1440e-05 - val_loss: 6.0686e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0576e-05 - val_loss: 5.9775e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9727e-05 - val_loss: 5.8876e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8888e-05 - val_loss: 5.7998e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8066e-05 - val_loss: 5.7134e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7259e-05 - val_loss: 5.6282e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6461e-05 - val_loss: 5.5448e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5681e-05 - val_loss: 5.4626e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.4913e-05 - val_loss: 5.3816e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4156e-05 - val_loss: 5.3021e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3411e-05 - val_loss: 5.2240e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2681e-05 - val_loss: 5.1471e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1961e-05 - val_loss: 5.0714e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1254e-05 - val_loss: 4.9971e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0559e-05 - val_loss: 4.9237e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9872e-05 - val_loss: 4.8519e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9198e-05 - val_loss: 4.7814e-05\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8537e-05 - val_loss: 4.7116e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7885e-05 - val_loss: 4.6432e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7244e-05 - val_loss: 4.5757e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6612e-05 - val_loss: 4.5095e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5992e-05 - val_loss: 4.4445e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5380e-05 - val_loss: 4.3806e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4779e-05 - val_loss: 4.3176e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4191e-05 - val_loss: 4.2552e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3606e-05 - val_loss: 4.1943e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3033e-05 - val_loss: 4.1344e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2471e-05 - val_loss: 4.0753e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1915e-05 - val_loss: 4.0173e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1370e-05 - val_loss: 3.9603e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0832e-05 - val_loss: 3.9041e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 4.0304e-05 - val_loss: 3.8490e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9784e-05 - val_loss: 3.7945e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9272e-05 - val_loss: 3.7408e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8768e-05 - val_loss: 3.6880e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8272e-05 - val_loss: 3.6361e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7784e-05 - val_loss: 3.5850e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7302e-05 - val_loss: 3.5347e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6829e-05 - val_loss: 3.4854e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6363e-05 - val_loss: 3.4367e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5904e-05 - val_loss: 3.3890e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5452e-05 - val_loss: 3.3420e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5008e-05 - val_loss: 3.2955e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4572e-05 - val_loss: 3.2496e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4139e-05 - val_loss: 3.2046e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3714e-05 - val_loss: 3.1604e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3297e-05 - val_loss: 3.1171e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2886e-05 - val_loss: 3.0740e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2481e-05 - val_loss: 3.0317e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2081e-05 - val_loss: 2.9903e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1688e-05 - val_loss: 2.9494e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1300e-05 - val_loss: 2.9094e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0921e-05 - val_loss: 2.8697e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0546e-05 - val_loss: 2.8305e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0175e-05 - val_loss: 2.7922e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9811e-05 - val_loss: 2.7544e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9452e-05 - val_loss: 2.7174e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9099e-05 - val_loss: 2.6808e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8751e-05 - val_loss: 2.6447e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8408e-05 - val_loss: 2.6093e-05\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8071e-05 - val_loss: 2.5743e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7740e-05 - val_loss: 2.5395e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7411e-05 - val_loss: 2.5057e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7088e-05 - val_loss: 2.4724e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6770e-05 - val_loss: 2.4395e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6457e-05 - val_loss: 2.4072e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6149e-05 - val_loss: 2.3751e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5845e-05 - val_loss: 2.3436e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5545e-05 - val_loss: 2.3127e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5249e-05 - val_loss: 2.2822e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4958e-05 - val_loss: 2.2524e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4672e-05 - val_loss: 2.2229e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4389e-05 - val_loss: 2.1939e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4112e-05 - val_loss: 2.1653e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3838e-05 - val_loss: 2.1369e-05\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3567e-05 - val_loss: 2.1090e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3301e-05 - val_loss: 2.0818e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3038e-05 - val_loss: 2.0547e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2780e-05 - val_loss: 2.0281e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2525e-05 - val_loss: 2.0018e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2274e-05 - val_loss: 1.9760e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2026e-05 - val_loss: 1.9505e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1782e-05 - val_loss: 1.9255e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1541e-05 - val_loss: 1.9010e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1304e-05 - val_loss: 1.8767e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1070e-05 - val_loss: 1.8527e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0839e-05 - val_loss: 1.8291e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0612e-05 - val_loss: 1.8059e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0388e-05 - val_loss: 1.7831e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0168e-05 - val_loss: 1.7605e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9950e-05 - val_loss: 1.7384e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9735e-05 - val_loss: 1.7165e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9524e-05 - val_loss: 1.6948e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9315e-05 - val_loss: 1.6737e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9109e-05 - val_loss: 1.6527e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8907e-05 - val_loss: 1.6319e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8707e-05 - val_loss: 1.6116e-05\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8509e-05 - val_loss: 1.5918e-05\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8315e-05 - val_loss: 1.5721e-05\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8123e-05 - val_loss: 1.5527e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7934e-05 - val_loss: 1.5335e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7748e-05 - val_loss: 1.5144e-05\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7563e-05 - val_loss: 1.4958e-05\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7382e-05 - val_loss: 1.4775e-05\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7203e-05 - val_loss: 1.4594e-05\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7027e-05 - val_loss: 1.4417e-05\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6853e-05 - val_loss: 1.4241e-05\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6681e-05 - val_loss: 1.4066e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6512e-05 - val_loss: 1.3898e-05\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6345e-05 - val_loss: 1.3729e-05\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6180e-05 - val_loss: 1.3562e-05\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6017e-05 - val_loss: 1.3399e-05\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5857e-05 - val_loss: 1.3238e-05\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5698e-05 - val_loss: 1.3078e-05\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5542e-05 - val_loss: 1.2922e-05\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5388e-05 - val_loss: 1.2768e-05\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5236e-05 - val_loss: 1.2614e-05\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5086e-05 - val_loss: 1.2464e-05\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4938e-05 - val_loss: 1.2317e-05\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.4792e-05 - val_loss: 1.2170e-05\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4648e-05 - val_loss: 1.2027e-05\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4506e-05 - val_loss: 1.1885e-05\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4365e-05 - val_loss: 1.1745e-05\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4227e-05 - val_loss: 1.1608e-05\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4090e-05 - val_loss: 1.1473e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3955e-05 - val_loss: 1.1338e-05\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3822e-05 - val_loss: 1.1206e-05\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3691e-05 - val_loss: 1.1074e-05\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3561e-05 - val_loss: 1.0944e-05\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3433e-05 - val_loss: 1.0819e-05\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3307e-05 - val_loss: 1.0694e-05\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3182e-05 - val_loss: 1.0569e-05\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3059e-05 - val_loss: 1.0448e-05\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2937e-05 - val_loss: 1.0327e-05\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2817e-05 - val_loss: 1.0209e-05\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2698e-05 - val_loss: 1.0093e-05\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2581e-05 - val_loss: 9.9772e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2466e-05 - val_loss: 9.8642e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2351e-05 - val_loss: 9.7528e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2239e-05 - val_loss: 9.6415e-06\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2127e-05 - val_loss: 9.5319e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2017e-05 - val_loss: 9.4247e-06\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1909e-05 - val_loss: 9.3164e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1802e-05 - val_loss: 9.2128e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1696e-05 - val_loss: 9.1115e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1592e-05 - val_loss: 9.0097e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1489e-05 - val_loss: 8.9106e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1386e-05 - val_loss: 8.8098e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1286e-05 - val_loss: 8.7118e-06\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1186e-05 - val_loss: 8.6163e-06\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1088e-05 - val_loss: 8.5172e-06\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0991e-05 - val_loss: 8.4233e-06\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0895e-05 - val_loss: 8.3327e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0800e-05 - val_loss: 8.2398e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0706e-05 - val_loss: 8.1496e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0613e-05 - val_loss: 8.0593e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0522e-05 - val_loss: 7.9701e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0431e-05 - val_loss: 7.8846e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0342e-05 - val_loss: 7.8002e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0254e-05 - val_loss: 7.7156e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0167e-05 - val_loss: 7.6325e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0080e-05 - val_loss: 7.5489e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9950e-06 - val_loss: 7.4650e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9108e-06 - val_loss: 7.3846e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8279e-06 - val_loss: 7.3061e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7456e-06 - val_loss: 7.2296e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6643e-06 - val_loss: 7.1506e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5836e-06 - val_loss: 7.0737e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5041e-06 - val_loss: 6.9987e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4257e-06 - val_loss: 6.9244e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3478e-06 - val_loss: 6.8512e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2712e-06 - val_loss: 6.7772e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1954e-06 - val_loss: 6.7060e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1205e-06 - val_loss: 6.6365e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0459e-06 - val_loss: 6.5662e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9725e-06 - val_loss: 6.4972e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8997e-06 - val_loss: 6.4281e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8283e-06 - val_loss: 6.3604e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7572e-06 - val_loss: 6.2952e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6867e-06 - val_loss: 6.2268e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6174e-06 - val_loss: 6.1606e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5488e-06 - val_loss: 6.0974e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4807e-06 - val_loss: 6.0344e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4137e-06 - val_loss: 5.9717e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3473e-06 - val_loss: 5.9109e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2814e-06 - val_loss: 5.8498e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2167e-06 - val_loss: 5.7874e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1526e-06 - val_loss: 5.7295e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0884e-06 - val_loss: 5.6715e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0258e-06 - val_loss: 5.6134e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9636e-06 - val_loss: 5.5567e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9014e-06 - val_loss: 5.4997e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8404e-06 - val_loss: 5.4403e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7804e-06 - val_loss: 5.3857e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7208e-06 - val_loss: 5.3331e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6611e-06 - val_loss: 5.2774e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6025e-06 - val_loss: 5.2230e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5445e-06 - val_loss: 5.1714e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4875e-06 - val_loss: 5.1174e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4307e-06 - val_loss: 5.0654e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3745e-06 - val_loss: 5.0159e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3189e-06 - val_loss: 4.9657e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2638e-06 - val_loss: 4.9149e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2093e-06 - val_loss: 4.8658e-06\n",
      "Epoch 420/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1554e-06 - val_loss: 4.8174e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1024e-06 - val_loss: 4.7680e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0495e-06 - val_loss: 4.7216e-06\n",
      "Epoch 423/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9971e-06 - val_loss: 4.6761e-06\n",
      "Epoch 424/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9460e-06 - val_loss: 4.6271e-06\n",
      "Epoch 425/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8943e-06 - val_loss: 4.5815e-06\n",
      "Epoch 426/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8435e-06 - val_loss: 4.5377e-06\n",
      "Epoch 427/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7929e-06 - val_loss: 4.4912e-06\n",
      "Epoch 428/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7434e-06 - val_loss: 4.4459e-06\n",
      "Epoch 429/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6939e-06 - val_loss: 4.4026e-06\n",
      "Epoch 430/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6452e-06 - val_loss: 4.3591e-06\n",
      "Epoch 431/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5971e-06 - val_loss: 4.3167e-06\n",
      "Epoch 432/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5490e-06 - val_loss: 4.2745e-06\n",
      "Epoch 433/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5015e-06 - val_loss: 4.2312e-06\n",
      "Epoch 434/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4546e-06 - val_loss: 4.1887e-06\n",
      "Epoch 435/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4085e-06 - val_loss: 4.1487e-06\n",
      "Epoch 436/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3621e-06 - val_loss: 4.1087e-06\n",
      "Epoch 437/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3164e-06 - val_loss: 4.0680e-06\n",
      "Epoch 438/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2714e-06 - val_loss: 4.0275e-06\n",
      "Epoch 439/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2266e-06 - val_loss: 3.9891e-06\n",
      "Epoch 440/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1824e-06 - val_loss: 3.9509e-06\n",
      "Epoch 441/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1388e-06 - val_loss: 3.9104e-06\n",
      "Epoch 442/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0950e-06 - val_loss: 3.8728e-06\n",
      "Epoch 443/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0520e-06 - val_loss: 3.8366e-06\n",
      "Epoch 444/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0093e-06 - val_loss: 3.7988e-06\n",
      "Epoch 445/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9672e-06 - val_loss: 3.7621e-06\n",
      "Epoch 446/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9249e-06 - val_loss: 3.7253e-06\n",
      "Epoch 447/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8837e-06 - val_loss: 3.6891e-06\n",
      "Epoch 448/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8423e-06 - val_loss: 3.6530e-06\n",
      "Epoch 449/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8018e-06 - val_loss: 3.6168e-06\n",
      "Epoch 450/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7615e-06 - val_loss: 3.5828e-06\n",
      "Epoch 451/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7214e-06 - val_loss: 3.5494e-06\n",
      "Epoch 452/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6817e-06 - val_loss: 3.5150e-06\n",
      "Epoch 453/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6423e-06 - val_loss: 3.4806e-06\n",
      "Epoch 454/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6036e-06 - val_loss: 3.4461e-06\n",
      "Epoch 455/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5649e-06 - val_loss: 3.4125e-06\n",
      "Epoch 456/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5267e-06 - val_loss: 3.3808e-06\n",
      "Epoch 457/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4890e-06 - val_loss: 3.3489e-06\n",
      "Epoch 458/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4513e-06 - val_loss: 3.3171e-06\n",
      "Epoch 459/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4142e-06 - val_loss: 3.2866e-06\n",
      "Epoch 460/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3775e-06 - val_loss: 3.2546e-06\n",
      "Epoch 461/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3412e-06 - val_loss: 3.2234e-06\n",
      "Epoch 462/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3047e-06 - val_loss: 3.1927e-06\n",
      "Epoch 463/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2687e-06 - val_loss: 3.1625e-06\n",
      "Epoch 464/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2329e-06 - val_loss: 3.1322e-06\n",
      "Epoch 465/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1979e-06 - val_loss: 3.1025e-06\n",
      "Epoch 466/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1630e-06 - val_loss: 3.0729e-06\n",
      "Epoch 467/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.1285e-06 - val_loss: 3.0447e-06\n",
      "Epoch 468/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0939e-06 - val_loss: 3.0168e-06\n",
      "Epoch 469/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0602e-06 - val_loss: 2.9869e-06\n",
      "Epoch 470/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.0268e-06 - val_loss: 2.9587e-06\n",
      "Epoch 471/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9933e-06 - val_loss: 2.9324e-06\n",
      "Epoch 472/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9598e-06 - val_loss: 2.9043e-06\n",
      "Epoch 473/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.9273e-06 - val_loss: 2.8741e-06\n",
      "Epoch 474/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8941e-06 - val_loss: 2.8474e-06\n",
      "Epoch 475/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8617e-06 - val_loss: 2.8225e-06\n",
      "Epoch 476/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.8302e-06 - val_loss: 2.7951e-06\n",
      "Epoch 477/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7983e-06 - val_loss: 2.7691e-06\n",
      "Epoch 478/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7671e-06 - val_loss: 2.7446e-06\n",
      "Epoch 479/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7355e-06 - val_loss: 2.7194e-06\n",
      "Epoch 480/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.7041e-06 - val_loss: 2.6927e-06\n",
      "Epoch 481/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6735e-06 - val_loss: 2.6662e-06\n",
      "Epoch 482/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6432e-06 - val_loss: 2.6410e-06\n",
      "Epoch 483/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.6130e-06 - val_loss: 2.6173e-06\n",
      "Epoch 484/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5832e-06 - val_loss: 2.5934e-06\n",
      "Epoch 485/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5535e-06 - val_loss: 2.5701e-06\n",
      "Epoch 486/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.5240e-06 - val_loss: 2.5460e-06\n",
      "Epoch 487/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4947e-06 - val_loss: 2.5216e-06\n",
      "Epoch 488/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4659e-06 - val_loss: 2.4974e-06\n",
      "Epoch 489/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4372e-06 - val_loss: 2.4742e-06\n",
      "Epoch 490/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.4087e-06 - val_loss: 2.4518e-06\n",
      "Epoch 491/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3808e-06 - val_loss: 2.4291e-06\n",
      "Epoch 492/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3525e-06 - val_loss: 2.4065e-06\n",
      "Epoch 493/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.3248e-06 - val_loss: 2.3847e-06\n",
      "Epoch 494/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2977e-06 - val_loss: 2.3638e-06\n",
      "Epoch 495/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2699e-06 - val_loss: 2.3415e-06\n",
      "Epoch 496/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2430e-06 - val_loss: 2.3197e-06\n",
      "Epoch 497/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.2160e-06 - val_loss: 2.2981e-06\n",
      "Epoch 498/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1897e-06 - val_loss: 2.2765e-06\n",
      "Epoch 499/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1633e-06 - val_loss: 2.2555e-06\n",
      "Epoch 500/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1374e-06 - val_loss: 2.2361e-06\n",
      "Epoch 501/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.1113e-06 - val_loss: 2.2153e-06\n",
      "Epoch 502/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0855e-06 - val_loss: 2.1932e-06\n",
      "Epoch 503/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0598e-06 - val_loss: 2.1732e-06\n",
      "Epoch 504/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0347e-06 - val_loss: 2.1547e-06\n",
      "Epoch 505/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 4.0093e-06 - val_loss: 2.1362e-06\n",
      "Epoch 506/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9853e-06 - val_loss: 2.1141e-06\n",
      "Epoch 507/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9600e-06 - val_loss: 2.0951e-06\n",
      "Epoch 508/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9353e-06 - val_loss: 2.0769e-06\n",
      "Epoch 509/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.9110e-06 - val_loss: 2.0590e-06\n",
      "Epoch 510/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8867e-06 - val_loss: 2.0399e-06\n",
      "Epoch 511/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8627e-06 - val_loss: 2.0209e-06\n",
      "Epoch 512/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8389e-06 - val_loss: 2.0026e-06\n",
      "Epoch 513/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.8155e-06 - val_loss: 1.9851e-06\n",
      "Epoch 514/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7922e-06 - val_loss: 1.9672e-06\n",
      "Epoch 515/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7689e-06 - val_loss: 1.9485e-06\n",
      "Epoch 516/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7459e-06 - val_loss: 1.9309e-06\n",
      "Epoch 517/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7231e-06 - val_loss: 1.9139e-06\n",
      "Epoch 518/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.7005e-06 - val_loss: 1.8959e-06\n",
      "Epoch 519/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6782e-06 - val_loss: 1.8794e-06\n",
      "Epoch 520/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6561e-06 - val_loss: 1.8632e-06\n",
      "Epoch 521/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6337e-06 - val_loss: 1.8466e-06\n",
      "Epoch 522/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.6118e-06 - val_loss: 1.8298e-06\n",
      "Epoch 523/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5907e-06 - val_loss: 1.8118e-06\n",
      "Epoch 524/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5691e-06 - val_loss: 1.7949e-06\n",
      "Epoch 525/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5473e-06 - val_loss: 1.7791e-06\n",
      "Epoch 526/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5259e-06 - val_loss: 1.7652e-06\n",
      "Epoch 527/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.5052e-06 - val_loss: 1.7481e-06\n",
      "Epoch 528/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4840e-06 - val_loss: 1.7327e-06\n",
      "Epoch 529/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4636e-06 - val_loss: 1.7178e-06\n",
      "Epoch 530/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4432e-06 - val_loss: 1.7028e-06\n",
      "Epoch 531/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4229e-06 - val_loss: 1.6901e-06\n",
      "Epoch 532/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.4025e-06 - val_loss: 1.6745e-06\n",
      "Epoch 533/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3831e-06 - val_loss: 1.6578e-06\n",
      "Epoch 534/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3625e-06 - val_loss: 1.6427e-06\n",
      "Epoch 535/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3428e-06 - val_loss: 1.6292e-06\n",
      "Epoch 536/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3231e-06 - val_loss: 1.6147e-06\n",
      "Epoch 537/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.3033e-06 - val_loss: 1.5993e-06\n",
      "Epoch 538/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2842e-06 - val_loss: 1.5852e-06\n",
      "Epoch 539/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2650e-06 - val_loss: 1.5712e-06\n",
      "Epoch 540/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2460e-06 - val_loss: 1.5573e-06\n",
      "Epoch 541/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2274e-06 - val_loss: 1.5438e-06\n",
      "Epoch 542/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.2090e-06 - val_loss: 1.5309e-06\n",
      "Epoch 543/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1904e-06 - val_loss: 1.5189e-06\n",
      "Epoch 544/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1721e-06 - val_loss: 1.5057e-06\n",
      "Epoch 545/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1537e-06 - val_loss: 1.4922e-06\n",
      "Epoch 546/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1356e-06 - val_loss: 1.4780e-06\n",
      "Epoch 547/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1176e-06 - val_loss: 1.4649e-06\n",
      "Epoch 548/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.1002e-06 - val_loss: 1.4528e-06\n",
      "Epoch 549/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0822e-06 - val_loss: 1.4411e-06\n",
      "Epoch 550/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0646e-06 - val_loss: 1.4298e-06\n",
      "Epoch 551/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0476e-06 - val_loss: 1.4157e-06\n",
      "Epoch 552/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0295e-06 - val_loss: 1.4026e-06\n",
      "Epoch 553/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 3.0123e-06 - val_loss: 1.3905e-06\n",
      "Epoch 554/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9955e-06 - val_loss: 1.3787e-06\n",
      "Epoch 555/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9790e-06 - val_loss: 1.3672e-06\n",
      "Epoch 556/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9617e-06 - val_loss: 1.3549e-06\n",
      "Epoch 557/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9451e-06 - val_loss: 1.3438e-06\n",
      "Epoch 558/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9285e-06 - val_loss: 1.3324e-06\n",
      "Epoch 559/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.9125e-06 - val_loss: 1.3211e-06\n",
      "Epoch 560/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8962e-06 - val_loss: 1.3107e-06\n",
      "Epoch 561/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8799e-06 - val_loss: 1.2992e-06\n",
      "Epoch 562/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8640e-06 - val_loss: 1.2874e-06\n",
      "Epoch 563/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8480e-06 - val_loss: 1.2765e-06\n",
      "Epoch 564/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8323e-06 - val_loss: 1.2664e-06\n",
      "Epoch 565/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8169e-06 - val_loss: 1.2556e-06\n",
      "Epoch 566/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.8012e-06 - val_loss: 1.2452e-06\n",
      "Epoch 567/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7859e-06 - val_loss: 1.2349e-06\n",
      "Epoch 568/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7708e-06 - val_loss: 1.2247e-06\n",
      "Epoch 569/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7555e-06 - val_loss: 1.2146e-06\n",
      "Epoch 570/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7405e-06 - val_loss: 1.2045e-06\n",
      "Epoch 571/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7255e-06 - val_loss: 1.1949e-06\n",
      "Epoch 572/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.7110e-06 - val_loss: 1.1848e-06\n",
      "Epoch 573/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6968e-06 - val_loss: 1.1731e-06\n",
      "Epoch 574/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6819e-06 - val_loss: 1.1633e-06\n",
      "Epoch 575/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6675e-06 - val_loss: 1.1549e-06\n",
      "Epoch 576/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6530e-06 - val_loss: 1.1454e-06\n",
      "Epoch 577/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6386e-06 - val_loss: 1.1374e-06\n",
      "Epoch 578/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6244e-06 - val_loss: 1.1274e-06\n",
      "Epoch 579/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.6102e-06 - val_loss: 1.1183e-06\n",
      "Epoch 580/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5962e-06 - val_loss: 1.1087e-06\n",
      "Epoch 581/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5828e-06 - val_loss: 1.0999e-06\n",
      "Epoch 582/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5688e-06 - val_loss: 1.0909e-06\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5555e-06 - val_loss: 1.0825e-06\n",
      "Epoch 584/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5417e-06 - val_loss: 1.0732e-06\n",
      "Epoch 585/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5284e-06 - val_loss: 1.0646e-06\n",
      "Epoch 586/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5154e-06 - val_loss: 1.0554e-06\n",
      "Epoch 587/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.5032e-06 - val_loss: 1.0476e-06\n",
      "Epoch 588/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4903e-06 - val_loss: 1.0396e-06\n",
      "Epoch 589/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4769e-06 - val_loss: 1.0309e-06\n",
      "Epoch 590/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4639e-06 - val_loss: 1.0219e-06\n",
      "Epoch 591/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4509e-06 - val_loss: 1.0155e-06\n",
      "Epoch 592/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4381e-06 - val_loss: 1.0078e-06\n",
      "Epoch 593/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4251e-06 - val_loss: 9.9967e-07\n",
      "Epoch 594/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4128e-06 - val_loss: 9.9130e-07\n",
      "Epoch 595/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.4003e-06 - val_loss: 9.8347e-07\n",
      "Epoch 596/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3878e-06 - val_loss: 9.7609e-07\n",
      "Epoch 597/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3754e-06 - val_loss: 9.6872e-07\n",
      "Epoch 598/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3636e-06 - val_loss: 9.6197e-07\n",
      "Epoch 599/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3519e-06 - val_loss: 9.5368e-07\n",
      "Epoch 600/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3395e-06 - val_loss: 9.4548e-07\n",
      "Epoch 601/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3279e-06 - val_loss: 9.3892e-07\n",
      "Epoch 602/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3159e-06 - val_loss: 9.3165e-07\n",
      "Epoch 603/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.3042e-06 - val_loss: 9.2515e-07\n",
      "Epoch 604/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2925e-06 - val_loss: 9.1807e-07\n",
      "Epoch 605/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2812e-06 - val_loss: 9.1095e-07\n",
      "Epoch 606/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2696e-06 - val_loss: 9.0341e-07\n",
      "Epoch 607/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2585e-06 - val_loss: 8.9670e-07\n",
      "Epoch 608/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2477e-06 - val_loss: 8.9068e-07\n",
      "Epoch 609/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2359e-06 - val_loss: 8.8321e-07\n",
      "Epoch 610/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2251e-06 - val_loss: 8.7765e-07\n",
      "Epoch 611/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2142e-06 - val_loss: 8.7165e-07\n",
      "Epoch 612/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.2031e-06 - val_loss: 8.6501e-07\n",
      "Epoch 613/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1924e-06 - val_loss: 8.5744e-07\n",
      "Epoch 614/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1816e-06 - val_loss: 8.5096e-07\n",
      "Epoch 615/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1709e-06 - val_loss: 8.4498e-07\n",
      "Epoch 616/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1602e-06 - val_loss: 8.3914e-07\n",
      "Epoch 617/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1496e-06 - val_loss: 8.3441e-07\n",
      "Epoch 618/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1396e-06 - val_loss: 8.2850e-07\n",
      "Epoch 619/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1293e-06 - val_loss: 8.2273e-07\n",
      "Epoch 620/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1186e-06 - val_loss: 8.1756e-07\n",
      "Epoch 621/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.1090e-06 - val_loss: 8.1100e-07\n",
      "Epoch 622/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0983e-06 - val_loss: 8.0473e-07\n",
      "Epoch 623/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0885e-06 - val_loss: 7.9930e-07\n",
      "Epoch 624/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0784e-06 - val_loss: 7.9350e-07\n",
      "Epoch 625/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0684e-06 - val_loss: 7.8801e-07\n",
      "Epoch 626/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0589e-06 - val_loss: 7.8350e-07\n",
      "Epoch 627/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0498e-06 - val_loss: 7.7873e-07\n",
      "Epoch 628/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0398e-06 - val_loss: 7.7284e-07\n",
      "Epoch 629/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0300e-06 - val_loss: 7.6662e-07\n",
      "Epoch 630/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0212e-06 - val_loss: 7.6078e-07\n",
      "Epoch 631/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0120e-06 - val_loss: 7.5503e-07\n",
      "Epoch 632/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 2.0021e-06 - val_loss: 7.5089e-07\n",
      "Epoch 633/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9924e-06 - val_loss: 7.4524e-07\n",
      "Epoch 634/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9828e-06 - val_loss: 7.4011e-07\n",
      "Epoch 635/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9735e-06 - val_loss: 7.3606e-07\n",
      "Epoch 636/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9648e-06 - val_loss: 7.3106e-07\n",
      "Epoch 637/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9552e-06 - val_loss: 7.2695e-07\n",
      "Epoch 638/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9466e-06 - val_loss: 7.2140e-07\n",
      "Epoch 639/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9374e-06 - val_loss: 7.1637e-07\n",
      "Epoch 640/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9286e-06 - val_loss: 7.1173e-07\n",
      "Epoch 641/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9198e-06 - val_loss: 7.0758e-07\n",
      "Epoch 642/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9110e-06 - val_loss: 7.0296e-07\n",
      "Epoch 643/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.9024e-06 - val_loss: 6.9856e-07\n",
      "Epoch 644/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8936e-06 - val_loss: 6.9329e-07\n",
      "Epoch 645/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8853e-06 - val_loss: 6.8943e-07\n",
      "Epoch 646/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8775e-06 - val_loss: 6.8693e-07\n",
      "Epoch 647/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8691e-06 - val_loss: 6.8383e-07\n",
      "Epoch 648/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8604e-06 - val_loss: 6.7947e-07\n",
      "Epoch 649/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8522e-06 - val_loss: 6.7473e-07\n",
      "Epoch 650/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8439e-06 - val_loss: 6.6967e-07\n",
      "Epoch 651/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8352e-06 - val_loss: 6.6507e-07\n",
      "Epoch 652/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8272e-06 - val_loss: 6.6088e-07\n",
      "Epoch 653/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8190e-06 - val_loss: 6.5643e-07\n",
      "Epoch 654/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8111e-06 - val_loss: 6.5230e-07\n",
      "Epoch 655/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.8031e-06 - val_loss: 6.4802e-07\n",
      "Epoch 656/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7955e-06 - val_loss: 6.4494e-07\n",
      "Epoch 657/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7874e-06 - val_loss: 6.4048e-07\n",
      "Epoch 658/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7804e-06 - val_loss: 6.3797e-07\n",
      "Epoch 659/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7726e-06 - val_loss: 6.3431e-07\n",
      "Epoch 660/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7646e-06 - val_loss: 6.3000e-07\n",
      "Epoch 661/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7571e-06 - val_loss: 6.2619e-07\n",
      "Epoch 662/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7494e-06 - val_loss: 6.2204e-07\n",
      "Epoch 663/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7420e-06 - val_loss: 6.1902e-07\n",
      "Epoch 664/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7343e-06 - val_loss: 6.1538e-07\n",
      "Epoch 665/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7270e-06 - val_loss: 6.1107e-07\n",
      "Epoch 666/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7193e-06 - val_loss: 6.0756e-07\n",
      "Epoch 667/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7124e-06 - val_loss: 6.0482e-07\n",
      "Epoch 668/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.7053e-06 - val_loss: 6.0166e-07\n",
      "Epoch 669/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6976e-06 - val_loss: 5.9766e-07\n",
      "Epoch 670/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6906e-06 - val_loss: 5.9464e-07\n",
      "Epoch 671/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6838e-06 - val_loss: 5.9184e-07\n",
      "Epoch 672/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6763e-06 - val_loss: 5.8818e-07\n",
      "Epoch 673/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6692e-06 - val_loss: 5.8525e-07\n",
      "Epoch 674/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6625e-06 - val_loss: 5.8326e-07\n",
      "Epoch 675/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6558e-06 - val_loss: 5.8186e-07\n",
      "Epoch 676/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6494e-06 - val_loss: 5.7887e-07\n",
      "Epoch 677/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6420e-06 - val_loss: 5.7582e-07\n",
      "Epoch 678/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6351e-06 - val_loss: 5.7269e-07\n",
      "Epoch 679/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6282e-06 - val_loss: 5.6933e-07\n",
      "Epoch 680/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6215e-06 - val_loss: 5.6640e-07\n",
      "Epoch 681/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6157e-06 - val_loss: 5.6449e-07\n",
      "Epoch 682/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6087e-06 - val_loss: 5.6098e-07\n",
      "Epoch 683/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.6022e-06 - val_loss: 5.5834e-07\n",
      "Epoch 684/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5957e-06 - val_loss: 5.5419e-07\n",
      "Epoch 685/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5894e-06 - val_loss: 5.5211e-07\n",
      "Epoch 686/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5830e-06 - val_loss: 5.4831e-07\n",
      "Epoch 687/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5765e-06 - val_loss: 5.4562e-07\n",
      "Epoch 688/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5700e-06 - val_loss: 5.4317e-07\n",
      "Epoch 689/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5637e-06 - val_loss: 5.4044e-07\n",
      "Epoch 690/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5573e-06 - val_loss: 5.3800e-07\n",
      "Epoch 691/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.5512e-06 - val_loss: 5.3584e-07\n",
      "Epoch 692/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5449e-06 - val_loss: 5.3330e-07\n",
      "Epoch 693/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5389e-06 - val_loss: 5.3055e-07\n",
      "Epoch 694/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5330e-06 - val_loss: 5.2879e-07\n",
      "Epoch 695/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5266e-06 - val_loss: 5.2588e-07\n",
      "Epoch 696/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5207e-06 - val_loss: 5.2365e-07\n",
      "Epoch 697/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5145e-06 - val_loss: 5.2046e-07\n",
      "Epoch 698/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5090e-06 - val_loss: 5.1822e-07\n",
      "Epoch 699/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.5028e-06 - val_loss: 5.1626e-07\n",
      "Epoch 700/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4971e-06 - val_loss: 5.1472e-07\n",
      "Epoch 701/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4914e-06 - val_loss: 5.1236e-07\n",
      "Epoch 702/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4856e-06 - val_loss: 5.0990e-07\n",
      "Epoch 703/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4799e-06 - val_loss: 5.0782e-07\n",
      "Epoch 704/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4743e-06 - val_loss: 5.0608e-07\n",
      "Epoch 705/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4683e-06 - val_loss: 5.0337e-07\n",
      "Epoch 706/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4627e-06 - val_loss: 5.0136e-07\n",
      "Epoch 707/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4572e-06 - val_loss: 5.0009e-07\n",
      "Epoch 708/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4515e-06 - val_loss: 4.9821e-07\n",
      "Epoch 709/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4460e-06 - val_loss: 4.9617e-07\n",
      "Epoch 710/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4404e-06 - val_loss: 4.9340e-07\n",
      "Epoch 711/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4351e-06 - val_loss: 4.9130e-07\n",
      "Epoch 712/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4302e-06 - val_loss: 4.8966e-07\n",
      "Epoch 713/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4242e-06 - val_loss: 4.8721e-07\n",
      "Epoch 714/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4192e-06 - val_loss: 4.8616e-07\n",
      "Epoch 715/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4137e-06 - val_loss: 4.8437e-07\n",
      "Epoch 716/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4084e-06 - val_loss: 4.8301e-07\n",
      "Epoch 717/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.4031e-06 - val_loss: 4.8103e-07\n",
      "Epoch 718/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3977e-06 - val_loss: 4.7929e-07\n",
      "Epoch 719/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3926e-06 - val_loss: 4.7750e-07\n",
      "Epoch 720/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3875e-06 - val_loss: 4.7516e-07\n",
      "Epoch 721/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3822e-06 - val_loss: 4.7337e-07\n",
      "Epoch 722/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3773e-06 - val_loss: 4.7224e-07\n",
      "Epoch 723/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3720e-06 - val_loss: 4.7024e-07\n",
      "Epoch 724/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3672e-06 - val_loss: 4.6824e-07\n",
      "Epoch 725/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3623e-06 - val_loss: 4.6724e-07\n",
      "Epoch 726/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3570e-06 - val_loss: 4.6507e-07\n",
      "Epoch 727/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3523e-06 - val_loss: 4.6428e-07\n",
      "Epoch 728/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3469e-06 - val_loss: 4.6192e-07\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3422e-06 - val_loss: 4.6026e-07\n",
      "Epoch 730/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3370e-06 - val_loss: 4.5788e-07\n",
      "Epoch 731/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3322e-06 - val_loss: 4.5614e-07\n",
      "Epoch 732/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3277e-06 - val_loss: 4.5559e-07\n",
      "Epoch 733/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3229e-06 - val_loss: 4.5486e-07\n",
      "Epoch 734/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3179e-06 - val_loss: 4.5266e-07\n",
      "Epoch 735/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3132e-06 - val_loss: 4.5127e-07\n",
      "Epoch 736/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3084e-06 - val_loss: 4.4943e-07\n",
      "Epoch 737/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.3039e-06 - val_loss: 4.4832e-07\n",
      "Epoch 738/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2995e-06 - val_loss: 4.4713e-07\n",
      "Epoch 739/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2944e-06 - val_loss: 4.4505e-07\n",
      "Epoch 740/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.2899e-06 - val_loss: 4.4339e-07\n",
      "Epoch 741/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2857e-06 - val_loss: 4.4222e-07\n",
      "Epoch 742/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2810e-06 - val_loss: 4.4141e-07\n",
      "Epoch 743/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2765e-06 - val_loss: 4.4056e-07\n",
      "Epoch 744/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2719e-06 - val_loss: 4.3972e-07\n",
      "Epoch 745/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2674e-06 - val_loss: 4.3823e-07\n",
      "Epoch 746/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2626e-06 - val_loss: 4.3679e-07\n",
      "Epoch 747/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2583e-06 - val_loss: 4.3559e-07\n",
      "Epoch 748/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2541e-06 - val_loss: 4.3528e-07\n",
      "Epoch 749/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2497e-06 - val_loss: 4.3437e-07\n",
      "Epoch 750/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2464e-06 - val_loss: 4.3351e-07\n",
      "Epoch 751/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2415e-06 - val_loss: 4.3077e-07\n",
      "Epoch 752/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2366e-06 - val_loss: 4.2903e-07\n",
      "Epoch 753/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2321e-06 - val_loss: 4.2723e-07\n",
      "Epoch 754/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2277e-06 - val_loss: 4.2590e-07\n",
      "Epoch 755/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2234e-06 - val_loss: 4.2405e-07\n",
      "Epoch 756/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2194e-06 - val_loss: 4.2388e-07\n",
      "Epoch 757/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2148e-06 - val_loss: 4.2184e-07\n",
      "Epoch 758/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2108e-06 - val_loss: 4.2140e-07\n",
      "Epoch 759/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2067e-06 - val_loss: 4.2102e-07\n",
      "Epoch 760/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.2028e-06 - val_loss: 4.2028e-07\n",
      "Epoch 761/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1982e-06 - val_loss: 4.1765e-07\n",
      "Epoch 762/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1941e-06 - val_loss: 4.1653e-07\n",
      "Epoch 763/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1901e-06 - val_loss: 4.1529e-07\n",
      "Epoch 764/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1863e-06 - val_loss: 4.1408e-07\n",
      "Epoch 765/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1822e-06 - val_loss: 4.1249e-07\n",
      "Epoch 766/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1777e-06 - val_loss: 4.1138e-07\n",
      "Epoch 767/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1738e-06 - val_loss: 4.1142e-07\n",
      "Epoch 768/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1699e-06 - val_loss: 4.1114e-07\n",
      "Epoch 769/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1659e-06 - val_loss: 4.1085e-07\n",
      "Epoch 770/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1622e-06 - val_loss: 4.0909e-07\n",
      "Epoch 771/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1579e-06 - val_loss: 4.0820e-07\n",
      "Epoch 772/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1538e-06 - val_loss: 4.0634e-07\n",
      "Epoch 773/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1500e-06 - val_loss: 4.0472e-07\n",
      "Epoch 774/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1462e-06 - val_loss: 4.0360e-07\n",
      "Epoch 775/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1424e-06 - val_loss: 4.0288e-07\n",
      "Epoch 776/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1386e-06 - val_loss: 4.0197e-07\n",
      "Epoch 777/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1347e-06 - val_loss: 4.0048e-07\n",
      "Epoch 778/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1312e-06 - val_loss: 3.9997e-07\n",
      "Epoch 779/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1272e-06 - val_loss: 3.9966e-07\n",
      "Epoch 780/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.1233e-06 - val_loss: 3.9841e-07\n",
      "Epoch 781/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1194e-06 - val_loss: 3.9737e-07\n",
      "Epoch 782/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1155e-06 - val_loss: 3.9597e-07\n",
      "Epoch 783/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1119e-06 - val_loss: 3.9626e-07\n",
      "Epoch 784/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1080e-06 - val_loss: 3.9510e-07\n",
      "Epoch 785/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1045e-06 - val_loss: 3.9409e-07\n",
      "Epoch 786/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.1008e-06 - val_loss: 3.9291e-07\n",
      "Epoch 787/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0974e-06 - val_loss: 3.9169e-07\n",
      "Epoch 788/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0938e-06 - val_loss: 3.9135e-07\n",
      "Epoch 789/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0901e-06 - val_loss: 3.9100e-07\n",
      "Epoch 790/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0864e-06 - val_loss: 3.9015e-07\n",
      "Epoch 791/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0828e-06 - val_loss: 3.8830e-07\n",
      "Epoch 792/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0789e-06 - val_loss: 3.8781e-07\n",
      "Epoch 793/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0753e-06 - val_loss: 3.8694e-07\n",
      "Epoch 794/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0721e-06 - val_loss: 3.8725e-07\n",
      "Epoch 795/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0681e-06 - val_loss: 3.8582e-07\n",
      "Epoch 796/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0647e-06 - val_loss: 3.8433e-07\n",
      "Epoch 797/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0610e-06 - val_loss: 3.8406e-07\n",
      "Epoch 798/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0576e-06 - val_loss: 3.8328e-07\n",
      "Epoch 799/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0546e-06 - val_loss: 3.8109e-07\n",
      "Epoch 800/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0509e-06 - val_loss: 3.8080e-07\n",
      "Epoch 801/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0471e-06 - val_loss: 3.7997e-07\n",
      "Epoch 802/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0436e-06 - val_loss: 3.7984e-07\n",
      "Epoch 803/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0402e-06 - val_loss: 3.7901e-07\n",
      "Epoch 804/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0366e-06 - val_loss: 3.7741e-07\n",
      "Epoch 805/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0334e-06 - val_loss: 3.7633e-07\n",
      "Epoch 806/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0300e-06 - val_loss: 3.7652e-07\n",
      "Epoch 807/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0265e-06 - val_loss: 3.7568e-07\n",
      "Epoch 808/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0229e-06 - val_loss: 3.7507e-07\n",
      "Epoch 809/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0196e-06 - val_loss: 3.7389e-07\n",
      "Epoch 810/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0162e-06 - val_loss: 3.7360e-07\n",
      "Epoch 811/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0130e-06 - val_loss: 3.7258e-07\n",
      "Epoch 812/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0096e-06 - val_loss: 3.7147e-07\n",
      "Epoch 813/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0062e-06 - val_loss: 3.7012e-07\n",
      "Epoch 814/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 1.0030e-06 - val_loss: 3.7040e-07\n",
      "Epoch 815/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9962e-07 - val_loss: 3.7040e-07\n",
      "Epoch 816/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9633e-07 - val_loss: 3.6941e-07\n",
      "Epoch 817/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.9297e-07 - val_loss: 3.6804e-07\n",
      "Epoch 818/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8971e-07 - val_loss: 3.6666e-07\n",
      "Epoch 819/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8645e-07 - val_loss: 3.6557e-07\n",
      "Epoch 820/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.8315e-07 - val_loss: 3.6517e-07\n",
      "Epoch 821/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7988e-07 - val_loss: 3.6413e-07\n",
      "Epoch 822/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7679e-07 - val_loss: 3.6395e-07\n",
      "Epoch 823/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7353e-07 - val_loss: 3.6349e-07\n",
      "Epoch 824/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.7062e-07 - val_loss: 3.6434e-07\n",
      "Epoch 825/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6719e-07 - val_loss: 3.6253e-07\n",
      "Epoch 826/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6402e-07 - val_loss: 3.6042e-07\n",
      "Epoch 827/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.6088e-07 - val_loss: 3.5969e-07\n",
      "Epoch 828/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5785e-07 - val_loss: 3.5972e-07\n",
      "Epoch 829/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5448e-07 - val_loss: 3.5871e-07\n",
      "Epoch 830/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.5124e-07 - val_loss: 3.5767e-07\n",
      "Epoch 831/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4822e-07 - val_loss: 3.5759e-07\n",
      "Epoch 832/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4546e-07 - val_loss: 3.5713e-07\n",
      "Epoch 833/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.4229e-07 - val_loss: 3.5720e-07\n",
      "Epoch 834/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3900e-07 - val_loss: 3.5733e-07\n",
      "Epoch 835/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3581e-07 - val_loss: 3.5552e-07\n",
      "Epoch 836/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.3264e-07 - val_loss: 3.5471e-07\n",
      "Epoch 837/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2957e-07 - val_loss: 3.5382e-07\n",
      "Epoch 838/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2652e-07 - val_loss: 3.5164e-07\n",
      "Epoch 839/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2362e-07 - val_loss: 3.5226e-07\n",
      "Epoch 840/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.2070e-07 - val_loss: 3.5003e-07\n",
      "Epoch 841/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 9.1750e-07 - val_loss: 3.4946e-07\n",
      "Epoch 842/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1462e-07 - val_loss: 3.4999e-07\n",
      "Epoch 843/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.1163e-07 - val_loss: 3.5070e-07\n",
      "Epoch 844/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0874e-07 - val_loss: 3.5165e-07\n",
      "Epoch 845/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0574e-07 - val_loss: 3.4852e-07\n",
      "Epoch 846/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 9.0256e-07 - val_loss: 3.4642e-07\n",
      "Epoch 847/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9956e-07 - val_loss: 3.4581e-07\n",
      "Epoch 848/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9665e-07 - val_loss: 3.4632e-07\n",
      "Epoch 849/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9370e-07 - val_loss: 3.4683e-07\n",
      "Epoch 850/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.9081e-07 - val_loss: 3.4501e-07\n",
      "Epoch 851/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8748e-07 - val_loss: 3.4393e-07\n",
      "Epoch 852/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8467e-07 - val_loss: 3.4326e-07\n",
      "Epoch 853/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.8178e-07 - val_loss: 3.4207e-07\n",
      "Epoch 854/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7888e-07 - val_loss: 3.4160e-07\n",
      "Epoch 855/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7623e-07 - val_loss: 3.4080e-07\n",
      "Epoch 856/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7377e-07 - val_loss: 3.4144e-07\n",
      "Epoch 857/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.7079e-07 - val_loss: 3.4134e-07\n",
      "Epoch 858/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6761e-07 - val_loss: 3.3877e-07\n",
      "Epoch 859/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6437e-07 - val_loss: 3.3857e-07\n",
      "Epoch 860/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.6142e-07 - val_loss: 3.3823e-07\n",
      "Epoch 861/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5870e-07 - val_loss: 3.3792e-07\n",
      "Epoch 862/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5605e-07 - val_loss: 3.3733e-07\n",
      "Epoch 863/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5302e-07 - val_loss: 3.3636e-07\n",
      "Epoch 864/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.5003e-07 - val_loss: 3.3587e-07\n",
      "Epoch 865/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4758e-07 - val_loss: 3.3573e-07\n",
      "Epoch 866/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4442e-07 - val_loss: 3.3374e-07\n",
      "Epoch 867/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.4169e-07 - val_loss: 3.3301e-07\n",
      "Epoch 868/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3871e-07 - val_loss: 3.3187e-07\n",
      "Epoch 869/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3615e-07 - val_loss: 3.3105e-07\n",
      "Epoch 870/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3325e-07 - val_loss: 3.3003e-07\n",
      "Epoch 871/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.3041e-07 - val_loss: 3.3032e-07\n",
      "Epoch 872/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2780e-07 - val_loss: 3.3004e-07\n",
      "Epoch 873/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2525e-07 - val_loss: 3.3100e-07\n",
      "Epoch 874/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.2233e-07 - val_loss: 3.2893e-07\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1940e-07 - val_loss: 3.2859e-07\n",
      "Epoch 876/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1686e-07 - val_loss: 3.2901e-07\n",
      "Epoch 877/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1410e-07 - val_loss: 3.2761e-07\n",
      "Epoch 878/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.1131e-07 - val_loss: 3.2632e-07\n",
      "Epoch 879/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0865e-07 - val_loss: 3.2580e-07\n",
      "Epoch 880/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0572e-07 - val_loss: 3.2457e-07\n",
      "Epoch 881/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0304e-07 - val_loss: 3.2442e-07\n",
      "Epoch 882/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 8.0028e-07 - val_loss: 3.2323e-07\n",
      "Epoch 883/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9765e-07 - val_loss: 3.2297e-07\n",
      "Epoch 884/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9508e-07 - val_loss: 3.2264e-07\n",
      "Epoch 885/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.9214e-07 - val_loss: 3.2154e-07\n",
      "Epoch 886/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8954e-07 - val_loss: 3.2002e-07\n",
      "Epoch 887/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8698e-07 - val_loss: 3.2011e-07\n",
      "Epoch 888/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8428e-07 - val_loss: 3.1999e-07\n",
      "Epoch 889/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.8174e-07 - val_loss: 3.2016e-07\n",
      "Epoch 890/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7911e-07 - val_loss: 3.1879e-07\n",
      "Epoch 891/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7641e-07 - val_loss: 3.1792e-07\n",
      "Epoch 892/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7403e-07 - val_loss: 3.1827e-07\n",
      "Epoch 893/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.7169e-07 - val_loss: 3.1645e-07\n",
      "Epoch 894/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6908e-07 - val_loss: 3.1521e-07\n",
      "Epoch 895/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6621e-07 - val_loss: 3.1643e-07\n",
      "Epoch 896/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6358e-07 - val_loss: 3.1433e-07\n",
      "Epoch 897/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.6088e-07 - val_loss: 3.1232e-07\n",
      "Epoch 898/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5818e-07 - val_loss: 3.1311e-07\n",
      "Epoch 899/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5552e-07 - val_loss: 3.1281e-07\n",
      "Epoch 900/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5288e-07 - val_loss: 3.1209e-07\n",
      "Epoch 901/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.5033e-07 - val_loss: 3.1137e-07\n",
      "Epoch 902/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4784e-07 - val_loss: 3.1063e-07\n",
      "Epoch 903/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4540e-07 - val_loss: 3.1039e-07\n",
      "Epoch 904/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4299e-07 - val_loss: 3.1008e-07\n",
      "Epoch 905/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.4074e-07 - val_loss: 3.1064e-07\n",
      "Epoch 906/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3771e-07 - val_loss: 3.0869e-07\n",
      "Epoch 907/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3513e-07 - val_loss: 3.0772e-07\n",
      "Epoch 908/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3250e-07 - val_loss: 3.0602e-07\n",
      "Epoch 909/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.3008e-07 - val_loss: 3.0472e-07\n",
      "Epoch 910/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2757e-07 - val_loss: 3.0506e-07\n",
      "Epoch 911/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2511e-07 - val_loss: 3.0538e-07\n",
      "Epoch 912/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2262e-07 - val_loss: 3.0518e-07\n",
      "Epoch 913/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.2006e-07 - val_loss: 3.0459e-07\n",
      "Epoch 914/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1748e-07 - val_loss: 3.0334e-07\n",
      "Epoch 915/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1507e-07 - val_loss: 3.0221e-07\n",
      "Epoch 916/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1258e-07 - val_loss: 3.0154e-07\n",
      "Epoch 917/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.1025e-07 - val_loss: 3.0117e-07\n",
      "Epoch 918/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0777e-07 - val_loss: 3.0099e-07\n",
      "Epoch 919/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0517e-07 - val_loss: 2.9949e-07\n",
      "Epoch 920/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0282e-07 - val_loss: 2.9893e-07\n",
      "Epoch 921/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 7.0040e-07 - val_loss: 2.9752e-07\n",
      "Epoch 922/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9794e-07 - val_loss: 2.9780e-07\n",
      "Epoch 923/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9561e-07 - val_loss: 2.9706e-07\n",
      "Epoch 924/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9312e-07 - val_loss: 2.9645e-07\n",
      "Epoch 925/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.9081e-07 - val_loss: 2.9690e-07\n",
      "Epoch 926/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8859e-07 - val_loss: 2.9496e-07\n",
      "Epoch 927/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8589e-07 - val_loss: 2.9481e-07\n",
      "Epoch 928/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8335e-07 - val_loss: 2.9388e-07\n",
      "Epoch 929/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.8111e-07 - val_loss: 2.9383e-07\n",
      "Epoch 930/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7870e-07 - val_loss: 2.9308e-07\n",
      "Epoch 931/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7628e-07 - val_loss: 2.9193e-07\n",
      "Epoch 932/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7386e-07 - val_loss: 2.9117e-07\n",
      "Epoch 933/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.7158e-07 - val_loss: 2.9096e-07\n",
      "Epoch 934/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6947e-07 - val_loss: 2.9006e-07\n",
      "Epoch 935/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6721e-07 - val_loss: 2.8992e-07\n",
      "Epoch 936/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6470e-07 - val_loss: 2.8952e-07\n",
      "Epoch 937/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.6234e-07 - val_loss: 2.8870e-07\n",
      "Epoch 938/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5988e-07 - val_loss: 2.8699e-07\n",
      "Epoch 939/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5763e-07 - val_loss: 2.8665e-07\n",
      "Epoch 940/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5540e-07 - val_loss: 2.8572e-07\n",
      "Epoch 941/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5313e-07 - val_loss: 2.8578e-07\n",
      "Epoch 942/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.5063e-07 - val_loss: 2.8597e-07\n",
      "Epoch 943/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4822e-07 - val_loss: 2.8504e-07\n",
      "Epoch 944/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4604e-07 - val_loss: 2.8448e-07\n",
      "Epoch 945/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4360e-07 - val_loss: 2.8303e-07\n",
      "Epoch 946/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.4135e-07 - val_loss: 2.8221e-07\n",
      "Epoch 947/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3924e-07 - val_loss: 2.8121e-07\n",
      "Epoch 948/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3703e-07 - val_loss: 2.8199e-07\n",
      "Epoch 949/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3476e-07 - val_loss: 2.8097e-07\n",
      "Epoch 950/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3236e-07 - val_loss: 2.8073e-07\n",
      "Epoch 951/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.3024e-07 - val_loss: 2.7974e-07\n",
      "Epoch 952/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2795e-07 - val_loss: 2.7901e-07\n",
      "Epoch 953/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2546e-07 - val_loss: 2.7774e-07\n",
      "Epoch 954/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2322e-07 - val_loss: 2.7749e-07\n",
      "Epoch 955/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.2097e-07 - val_loss: 2.7681e-07\n",
      "Epoch 956/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1883e-07 - val_loss: 2.7642e-07\n",
      "Epoch 957/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1658e-07 - val_loss: 2.7571e-07\n",
      "Epoch 958/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1446e-07 - val_loss: 2.7599e-07\n",
      "Epoch 959/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.1218e-07 - val_loss: 2.7470e-07\n",
      "Epoch 960/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0981e-07 - val_loss: 2.7353e-07\n",
      "Epoch 961/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0765e-07 - val_loss: 2.7223e-07\n",
      "Epoch 962/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0551e-07 - val_loss: 2.7205e-07\n",
      "Epoch 963/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0326e-07 - val_loss: 2.7120e-07\n",
      "Epoch 964/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 6.0121e-07 - val_loss: 2.7084e-07\n",
      "Epoch 965/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9915e-07 - val_loss: 2.7049e-07\n",
      "Epoch 966/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9703e-07 - val_loss: 2.6936e-07\n",
      "Epoch 967/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9503e-07 - val_loss: 2.6951e-07\n",
      "Epoch 968/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9242e-07 - val_loss: 2.6868e-07\n",
      "Epoch 969/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.9025e-07 - val_loss: 2.6722e-07\n",
      "Epoch 970/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8821e-07 - val_loss: 2.6742e-07\n",
      "Epoch 971/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8598e-07 - val_loss: 2.6649e-07\n",
      "Epoch 972/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8392e-07 - val_loss: 2.6585e-07\n",
      "Epoch 973/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.8182e-07 - val_loss: 2.6575e-07\n",
      "Epoch 974/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7957e-07 - val_loss: 2.6515e-07\n",
      "Epoch 975/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7745e-07 - val_loss: 2.6387e-07\n",
      "Epoch 976/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7532e-07 - val_loss: 2.6341e-07\n",
      "Epoch 977/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7332e-07 - val_loss: 2.6339e-07\n",
      "Epoch 978/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.7111e-07 - val_loss: 2.6194e-07\n",
      "Epoch 979/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6915e-07 - val_loss: 2.6165e-07\n",
      "Epoch 980/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6690e-07 - val_loss: 2.6082e-07\n",
      "Epoch 981/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6487e-07 - val_loss: 2.6044e-07\n",
      "Epoch 982/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6275e-07 - val_loss: 2.5918e-07\n",
      "Epoch 983/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.6070e-07 - val_loss: 2.5876e-07\n",
      "Epoch 984/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5863e-07 - val_loss: 2.5831e-07\n",
      "Epoch 985/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5652e-07 - val_loss: 2.5745e-07\n",
      "Epoch 986/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5448e-07 - val_loss: 2.5711e-07\n",
      "Epoch 987/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5259e-07 - val_loss: 2.5682e-07\n",
      "Epoch 988/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.5039e-07 - val_loss: 2.5601e-07\n",
      "Epoch 989/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4850e-07 - val_loss: 2.5574e-07\n",
      "Epoch 990/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4635e-07 - val_loss: 2.5485e-07\n",
      "Epoch 991/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4439e-07 - val_loss: 2.5441e-07\n",
      "Epoch 992/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4234e-07 - val_loss: 2.5362e-07\n",
      "Epoch 993/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.4036e-07 - val_loss: 2.5253e-07\n",
      "Epoch 994/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3847e-07 - val_loss: 2.5178e-07\n",
      "Epoch 995/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3639e-07 - val_loss: 2.5113e-07\n",
      "Epoch 996/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3443e-07 - val_loss: 2.5107e-07\n",
      "Epoch 997/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3231e-07 - val_loss: 2.5025e-07\n",
      "Epoch 998/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.3032e-07 - val_loss: 2.5000e-07\n",
      "Epoch 999/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2827e-07 - val_loss: 2.4869e-07\n",
      "Epoch 1000/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 5.2632e-07 - val_loss: 2.4828e-07\n"
     ]
    }
   ],
   "source": [
    "numOfLayers = 2\n",
    "numOfNeurons = 4 #np.power(2,i)\n",
    "#[best_model,loss_history] = trainLSTM(numOfLayers, numOfNeurons)\n",
    "[model, validatoinLoss, numOfEpochs, history] = trainLSTM(numOfLayers, numOfNeurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final LSTM evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:  1.0\n",
      "Recall is:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = model.predict(LSTMTest_data)\n",
    "mse = (np.square(LSTMTest_data - predicted)).mean(axis=1)\n",
    "mse = mse.reshape(testDataSize)\n",
    "reshaped_test_labels = test_labels.reshape(testDataSize)\n",
    "mse_label = np.vstack((mse, reshaped_test_labels)).T\n",
    "precision = rankedPrecision(mse_label)\n",
    "recall = rankedRecall(mse_label)\n",
    "lstmPrecision = precision\n",
    "lstmRecall = recall\n",
    "print(\"precision is: \", precision)\n",
    "print(\"Recall is: \", precision)\n",
    "show_curve(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-encoder\n",
    "Next architecture we want to use is the Auto-Encoder. Again we first defined a function to use in tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAutoencoder(numOfHiddenLayersInEncoder, NeuronsCountInFirstLayer, printSummary = 1, vrbs = 1, return_best = 0):\n",
    "    \n",
    "    print('Training model.')\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    #NeuronsCountInFirstLayer = 64\n",
    "    model.add(Dense(NeuronsCountInFirstLayer, input_shape=(sequenceLen,), activation='relu'))\n",
    "    for i in range(1,numOfHiddenLayersInEncoder):\n",
    "        model.add(Dense(int(NeuronsCountInFirstLayer/np.power(2,i)), activation=\"relu\"))\n",
    "        \n",
    "    for j in range(1,numOfHiddenLayersInEncoder):    \n",
    "        model.add(Dense(int(NeuronsCountInFirstLayer/np.power(2,(numOfHiddenLayersInEncoder - j - 1))), activation=\"relu\"))\n",
    "        \n",
    "    model.add(Dense(100, activation=\"linear\"))\n",
    "\n",
    "    if(printSummary == True):\n",
    "            model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "        loss='mean_squared_error',\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "    callbacksArray = [es]\n",
    "    if(return_best):\n",
    "        mc = ModelCheckpoint('best_Autoencoder.h5', monitor='val_loss', mode='min')\n",
    "        callbacksArray = [es, mc]\n",
    "\n",
    "    history=model.fit(training_data, training_data,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True,\n",
    "                        epochs=1000, # Change this to at least 20 for final run\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=callbacksArray,\n",
    "                        verbose = vrbs\n",
    "                        )\n",
    "    \n",
    "    if(return_best):\n",
    "        best_model = load_model('best_Autoencoder.h5')\n",
    "        \n",
    "    returnModel = model\n",
    "    if(return_best):\n",
    "        returnModel = best_model\n",
    "    return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Auto-encoder depth tuning\n",
    "In this part we try to tune the Auto-Encoder depth. We used 1,3,5 and 7 hidden layers to find out which works the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_178 (Dense)            (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 12,964\n",
      "Trainable params: 12,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1287 - val_loss: 0.1118\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.1054 - val_loss: 0.0956\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0927 - val_loss: 0.0853\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0839 - val_loss: 0.0773\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0768 - val_loss: 0.0705\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0707 - val_loss: 0.0647\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0654 - val_loss: 0.0599\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0609 - val_loss: 0.0560\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0569 - val_loss: 0.0526\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0533 - val_loss: 0.0494\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0499 - val_loss: 0.0464\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0468 - val_loss: 0.0433\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0438 - val_loss: 0.0405\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0411 - val_loss: 0.0376\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0384 - val_loss: 0.0349\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0359 - val_loss: 0.0323\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0336 - val_loss: 0.0302\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0315 - val_loss: 0.0283\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0294 - val_loss: 0.0263\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0275 - val_loss: 0.0243\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0257 - val_loss: 0.0224\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0239 - val_loss: 0.0207\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0223 - val_loss: 0.0192\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0208 - val_loss: 0.0179\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0195 - val_loss: 0.0166\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0183 - val_loss: 0.0153\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0172 - val_loss: 0.0141\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0144 - val_loss: 0.0114\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0083 - val_loss: 0.0059\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0076 - val_loss: 0.0054\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.006 - 0s 38us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 31us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 36us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 9.9869e-04\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 9.5937e-04\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0018 - val_loss: 9.3807e-04\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0019 - val_loss: 9.8792e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 9.9228e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0018 - val_loss: 9.5207e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 9.2620e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 9.1506e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 9.1665e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 8.7588e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0017 - val_loss: 9.1237e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 9.3398e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 9.2795e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 8.5294e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0016 - val_loss: 8.5958e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 8.7024e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 8.2174e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 8.0236e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 7.8561e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0016 - val_loss: 7.9551e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0016 - val_loss: 8.2879e-04\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 34us/step - loss: 0.0016 - val_loss: 7.8286e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0015 - val_loss: 7.5667e-04\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 7.8582e-04\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0015 - val_loss: 7.5919e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 7.3667e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 7.5719e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 7.4843e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 7.5255e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 7.5174e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 7.1920e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0015 - val_loss: 7.3179e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 7.1970e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0014 - val_loss: 7.6276e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 7.2961e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0014 - val_loss: 7.6915e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 7.4259e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0014 - val_loss: 7.0571e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0014 - val_loss: 6.8616e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 6.7869e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 7.2109e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 7.5471e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0014 - val_loss: 6.9543e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0014 - val_loss: 6.7420e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0013 - val_loss: 6.7108e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0014 - val_loss: 7.0744e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0014 - val_loss: 6.9376e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0013 - val_loss: 6.5818e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.4104e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.3434e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0013 - val_loss: 6.1743e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0013 - val_loss: 6.1016e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.1293e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.0457e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 5.9308e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0012 - val_loss: 6.0627e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 6.6557e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0013 - val_loss: 6.4263e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.2449e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 6.0614e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 5.6928e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0012 - val_loss: 5.7724e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0012 - val_loss: 5.7780e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.7955e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.9005e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 33us/step - loss: 0.0012 - val_loss: 5.7991e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 6.0958e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.8814e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 5.7431e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.6639e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 5.3285e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.3274e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 5.3226e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 5.1908e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0011 - val_loss: 5.0961e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 5.1928e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 5.4062e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0011 - val_loss: 5.5684e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.6326e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 5.6154e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0012 - val_loss: 6.1188e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 5.4873e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 5.3968e-04\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0011 - val_loss: 5.2560e-04\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0011 - val_loss: 5.1022e-04\n",
      "Epoch 00213: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 17,156\n",
      "Trainable params: 17,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1044 - val_loss: 0.0953\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0922 - val_loss: 0.0861\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0835 - val_loss: 0.0769\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0752 - val_loss: 0.0701\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0698 - val_loss: 0.0657\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0659 - val_loss: 0.0623\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0628 - val_loss: 0.0592\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0598 - val_loss: 0.0563\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0568 - val_loss: 0.0536\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0541 - val_loss: 0.0511\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0515 - val_loss: 0.0489\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0492 - val_loss: 0.0467\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0470 - val_loss: 0.0445\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0451 - val_loss: 0.0425\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0431 - val_loss: 0.0407\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0413 - val_loss: 0.0388\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0395 - val_loss: 0.0371\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0380 - val_loss: 0.0357\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0363 - val_loss: 0.0342\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0348 - val_loss: 0.0323\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0331 - val_loss: 0.0309\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0317 - val_loss: 0.0292\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0301 - val_loss: 0.0277\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0288 - val_loss: 0.0263\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0273 - val_loss: 0.0249\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0260 - val_loss: 0.0236\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0249 - val_loss: 0.0226\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0240 - val_loss: 0.0216\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0230 - val_loss: 0.0204\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0220 - val_loss: 0.0199\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0213 - val_loss: 0.0189\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0207 - val_loss: 0.0183\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0199 - val_loss: 0.0177\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0193 - val_loss: 0.0171\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0186 - val_loss: 0.0162\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0181 - val_loss: 0.0160\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0175 - val_loss: 0.0152\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0169 - val_loss: 0.0148\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0165 - val_loss: 0.0141\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0160 - val_loss: 0.0139\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0152 - val_loss: 0.0132\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0139 - val_loss: 0.0117\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0124 - val_loss: 0.0103\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0117 - val_loss: 0.0097\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0095 - val_loss: 0.0076\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0086 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0085 - val_loss: 0.0068\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 60us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 00233: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_184 (Dense)            (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 18,228\n",
      "Trainable params: 18,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0991 - val_loss: 0.0934\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0909 - val_loss: 0.0830\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0806 - val_loss: 0.0718\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0729 - val_loss: 0.0678\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0694 - val_loss: 0.0662\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0676 - val_loss: 0.0652\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0664 - val_loss: 0.0643\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0653 - val_loss: 0.0630\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0638 - val_loss: 0.0613\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0620 - val_loss: 0.0594\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0601 - val_loss: 0.0574\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0581 - val_loss: 0.0553\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0562 - val_loss: 0.0534\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0544 - val_loss: 0.0520\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0526 - val_loss: 0.0505\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0512 - val_loss: 0.0496\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0499 - val_loss: 0.0487\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0488 - val_loss: 0.0474\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0479 - val_loss: 0.0466\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0470 - val_loss: 0.0461\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0462 - val_loss: 0.0451\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0454 - val_loss: 0.0441\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0445 - val_loss: 0.0432\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0438 - val_loss: 0.0428\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0430 - val_loss: 0.0417\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0421 - val_loss: 0.0410\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0414 - val_loss: 0.0400\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0408 - val_loss: 0.0395\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0399 - val_loss: 0.0384\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0393 - val_loss: 0.0376\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0385 - val_loss: 0.0369\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0380 - val_loss: 0.0362\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0374 - val_loss: 0.0359\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0368 - val_loss: 0.0347\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0362 - val_loss: 0.0342\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0356 - val_loss: 0.0336\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0349 - val_loss: 0.0327\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0344 - val_loss: 0.0322\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0338 - val_loss: 0.0316\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0336 - val_loss: 0.0310\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0331 - val_loss: 0.0304\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0325 - val_loss: 0.0300\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0321 - val_loss: 0.0298\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0319 - val_loss: 0.0294\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0314 - val_loss: 0.0286\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0309 - val_loss: 0.0285\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0307 - val_loss: 0.0282\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0303 - val_loss: 0.0277\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0299 - val_loss: 0.0276\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0297 - val_loss: 0.0271\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0295 - val_loss: 0.0269\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 61us/step - loss: 0.0294 - val_loss: 0.0270\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0291 - val_loss: 0.0266\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0287 - val_loss: 0.0264\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0285 - val_loss: 0.0262\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0284 - val_loss: 0.0257\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0280 - val_loss: 0.0255\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0280 - val_loss: 0.0254\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0277 - val_loss: 0.0253\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0276 - val_loss: 0.0250\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0273 - val_loss: 0.0249\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0270 - val_loss: 0.0246\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0267 - val_loss: 0.0242\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0265 - val_loss: 0.0240\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0263 - val_loss: 0.0240\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 60us/step - loss: 0.0261 - val_loss: 0.0235\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0259 - val_loss: 0.0234\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0258 - val_loss: 0.0231\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0256 - val_loss: 0.0233\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0256 - val_loss: 0.0229\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0252 - val_loss: 0.0226\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0248 - val_loss: 0.0228\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0249 - val_loss: 0.0225\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0246 - val_loss: 0.0224\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0245 - val_loss: 0.0222\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0244 - val_loss: 0.0219\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0241 - val_loss: 0.0218\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0240 - val_loss: 0.0216\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0239 - val_loss: 0.0215\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0237 - val_loss: 0.0213\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0235 - val_loss: 0.0210\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0233 - val_loss: 0.0210\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0231 - val_loss: 0.0208\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0230 - val_loss: 0.0210\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0230 - val_loss: 0.0208\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0229 - val_loss: 0.0208\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0228 - val_loss: 0.0206\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0226 - val_loss: 0.0202\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0224 - val_loss: 0.0203\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0225 - val_loss: 0.0199\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0222 - val_loss: 0.0200\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0221 - val_loss: 0.0199\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0219 - val_loss: 0.0197\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0217 - val_loss: 0.0195\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0217 - val_loss: 0.0196\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0216 - val_loss: 0.0196\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0215 - val_loss: 0.0194\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0212 - val_loss: 0.0194\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0211 - val_loss: 0.0195\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0210 - val_loss: 0.0193\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0211 - val_loss: 0.0189\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0207 - val_loss: 0.0187\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0205 - val_loss: 0.0189\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0205 - val_loss: 0.0187\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0204 - val_loss: 0.0185\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0204 - val_loss: 0.0184\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0201 - val_loss: 0.0184\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0200 - val_loss: 0.0182\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0199 - val_loss: 0.0180\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0197 - val_loss: 0.0181\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0199 - val_loss: 0.0180\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0198 - val_loss: 0.0178\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0196 - val_loss: 0.0181\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0196 - val_loss: 0.0179\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0196 - val_loss: 0.0178\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0194 - val_loss: 0.0175\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0191 - val_loss: 0.0171\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0191 - val_loss: 0.0174\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0191 - val_loss: 0.0176\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0190 - val_loss: 0.0172\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0188 - val_loss: 0.0171\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0186 - val_loss: 0.0171\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0186 - val_loss: 0.0169\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0186 - val_loss: 0.0172\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0186 - val_loss: 0.0170\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0185 - val_loss: 0.0169\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0185 - val_loss: 0.0168\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0184 - val_loss: 0.0165\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0182 - val_loss: 0.0164\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0180 - val_loss: 0.0161\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0179 - val_loss: 0.0164\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0181 - val_loss: 0.0162\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0178 - val_loss: 0.0162\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0178 - val_loss: 0.0160\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0178 - val_loss: 0.0159\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0175 - val_loss: 0.0158\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0174 - val_loss: 0.0158\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0173 - val_loss: 0.0156\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0174 - val_loss: 0.0158\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0172 - val_loss: 0.0154\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0173 - val_loss: 0.0155\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0172 - val_loss: 0.0155\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0173 - val_loss: 0.0154\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0171 - val_loss: 0.0151\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0171 - val_loss: 0.0153\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0170 - val_loss: 0.0153\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0169 - val_loss: 0.0152\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0168 - val_loss: 0.0151\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0166 - val_loss: 0.0150\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0166 - val_loss: 0.0149\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0165 - val_loss: 0.0147\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0165 - val_loss: 0.0149\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 50us/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0162 - val_loss: 0.0147\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0162 - val_loss: 0.0144\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0161 - val_loss: 0.0145\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0160 - val_loss: 0.0142\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0159 - val_loss: 0.0141\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0159 - val_loss: 0.0143\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0158 - val_loss: 0.0140\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0157 - val_loss: 0.0140\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0156 - val_loss: 0.0139\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0156 - val_loss: 0.0139\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0156 - val_loss: 0.0141\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0156 - val_loss: 0.0137\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0155 - val_loss: 0.0136\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0154 - val_loss: 0.0137\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0154 - val_loss: 0.0135\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0155 - val_loss: 0.0135\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0153 - val_loss: 0.0134\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0152 - val_loss: 0.0135\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0151 - val_loss: 0.0133\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0151 - val_loss: 0.0132\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0150 - val_loss: 0.0132\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0148 - val_loss: 0.0132\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0146 - val_loss: 0.0131\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0147 - val_loss: 0.0133\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0146 - val_loss: 0.0131\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0145 - val_loss: 0.0130\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0144 - val_loss: 0.0127\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0142 - val_loss: 0.0129\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0141 - val_loss: 0.0128\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0140 - val_loss: 0.0126\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0140 - val_loss: 0.0124\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0140 - val_loss: 0.0122\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0137 - val_loss: 0.0121\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0135 - val_loss: 0.0120\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0131 - val_loss: 0.0119\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0129 - val_loss: 0.0113\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0127 - val_loss: 0.0113\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0123 - val_loss: 0.0109\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0119 - val_loss: 0.0104\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.011 - 0s 45us/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0083\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0095 - val_loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0090 - val_loss: 0.0076\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 0s 46us/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 0s 45us/step - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 00332: early stopping\n",
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_190 (Dense)            (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 18,508\n",
      "Trainable params: 18,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0987 - val_loss: 0.0957\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0934 - val_loss: 0.0880\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0849 - val_loss: 0.0783\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0773 - val_loss: 0.0712\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0718 - val_loss: 0.0672\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0686 - val_loss: 0.0645\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0662 - val_loss: 0.0628\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0646 - val_loss: 0.0615\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0633 - val_loss: 0.0604\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0621 - val_loss: 0.0594\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0611 - val_loss: 0.0582\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0602 - val_loss: 0.0572\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0594 - val_loss: 0.0564\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0585 - val_loss: 0.0554\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0575 - val_loss: 0.0546\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0568 - val_loss: 0.0536\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.057 - 0s 54us/step - loss: 0.0559 - val_loss: 0.0528\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0551 - val_loss: 0.0522\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0543 - val_loss: 0.0516\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0537 - val_loss: 0.0509\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0528 - val_loss: 0.0501\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0522 - val_loss: 0.0496\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0515 - val_loss: 0.0490\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0509 - val_loss: 0.0485\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0502 - val_loss: 0.0477\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0497 - val_loss: 0.0475\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0492 - val_loss: 0.0471\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0484 - val_loss: 0.0463\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0479 - val_loss: 0.0460\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0474 - val_loss: 0.0458\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0470 - val_loss: 0.0455\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0465 - val_loss: 0.0452\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0460 - val_loss: 0.0443\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0457 - val_loss: 0.0440\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0454 - val_loss: 0.0437\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0450 - val_loss: 0.0436\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0446 - val_loss: 0.0433\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0442 - val_loss: 0.0431\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0439 - val_loss: 0.0426\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0436 - val_loss: 0.0423\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0431 - val_loss: 0.0420\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0427 - val_loss: 0.0417\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0424 - val_loss: 0.0415\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0421 - val_loss: 0.0414\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0419 - val_loss: 0.0411\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0416 - val_loss: 0.0408\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 59us/step - loss: 0.0413 - val_loss: 0.0403\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0409 - val_loss: 0.0401\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0407 - val_loss: 0.0400\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0404 - val_loss: 0.0397\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0401 - val_loss: 0.0394\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0399 - val_loss: 0.0394\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0398 - val_loss: 0.0390\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0394 - val_loss: 0.0390\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0392 - val_loss: 0.0387\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0391 - val_loss: 0.0386\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0389 - val_loss: 0.0382\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0387 - val_loss: 0.0383\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0384 - val_loss: 0.0379\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0381 - val_loss: 0.0377\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0377 - val_loss: 0.0372\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0378 - val_loss: 0.0374\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0375 - val_loss: 0.0369\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0372 - val_loss: 0.0366\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0372 - val_loss: 0.0366\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0370 - val_loss: 0.0366\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0370 - val_loss: 0.0365\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0370 - val_loss: 0.0364\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0368 - val_loss: 0.0358\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0367 - val_loss: 0.0357\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0367 - val_loss: 0.0359\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0364 - val_loss: 0.0358\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0361 - val_loss: 0.0355\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0361 - val_loss: 0.0352\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0360 - val_loss: 0.0352\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0359 - val_loss: 0.0358\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0359 - val_loss: 0.0355\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0358 - val_loss: 0.0355\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0357 - val_loss: 0.0348\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0353 - val_loss: 0.0349\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0352 - val_loss: 0.0348\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0352 - val_loss: 0.0346\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0351 - val_loss: 0.0346\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0348 - val_loss: 0.0343\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0349 - val_loss: 0.0344\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0348 - val_loss: 0.0345\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0346 - val_loss: 0.0342\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0346 - val_loss: 0.0344\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0344 - val_loss: 0.0340\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0344 - val_loss: 0.0339\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0343 - val_loss: 0.0339\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0342 - val_loss: 0.0344\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0343 - val_loss: 0.0338\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0341 - val_loss: 0.0334\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0337 - val_loss: 0.0336\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0339 - val_loss: 0.0333\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0335 - val_loss: 0.0333\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0333 - val_loss: 0.0327\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0331 - val_loss: 0.0330\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0332 - val_loss: 0.0330\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0331 - val_loss: 0.0326\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0328 - val_loss: 0.0327\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0329 - val_loss: 0.0329\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0328 - val_loss: 0.0326\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0326 - val_loss: 0.0325\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0325 - val_loss: 0.0324\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0326 - val_loss: 0.0321\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0325 - val_loss: 0.0320\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0323 - val_loss: 0.0320\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0322 - val_loss: 0.0319\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0321 - val_loss: 0.0318\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0320 - val_loss: 0.0317\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0319 - val_loss: 0.0319\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0319 - val_loss: 0.0319\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 55us/step - loss: 0.0319 - val_loss: 0.0319\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0318 - val_loss: 0.0315\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0317 - val_loss: 0.0315\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0317 - val_loss: 0.0313\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0316 - val_loss: 0.0313\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0313 - val_loss: 0.0313\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0314 - val_loss: 0.0311\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0313 - val_loss: 0.0311\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0312 - val_loss: 0.0313\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0313 - val_loss: 0.0314\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0311 - val_loss: 0.0311\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0311 - val_loss: 0.0310\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0310 - val_loss: 0.0307\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0310 - val_loss: 0.0305\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0309 - val_loss: 0.0304\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0306 - val_loss: 0.0305\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0306 - val_loss: 0.0304\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0305 - val_loss: 0.0304\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0304 - val_loss: 0.0302\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0304 - val_loss: 0.0301\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0302 - val_loss: 0.0301\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0302 - val_loss: 0.0304\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0301 - val_loss: 0.0303\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0301 - val_loss: 0.0304\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0300 - val_loss: 0.0299\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0300 - val_loss: 0.0299\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0300 - val_loss: 0.0300\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0301 - val_loss: 0.0298\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0299 - val_loss: 0.0298\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0296 - val_loss: 0.0293\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0295 - val_loss: 0.0295\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0294 - val_loss: 0.0297\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0293 - val_loss: 0.0293\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0292 - val_loss: 0.0293\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0292 - val_loss: 0.0291\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0292 - val_loss: 0.0291\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0290 - val_loss: 0.0292\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0288 - val_loss: 0.0290\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0287 - val_loss: 0.0290\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0288 - val_loss: 0.0288\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0287 - val_loss: 0.0285\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0288 - val_loss: 0.0287\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0286 - val_loss: 0.0286\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0286 - val_loss: 0.0283\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0284 - val_loss: 0.0283\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0284 - val_loss: 0.0282\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0281 - val_loss: 0.0281\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0282 - val_loss: 0.0280\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 59us/step - loss: 0.0283 - val_loss: 0.0281\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0280 - val_loss: 0.0280\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0279 - val_loss: 0.0280\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0279 - val_loss: 0.0279\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0279 - val_loss: 0.0281\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0278 - val_loss: 0.0280\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0277 - val_loss: 0.0279\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0276 - val_loss: 0.0279\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0276 - val_loss: 0.0279\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0276 - val_loss: 0.0275\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0275 - val_loss: 0.0276\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0274 - val_loss: 0.0276\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0273 - val_loss: 0.0275\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0277 - val_loss: 0.0278\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0278 - val_loss: 0.0272\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0272 - val_loss: 0.0273\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0272 - val_loss: 0.0271\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0272 - val_loss: 0.0273\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0270 - val_loss: 0.0272\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0271 - val_loss: 0.0273\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0271 - val_loss: 0.0271\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0269 - val_loss: 0.0270\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0269 - val_loss: 0.0273\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0270 - val_loss: 0.0275\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0270 - val_loss: 0.0273\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0268 - val_loss: 0.0270\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0268 - val_loss: 0.0271\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0268 - val_loss: 0.0271\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0267 - val_loss: 0.0268\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0267 - val_loss: 0.0268\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0269 - val_loss: 0.0270\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0269 - val_loss: 0.0271\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0266 - val_loss: 0.0272\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0267 - val_loss: 0.0269\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0267 - val_loss: 0.0270\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0265 - val_loss: 0.0269\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0264 - val_loss: 0.0269\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0266 - val_loss: 0.0270\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 0s 60us/step - loss: 0.0264 - val_loss: 0.0267\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0265 - val_loss: 0.0269\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 0s 59us/step - loss: 0.0263 - val_loss: 0.0269\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0263 - val_loss: 0.0266\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0262 - val_loss: 0.0269\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0263 - val_loss: 0.0267\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0261 - val_loss: 0.0268\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0262 - val_loss: 0.0268\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0262 - val_loss: 0.0267\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0261 - val_loss: 0.0266\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0261 - val_loss: 0.0267\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0261 - val_loss: 0.0266\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0260 - val_loss: 0.0272\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0264 - val_loss: 0.0269\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0262 - val_loss: 0.0269\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0261 - val_loss: 0.0269\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0260 - val_loss: 0.0264\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0259 - val_loss: 0.0263\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0258 - val_loss: 0.0263\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0258 - val_loss: 0.0264\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0257 - val_loss: 0.0262\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0257 - val_loss: 0.0263\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0256 - val_loss: 0.0263\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0257 - val_loss: 0.0262\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0257 - val_loss: 0.0261\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0256 - val_loss: 0.0262\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0256 - val_loss: 0.0261\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0255 - val_loss: 0.0260\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0254 - val_loss: 0.0262\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0254 - val_loss: 0.0261\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0254 - val_loss: 0.0262\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0254 - val_loss: 0.0263\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0255 - val_loss: 0.0261\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0255 - val_loss: 0.0260\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0255 - val_loss: 0.0264\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0256 - val_loss: 0.0263\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0255 - val_loss: 0.0264\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0255 - val_loss: 0.0261\n",
      "Epoch 00259: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,5):\n",
    "    numOfLayers = i\n",
    "    numOfNeurons = 4\n",
    "    [model, validatoinLoss, numOfEpochs,_] = trainAutoencoder(numOfLayers, numOfNeurons)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Models validation loss vs. depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Depth')\n",
    "plt.xticks(np.arange(4), [1,3,5,7])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the figure above, it seems that the simplest model with just one hidden layer has the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Auto-Encoder learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 12,964\n",
      "Trainable params: 12,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.1347 - val_loss: 0.1152\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.1091 - val_loss: 0.0974\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0946 - val_loss: 0.0861\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0847 - val_loss: 0.0776\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0769 - val_loss: 0.0708\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0705 - val_loss: 0.0653\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0653 - val_loss: 0.0608\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0609 - val_loss: 0.0568\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0569 - val_loss: 0.0530\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0533 - val_loss: 0.0496\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0500 - val_loss: 0.0465\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0470 - val_loss: 0.0435\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0442 - val_loss: 0.0406\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0414 - val_loss: 0.0378\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0388 - val_loss: 0.0353\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0365 - val_loss: 0.0329\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0343 - val_loss: 0.0307\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0322 - val_loss: 0.0287\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0302 - val_loss: 0.0269\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0283 - val_loss: 0.0249\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0266 - val_loss: 0.0231\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0249 - val_loss: 0.0217\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0234 - val_loss: 0.0200\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0221 - val_loss: 0.0186\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0207 - val_loss: 0.0172\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0194 - val_loss: 0.0160\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0183 - val_loss: 0.0149\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0172 - val_loss: 0.0138\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0162 - val_loss: 0.0129\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0099 - val_loss: 0.0072\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0095 - val_loss: 0.0068\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0081 - val_loss: 0.0056\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 43us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 44us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.002 - 0s 44us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0020 - val_loss: 9.8440e-04\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 9.6706e-04\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 9.9690e-04\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 9.5213e-04\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0019 - val_loss: 9.5166e-04\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0019 - val_loss: 9.5652e-04\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 9.1767e-04\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 8.9544e-04\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0018 - val_loss: 9.0521e-04\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 8.7510e-04\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0018 - val_loss: 8.9458e-04\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 8.9133e-04\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 9.3690e-04\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0018 - val_loss: 9.5571e-04\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0018 - val_loss: 9.1017e-04\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 9.4857e-04\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 9.3732e-04\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0017 - val_loss: 9.1887e-04\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 9.0827e-04\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0017 - val_loss: 8.6082e-04\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0017 - val_loss: 8.9865e-04\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 39us/step - loss: 0.0017 - val_loss: 9.0066e-04\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0017 - val_loss: 8.9974e-04\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0016 - val_loss: 8.5964e-04\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0016 - val_loss: 8.1979e-04\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0016 - val_loss: 8.1243e-04\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0016 - val_loss: 8.5076e-04\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0016 - val_loss: 8.2482e-04\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0016 - val_loss: 7.8413e-04\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 8.0317e-04\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 7.8747e-04\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 7.8373e-04\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0015 - val_loss: 7.8257e-04\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0015 - val_loss: 7.8953e-04\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 34us/step - loss: 0.0015 - val_loss: 8.4966e-04\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 7.7572e-04\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 7.5149e-04\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0015 - val_loss: 7.6942e-04\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0015 - val_loss: 8.0966e-04\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0015 - val_loss: 7.8190e-04\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 8.2308e-04\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 7.6453e-04\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0015 - val_loss: 7.7140e-04\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0015 - val_loss: 7.4030e-04\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0014 - val_loss: 7.2274e-04\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0014 - val_loss: 7.4344e-04\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0014 - val_loss: 7.8391e-04\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0014 - val_loss: 7.4086e-04\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0014 - val_loss: 7.2910e-04\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0014 - val_loss: 7.8588e-04\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0014 - val_loss: 7.1176e-04\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0014 - val_loss: 6.9915e-04\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0014 - val_loss: 6.9756e-04\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0014 - val_loss: 7.0388e-04\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0013 - val_loss: 6.6850e-04\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0013 - val_loss: 7.1809e-04\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0014 - val_loss: 7.0336e-04\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0013 - val_loss: 6.8584e-04\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0013 - val_loss: 6.5536e-04\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0013 - val_loss: 6.5213e-04\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0013 - val_loss: 6.6706e-04\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0013 - val_loss: 6.3226e-04\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0013 - val_loss: 6.5871e-04\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0013 - val_loss: 6.6744e-04\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.3096e-04\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0013 - val_loss: 6.3070e-04\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0012 - val_loss: 6.6705e-04\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0013 - val_loss: 6.7455e-04\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 37us/step - loss: 0.0013 - val_loss: 6.3879e-04\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 41us/step - loss: 0.0012 - val_loss: 6.1787e-04\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 42us/step - loss: 0.0012 - val_loss: 6.1467e-04\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0012 - val_loss: 6.2455e-04\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0012 - val_loss: 6.2034e-04\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0012 - val_loss: 6.4711e-04\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0012 - val_loss: 6.9719e-04\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0013 - val_loss: 6.6564e-04\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 35us/step - loss: 0.0013 - val_loss: 6.9038e-04\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0013 - val_loss: 6.9863e-04\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 39us/step - loss: 0.0013 - val_loss: 6.2248e-04\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 38us/step - loss: 0.0012 - val_loss: 6.3124e-04\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 40us/step - loss: 0.0012 - val_loss: 7.0397e-04\n",
      "Epoch 00211: early stopping\n"
     ]
    }
   ],
   "source": [
    "numOfHiddenLayers = 1\n",
    "numOfNeurons = 64\n",
    "[model, validatoinLoss, numOfEpochs, history] = trainAutoencoder(numOfHiddenLayers, numOfNeurons, return_best = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Auto-encoder evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:  0.78\n",
      "Recall is:  0.78\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = model.predict(test_data)\n",
    "mse = (np.square(test_data - predicted)).mean(axis=1)\n",
    "mse = mse.reshape(testDataSize)\n",
    "reshaped_test_labels = test_labels.reshape(testDataSize)\n",
    "mse_label = np.vstack((mse, reshaped_test_labels)).T\n",
    "precision = rankedPrecision(mse_label)\n",
    "recall = rankedRecall(mse_label)\n",
    "autoencoderPrecision = precision\n",
    "autoencoderRecall = recall\n",
    "print(\"Precision is: \", precision)\n",
    "print(\"Recall is: \", precision)\n",
    "show_curve(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1DConv(numOfHiddenLayersInEncoder, FiltersCountInFirstLayer = 32, printSummary = 1, vrbs = 1, return_best = 0, filterSize = 3):\n",
    "    numOfHiddenLayersInEncoder = numOfHiddenLayersInEncoder + 1\n",
    "    model = Sequential()    \n",
    "    poolingSize = 2\n",
    "    numOfFiltersInEncoder = [FiltersCountInFirstLayer]\n",
    "    paddedSequenceLen = 128\n",
    "    encoderLayersFilterSizes = [paddedSequenceLen]\n",
    "    model.add(ZeroPadding1D(14,input_shape=(sequenceLen,1)))\n",
    "    model.add(Conv1D(int(FiltersCountInFirstLayer), filterSize, activation='relu', padding = 'same'))\n",
    "    for i in range(1,numOfHiddenLayersInEncoder):\n",
    "        model.add(MaxPooling1D(poolingSize, padding='same'))\n",
    "        model.add(Conv1D(int(FiltersCountInFirstLayer*np.power(2,i)), filterSize, activation='relu', padding = 'same'))\n",
    "        encoderLayersFilterSizes.append(int(np.ceil(paddedSequenceLen/np.power(2,i))))\n",
    "        numOfFiltersInEncoder.append(int(FiltersCountInFirstLayer*np.power(2,i)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Reshape((encoderLayersFilterSizes[-1], numOfFiltersInEncoder[-1])))\n",
    "    for j in range(1,numOfHiddenLayersInEncoder):    \n",
    "        model.add(Conv1D(numOfFiltersInEncoder[-j], filterSize, activation='relu', padding = 'same'))\n",
    "        model.add(UpSampling1D(poolingSize))\n",
    "\n",
    "    model.add(Conv1D(numOfFiltersInEncoder[0], filterSize, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(1, filterSize, activation='linear', padding='same'))\n",
    "    model.add(Cropping1D(14))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error',\n",
    "                  )\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "    callbacksArray = [es]\n",
    "    if(return_best):\n",
    "        mc = ModelCheckpoint('best_1DConv.h5', monitor='val_loss', mode='min')\n",
    "        callbacksArray = [es, mc]\n",
    "\n",
    "    history=model.fit(LSTMTraining_data, LSTMTraining_data,\n",
    "                        batch_size=128,\n",
    "                        epochs=1000, \n",
    "                        shuffle=True,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=callbacksArray,\n",
    "                        )\n",
    "    if(return_best):\n",
    "        best_model = load_model('best_1DConv.h5')\n",
    "        \n",
    "    returnModel = model\n",
    "    if(return_best):\n",
    "        returnModel = best_model\n",
    "    return [returnModel,min(history.history['val_loss']),len(history.history['val_loss']),history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network Depth tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_60 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_654 (Conv1D)          (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_336 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_655 (Conv1D)          (None, 64, 64)            6208      \n",
      "_________________________________________________________________\n",
      "flatten_114 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_94 (Reshape)         (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_656 (Conv1D)          (None, 64, 64)            12352     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_182 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_657 (Conv1D)          (None, 128, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_658 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_19 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 24,961\n",
      "Trainable params: 24,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 7s 8ms/step - loss: 0.0704 - val_loss: 0.0496\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 0.0413 - val_loss: 0.0292\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 0.0237 - val_loss: 0.0154\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 120us/step - loss: 0.0116 - val_loss: 0.0059\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 119us/step - loss: 0.0035 - val_loss: 7.3926e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 3.7808e-04 - val_loss: 2.4758e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.9509e-04 - val_loss: 1.2589e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 1.0226e-04 - val_loss: 6.1595e-05\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 4.8412e-05 - val_loss: 3.5858e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.6988e-05 - val_loss: 1.9069e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 1.7298e-05 - val_loss: 1.1547e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 1.1044e-05 - val_loss: 9.2704e-06\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 8.9212e-06 - val_loss: 7.5402e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 7.1636e-06 - val_loss: 6.1394e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 6.1939e-06 - val_loss: 5.4059e-06\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 5.4503e-06 - val_loss: 4.8129e-06\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 4.9093e-06 - val_loss: 4.3340e-06\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 4.4558e-06 - val_loss: 3.9569e-06\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 4.0665e-06 - val_loss: 3.6303e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 3.7355e-06 - val_loss: 3.3250e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 3.4218e-06 - val_loss: 3.0128e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 3.1130e-06 - val_loss: 2.7472e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 2.8589e-06 - val_loss: 2.5189e-06\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.6411e-06 - val_loss: 2.3383e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 2.4594e-06 - val_loss: 2.1919e-06\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.3116e-06 - val_loss: 2.0596e-06\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 2.1782e-06 - val_loss: 1.9377e-06\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.0550e-06 - val_loss: 1.8359e-06\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.9513e-06 - val_loss: 1.7369e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.8479e-06 - val_loss: 1.6373e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.7498e-06 - val_loss: 1.5556e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.6621e-06 - val_loss: 1.4860e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.6010e-06 - val_loss: 1.4097e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.5126e-06 - val_loss: 1.3398e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.4448e-06 - val_loss: 1.2846e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.3793e-06 - val_loss: 1.2145e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 1.3102e-06 - val_loss: 1.1575e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.2492e-06 - val_loss: 1.0991e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 1.1922e-06 - val_loss: 1.0501e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.1371e-06 - val_loss: 9.9796e-07\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 1.0845e-06 - val_loss: 9.6784e-07\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 1.0434e-06 - val_loss: 9.1629e-07\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 9.9664e-07 - val_loss: 8.7247e-07\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 9.5450e-07 - val_loss: 8.3643e-07\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 9.1848e-07 - val_loss: 8.1760e-07\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 107us/step - loss: 8.8958e-07 - val_loss: 7.7788e-07\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 8.5560e-07 - val_loss: 7.4217e-07\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 106us/step - loss: 8.1783e-07 - val_loss: 7.1794e-07\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 7.9272e-07 - val_loss: 6.8862e-07\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 7.6070e-07 - val_loss: 6.6184e-07\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 7.3391e-07 - val_loss: 6.3719e-07\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 7.0769e-07 - val_loss: 6.1109e-07\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 6.8454e-07 - val_loss: 5.9159e-07\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 6.6005e-07 - val_loss: 5.7036e-07\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 6.3679e-07 - val_loss: 5.4613e-07\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 6.1396e-07 - val_loss: 5.3713e-07\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 6.0028e-07 - val_loss: 5.1941e-07\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 5.7835e-07 - val_loss: 4.9119e-07\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 5.5660e-07 - val_loss: 4.7591e-07\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 5.3636e-07 - val_loss: 4.6005e-07\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 5.1888e-07 - val_loss: 4.4218e-07\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 5.0322e-07 - val_loss: 4.2891e-07\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 4.8806e-07 - val_loss: 4.1906e-07\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 4.7317e-07 - val_loss: 4.0346e-07\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 4.5910e-07 - val_loss: 3.8975e-07\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 4.4400e-07 - val_loss: 3.8012e-07\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 4.3216e-07 - val_loss: 3.6387e-07\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 4.1854e-07 - val_loss: 3.5868e-07\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 4.0612e-07 - val_loss: 3.3978e-07\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 3.9254e-07 - val_loss: 3.2980e-07\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 3.8096e-07 - val_loss: 3.1940e-07\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 3.6908e-07 - val_loss: 3.0802e-07\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 120us/step - loss: 3.5775e-07 - val_loss: 3.0059e-07\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 3.4837e-07 - val_loss: 2.9053e-07\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 3.3899e-07 - val_loss: 2.8025e-07\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.2836e-07 - val_loss: 2.7131e-07\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 126us/step - loss: 3.1805e-07 - val_loss: 2.6383e-07\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 127us/step - loss: 3.0916e-07 - val_loss: 2.5512e-07\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 117us/step - loss: 3.0032e-07 - val_loss: 2.4771e-07\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.9321e-07 - val_loss: 2.4004e-07\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 2.8538e-07 - val_loss: 2.4181e-07\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 2.8266e-07 - val_loss: 2.3157e-07\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 2.7290e-07 - val_loss: 2.2199e-07\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 110us/step - loss: 2.6980e-07 - val_loss: 2.6086e-07\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 3.7077e-07 - val_loss: 4.8021e-07\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 7.7119e-07 - val_loss: 1.7253e-06\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 109us/step - loss: 3.8871e-06 - val_loss: 6.9594e-06\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 3.4067e-06 - val_loss: 8.3748e-07\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 120us/step - loss: 1.7072e-06 - val_loss: 4.2322e-07\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 109us/step - loss: 5.8846e-07 - val_loss: 9.3524e-07\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 5.6025e-07 - val_loss: 2.3332e-07\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 4.8109e-07 - val_loss: 5.5298e-07\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 109us/step - loss: 4.8172e-07 - val_loss: 3.0809e-07\n",
      "Epoch 00093: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_61 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_659 (Conv1D)          (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_337 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_660 (Conv1D)          (None, 64, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_338 (MaxPoolin (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_661 (Conv1D)          (None, 32, 128)           24704     \n",
      "_________________________________________________________________\n",
      "flatten_115 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_95 (Reshape)         (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_662 (Conv1D)          (None, 32, 128)           49280     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_183 (UpSamplin (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_663 (Conv1D)          (None, 64, 64)            24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_184 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_664 (Conv1D)          (None, 128, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_665 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_20 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 111,233\n",
      "Trainable params: 111,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 7s 8ms/step - loss: 0.0844 - val_loss: 0.0646\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 175us/step - loss: 0.0551 - val_loss: 0.0404\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 173us/step - loss: 0.0326 - val_loss: 0.0193\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 161us/step - loss: 0.0128 - val_loss: 0.0040\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 0.0010 - val_loss: 6.3776e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 4.3247e-04 - val_loss: 2.4568e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.9691e-04 - val_loss: 1.3612e-04\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 158us/step - loss: 1.2145e-04 - val_loss: 8.2749e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 7.8642e-05 - val_loss: 4.8642e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 153us/step - loss: 4.8779e-05 - val_loss: 4.0208e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 3.8291e-05 - val_loss: 2.3763e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 2.8771e-05 - val_loss: 2.0818e-05\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 2.4366e-05 - val_loss: 1.7264e-05\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 2.0764e-05 - val_loss: 1.4559e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.8121e-05 - val_loss: 1.1678e-05\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 153us/step - loss: 1.6840e-05 - val_loss: 1.1964e-05\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.5061e-05 - val_loss: 1.0595e-05\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 1.3565e-05 - val_loss: 9.2459e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.5017e-05 - val_loss: 1.4724e-05\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.8374e-05 - val_loss: 1.1191e-05\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 1.2503e-05 - val_loss: 6.9706e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.1143e-05 - val_loss: 2.0299e-05\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.0809e-04 - val_loss: 2.2355e-04\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 160us/step - loss: 8.7557e-05 - val_loss: 5.7395e-05\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 2.9056e-05 - val_loss: 1.1710e-05\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 1.5553e-05 - val_loss: 8.4723e-06\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.2425e-05 - val_loss: 1.0152e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 9.5139e-06 - val_loss: 8.3426e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 8.1336e-06 - val_loss: 6.7625e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 7.1612e-06 - val_loss: 4.0260e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 5.6706e-06 - val_loss: 3.6461e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 5.1490e-06 - val_loss: 3.6868e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 5.2506e-06 - val_loss: 3.6267e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 4.7813e-06 - val_loss: 3.1787e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 4.3996e-06 - val_loss: 2.9069e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 4.1602e-06 - val_loss: 2.6824e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 3.9805e-06 - val_loss: 2.5258e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 158us/step - loss: 3.8266e-06 - val_loss: 3.2253e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 7.8671e-06 - val_loss: 2.5688e-05\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 1.0737e-04 - val_loss: 1.6877e-04\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 6.9801e-05 - val_loss: 4.4461e-05\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 3.2962e-05 - val_loss: 2.7224e-05\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.7739e-05 - val_loss: 1.4373e-05\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 8.9219e-06 - val_loss: 1.0077e-05\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 5.9105e-06 - val_loss: 4.0251e-06\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 3.7662e-06 - val_loss: 2.1740e-06\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 2.9852e-06 - val_loss: 2.1243e-06\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 2.6875e-06 - val_loss: 1.9020e-06\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 2.5258e-06 - val_loss: 1.8103e-06\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 2.8346e-06 - val_loss: 1.8970e-06\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 2.5424e-06 - val_loss: 1.4748e-06\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 2.1607e-06 - val_loss: 1.3180e-06\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 2.0263e-06 - val_loss: 1.2705e-06\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 1.9733e-06 - val_loss: 1.2334e-06\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 1.8750e-06 - val_loss: 1.2684e-06\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 1.8630e-06 - val_loss: 1.1159e-06\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.7493e-06 - val_loss: 1.2966e-06\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 2.0167e-06 - val_loss: 2.3395e-06\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 6.5780e-06 - val_loss: 2.0240e-05\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 158us/step - loss: 5.6249e-05 - val_loss: 5.7491e-05\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 2.4732e-05 - val_loss: 1.5696e-05\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.3062e-05 - val_loss: 2.7676e-06\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 3.5669e-06 - val_loss: 2.0810e-06\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 2.1107e-06 - val_loss: 1.2736e-06\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.9318e-06 - val_loss: 1.0951e-06\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 158us/step - loss: 1.5054e-06 - val_loss: 1.5041e-06\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.7742e-06 - val_loss: 9.1905e-07\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.3370e-06 - val_loss: 8.2263e-07\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.2704e-06 - val_loss: 1.2023e-06\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.5158e-06 - val_loss: 1.3006e-06\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 160us/step - loss: 1.5440e-06 - val_loss: 1.9561e-06\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 1.0592e-05 - val_loss: 4.8951e-05\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 9.1874e-05 - val_loss: 5.6987e-05\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 4.5994e-05 - val_loss: 1.8709e-05\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 158us/step - loss: 3.5869e-05 - val_loss: 8.7443e-06\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 155us/step - loss: 1.8241e-05 - val_loss: 1.2719e-05\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 156us/step - loss: 1.0227e-05 - val_loss: 1.3285e-05\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 154us/step - loss: 6.7443e-06 - val_loss: 4.6022e-06\n",
      "Epoch 00079: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_62 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_666 (Conv1D)          (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_339 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_667 (Conv1D)          (None, 64, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_340 (MaxPoolin (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_668 (Conv1D)          (None, 32, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_341 (MaxPoolin (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_669 (Conv1D)          (None, 16, 256)           98560     \n",
      "_________________________________________________________________\n",
      "flatten_116 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_96 (Reshape)         (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_670 (Conv1D)          (None, 16, 256)           196864    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_185 (UpSamplin (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_671 (Conv1D)          (None, 32, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_186 (UpSamplin (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_672 (Conv1D)          (None, 64, 64)            24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_187 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_673 (Conv1D)          (None, 128, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_674 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_21 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 455,809\n",
      "Trainable params: 455,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 7s 8ms/step - loss: 0.0921 - val_loss: 0.0885\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 245us/step - loss: 0.0854 - val_loss: 0.0747\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 229us/step - loss: 0.0666 - val_loss: 0.0569\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 0.0533 - val_loss: 0.0475\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 0.0440 - val_loss: 0.0357\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 0.0298 - val_loss: 0.0189\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 0.0138 - val_loss: 0.0071\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 9.8558e-04 - val_loss: 7.5097e-04\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 7.2584e-04 - val_loss: 5.6706e-04\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 5.4562e-04 - val_loss: 4.0938e-04\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 4.0561e-04 - val_loss: 3.3465e-04\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 3.2296e-04 - val_loss: 2.3782e-04\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 2.4726e-04 - val_loss: 1.8418e-04\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 219us/step - loss: 1.9865e-04 - val_loss: 1.5838e-04\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 1.6569e-04 - val_loss: 1.2593e-04\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 1.3775e-04 - val_loss: 1.0649e-04\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 1.2268e-04 - val_loss: 1.0568e-04\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 216us/step - loss: 1.0756e-04 - val_loss: 8.6951e-05\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 9.3131e-05 - val_loss: 7.3729e-05\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 209us/step - loss: 9.1765e-05 - val_loss: 7.5931e-05\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 218us/step - loss: 7.9192e-05 - val_loss: 7.8221e-05\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 218us/step - loss: 7.6180e-05 - val_loss: 8.1067e-05\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 6.9177e-05 - val_loss: 6.8144e-05\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 6.0083e-05 - val_loss: 6.3139e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 5.7282e-05 - val_loss: 4.7389e-05\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 4.6001e-05 - val_loss: 4.6827e-05\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 6.0120e-05 - val_loss: 4.7705e-05\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 4.2460e-05 - val_loss: 4.9725e-05\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 5.4784e-05 - val_loss: 3.0430e-05\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 5.2097e-05 - val_loss: 3.0747e-05\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 209us/step - loss: 4.6687e-05 - val_loss: 4.9692e-05\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 4.4569e-05 - val_loss: 7.5271e-05\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 6.2826e-05 - val_loss: 6.2839e-05\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 4.7648e-05 - val_loss: 3.0545e-05\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 3.2176e-05 - val_loss: 2.7588e-05\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 2.6273e-05 - val_loss: 2.8329e-05\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 2.4584e-05 - val_loss: 1.7032e-05\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 1.9325e-05 - val_loss: 2.1081e-05\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 4.5235e-05 - val_loss: 7.2096e-05\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 4.2957e-05 - val_loss: 2.9668e-05\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 2.9753e-05 - val_loss: 1.6855e-05\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 218us/step - loss: 1.8336e-05 - val_loss: 1.6822e-05\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 2.4458e-05 - val_loss: 5.4848e-05\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 209us/step - loss: 6.1802e-05 - val_loss: 1.6046e-05\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 225us/step - loss: 4.0282e-05 - val_loss: 3.0166e-05\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 3.5457e-05 - val_loss: 3.1389e-05\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 208us/step - loss: 2.2702e-05 - val_loss: 2.8050e-05\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 2.5196e-05 - val_loss: 1.5930e-05\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 220us/step - loss: 1.7356e-05 - val_loss: 2.0041e-05\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 2.7308e-05 - val_loss: 2.4285e-05\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 2.5017e-05 - val_loss: 4.3637e-05\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 5.3640e-05 - val_loss: 2.6079e-05\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 2.8142e-05 - val_loss: 3.3938e-05\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 2.2978e-05 - val_loss: 2.7577e-05\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 2.1621e-05 - val_loss: 1.3625e-05\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 1.2445e-05 - val_loss: 1.1766e-05\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 1.4263e-05 - val_loss: 2.4943e-05\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 216us/step - loss: 6.8305e-05 - val_loss: 8.4388e-05\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 4.0402e-05 - val_loss: 3.1947e-05\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 2.5709e-05 - val_loss: 1.6867e-05\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 2.4216e-05 - val_loss: 1.2418e-05\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 2.1463e-05 - val_loss: 1.0388e-05\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 1.2617e-05 - val_loss: 1.4748e-05\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 1.2440e-05 - val_loss: 1.0841e-05\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 223us/step - loss: 1.0144e-05 - val_loss: 8.8718e-06\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 218us/step - loss: 8.6263e-06 - val_loss: 9.8272e-06\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 3.4488e-05 - val_loss: 1.2180e-04\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 209us/step - loss: 5.7453e-05 - val_loss: 9.3954e-05\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 1.1663e-04 - val_loss: 1.3763e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 216us/step - loss: 7.3670e-05 - val_loss: 2.0442e-05\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 218us/step - loss: 3.0204e-05 - val_loss: 2.8556e-05\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 1.7947e-05 - val_loss: 1.1730e-05\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 1.0856e-05 - val_loss: 7.2811e-06\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 219us/step - loss: 8.3146e-06 - val_loss: 8.8894e-06\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 216us/step - loss: 8.4584e-06 - val_loss: 7.9803e-06\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 7.6429e-06 - val_loss: 8.1525e-06\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 213us/step - loss: 8.4730e-06 - val_loss: 8.0005e-06\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 217us/step - loss: 9.7013e-06 - val_loss: 9.0625e-06\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 1.0127e-05 - val_loss: 6.2472e-06\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 6.3149e-06 - val_loss: 5.8803e-06\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 6.1627e-06 - val_loss: 9.6742e-06\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 1.6597e-05 - val_loss: 1.1506e-05\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 9.1765e-06 - val_loss: 1.9668e-05\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 4.9260e-05 - val_loss: 8.3124e-05\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 3.7756e-05 - val_loss: 2.3814e-05\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 1.3737e-05 - val_loss: 1.0250e-05\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 215us/step - loss: 9.4503e-06 - val_loss: 7.3990e-06\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 211us/step - loss: 2.1687e-05 - val_loss: 1.5349e-05\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 214us/step - loss: 1.0523e-05 - val_loss: 1.1864e-05\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 212us/step - loss: 7.4746e-06 - val_loss: 9.1474e-06\n",
      "Epoch 00094: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_63 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_675 (Conv1D)          (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_342 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_676 (Conv1D)          (None, 64, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_343 (MaxPoolin (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_677 (Conv1D)          (None, 32, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_344 (MaxPoolin (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_678 (Conv1D)          (None, 16, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_345 (MaxPoolin (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_679 (Conv1D)          (None, 8, 512)            393728    \n",
      "_________________________________________________________________\n",
      "flatten_117 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_97 (Reshape)         (None, 8, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_680 (Conv1D)          (None, 8, 512)            786944    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_188 (UpSamplin (None, 16, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_681 (Conv1D)          (None, 16, 256)           393472    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_189 (UpSamplin (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_682 (Conv1D)          (None, 32, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_190 (UpSamplin (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_683 (Conv1D)          (None, 64, 64)            24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_191 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_684 (Conv1D)          (None, 128, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_685 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_22 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,833,089\n",
      "Trainable params: 1,833,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 8s 9ms/step - loss: 0.0929 - val_loss: 0.0897\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 360us/step - loss: 0.0897 - val_loss: 0.0891\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 327us/step - loss: 0.0885 - val_loss: 0.0851\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 0.0811 - val_loss: 0.0763\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 0.0723 - val_loss: 0.0645\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 317us/step - loss: 0.0621 - val_loss: 0.0568\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 327us/step - loss: 0.0546 - val_loss: 0.0500\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 326us/step - loss: 0.0487 - val_loss: 0.0432\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 0.0420 - val_loss: 0.0356\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 0.0342 - val_loss: 0.0312\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 0.0283 - val_loss: 0.0249\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 325us/step - loss: 0.0227 - val_loss: 0.0186\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 0.0168 - val_loss: 0.0165\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 322us/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 322us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 9.4762e-04 - val_loss: 7.3194e-04\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 6.9499e-04 - val_loss: 6.2995e-04\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 5.6343e-04 - val_loss: 4.3152e-04\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 4.4829e-04 - val_loss: 3.9717e-04\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 4.0360e-04 - val_loss: 3.7023e-04\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 3.4015e-04 - val_loss: 2.8284e-04\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 2.7954e-04 - val_loss: 2.6825e-04\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 326us/step - loss: 2.5533e-04 - val_loss: 2.4716e-04\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 323us/step - loss: 2.3021e-04 - val_loss: 2.0488e-04\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 2.1536e-04 - val_loss: 1.8607e-04\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 1.7853e-04 - val_loss: 1.8224e-04\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 322us/step - loss: 1.6661e-04 - val_loss: 1.5534e-04\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 326us/step - loss: 1.5192e-04 - val_loss: 1.4071e-04\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 1.4134e-04 - val_loss: 1.2554e-04\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 1.2754e-04 - val_loss: 1.2869e-04\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 1.2114e-04 - val_loss: 1.1339e-04\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 1.0952e-04 - val_loss: 1.1463e-04\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 325us/step - loss: 1.0596e-04 - val_loss: 1.2294e-04\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 1.0910e-04 - val_loss: 1.1909e-04\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 1.0731e-04 - val_loss: 1.2762e-04\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 1.6397e-04 - val_loss: 1.2512e-04\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 1.0489e-04 - val_loss: 1.1061e-04\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 325us/step - loss: 9.9245e-05 - val_loss: 1.1175e-04\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 9.5131e-05 - val_loss: 1.0807e-04\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 325us/step - loss: 8.9432e-05 - val_loss: 1.3184e-04\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 1.0166e-04 - val_loss: 8.5992e-05\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 8.0218e-05 - val_loss: 9.2738e-05\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 325us/step - loss: 9.1005e-05 - val_loss: 8.6127e-05\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 323us/step - loss: 9.8956e-05 - val_loss: 9.0333e-05\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 7.5424e-05 - val_loss: 8.5717e-05\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 8.0575e-05 - val_loss: 6.1196e-05\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 5.4058e-05 - val_loss: 5.8768e-05\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 327us/step - loss: 6.2891e-05 - val_loss: 8.9030e-05\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 6.1985e-05 - val_loss: 5.4506e-05\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 4.7102e-05 - val_loss: 5.2301e-05\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 4.7712e-05 - val_loss: 5.4830e-05\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 5.3889e-05 - val_loss: 1.8376e-04\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 329us/step - loss: 4.8486e-04 - val_loss: 4.6889e-04\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 326us/step - loss: 2.7214e-04 - val_loss: 2.1591e-04\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 1.4438e-04 - val_loss: 9.7876e-05\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 326us/step - loss: 1.1305e-04 - val_loss: 1.4569e-04\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 324us/step - loss: 8.5897e-05 - val_loss: 7.7504e-05\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 317us/step - loss: 6.1375e-05 - val_loss: 5.4527e-05\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 322us/step - loss: 4.6357e-05 - val_loss: 4.5443e-05\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 3.9957e-05 - val_loss: 4.8285e-05\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 4.6600e-05 - val_loss: 4.0600e-05\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 317us/step - loss: 3.8925e-05 - val_loss: 4.3524e-05\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 3.6777e-05 - val_loss: 4.9730e-05\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 4.0910e-05 - val_loss: 3.5635e-05\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 3.3001e-05 - val_loss: 3.6839e-05\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 3.4353e-05 - val_loss: 3.6193e-05\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 2.9588e-05 - val_loss: 3.3875e-05\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 3.1126e-05 - val_loss: 3.1479e-05\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 3.6788e-05 - val_loss: 3.9166e-05\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 3.1452e-05 - val_loss: 3.3570e-05\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 2.8300e-05 - val_loss: 2.8565e-05\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 3.5618e-05 - val_loss: 3.6948e-05\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 3.4172e-05 - val_loss: 3.5157e-05\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 322us/step - loss: 2.8041e-05 - val_loss: 3.5785e-05\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 326us/step - loss: 2.8421e-05 - val_loss: 3.4889e-05\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 2.7628e-05 - val_loss: 4.5417e-05\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 316us/step - loss: 4.6278e-05 - val_loss: 2.9210e-05\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 317us/step - loss: 2.7164e-05 - val_loss: 2.7942e-05\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 323us/step - loss: 2.3577e-05 - val_loss: 2.9112e-05\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 3.4945e-05 - val_loss: 1.0057e-04\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 1.2796e-04 - val_loss: 3.7332e-05\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 3.8639e-05 - val_loss: 4.6328e-05\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 3.2836e-05 - val_loss: 2.7458e-05\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 2.3860e-05 - val_loss: 2.7427e-05\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 2.3724e-05 - val_loss: 2.6530e-05\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 2.2892e-05 - val_loss: 2.9170e-05\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 322us/step - loss: 2.3336e-05 - val_loss: 4.9849e-05\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 1.3188e-04 - val_loss: 1.6521e-04\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 321us/step - loss: 8.4671e-05 - val_loss: 8.9021e-05\n",
      "Epoch 95/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 319us/step - loss: 6.7120e-05 - val_loss: 4.6444e-05\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 4.4713e-05 - val_loss: 3.5712e-05\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 2.6953e-05 - val_loss: 2.4827e-05\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 323us/step - loss: 2.1382e-05 - val_loss: 2.9282e-05\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 2.4159e-05 - val_loss: 5.1704e-05\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 4.8111e-05 - val_loss: 2.6212e-05\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 8.0910e-05 - val_loss: 6.4322e-05\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 4.9866e-05 - val_loss: 4.3519e-05\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 3.7137e-05 - val_loss: 3.1674e-05\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 319us/step - loss: 7.0029e-05 - val_loss: 8.4304e-05\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 320us/step - loss: 5.3524e-05 - val_loss: 4.5091e-05\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 318us/step - loss: 4.1169e-05 - val_loss: 3.3548e-05\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 317us/step - loss: 3.3607e-05 - val_loss: 2.6662e-05\n",
      "Epoch 00107: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_64 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_686 (Conv1D)          (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_346 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_687 (Conv1D)          (None, 64, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_347 (MaxPoolin (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_688 (Conv1D)          (None, 32, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_348 (MaxPoolin (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_689 (Conv1D)          (None, 16, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_349 (MaxPoolin (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_690 (Conv1D)          (None, 8, 512)            393728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_350 (MaxPoolin (None, 4, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_691 (Conv1D)          (None, 4, 1024)           1573888   \n",
      "_________________________________________________________________\n",
      "flatten_118 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_98 (Reshape)         (None, 4, 1024)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_692 (Conv1D)          (None, 4, 1024)           3146752   \n",
      "_________________________________________________________________\n",
      "up_sampling1d_192 (UpSamplin (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_693 (Conv1D)          (None, 8, 512)            1573376   \n",
      "_________________________________________________________________\n",
      "up_sampling1d_193 (UpSamplin (None, 16, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_694 (Conv1D)          (None, 16, 256)           393472    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_194 (UpSamplin (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_695 (Conv1D)          (None, 32, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_195 (UpSamplin (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_696 (Conv1D)          (None, 64, 64)            24640     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_196 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_697 (Conv1D)          (None, 128, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_698 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_23 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 7,340,161\n",
      "Trainable params: 7,340,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 9s 10ms/step - loss: 0.0944 - val_loss: 0.0900\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 631us/step - loss: 0.0900 - val_loss: 0.0896\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0895 - val_loss: 0.0887\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.0879 - val_loss: 0.0827\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0818 - val_loss: 0.0741\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 586us/step - loss: 0.0747 - val_loss: 0.0715\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0724 - val_loss: 0.0673\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 0.0684 - val_loss: 0.0670\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 0.0647 - val_loss: 0.0591\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 0.0586 - val_loss: 0.0559\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 0.0549 - val_loss: 0.0502\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.0500 - val_loss: 0.0456\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0455 - val_loss: 0.0432\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 584us/step - loss: 0.0426 - val_loss: 0.0457\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0420 - val_loss: 0.0405\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 0.0386 - val_loss: 0.0335\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0342 - val_loss: 0.0333\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0319 - val_loss: 0.0271\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0268 - val_loss: 0.0236\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 577us/step - loss: 0.0247 - val_loss: 0.0268\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 0.0234 - val_loss: 0.0223\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 577us/step - loss: 0.0212 - val_loss: 0.0189\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.0179 - val_loss: 0.0152\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 0.0158 - val_loss: 0.0163\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0146 - val_loss: 0.0136\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 0.0127 - val_loss: 0.0141\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0136 - val_loss: 0.0118\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 577us/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 575us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 576us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 575us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 574us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 0.0013 - val_loss: 8.4718e-04\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 577us/step - loss: 0.0010 - val_loss: 7.0745e-04\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 8.5103e-04 - val_loss: 6.1312e-04\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 7.7255e-04 - val_loss: 4.9426e-04\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 6.7023e-04 - val_loss: 4.4865e-04\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 1s 574us/step - loss: 6.0196e-04 - val_loss: 4.6414e-04\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 6.9144e-04 - val_loss: 4.7734e-04\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 6.6165e-04 - val_loss: 4.5320e-04\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 1s 575us/step - loss: 5.7983e-04 - val_loss: 3.7741e-04\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 4.9075e-04 - val_loss: 3.4156e-04\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 4.4262e-04 - val_loss: 3.4403e-04\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 1s 577us/step - loss: 4.5358e-04 - val_loss: 3.2549e-04\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 3.9355e-04 - val_loss: 3.1217e-04\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 3.6436e-04 - val_loss: 2.8162e-04\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 3.3607e-04 - val_loss: 2.7638e-04\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 1s 586us/step - loss: 3.2202e-04 - val_loss: 2.6071e-04\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 3.0230e-04 - val_loss: 2.8419e-04\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 3.0277e-04 - val_loss: 2.5331e-04\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 2.7700e-04 - val_loss: 2.6197e-04\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 1s 586us/step - loss: 2.7475e-04 - val_loss: 2.3529e-04\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 2.6991e-04 - val_loss: 2.3748e-04\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 2.5100e-04 - val_loss: 2.2659e-04\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 2.4094e-04 - val_loss: 2.2125e-04\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 1s 578us/step - loss: 2.3157e-04 - val_loss: 2.2610e-04\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 2.1444e-04 - val_loss: 3.1445e-04\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 3.1543e-04 - val_loss: 3.1335e-04\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 1s 585us/step - loss: 2.8263e-04 - val_loss: 2.5878e-04\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 1s 581us/step - loss: 2.4781e-04 - val_loss: 2.6663e-04\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 1s 584us/step - loss: 2.3439e-04 - val_loss: 2.2754e-04\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 2.0828e-04 - val_loss: 1.9775e-04\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 1.8441e-04 - val_loss: 1.9103e-04\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 1.7420e-04 - val_loss: 1.7881e-04\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 1.6428e-04 - val_loss: 1.8012e-04\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 1.5709e-04 - val_loss: 1.8309e-04\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 1s 584us/step - loss: 1.5114e-04 - val_loss: 1.9083e-04\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 1s 584us/step - loss: 1.4502e-04 - val_loss: 1.8631e-04\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 1.4056e-04 - val_loss: 1.9173e-04\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 1s 580us/step - loss: 1.4040e-04 - val_loss: 1.8888e-04\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 1.4389e-04 - val_loss: 2.1636e-04\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 1s 582us/step - loss: 1.4866e-04 - val_loss: 1.9172e-04\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 1.9635e-04 - val_loss: 2.7697e-04\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 1s 583us/step - loss: 2.1992e-04 - val_loss: 2.1561e-04\n",
      "Epoch 00088: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,6):\n",
    "    numOfLayers = i\n",
    "    filtersCountInFirstLayer = 32\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, filtersCountInFirstLayer)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('Models validation loss vs. encoder depth')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Encoder Depth(number of down sampling layers)')\n",
    "plt.xticks(np.arange(5), [1,2,3,4,5])\n",
    "#plt.legend(['validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network filter size tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_65 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_699 (Conv1D)          (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_351 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_700 (Conv1D)          (None, 64, 64)            6208      \n",
      "_________________________________________________________________\n",
      "flatten_119 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_99 (Reshape)         (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_701 (Conv1D)          (None, 64, 64)            12352     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_197 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_702 (Conv1D)          (None, 128, 32)           6176      \n",
      "_________________________________________________________________\n",
      "conv1d_703 (Conv1D)          (None, 128, 1)            97        \n",
      "_________________________________________________________________\n",
      "cropping1d_24 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 24,961\n",
      "Trainable params: 24,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 7s 8ms/step - loss: 0.0815 - val_loss: 0.0561\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 0.0454 - val_loss: 0.0349\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 0.0292 - val_loss: 0.0202\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 126us/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 119us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 119us/step - loss: 0.0014 - val_loss: 5.9655e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 119us/step - loss: 3.7961e-04 - val_loss: 1.8712e-04\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.2368e-04 - val_loss: 5.7040e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 119us/step - loss: 5.0055e-05 - val_loss: 3.8242e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 117us/step - loss: 3.2332e-05 - val_loss: 2.3535e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 2.1141e-05 - val_loss: 1.5452e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 119us/step - loss: 1.3562e-05 - val_loss: 1.1272e-05\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.0510e-05 - val_loss: 8.6918e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 7.9166e-06 - val_loss: 6.6928e-06\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 6.2844e-06 - val_loss: 5.3071e-06\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 5.1272e-06 - val_loss: 4.4169e-06\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 4.3402e-06 - val_loss: 3.7580e-06\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.7522e-06 - val_loss: 3.3248e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.3466e-06 - val_loss: 2.9562e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.9906e-06 - val_loss: 2.6523e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 2.7002e-06 - val_loss: 2.3904e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 2.4507e-06 - val_loss: 2.1542e-06\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.2160e-06 - val_loss: 1.9510e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 2.0183e-06 - val_loss: 1.7912e-06\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.8628e-06 - val_loss: 1.6269e-06\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.6967e-06 - val_loss: 1.4832e-06\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.5596e-06 - val_loss: 1.3754e-06\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.4456e-06 - val_loss: 1.2775e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.3436e-06 - val_loss: 1.1754e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.2406e-06 - val_loss: 1.0817e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.1525e-06 - val_loss: 1.0005e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.0731e-06 - val_loss: 9.2659e-07\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.0034e-06 - val_loss: 8.6170e-07\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 9.4267e-07 - val_loss: 8.0515e-07\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 8.8326e-07 - val_loss: 7.5680e-07\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 8.3152e-07 - val_loss: 7.0593e-07\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 7.8272e-07 - val_loss: 6.5755e-07\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 7.3736e-07 - val_loss: 6.1842e-07\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 6.9953e-07 - val_loss: 5.8897e-07\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 6.6741e-07 - val_loss: 5.6159e-07\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 6.3920e-07 - val_loss: 5.3642e-07\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 6.0645e-07 - val_loss: 5.0410e-07\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 5.8015e-07 - val_loss: 4.7458e-07\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 5.5181e-07 - val_loss: 4.6411e-07\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 5.3344e-07 - val_loss: 4.2662e-07\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 5.0405e-07 - val_loss: 4.0546e-07\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 4.8220e-07 - val_loss: 3.8493e-07\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 4.6131e-07 - val_loss: 3.7118e-07\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 4.4581e-07 - val_loss: 3.5238e-07\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 4.2758e-07 - val_loss: 3.3412e-07\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 4.1223e-07 - val_loss: 3.1873e-07\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 3.9567e-07 - val_loss: 3.0191e-07\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 3.7939e-07 - val_loss: 2.8817e-07\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 3.6554e-07 - val_loss: 2.7615e-07\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 3.5295e-07 - val_loss: 2.6430e-07\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 3.4070e-07 - val_loss: 2.6249e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 3.3281e-07 - val_loss: 2.4280e-07\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.1768e-07 - val_loss: 2.3218e-07\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 3.0707e-07 - val_loss: 2.2376e-07\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.9938e-07 - val_loss: 2.1642e-07\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.8900e-07 - val_loss: 2.1424e-07\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 2.8547e-07 - val_loss: 1.9962e-07\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.7158e-07 - val_loss: 1.9033e-07\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.6112e-07 - val_loss: 1.7940e-07\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 2.5241e-07 - val_loss: 1.7479e-07\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 112us/step - loss: 2.4683e-07 - val_loss: 1.8130e-07\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 2.4863e-07 - val_loss: 1.7038e-07\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.3373e-07 - val_loss: 1.5435e-07\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 2.2355e-07 - val_loss: 1.4717e-07\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 117us/step - loss: 2.1480e-07 - val_loss: 1.4023e-07\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.0674e-07 - val_loss: 1.3187e-07\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 117us/step - loss: 1.9951e-07 - val_loss: 1.4596e-07\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 2.0584e-07 - val_loss: 1.2265e-07\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.8985e-07 - val_loss: 1.1469e-07\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.8060e-07 - val_loss: 1.0746e-07\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 117us/step - loss: 1.7638e-07 - val_loss: 1.0420e-07\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 120us/step - loss: 1.7043e-07 - val_loss: 1.1232e-07\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.7433e-07 - val_loss: 1.0011e-07\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.7786e-07 - val_loss: 1.0863e-07\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.6814e-07 - val_loss: 1.3498e-07\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 1.8814e-07 - val_loss: 1.1964e-07\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.6116e-07 - val_loss: 8.4967e-08\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.4538e-07 - val_loss: 8.4413e-08\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.4555e-07 - val_loss: 7.4987e-08\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.3808e-07 - val_loss: 8.2918e-08\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.7370e-07 - val_loss: 1.2516e-07\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 121us/step - loss: 1.5603e-07 - val_loss: 6.5996e-08\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.4328e-07 - val_loss: 1.1743e-07\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.5442e-07 - val_loss: 9.3489e-08\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 2.3048e-07 - val_loss: 6.0932e-07\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 6.1857e-07 - val_loss: 6.5024e-07\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 4.7606e-07 - val_loss: 2.9592e-07\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 2.5583e-07 - val_loss: 5.7179e-08\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.7207e-07 - val_loss: 9.6647e-08\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.3727e-07 - val_loss: 1.1795e-07\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.4163e-07 - val_loss: 7.5594e-08\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 1.1551e-07 - val_loss: 6.9780e-08\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.1207e-07 - val_loss: 5.6185e-08\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.0410e-07 - val_loss: 4.2663e-08\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 1.0560e-07 - val_loss: 4.6809e-08\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 9.8384e-08 - val_loss: 4.1220e-08\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 9.5308e-08 - val_loss: 5.4225e-08\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 1.8482e-07 - val_loss: 2.9489e-07\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 5.8076e-07 - val_loss: 1.3499e-06\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.8927e-06 - val_loss: 5.4129e-06\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.5113e-06 - val_loss: 2.7180e-07\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.3023e-06 - val_loss: 3.2013e-07\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.1171e-07 - val_loss: 5.4676e-07\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 2.8550e-07 - val_loss: 9.7459e-08\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.9877e-07 - val_loss: 8.0387e-08\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 9.9672e-08 - val_loss: 3.3864e-08\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 9.8791e-08 - val_loss: 8.2491e-08\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.7883e-07 - val_loss: 3.5869e-07\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 116us/step - loss: 8.2610e-07 - val_loss: 1.2029e-06\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 1.1104e-06 - val_loss: 6.7500e-07\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 111us/step - loss: 5.2681e-07 - val_loss: 2.7101e-07\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 113us/step - loss: 3.0415e-07 - val_loss: 6.3033e-07\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 2.7639e-06 - val_loss: 6.5161e-06\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 3.1420e-06 - val_loss: 5.2259e-07\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 114us/step - loss: 1.2863e-06 - val_loss: 3.4046e-07\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 115us/step - loss: 3.1710e-07 - val_loss: 7.4953e-07\n",
      "Epoch 00122: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_66 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_704 (Conv1D)          (None, 128, 32)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_352 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_705 (Conv1D)          (None, 64, 64)            10304     \n",
      "_________________________________________________________________\n",
      "flatten_120 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_100 (Reshape)        (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_706 (Conv1D)          (None, 64, 64)            20544     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_198 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_707 (Conv1D)          (None, 128, 32)           10272     \n",
      "_________________________________________________________________\n",
      "conv1d_708 (Conv1D)          (None, 128, 1)            161       \n",
      "_________________________________________________________________\n",
      "cropping1d_25 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 41,473\n",
      "Trainable params: 41,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 8s 9ms/step - loss: 0.0766 - val_loss: 0.0418\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 0.0329 - val_loss: 0.0220\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 135us/step - loss: 0.0177 - val_loss: 0.0114\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 6.6384e-04 - val_loss: 3.5564e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 2.7270e-04 - val_loss: 1.3942e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 1.0781e-04 - val_loss: 6.8555e-05\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 5.5951e-05 - val_loss: 3.3329e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 3.1757e-05 - val_loss: 2.3674e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 2.0881e-05 - val_loss: 1.4699e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.4331e-05 - val_loss: 1.0798e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 1.0895e-05 - val_loss: 8.3054e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 8.6160e-06 - val_loss: 6.4530e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 7.1088e-06 - val_loss: 5.3580e-06\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 5.9704e-06 - val_loss: 4.6272e-06\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 5.1817e-06 - val_loss: 3.9854e-06\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 4.5294e-06 - val_loss: 3.5676e-06\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 4.0359e-06 - val_loss: 3.1164e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 3.6057e-06 - val_loss: 2.7885e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 3.2303e-06 - val_loss: 2.5227e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 2.9230e-06 - val_loss: 2.3813e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 121us/step - loss: 2.7160e-06 - val_loss: 2.1695e-06\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 2.4936e-06 - val_loss: 2.0601e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 2.3123e-06 - val_loss: 1.8539e-06\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 2.1581e-06 - val_loss: 1.7303e-06\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 2.0086e-06 - val_loss: 1.8585e-06\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 1.9787e-06 - val_loss: 1.5883e-06\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.8058e-06 - val_loss: 1.5239e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 1.7029e-06 - val_loss: 1.4126e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 1.5932e-06 - val_loss: 1.3563e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 1.5186e-06 - val_loss: 1.2778e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 1.4513e-06 - val_loss: 1.2411e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.3873e-06 - val_loss: 1.2007e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 1.3406e-06 - val_loss: 1.1797e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.2917e-06 - val_loss: 1.1081e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.2365e-06 - val_loss: 1.0773e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 1.2038e-06 - val_loss: 1.0338e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 1.1430e-06 - val_loss: 1.0446e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.1292e-06 - val_loss: 9.5748e-07\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 1.0714e-06 - val_loss: 9.9668e-07\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 1.0506e-06 - val_loss: 1.0064e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 1.0222e-06 - val_loss: 8.7717e-07\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 9.8857e-07 - val_loss: 9.9455e-07\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 9.9494e-07 - val_loss: 8.9757e-07\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 9.4886e-07 - val_loss: 8.1615e-07\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 9.1643e-07 - val_loss: 7.7226e-07\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 8.5282e-07 - val_loss: 7.5478e-07\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 8.1769e-07 - val_loss: 7.8712e-07\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 8.6247e-07 - val_loss: 7.7935e-07\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 8.2739e-07 - val_loss: 8.4354e-07\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 9.0707e-07 - val_loss: 6.6721e-07\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 7.6149e-07 - val_loss: 6.5046e-07\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 7.6491e-07 - val_loss: 6.9951e-07\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 7.1245e-07 - val_loss: 6.3663e-07\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 6.6716e-07 - val_loss: 5.9782e-07\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 126us/step - loss: 6.4195e-07 - val_loss: 6.4695e-07\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 126us/step - loss: 6.7784e-07 - val_loss: 6.1304e-07\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 6.3338e-07 - val_loss: 5.7505e-07\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 6.1204e-07 - val_loss: 5.5455e-07\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 6.2513e-07 - val_loss: 5.3446e-07\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 5.6746e-07 - val_loss: 5.4607e-07\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 5.8838e-07 - val_loss: 5.4522e-07\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 5.8190e-07 - val_loss: 5.3704e-07\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 6.3883e-07 - val_loss: 4.8579e-07\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 6.1712e-07 - val_loss: 6.9435e-07\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 7.4066e-07 - val_loss: 6.3476e-07\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 5.8768e-07 - val_loss: 5.5279e-07\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 7.2988e-07 - val_loss: 1.2426e-06\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 2.2351e-06 - val_loss: 4.2115e-06\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 125us/step - loss: 2.4924e-06 - val_loss: 9.1648e-07\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.7140e-06 - val_loss: 4.4441e-07\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 124us/step - loss: 7.8257e-07 - val_loss: 7.4308e-07\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 6.0054e-07 - val_loss: 4.4020e-07\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 5.4732e-07 - val_loss: 7.2795e-07\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.3994e-06 - val_loss: 2.8646e-06\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 3.0411e-06 - val_loss: 1.1272e-06\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 121us/step - loss: 6.5387e-07 - val_loss: 6.9825e-07\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 8.1880e-07 - val_loss: 8.1032e-07\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 7.7778e-07 - val_loss: 7.0440e-07\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 122us/step - loss: 9.2191e-07 - val_loss: 1.6410e-06\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 3.2985e-06 - val_loss: 1.1082e-05\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 1.2231e-05 - val_loss: 6.9737e-07\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 123us/step - loss: 3.0891e-06 - val_loss: 2.0795e-06\n",
      "Epoch 00084: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_67 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_709 (Conv1D)          (None, 128, 32)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_353 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_710 (Conv1D)          (None, 64, 64)            14400     \n",
      "_________________________________________________________________\n",
      "flatten_121 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_101 (Reshape)        (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_711 (Conv1D)          (None, 64, 64)            28736     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_199 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_712 (Conv1D)          (None, 128, 32)           14368     \n",
      "_________________________________________________________________\n",
      "conv1d_713 (Conv1D)          (None, 128, 1)            225       \n",
      "_________________________________________________________________\n",
      "cropping1d_26 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 57,985\n",
      "Trainable params: 57,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 8s 9ms/step - loss: 0.0676 - val_loss: 0.0415\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 0.0325 - val_loss: 0.0185\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 135us/step - loss: 0.0138 - val_loss: 0.0075\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 0.0012 - val_loss: 4.1460e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 3.7323e-04 - val_loss: 2.9314e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 2.1716e-04 - val_loss: 1.2358e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.0761e-04 - val_loss: 7.1957e-05\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 6.1965e-05 - val_loss: 4.7013e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 4.2209e-05 - val_loss: 3.0471e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 2.8778e-05 - val_loss: 2.2292e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 2.2280e-05 - val_loss: 1.8785e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 1.8598e-05 - val_loss: 1.5382e-05\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 1.6072e-05 - val_loss: 1.3940e-05\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.4787e-05 - val_loss: 1.3437e-05\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.6168e-05 - val_loss: 1.1215e-05\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 1.1805e-05 - val_loss: 1.0878e-05\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.9245e-05 - val_loss: 7.7337e-05\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 5.7508e-05 - val_loss: 4.2227e-05\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 2.3311e-05 - val_loss: 2.3420e-05\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.5881e-05 - val_loss: 1.0050e-05\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.0939e-05 - val_loss: 7.0215e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 8.7815e-06 - val_loss: 7.3061e-06\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 7.7801e-06 - val_loss: 6.3274e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 7.1386e-06 - val_loss: 5.9068e-06\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 6.5793e-06 - val_loss: 5.4866e-06\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 7.1951e-06 - val_loss: 1.4318e-05\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 4.6249e-05 - val_loss: 5.4923e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 2.9846e-05 - val_loss: 6.4716e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 1.6191e-05 - val_loss: 1.8077e-05\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 1.1458e-05 - val_loss: 5.2963e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 129us/step - loss: 8.6195e-06 - val_loss: 7.6393e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 6.2409e-06 - val_loss: 4.5686e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 4.8371e-06 - val_loss: 3.7478e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 4.3682e-06 - val_loss: 3.7429e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 4.2729e-06 - val_loss: 4.2662e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 7.1048e-06 - val_loss: 1.3231e-05\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 2.6205e-05 - val_loss: 2.5952e-05\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.1238e-05 - val_loss: 2.0192e-05\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.6565e-05 - val_loss: 5.7923e-06\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 7.9808e-06 - val_loss: 2.8217e-06\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 5.1266e-06 - val_loss: 3.8542e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 3.6343e-06 - val_loss: 5.4183e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 2.1970e-05 - val_loss: 5.3650e-05\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 132us/step - loss: 2.9259e-05 - val_loss: 1.9453e-05\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 1.4492e-05 - val_loss: 1.2710e-05\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 7.6682e-06 - val_loss: 7.3060e-06\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 4.9578e-06 - val_loss: 3.8787e-06\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 3.9398e-06 - val_loss: 3.7222e-06\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 3.1309e-06 - val_loss: 3.7625e-06\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 4.3665e-06 - val_loss: 2.5355e-06\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 2.5637e-06 - val_loss: 2.0814e-06\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 129us/step - loss: 5.8442e-06 - val_loss: 2.4243e-05\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 7.7420e-05 - val_loss: 4.0092e-05\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 2.8123e-05 - val_loss: 1.6401e-05\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 1.4610e-05 - val_loss: 2.4277e-06\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 5.9275e-06 - val_loss: 4.1481e-06\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 3.7795e-06 - val_loss: 4.0269e-06\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 3.0770e-06 - val_loss: 1.5630e-06\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 130us/step - loss: 2.3097e-06 - val_loss: 1.9018e-06\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 2.0625e-06 - val_loss: 1.3850e-06\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.8350e-06 - val_loss: 1.4015e-06\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.7753e-06 - val_loss: 1.3665e-06\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.6821e-06 - val_loss: 1.5744e-06\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.8647e-06 - val_loss: 1.2345e-06\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 1.6601e-06 - val_loss: 1.1763e-06\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.7064e-06 - val_loss: 1.5678e-06\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.5808e-06 - val_loss: 1.1862e-06\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.6205e-06 - val_loss: 1.1788e-06\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 1.4672e-06 - val_loss: 1.4208e-06\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 134us/step - loss: 3.2422e-06 - val_loss: 1.3689e-05\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 7.3657e-05 - val_loss: 1.8082e-04\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 6.9668e-05 - val_loss: 2.5933e-05\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 132us/step - loss: 1.9179e-05 - val_loss: 1.9449e-05\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 133us/step - loss: 1.0000e-05 - val_loss: 1.0145e-05\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 131us/step - loss: 5.1709e-06 - val_loss: 3.9480e-06\n",
      "Epoch 00076: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_68 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_714 (Conv1D)          (None, 128, 32)           320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_354 (MaxPoolin (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_715 (Conv1D)          (None, 64, 64)            18496     \n",
      "_________________________________________________________________\n",
      "flatten_122 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_102 (Reshape)        (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_716 (Conv1D)          (None, 64, 64)            36928     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_200 (UpSamplin (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_717 (Conv1D)          (None, 128, 32)           18464     \n",
      "_________________________________________________________________\n",
      "conv1d_718 (Conv1D)          (None, 128, 1)            289       \n",
      "_________________________________________________________________\n",
      "cropping1d_27 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 74,497\n",
      "Trainable params: 74,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 8s 9ms/step - loss: 0.0807 - val_loss: 0.0501\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 157us/step - loss: 0.0409 - val_loss: 0.0286\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 153us/step - loss: 0.0213 - val_loss: 0.0111\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 147us/step - loss: 0.0075 - val_loss: 0.0036\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 0.0024 - val_loss: 7.7198e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 5.9485e-04 - val_loss: 4.4468e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 3.6085e-04 - val_loss: 1.9586e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 1.6582e-04 - val_loss: 1.1218e-04\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 143us/step - loss: 1.0046e-04 - val_loss: 7.6224e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 6.6974e-05 - val_loss: 4.8661e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 4.7966e-05 - val_loss: 3.5444e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 139us/step - loss: 3.6419e-05 - val_loss: 2.8596e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 139us/step - loss: 3.0665e-05 - val_loss: 2.3750e-05\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 2.5884e-05 - val_loss: 2.1393e-05\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 139us/step - loss: 2.3491e-05 - val_loss: 1.8156e-05\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 2.9969e-05 - val_loss: 8.1692e-05\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 7.6290e-05 - val_loss: 5.4526e-05\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 137us/step - loss: 3.5294e-05 - val_loss: 1.5351e-05\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 137us/step - loss: 2.2399e-05 - val_loss: 1.6243e-05\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 1.7731e-05 - val_loss: 1.9792e-05\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 2.0207e-05 - val_loss: 1.6342e-05\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 139us/step - loss: 1.5990e-05 - val_loss: 1.4894e-05\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 1.3645e-05 - val_loss: 1.1190e-05\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 1.2603e-05 - val_loss: 8.4264e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 1.1518e-05 - val_loss: 1.8960e-05\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 6.9678e-05 - val_loss: 1.0952e-04\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 144us/step - loss: 5.1146e-05 - val_loss: 2.7933e-05\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 3.0796e-05 - val_loss: 1.1688e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 2.0171e-05 - val_loss: 7.1477e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 1.3209e-05 - val_loss: 6.4812e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 9.9128e-06 - val_loss: 8.6998e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 9.0904e-06 - val_loss: 6.1112e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 7.6419e-06 - val_loss: 5.4009e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 6.9715e-06 - val_loss: 5.0190e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 144us/step - loss: 6.7289e-06 - val_loss: 5.0575e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 6.4312e-06 - val_loss: 5.3378e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 7.5512e-06 - val_loss: 4.5658e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 9.4682e-06 - val_loss: 1.6868e-05\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 1.8258e-05 - val_loss: 9.8695e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 8.5333e-06 - val_loss: 2.1623e-05\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 3.3778e-05 - val_loss: 1.0148e-05\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 1.6911e-05 - val_loss: 1.2870e-05\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 1.0558e-05 - val_loss: 1.0047e-05\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 8.0516e-06 - val_loss: 8.1474e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 5.8226e-06 - val_loss: 4.9008e-06\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 143us/step - loss: 4.8699e-06 - val_loss: 3.0795e-06\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 143us/step - loss: 4.0709e-06 - val_loss: 3.2784e-06\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 3.9204e-06 - val_loss: 2.9081e-06\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 3.7591e-06 - val_loss: 4.4538e-06\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 5.4757e-05 - val_loss: 4.6407e-04\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 140us/step - loss: 2.0879e-04 - val_loss: 1.3309e-04\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 5.7272e-05 - val_loss: 5.4214e-05\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 142us/step - loss: 2.6670e-05 - val_loss: 2.0223e-05\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 143us/step - loss: 1.3763e-05 - val_loss: 5.5437e-06\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 8.4548e-06 - val_loss: 5.4326e-06\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 6.8639e-06 - val_loss: 6.4950e-06\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 5.8583e-06 - val_loss: 5.7807e-06\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 141us/step - loss: 4.9461e-06 - val_loss: 3.4916e-06\n",
      "Epoch 00058: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(3,10,2):\n",
    "    numOfLayers = 1\n",
    "    filtersCountInFirstLayer = 32\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, filtersCountInFirstLayer, filterSize = i)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "plt.title('Models validation loss vs. filter size')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Filter Size')\n",
    "plt.xticks(np.arange(4), [3,5,7,9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network first layer filter count tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_1 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 128, 2)            4         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 64, 2)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 64, 4)             12        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 64, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 64, 4)             20        \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 128, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 2)            10        \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 128, 1)            3         \n",
      "_________________________________________________________________\n",
      "cropping1d_1 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0660 - val_loss: 0.0636\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0627 - val_loss: 0.0616\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0613 - val_loss: 0.0607\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0602 - val_loss: 0.0594\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0589 - val_loss: 0.0581\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0577 - val_loss: 0.0570\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0565 - val_loss: 0.0558\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0554 - val_loss: 0.0548\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0544 - val_loss: 0.0538\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0535 - val_loss: 0.0530\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0527 - val_loss: 0.0523\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0520 - val_loss: 0.0516\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0514 - val_loss: 0.0511\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0510 - val_loss: 0.0508\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0507 - val_loss: 0.0505\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0504 - val_loss: 0.0503\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0502 - val_loss: 0.0502\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0501 - val_loss: 0.0501\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0501 - val_loss: 0.0500\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0500 - val_loss: 0.0500\n",
      "Epoch 00037: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_2 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 128, 4)            12        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 64, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 64, 8)             72        \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 64, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 64, 8)             136       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 128, 4)            68        \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 128, 1)            9         \n",
      "_________________________________________________________________\n",
      "cropping1d_2 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 297\n",
      "Trainable params: 297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0980 - val_loss: 0.0961\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0952 - val_loss: 0.0935\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0926 - val_loss: 0.0910\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0903 - val_loss: 0.0888\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0881 - val_loss: 0.0866\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0861 - val_loss: 0.0846\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0841 - val_loss: 0.0827\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0822 - val_loss: 0.0804\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0797 - val_loss: 0.0773\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0760 - val_loss: 0.0731\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0719 - val_loss: 0.0691\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0677 - val_loss: 0.0648\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0634 - val_loss: 0.0604\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0590 - val_loss: 0.0560\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0545 - val_loss: 0.0514\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0497 - val_loss: 0.0464\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0448 - val_loss: 0.0415\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0399 - val_loss: 0.0366\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0350 - val_loss: 0.0317\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0301 - val_loss: 0.0268\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0253 - val_loss: 0.0222\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0208 - val_loss: 0.0181\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0169 - val_loss: 0.0144\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 0.0013 - val_loss: 9.1842e-04\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.6151e-04 - val_loss: 5.5126e-04\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.5488e-04 - val_loss: 3.2554e-04\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.6793e-04 - val_loss: 1.8778e-04\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.5660e-04 - val_loss: 1.1364e-04\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.4045e-05 - val_loss: 6.8173e-05\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.8376e-05 - val_loss: 4.3038e-05\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.6892e-05 - val_loss: 2.6662e-05\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.2499e-05 - val_loss: 1.6178e-05\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.3497e-05 - val_loss: 9.7887e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.1328e-06 - val_loss: 5.8102e-06\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.9057e-06 - val_loss: 3.4795e-06\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.8981e-06 - val_loss: 2.0456e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.6564e-06 - val_loss: 1.1649e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 9.5489e-07 - val_loss: 6.6325e-07\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.4301e-07 - val_loss: 3.7150e-07\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.9951e-07 - val_loss: 2.0360e-07\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 1.6364e-07 - val_loss: 1.1064e-07\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.9081e-08 - val_loss: 5.9938e-08\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.8008e-08 - val_loss: 3.1788e-08\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.5146e-08 - val_loss: 1.6797e-08\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3385e-08 - val_loss: 9.2755e-09\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.3635e-09 - val_loss: 5.1100e-09\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 4.2033e-09 - val_loss: 3.0697e-09\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.5811e-09 - val_loss: 1.9992e-09\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.7441e-09 - val_loss: 1.3838e-09\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 1.2613e-09 - val_loss: 1.0676e-09\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.8821e-10 - val_loss: 8.6983e-10\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.2284e-10 - val_loss: 7.3562e-10\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.0009e-10 - val_loss: 6.3083e-10\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 6.0236e-10 - val_loss: 5.4151e-10\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.1951e-10 - val_loss: 4.6571e-10\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.4666e-10 - val_loss: 4.0148e-10\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.8442e-10 - val_loss: 3.4517e-10\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.3026e-10 - val_loss: 2.9552e-10\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.8288e-10 - val_loss: 2.5320e-10\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.4200e-10 - val_loss: 2.1707e-10\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.0679e-10 - val_loss: 1.8455e-10\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.7688e-10 - val_loss: 1.5823e-10\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.5027e-10 - val_loss: 1.3446e-10\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 1.2751e-10 - val_loss: 1.1332e-10\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.0829e-10 - val_loss: 9.7175e-11\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 9.1798e-11 - val_loss: 8.1806e-11\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.7785e-11 - val_loss: 6.9284e-11\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.5662e-11 - val_loss: 5.8554e-11\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.5444e-11 - val_loss: 4.9164e-11\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.6622e-11 - val_loss: 4.1326e-11\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.9308e-11 - val_loss: 3.4855e-11\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.2913e-11 - val_loss: 2.9085e-11\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.7507e-11 - val_loss: 2.4363e-11\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.3199e-11 - val_loss: 2.0917e-11\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.9534e-11 - val_loss: 1.7357e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.6297e-11 - val_loss: 1.4347e-11\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.3692e-11 - val_loss: 1.2126e-11\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 1.1427e-11 - val_loss: 1.0148e-11\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 9.5515e-12 - val_loss: 8.3216e-12\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.9678e-12 - val_loss: 7.0236e-12\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 6.6254e-12 - val_loss: 5.8492e-12\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.5339e-12 - val_loss: 4.8916e-12\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.5825e-12 - val_loss: 4.0269e-12\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.7879e-12 - val_loss: 3.3492e-12\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 3.1505e-12 - val_loss: 2.7882e-12\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.5989e-12 - val_loss: 2.2941e-12\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.1843e-12 - val_loss: 1.8664e-12\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 1.8100e-12 - val_loss: 1.5734e-12\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.5027e-12 - val_loss: 1.3270e-12\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.2551e-12 - val_loss: 1.1532e-12\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.0648e-12 - val_loss: 9.6083e-13\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 9.0107e-13 - val_loss: 7.9876e-13\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.7386e-13 - val_loss: 6.6896e-13\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.3781e-13 - val_loss: 5.5462e-13\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.3529e-13 - val_loss: 4.8754e-13\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.7161e-13 - val_loss: 4.1041e-13\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 47us/step - loss: 3.8881e-13 - val_loss: 3.5335e-13\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 3.3866e-13 - val_loss: 3.2243e-13\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.9769e-13 - val_loss: 2.5347e-13\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.5305e-13 - val_loss: 2.2647e-13\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.0803e-13 - val_loss: 1.7784e-13\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.8011e-13 - val_loss: 1.7423e-13\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.6925e-13 - val_loss: 1.4907e-13\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.3804e-13 - val_loss: 1.2605e-13\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.1587e-13 - val_loss: 1.1004e-13\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.0367e-13 - val_loss: 9.0866e-14\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.9151e-14 - val_loss: 9.1680e-14\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 8.2004e-14 - val_loss: 7.9462e-14\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.1551e-14 - val_loss: 7.0254e-14\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 6.6004e-14 - val_loss: 5.5487e-14\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 6.0312e-14 - val_loss: 5.6152e-14\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.2691e-14 - val_loss: 5.0012e-14\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.8857e-14 - val_loss: 4.8543e-14\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.3638e-14 - val_loss: 4.1548e-14\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.7514e-14 - val_loss: 4.1163e-14\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.4056e-14 - val_loss: 3.2798e-14\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.0278e-14 - val_loss: 3.1027e-14\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.9707e-14 - val_loss: 2.9463e-14\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.9140e-14 - val_loss: 2.8654e-14\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.6260e-14 - val_loss: 2.4592e-14\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.1389e-14 - val_loss: 2.9780e-14\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.2325e-14 - val_loss: 2.1077e-14\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.9752e-14 - val_loss: 1.8535e-14\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.0465e-14 - val_loss: 2.0708e-14\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.7150e-14 - val_loss: 1.8550e-14\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.8316e-14 - val_loss: 1.6590e-14\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 1.6100e-14 - val_loss: 1.4688e-14\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.5280e-14 - val_loss: 1.4748e-14\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 1.5574e-14 - val_loss: 1.7000e-14\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.4332e-14 - val_loss: 1.3515e-14\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.3046e-14 - val_loss: 1.0891e-14\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.2104e-14 - val_loss: 1.3134e-14\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.1599e-14 - val_loss: 1.3401e-14\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2291e-14 - val_loss: 1.2383e-14\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.1885e-14 - val_loss: 9.3026e-15\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 9.1946e-15 - val_loss: 8.3248e-15\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.0497e-15 - val_loss: 7.4910e-15\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.0103e-15 - val_loss: 7.8461e-15\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.7028e-15 - val_loss: 6.6718e-15\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.9468e-15 - val_loss: 9.4360e-15\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.8649e-15 - val_loss: 7.9110e-15\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.0197e-15 - val_loss: 7.1591e-15\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 7.7447e-15 - val_loss: 7.6292e-15\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.3510e-15 - val_loss: 7.7873e-15\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 6.6695e-15 - val_loss: 6.1780e-15\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 6.3302e-15 - val_loss: 6.9975e-15\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.5958e-15 - val_loss: 5.9369e-15\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 7.6441e-15 - val_loss: 8.1654e-15\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.6047e-15 - val_loss: 7.0729e-15\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.9582e-15 - val_loss: 6.8838e-15\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 6.8443e-15 - val_loss: 4.8469e-15\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.3037e-15 - val_loss: 5.1787e-15\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.3152e-15 - val_loss: 5.3225e-15\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 5.1851e-15 - val_loss: 5.3380e-15\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.0870e-15 - val_loss: 6.0894e-15\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.5199e-15 - val_loss: 6.5793e-15\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 4.0384e-15 - val_loss: 4.7818e-15\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.7644e-15 - val_loss: 7.8982e-15\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9076e-15 - val_loss: 6.2133e-15\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.0298e-15 - val_loss: 4.0085e-15\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 5.5971e-15 - val_loss: 4.8969e-15\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.1346e-15 - val_loss: 5.8789e-15\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 4.3029e-15 - val_loss: 3.8114e-15\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 4.5685e-15 - val_loss: 4.6608e-15\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.0352e-15 - val_loss: 3.8894e-15\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.7372e-15 - val_loss: 4.7073e-15\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 4.9235e-15 - val_loss: 3.9365e-15\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.2123e-15 - val_loss: 5.0040e-15\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.9628e-15 - val_loss: 3.8587e-15\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.9981e-15 - val_loss: 3.3330e-15\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.4764e-15 - val_loss: 2.6451e-15\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.3930e-15 - val_loss: 2.8264e-15\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.4150e-15 - val_loss: 2.1708e-15\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 3.5125e-15 - val_loss: 4.0915e-15\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.3393e-15 - val_loss: 2.8806e-15\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.5136e-15 - val_loss: 2.8844e-15\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 3.2027e-15 - val_loss: 1.7283e-15\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.0995e-15 - val_loss: 2.1160e-15\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.7176e-15 - val_loss: 4.5984e-15\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 3.6926e-15 - val_loss: 6.0694e-15\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.1983e-15 - val_loss: 2.8089e-15\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 2.7374e-15 - val_loss: 1.5418e-15\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 3.8227e-15 - val_loss: 3.8174e-15\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.6627e-15 - val_loss: 3.8912e-15\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.5527e-15 - val_loss: 3.4443e-15\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.0320e-15 - val_loss: 5.8111e-15\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.0083e-15 - val_loss: 5.1658e-15\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 4.3717e-15 - val_loss: 9.9262e-16\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.6482e-15 - val_loss: 3.0619e-15\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 2.4359e-15 - val_loss: 2.1067e-15\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.4145e-15 - val_loss: 1.1344e-15\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.1505e-15 - val_loss: 1.4650e-15\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.2226e-15 - val_loss: 3.0982e-15\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 48us/step - loss: 3.5470e-15 - val_loss: 1.8483e-15\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.0231e-15 - val_loss: 3.8822e-15\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 5.4010e-15 - val_loss: 4.2899e-15\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 4.8798e-15 - val_loss: 3.2687e-15\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.4255e-15 - val_loss: 4.0409e-15\n",
      "Epoch 00204: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_3 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 128, 8)            32        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 64, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 64, 16)            400       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 64, 16)            784       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 128, 8)            392       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 128, 1)            25        \n",
      "_________________________________________________________________\n",
      "cropping1d_3 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,633\n",
      "Trainable params: 1,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0931 - val_loss: 0.0847\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0788 - val_loss: 0.0702\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0661 - val_loss: 0.0594\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0561 - val_loss: 0.0503\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 56us/step - loss: 0.0481 - val_loss: 0.0440\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 54us/step - loss: 0.0422 - val_loss: 0.0386\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0369 - val_loss: 0.0338\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0316 - val_loss: 0.0280\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0255 - val_loss: 0.0219\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0195 - val_loss: 0.0162\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0014 - val_loss: 7.9076e-04\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9561e-04 - val_loss: 3.3890e-04\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5139e-04 - val_loss: 1.3134e-04\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.7344e-05 - val_loss: 6.2131e-05\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 5.2470e-05 - val_loss: 4.1236e-05\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.5080e-05 - val_loss: 2.8880e-05\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.6203e-05 - val_loss: 2.4227e-05\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2766e-05 - val_loss: 2.1734e-05\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0174e-05 - val_loss: 1.8909e-05\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7624e-05 - val_loss: 1.6583e-05\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.5628e-05 - val_loss: 1.4870e-05\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.4095e-05 - val_loss: 1.3357e-05\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.2755e-05 - val_loss: 1.2096e-05\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1581e-05 - val_loss: 1.1042e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0548e-05 - val_loss: 1.0078e-05\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.6401e-06 - val_loss: 9.2352e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.8713e-06 - val_loss: 8.5599e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 8.2191e-06 - val_loss: 7.9686e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.6977e-06 - val_loss: 7.4787e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.2460e-06 - val_loss: 7.0742e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.8560e-06 - val_loss: 6.6880e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.4991e-06 - val_loss: 6.3510e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.1857e-06 - val_loss: 6.0708e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9203e-06 - val_loss: 5.8053e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 5.6532e-06 - val_loss: 5.5413e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.3913e-06 - val_loss: 5.2445e-06\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.1000e-06 - val_loss: 4.9296e-06\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.8092e-06 - val_loss: 4.6189e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.5077e-06 - val_loss: 4.3064e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 4.2244e-06 - val_loss: 4.0236e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.9705e-06 - val_loss: 3.7772e-06\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.7525e-06 - val_loss: 3.5711e-06\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.5341e-06 - val_loss: 3.3488e-06\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.3513e-06 - val_loss: 3.2097e-06\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.2149e-06 - val_loss: 3.0408e-06\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.0262e-06 - val_loss: 2.8377e-06\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.8593e-06 - val_loss: 2.6830e-06\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.6998e-06 - val_loss: 2.5195e-06\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.5198e-06 - val_loss: 2.3227e-06\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.3241e-06 - val_loss: 2.1574e-06\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.1221e-06 - val_loss: 1.9117e-06\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.8832e-06 - val_loss: 1.6759e-06\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6299e-06 - val_loss: 1.4265e-06\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4077e-06 - val_loss: 1.2827e-06\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2767e-06 - val_loss: 1.1514e-06\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1610e-06 - val_loss: 1.0605e-06\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0795e-06 - val_loss: 9.8968e-07\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.0080e-06 - val_loss: 9.2764e-07\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.5020e-07 - val_loss: 8.7801e-07\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.9537e-07 - val_loss: 8.2465e-07\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.5894e-07 - val_loss: 8.0184e-07\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.1826e-07 - val_loss: 7.5917e-07\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.7152e-07 - val_loss: 7.1731e-07\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.3411e-07 - val_loss: 6.8988e-07\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.0462e-07 - val_loss: 6.5240e-07\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.7678e-07 - val_loss: 6.2763e-07\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.4749e-07 - val_loss: 6.1365e-07\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.2196e-07 - val_loss: 5.8419e-07\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9806e-07 - val_loss: 5.5921e-07\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.7523e-07 - val_loss: 5.3647e-07\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.5187e-07 - val_loss: 5.2313e-07\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.3245e-07 - val_loss: 5.0464e-07\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.1581e-07 - val_loss: 4.8461e-07\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.9568e-07 - val_loss: 4.6576e-07\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.7583e-07 - val_loss: 4.4445e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.5802e-07 - val_loss: 4.3021e-07\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.4100e-07 - val_loss: 4.1729e-07\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.2708e-07 - val_loss: 4.0210e-07\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.1019e-07 - val_loss: 3.8865e-07\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.9679e-07 - val_loss: 3.7355e-07\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.8190e-07 - val_loss: 3.5948e-07\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.7035e-07 - val_loss: 3.4969e-07\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.5588e-07 - val_loss: 3.3924e-07\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.4614e-07 - val_loss: 3.2590e-07\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.3391e-07 - val_loss: 3.1214e-07\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.2153e-07 - val_loss: 3.0559e-07\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.1053e-07 - val_loss: 2.9162e-07\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.0089e-07 - val_loss: 2.8528e-07\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.9015e-07 - val_loss: 2.7285e-07\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.8040e-07 - val_loss: 2.6628e-07\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.7142e-07 - val_loss: 2.5483e-07\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.6149e-07 - val_loss: 2.4703e-07\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.5205e-07 - val_loss: 2.3937e-07\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.4348e-07 - val_loss: 2.3173e-07\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.3573e-07 - val_loss: 2.2086e-07\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.2739e-07 - val_loss: 2.1424e-07\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.1964e-07 - val_loss: 2.0922e-07\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.1202e-07 - val_loss: 2.0169e-07\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0488e-07 - val_loss: 1.9335e-07\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9714e-07 - val_loss: 1.9125e-07\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.9375e-07 - val_loss: 1.8030e-07\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.8610e-07 - val_loss: 1.7424e-07\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.7806e-07 - val_loss: 1.6920e-07\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.7286e-07 - val_loss: 1.6259e-07\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.6657e-07 - val_loss: 1.5745e-07\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6052e-07 - val_loss: 1.5090e-07\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5498e-07 - val_loss: 1.4707e-07\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.4973e-07 - val_loss: 1.4094e-07\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.4431e-07 - val_loss: 1.3677e-07\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3967e-07 - val_loss: 1.3266e-07\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3487e-07 - val_loss: 1.2665e-07\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3065e-07 - val_loss: 1.2560e-07\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.2653e-07 - val_loss: 1.1836e-07\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2157e-07 - val_loss: 1.1421e-07\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1836e-07 - val_loss: 1.1245e-07\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1397e-07 - val_loss: 1.0716e-07\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1031e-07 - val_loss: 1.0327e-07\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.0614e-07 - val_loss: 9.9973e-08\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.0291e-07 - val_loss: 9.6879e-08\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.9164e-08 - val_loss: 9.3139e-08\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.6017e-08 - val_loss: 9.3404e-08\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.4499e-08 - val_loss: 8.7156e-08\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.1038e-08 - val_loss: 8.4451e-08\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.7164e-08 - val_loss: 8.3418e-08\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.5261e-08 - val_loss: 7.9469e-08\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.1804e-08 - val_loss: 7.6818e-08\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.8784e-08 - val_loss: 7.4249e-08\n",
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.6006e-08 - val_loss: 7.1133e-08\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.3549e-08 - val_loss: 6.9861e-08\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.1538e-08 - val_loss: 6.6809e-08\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.9475e-08 - val_loss: 6.5828e-08\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.7237e-08 - val_loss: 6.2900e-08\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.4792e-08 - val_loss: 6.1224e-08\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.3231e-08 - val_loss: 5.8557e-08\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.0805e-08 - val_loss: 5.6740e-08\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.9000e-08 - val_loss: 5.5751e-08\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.7017e-08 - val_loss: 5.3200e-08\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.5126e-08 - val_loss: 5.1520e-08\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.3387e-08 - val_loss: 5.1187e-08\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.2066e-08 - val_loss: 4.9385e-08\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.1109e-08 - val_loss: 4.9147e-08\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.9607e-08 - val_loss: 4.5635e-08\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.7733e-08 - val_loss: 4.5113e-08\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.6629e-08 - val_loss: 4.3728e-08\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.4725e-08 - val_loss: 4.2430e-08\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.3498e-08 - val_loss: 4.0641e-08\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.2091e-08 - val_loss: 3.9768e-08\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.0832e-08 - val_loss: 3.8191e-08\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.9637e-08 - val_loss: 3.7082e-08\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.8634e-08 - val_loss: 3.6869e-08\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.7560e-08 - val_loss: 3.5174e-08\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.6549e-08 - val_loss: 3.4335e-08\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.5363e-08 - val_loss: 3.3409e-08\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.4440e-08 - val_loss: 3.2594e-08\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.3588e-08 - val_loss: 3.1581e-08\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.2912e-08 - val_loss: 3.1321e-08\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.1965e-08 - val_loss: 2.9781e-08\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.0949e-08 - val_loss: 2.9797e-08\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.0371e-08 - val_loss: 2.8379e-08\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.9392e-08 - val_loss: 2.7689e-08\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.8885e-08 - val_loss: 2.7708e-08\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.8324e-08 - val_loss: 2.6643e-08\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.7533e-08 - val_loss: 2.5731e-08\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.6593e-08 - val_loss: 2.5060e-08\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.5949e-08 - val_loss: 2.6050e-08\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.6081e-08 - val_loss: 2.6182e-08\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5610e-08 - val_loss: 2.3603e-08\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.4256e-08 - val_loss: 2.2524e-08\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.3841e-08 - val_loss: 2.2726e-08\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.3130e-08 - val_loss: 2.1517e-08\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2405e-08 - val_loss: 2.1934e-08\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.2277e-08 - val_loss: 2.1415e-08\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.1690e-08 - val_loss: 2.0113e-08\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.1041e-08 - val_loss: 1.9849e-08\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0547e-08 - val_loss: 1.9627e-08\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0063e-08 - val_loss: 1.8900e-08\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.9565e-08 - val_loss: 1.8519e-08\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9208e-08 - val_loss: 1.8600e-08\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.8845e-08 - val_loss: 1.8015e-08\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.8319e-08 - val_loss: 1.7240e-08\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7841e-08 - val_loss: 1.7699e-08\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.7800e-08 - val_loss: 1.6418e-08\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7080e-08 - val_loss: 1.6218e-08\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6717e-08 - val_loss: 1.5972e-08\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6467e-08 - val_loss: 1.5603e-08\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.6036e-08 - val_loss: 1.5025e-08\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.5568e-08 - val_loss: 1.4790e-08\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.5463e-08 - val_loss: 1.4506e-08\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5106e-08 - val_loss: 1.4100e-08\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.4708e-08 - val_loss: 1.4307e-08\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4434e-08 - val_loss: 1.4193e-08\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4204e-08 - val_loss: 1.3188e-08\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3675e-08 - val_loss: 1.2844e-08\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3327e-08 - val_loss: 1.3170e-08\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3259e-08 - val_loss: 1.2796e-08\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3029e-08 - val_loss: 1.2881e-08\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3137e-08 - val_loss: 1.2999e-08\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3028e-08 - val_loss: 1.1754e-08\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2232e-08 - val_loss: 1.1411e-08\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1717e-08 - val_loss: 1.1037e-08\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1502e-08 - val_loss: 1.0927e-08\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1237e-08 - val_loss: 1.0609e-08\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0999e-08 - val_loss: 1.0645e-08\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1137e-08 - val_loss: 1.0567e-08\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0632e-08 - val_loss: 1.0246e-08\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0395e-08 - val_loss: 9.8248e-09\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.0138e-08 - val_loss: 9.4889e-09\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.8615e-09 - val_loss: 9.2870e-09\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.6414e-09 - val_loss: 9.0356e-09\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 9.4222e-09 - val_loss: 9.1780e-09\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.5185e-09 - val_loss: 8.8307e-09\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.0948e-09 - val_loss: 8.5712e-09\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.8532e-09 - val_loss: 8.4031e-09\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.6625e-09 - val_loss: 8.3640e-09\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 8.5426e-09 - val_loss: 8.0705e-09\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.3083e-09 - val_loss: 7.9041e-09\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.1732e-09 - val_loss: 8.3029e-09\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.6059e-09 - val_loss: 8.9955e-09\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.3655e-09 - val_loss: 7.5934e-09\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 53us/step - loss: 7.8242e-09 - val_loss: 8.1203e-09\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.8367e-09 - val_loss: 7.2276e-09\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.4295e-09 - val_loss: 6.9735e-09\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.1768e-09 - val_loss: 7.0120e-09\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.1818e-09 - val_loss: 6.6172e-09\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.8518e-09 - val_loss: 6.9437e-09\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.8268e-09 - val_loss: 6.7813e-09\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.8337e-09 - val_loss: 6.5410e-09\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.5023e-09 - val_loss: 6.0624e-09\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.2737e-09 - val_loss: 5.9363e-09\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.1124e-09 - val_loss: 6.1927e-09\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.1373e-09 - val_loss: 5.7516e-09\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.8882e-09 - val_loss: 5.5455e-09\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.7479e-09 - val_loss: 5.8299e-09\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 5.8101e-09 - val_loss: 6.6532e-09\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.4776e-09 - val_loss: 5.9135e-09\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.6721e-09 - val_loss: 5.1861e-09\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.3155e-09 - val_loss: 4.9244e-09\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.1761e-09 - val_loss: 5.5320e-09\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.2646e-09 - val_loss: 4.9511e-09\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.9840e-09 - val_loss: 5.4123e-09\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.0410e-09 - val_loss: 4.7911e-09\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.8787e-09 - val_loss: 5.3930e-09\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.1234e-09 - val_loss: 4.4088e-09\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.5937e-09 - val_loss: 4.6968e-09\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.7875e-09 - val_loss: 4.2452e-09\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.3455e-09 - val_loss: 4.2143e-09\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.3650e-09 - val_loss: 4.0593e-09\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.1771e-09 - val_loss: 3.9154e-09\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.0602e-09 - val_loss: 3.8074e-09\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.9131e-09 - val_loss: 3.6520e-09\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.8190e-09 - val_loss: 3.6399e-09\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.7240e-09 - val_loss: 3.5113e-09\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.6589e-09 - val_loss: 3.7128e-09\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.7049e-09 - val_loss: 3.3828e-09\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.5437e-09 - val_loss: 3.3160e-09\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.4018e-09 - val_loss: 3.4715e-09\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.3962e-09 - val_loss: 3.2158e-09\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.2547e-09 - val_loss: 3.1288e-09\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.2146e-09 - val_loss: 2.9694e-09\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.1251e-09 - val_loss: 2.9713e-09\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.0398e-09 - val_loss: 2.8166e-09\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.9544e-09 - val_loss: 2.8573e-09\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.9621e-09 - val_loss: 2.9723e-09\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.9245e-09 - val_loss: 2.6797e-09\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.7625e-09 - val_loss: 2.5831e-09\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.6699e-09 - val_loss: 2.6259e-09\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.6517e-09 - val_loss: 2.4380e-09\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5570e-09 - val_loss: 2.4188e-09\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5554e-09 - val_loss: 2.3509e-09\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.4160e-09 - val_loss: 2.3564e-09\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.4654e-09 - val_loss: 2.2408e-09\n",
      "Epoch 276/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.3260e-09 - val_loss: 2.2437e-09\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2536e-09 - val_loss: 2.2219e-09\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.2881e-09 - val_loss: 2.1428e-09\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.2182e-09 - val_loss: 2.0873e-09\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.1377e-09 - val_loss: 2.1679e-09\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.4060e-09 - val_loss: 2.0175e-09\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0457e-09 - val_loss: 1.8607e-09\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.9326e-09 - val_loss: 1.8930e-09\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.9428e-09 - val_loss: 1.8515e-09\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.8568e-09 - val_loss: 1.8320e-09\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.9884e-09 - val_loss: 1.6982e-09\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.8361e-09 - val_loss: 1.6311e-09\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.7988e-09 - val_loss: 1.6451e-09\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.7204e-09 - val_loss: 1.6398e-09\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.7129e-09 - val_loss: 1.5346e-09\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6764e-09 - val_loss: 1.5220e-09\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5860e-09 - val_loss: 1.4789e-09\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.5127e-09 - val_loss: 1.7811e-09\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6965e-09 - val_loss: 1.5029e-09\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6209e-09 - val_loss: 1.3491e-09\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6352e-09 - val_loss: 1.9014e-09\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5116e-09 - val_loss: 1.4044e-09\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3913e-09 - val_loss: 1.2239e-09\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3043e-09 - val_loss: 1.2165e-09\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.2762e-09 - val_loss: 1.1851e-09\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2876e-09 - val_loss: 1.1948e-09\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3099e-09 - val_loss: 1.2032e-09\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.1786e-09 - val_loss: 1.1626e-09\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2690e-09 - val_loss: 1.4269e-09\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 1.2510e-09 - val_loss: 1.0881e-09\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.1367e-09 - val_loss: 1.6448e-09\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.5999e-09 - val_loss: 1.7841e-09\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5301e-09 - val_loss: 2.2666e-09\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6188e-09 - val_loss: 1.4068e-09\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3626e-09 - val_loss: 1.0236e-09\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6732e-09 - val_loss: 1.0609e-09\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.9751e-10 - val_loss: 1.0575e-09\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 9.5694e-10 - val_loss: 9.0111e-10\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.4392e-10 - val_loss: 8.8893e-10\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.0058e-09 - val_loss: 8.0009e-10\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.4704e-10 - val_loss: 7.6006e-10\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.8848e-10 - val_loss: 7.2628e-10\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.5437e-10 - val_loss: 9.2012e-10\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1738e-09 - val_loss: 1.4646e-09\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.6341e-09 - val_loss: 8.4124e-10\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.5791e-09 - val_loss: 6.3566e-09\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.4715e-08 - val_loss: 8.2070e-09\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.1895e-09 - val_loss: 3.6683e-09\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.2405e-09 - val_loss: 7.7594e-10\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.7165e-09 - val_loss: 2.2563e-09\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.6364e-09 - val_loss: 1.6482e-09\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 9.6357e-10 - val_loss: 5.9113e-10\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.3722e-10 - val_loss: 5.7742e-10\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9755e-10 - val_loss: 5.4594e-10\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.5299e-10 - val_loss: 5.7899e-10\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.6234e-10 - val_loss: 4.9507e-10\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.1335e-10 - val_loss: 4.7659e-10\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.0003e-10 - val_loss: 5.3261e-10\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.8321e-10 - val_loss: 4.8996e-10\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.7942e-10 - val_loss: 5.8600e-10\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.5006e-10 - val_loss: 5.1788e-10\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 4.8997e-10 - val_loss: 4.3957e-10\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.3249e-10 - val_loss: 4.0713e-10\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.2168e-10 - val_loss: 3.8888e-10\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.9903e-10 - val_loss: 4.0076e-10\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.2829e-10 - val_loss: 3.8966e-10\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 4.1093e-10 - val_loss: 5.7365e-10\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 5.0611e-10 - val_loss: 3.5217e-10\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.8512e-10 - val_loss: 3.5359e-10\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.5342e-10 - val_loss: 4.9842e-10\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.5601e-10 - val_loss: 3.7813e-10\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.9200e-10 - val_loss: 3.5003e-10\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.4927e-10 - val_loss: 3.1220e-10\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.0649e-10 - val_loss: 2.8475e-10\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.1684e-10 - val_loss: 3.6669e-10\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.3412e-10 - val_loss: 3.0066e-10\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.0742e-10 - val_loss: 2.8351e-10\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.7758e-10 - val_loss: 2.4802e-10\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.7020e-10 - val_loss: 2.5207e-10\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5307e-10 - val_loss: 2.3445e-10\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5766e-10 - val_loss: 2.8649e-10\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.6351e-10 - val_loss: 2.4516e-10\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.1882e-10 - val_loss: 2.2155e-10\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.2104e-10 - val_loss: 2.1226e-10\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.2368e-10 - val_loss: 1.9572e-10\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0336e-10 - val_loss: 3.0955e-10\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.1609e-10 - val_loss: 2.3948e-10\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.4255e-10 - val_loss: 4.2668e-10\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.8510e-10 - val_loss: 2.8485e-10\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.9598e-10 - val_loss: 2.3299e-10\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.7119e-10 - val_loss: 1.5884e-10\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.8460e-10 - val_loss: 1.5354e-10\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 52us/step - loss: 1.6011e-10 - val_loss: 1.5298e-10\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.7196e-10 - val_loss: 1.4816e-10\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.7715e-10 - val_loss: 1.5012e-10\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.3419e-10 - val_loss: 4.4219e-10\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.5123e-10 - val_loss: 4.1900e-10\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.8154e-10 - val_loss: 5.3207e-10\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 5.4545e-10 - val_loss: 7.1035e-10\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.1264e-10 - val_loss: 7.4106e-10\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.2946e-10 - val_loss: 1.1404e-09\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.3463e-09 - val_loss: 3.8039e-08\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.6280e-06 - val_loss: 1.3038e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.2896e-06 - val_loss: 4.6605e-06\n",
      "Epoch 00379: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_4 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 128, 16)           80        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 64, 32)            2080      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 64, 32)            4128      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1 (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 128, 16)           2064      \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 128, 1)            65        \n",
      "_________________________________________________________________\n",
      "cropping1d_4 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 8,417\n",
      "Trainable params: 8,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.0792 - val_loss: 0.0617\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 0.0550 - val_loss: 0.0453\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 0.0390 - val_loss: 0.0302\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 0.0255 - val_loss: 0.0193\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 0.0162 - val_loss: 0.0119\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 76us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 7.6534e-04 - val_loss: 4.2316e-04\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 3.3585e-04 - val_loss: 2.4102e-04\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 1.9058e-04 - val_loss: 1.3756e-04\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 1.1688e-04 - val_loss: 9.1714e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 7.9546e-05 - val_loss: 6.4636e-05\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 5.7151e-05 - val_loss: 4.8867e-05\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 4.4487e-05 - val_loss: 3.9596e-05\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 3.6398e-05 - val_loss: 3.2851e-05\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 70us/step - loss: 3.0632e-05 - val_loss: 2.7967e-05\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.6357e-05 - val_loss: 2.4498e-05\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.3281e-05 - val_loss: 2.1721e-05\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.0834e-05 - val_loss: 1.9316e-05\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 1.8694e-05 - val_loss: 1.7761e-05\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 70us/step - loss: 1.7209e-05 - val_loss: 1.6029e-05\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 1.5677e-05 - val_loss: 1.4859e-05\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 1.4522e-05 - val_loss: 1.3662e-05\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 70us/step - loss: 1.3466e-05 - val_loss: 1.3019e-05\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 1.2669e-05 - val_loss: 1.2016e-05\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 1.1771e-05 - val_loss: 1.1737e-05\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 1.1551e-05 - val_loss: 1.1057e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 1.0836e-05 - val_loss: 1.0027e-05\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 1.0169e-05 - val_loss: 9.4400e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 9.5993e-06 - val_loss: 9.1332e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 9.0834e-06 - val_loss: 8.8808e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 8.7660e-06 - val_loss: 8.1212e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 8.3361e-06 - val_loss: 7.7658e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 7.8730e-06 - val_loss: 7.3982e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 67us/step - loss: 7.5021e-06 - val_loss: 7.0425e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 7.1895e-06 - val_loss: 6.7402e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 6.9112e-06 - val_loss: 6.4742e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 6.6458e-06 - val_loss: 6.2123e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 6.3750e-06 - val_loss: 5.9641e-06\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 67us/step - loss: 6.1407e-06 - val_loss: 5.7847e-06\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 5.9828e-06 - val_loss: 5.6402e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 5.7677e-06 - val_loss: 5.3460e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 5.5133e-06 - val_loss: 5.1197e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 5.3225e-06 - val_loss: 4.9541e-06\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 5.1444e-06 - val_loss: 4.7971e-06\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 4.9901e-06 - val_loss: 4.6123e-06\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 4.8279e-06 - val_loss: 4.4741e-06\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 4.6673e-06 - val_loss: 4.3162e-06\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 4.5224e-06 - val_loss: 4.2209e-06\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 4.4006e-06 - val_loss: 4.0434e-06\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 4.2764e-06 - val_loss: 3.9605e-06\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 67us/step - loss: 4.1387e-06 - val_loss: 3.8177e-06\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 4.0217e-06 - val_loss: 3.7500e-06\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 3.9193e-06 - val_loss: 3.6225e-06\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 3.8012e-06 - val_loss: 3.5268e-06\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 70us/step - loss: 3.7114e-06 - val_loss: 3.3873e-06\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 3.6160e-06 - val_loss: 3.2965e-06\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 3.4995e-06 - val_loss: 3.2219e-06\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 3.4281e-06 - val_loss: 3.1294e-06\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 3.3256e-06 - val_loss: 3.1351e-06\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 3.3031e-06 - val_loss: 2.9718e-06\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 3.1639e-06 - val_loss: 2.8908e-06\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 3.1152e-06 - val_loss: 2.8079e-06\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 67us/step - loss: 3.0733e-06 - val_loss: 2.8026e-06\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 70us/step - loss: 3.0153e-06 - val_loss: 2.9113e-06\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 2.9867e-06 - val_loss: 2.6085e-06\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.8049e-06 - val_loss: 2.5460e-06\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.7746e-06 - val_loss: 2.4907e-06\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 2.7026e-06 - val_loss: 2.5218e-06\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 2.6893e-06 - val_loss: 2.4440e-06\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.5896e-06 - val_loss: 2.3418e-06\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.5043e-06 - val_loss: 2.2449e-06\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 64us/step - loss: 2.4714e-06 - val_loss: 2.2395e-06\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.4097e-06 - val_loss: 2.2213e-06\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 3.0619e-06 - val_loss: 2.9439e-06\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.8043e-06 - val_loss: 2.0579e-06\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.2696e-06 - val_loss: 2.0193e-06\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 2.3644e-06 - val_loss: 2.0954e-06\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 2.4231e-06 - val_loss: 2.9644e-06\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 3.9964e-06 - val_loss: 3.8028e-06\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 67us/step - loss: 2.8140e-06 - val_loss: 2.1710e-06\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 3.4519e-06 - val_loss: 6.4228e-06\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 7.7479e-06 - val_loss: 4.4834e-06\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 67us/step - loss: 3.0495e-06 - val_loss: 1.9625e-06\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 2.1490e-06 - val_loss: 1.6936e-06\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.2709e-06 - val_loss: 3.1345e-06\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 4.0970e-06 - val_loss: 4.3447e-06\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 4.3248e-06 - val_loss: 1.8522e-06\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.5112e-06 - val_loss: 5.1615e-06\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 6.7732e-06 - val_loss: 2.8348e-06\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 2.1929e-06 - val_loss: 3.0084e-06\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 2.4480e-06 - val_loss: 1.4341e-06\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 65us/step - loss: 2.2886e-06 - val_loss: 3.3862e-06\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 3.4362e-06 - val_loss: 2.9343e-06\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 3.5922e-06 - val_loss: 3.3245e-06\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.9783e-06 - val_loss: 2.2337e-06\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 2.5226e-06 - val_loss: 2.5941e-06\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 69us/step - loss: 3.3305e-06 - val_loss: 4.5690e-06\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 66us/step - loss: 6.4735e-06 - val_loss: 6.3170e-06\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 70us/step - loss: 3.1304e-06 - val_loss: 3.2097e-06\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 4.9369e-06 - val_loss: 2.4188e-06\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 68us/step - loss: 1.8089e-06 - val_loss: 2.0313e-06\n",
      "Epoch 00103: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_5 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 128, 32)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 64, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 64, 64)            10304     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 64, 64)            20544     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1 (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 128, 32)           10272     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 128, 1)            161       \n",
      "_________________________________________________________________\n",
      "cropping1d_5 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 41,473\n",
      "Trainable params: 41,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0764 - val_loss: 0.0463\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 0.0365 - val_loss: 0.0242\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 0.0186 - val_loss: 0.0106\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 9.2883e-04 - val_loss: 7.5094e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 4.7772e-04 - val_loss: 1.4233e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 92us/step - loss: 1.7294e-04 - val_loss: 1.1444e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 7.8229e-05 - val_loss: 6.5695e-05\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 5.1987e-05 - val_loss: 3.3192e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 2.8509e-05 - val_loss: 2.0394e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.8799e-05 - val_loss: 1.3761e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.3052e-05 - val_loss: 1.0605e-05\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.0157e-05 - val_loss: 8.1163e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 8.3941e-06 - val_loss: 6.5757e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 7.0602e-06 - val_loss: 5.6174e-06\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 6.1702e-06 - val_loss: 4.9123e-06\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 5.4707e-06 - val_loss: 4.3800e-06\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 4.9293e-06 - val_loss: 3.8321e-06\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 4.4525e-06 - val_loss: 3.5053e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 4.0747e-06 - val_loss: 3.1531e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 3.7354e-06 - val_loss: 2.8778e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 3.4466e-06 - val_loss: 2.6514e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 3.1851e-06 - val_loss: 2.4667e-06\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 2.9902e-06 - val_loss: 2.3504e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 2.8034e-06 - val_loss: 2.1306e-06\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 2.5876e-06 - val_loss: 2.0019e-06\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 2.4476e-06 - val_loss: 1.8422e-06\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 2.2814e-06 - val_loss: 1.7486e-06\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 2.1748e-06 - val_loss: 1.7263e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 2.0371e-06 - val_loss: 1.5576e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.9110e-06 - val_loss: 1.5744e-06\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.8603e-06 - val_loss: 1.4171e-06\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.7545e-06 - val_loss: 1.3921e-06\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.6433e-06 - val_loss: 1.3771e-06\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 1.5923e-06 - val_loss: 1.2784e-06\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.5092e-06 - val_loss: 1.2209e-06\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.4421e-06 - val_loss: 1.1389e-06\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 1.3651e-06 - val_loss: 1.0929e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.3029e-06 - val_loss: 1.1314e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 1.2724e-06 - val_loss: 1.1579e-06\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.2425e-06 - val_loss: 9.8100e-07\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.1381e-06 - val_loss: 9.2469e-07\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 1.0680e-06 - val_loss: 8.8077e-07\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.0185e-06 - val_loss: 9.1345e-07\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 85us/step - loss: 1.0009e-06 - val_loss: 8.3936e-07\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 9.2846e-07 - val_loss: 7.9807e-07\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 8.8740e-07 - val_loss: 8.1170e-07\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 8.8328e-07 - val_loss: 7.6725e-07\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 8.2831e-07 - val_loss: 7.1472e-07\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 7.8336e-07 - val_loss: 6.9251e-07\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 7.4903e-07 - val_loss: 6.7575e-07\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 7.1159e-07 - val_loss: 6.5822e-07\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 6.9464e-07 - val_loss: 7.6290e-07\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 7.6991e-07 - val_loss: 6.6689e-07\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 6.6526e-07 - val_loss: 6.8358e-07\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 6.6652e-07 - val_loss: 8.1027e-07\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 7.0395e-07 - val_loss: 6.3213e-07\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 6.4054e-07 - val_loss: 5.8907e-07\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 6.4309e-07 - val_loss: 5.2396e-07\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 5.5880e-07 - val_loss: 5.4425e-07\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 5.3895e-07 - val_loss: 4.9662e-07\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 5.2632e-07 - val_loss: 5.0967e-07\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 5.6553e-07 - val_loss: 5.1739e-07\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 5.1767e-07 - val_loss: 4.8264e-07\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 5.2415e-07 - val_loss: 5.2743e-07\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 5.3708e-07 - val_loss: 5.9788e-07\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 5.4035e-07 - val_loss: 5.0226e-07\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 4.6399e-07 - val_loss: 4.4035e-07\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 4.3832e-07 - val_loss: 3.8579e-07\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 4.1893e-07 - val_loss: 4.1033e-07\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 4.9023e-07 - val_loss: 3.9265e-07\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 5.5206e-07 - val_loss: 1.0161e-06\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.6321e-06 - val_loss: 2.2066e-06\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 88us/step - loss: 1.8587e-06 - val_loss: 6.0105e-07\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 4.8086e-07 - val_loss: 6.0318e-07\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 4.4371e-07 - val_loss: 3.3793e-07\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 3.6934e-07 - val_loss: 5.1893e-07\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 2.5803e-06 - val_loss: 1.7364e-05\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 2.7600e-05 - val_loss: 6.1948e-06\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 9.1988e-06 - val_loss: 7.9031e-06\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 91us/step - loss: 3.7032e-06 - val_loss: 2.4645e-06\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 1.9420e-06 - val_loss: 3.7801e-07\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 8.3294e-07 - val_loss: 1.0464e-06\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 6.4926e-07 - val_loss: 3.0506e-07\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 3.6730e-07 - val_loss: 3.9891e-07\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 3.5189e-07 - val_loss: 2.8805e-07\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 3.5629e-07 - val_loss: 3.4575e-07\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 3.1390e-07 - val_loss: 3.4012e-07\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 3.2201e-07 - val_loss: 3.3247e-07\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 3.0323e-07 - val_loss: 3.3879e-07\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 3.0102e-07 - val_loss: 2.9871e-07\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 2.7649e-07 - val_loss: 2.5413e-07\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 2.7998e-07 - val_loss: 3.4306e-07\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 3.7603e-07 - val_loss: 2.6106e-07\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 3.3207e-07 - val_loss: 2.2999e-07\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 4.1597e-07 - val_loss: 8.4025e-07\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 1.0095e-06 - val_loss: 1.4043e-06\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 2.1426e-06 - val_loss: 4.2291e-06\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 6.6401e-06 - val_loss: 8.4609e-06\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 4.4709e-06 - val_loss: 2.7999e-07\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.1007e-06 - val_loss: 1.6325e-06\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 1.1279e-06 - val_loss: 3.9939e-07\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 3.4193e-07 - val_loss: 2.4625e-07\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 2.4235e-07 - val_loss: 2.1647e-07\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 2.1773e-07 - val_loss: 2.2109e-07\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 3.9546e-07 - val_loss: 1.3882e-06\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 7.0244e-06 - val_loss: 3.7227e-05\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 3.1678e-05 - val_loss: 9.8166e-06\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 6.1744e-06 - val_loss: 3.7747e-06\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 2.2065e-06 - val_loss: 1.0291e-06\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 90us/step - loss: 1.2174e-06 - val_loss: 8.8166e-07\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 88us/step - loss: 6.5644e-07 - val_loss: 4.8265e-07\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 89us/step - loss: 6.2695e-07 - val_loss: 9.6229e-07\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 86us/step - loss: 5.6272e-07 - val_loss: 3.3598e-07\n",
      "Epoch 00114: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_6 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 128, 64)           448       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 64, 128)           49280     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 64, 128)           98432     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1 (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 128, 64)           49216     \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 128, 1)            385       \n",
      "_________________________________________________________________\n",
      "cropping1d_6 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 197,761\n",
      "Trainable params: 197,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0682 - val_loss: 0.0328\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 189us/step - loss: 0.0220 - val_loss: 0.0091\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 194us/step - loss: 7.3072e-04 - val_loss: 4.4211e-04\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 3.3005e-04 - val_loss: 1.5019e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 1.3832e-04 - val_loss: 7.3632e-05\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 5.8942e-05 - val_loss: 4.3620e-05\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 3.0656e-05 - val_loss: 1.6373e-05\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 1.5625e-05 - val_loss: 1.0355e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 9.2585e-06 - val_loss: 6.6329e-06\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 5.8729e-06 - val_loss: 4.1690e-06\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 4.0916e-06 - val_loss: 2.9521e-06\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 3.1219e-06 - val_loss: 2.5514e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 2.6356e-06 - val_loss: 1.9148e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 2.1785e-06 - val_loss: 1.7019e-06\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 194us/step - loss: 1.9554e-06 - val_loss: 1.5946e-06\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 1.8558e-06 - val_loss: 1.4989e-06\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 1.6773e-06 - val_loss: 1.1574e-06\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 1.4949e-06 - val_loss: 1.1306e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 1.3775e-06 - val_loss: 1.1496e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 1.3188e-06 - val_loss: 1.1326e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 1.3463e-06 - val_loss: 1.1073e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 2.2623e-06 - val_loss: 1.1342e-05\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 188us/step - loss: 4.9918e-05 - val_loss: 1.2275e-06\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 2.0530e-05 - val_loss: 9.1068e-06\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 9.2467e-06 - val_loss: 3.1670e-06\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 4.6052e-06 - val_loss: 9.7046e-07\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 2.7561e-06 - val_loss: 8.0670e-07\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 189us/step - loss: 1.7652e-06 - val_loss: 8.3123e-07\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 1.0206e-06 - val_loss: 9.0370e-07\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 9.4828e-07 - val_loss: 6.3941e-07\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 8.6181e-07 - val_loss: 7.3406e-07\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 8.0068e-0 - 0s 192us/step - loss: 7.9955e-07 - val_loss: 5.8991e-07\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 7.4743e-07 - val_loss: 6.2406e-07\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 7.1975e-07 - val_loss: 4.9698e-07\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 7.0355e-07 - val_loss: 6.1728e-07\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 7.0887e-07 - val_loss: 6.6713e-07\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 193us/step - loss: 7.2132e-07 - val_loss: 5.5343e-07\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 1.1741e-06 - val_loss: 7.2792e-06\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 194us/step - loss: 8.1687e-05 - val_loss: 1.0525e-04\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 4.6580e-05 - val_loss: 2.6765e-05\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 1.8720e-05 - val_loss: 8.1512e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 8.3222e-06 - val_loss: 4.3124e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 192us/step - loss: 4.1542e-06 - val_loss: 3.7054e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 191us/step - loss: 2.1686e-06 - val_loss: 7.5792e-07\n",
      "Epoch 00045: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_7 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 128, 128)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 64, 256)           229632    \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 64, 256)           459008    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1 (None, 128, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 128, 128)          229504    \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 128, 1)            897       \n",
      "_________________________________________________________________\n",
      "cropping1d_7 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 920,065\n",
      "Trainable params: 920,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 1s 2ms/step - loss: 0.0630 - val_loss: 0.0280\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 375us/step - loss: 0.0141 - val_loss: 0.0013\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 0.0011 - val_loss: 5.6673e-04\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 368us/step - loss: 3.9482e-04 - val_loss: 2.5436e-04\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 375us/step - loss: 1.6078e-04 - val_loss: 1.0049e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 375us/step - loss: 6.2226e-05 - val_loss: 3.1911e-05\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 376us/step - loss: 2.9785e-05 - val_loss: 1.7774e-05\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 376us/step - loss: 1.5443e-05 - val_loss: 8.7559e-06\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 9.3700e-06 - val_loss: 5.0252e-06\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 5.3215e-06 - val_loss: 3.1168e-06\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 378us/step - loss: 3.8265e-06 - val_loss: 2.3272e-06\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 3.0397e-06 - val_loss: 1.6325e-06\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 2.2324e-06 - val_loss: 1.2528e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 375us/step - loss: 2.1435e-06 - val_loss: 3.8227e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 6.3533e-05 - val_loss: 2.8430e-04\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 1.0614e-04 - val_loss: 2.6611e-05\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 375us/step - loss: 3.3309e-05 - val_loss: 3.0884e-05\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 375us/step - loss: 1.6691e-05 - val_loss: 1.2722e-05\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 6.5662e-06 - val_loss: 6.8385e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 3.9876e-06 - val_loss: 3.2803e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 2.3280e-06 - val_loss: 1.9360e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 1.8200e-06 - val_loss: 6.5699e-07\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 368us/step - loss: 1.1701e-06 - val_loss: 8.8587e-07\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 377us/step - loss: 9.8510e-07 - val_loss: 6.0997e-07\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 8.5553e-07 - val_loss: 5.3429e-07\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 371us/step - loss: 7.2371e-07 - val_loss: 3.8434e-07\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 369us/step - loss: 6.3948e-07 - val_loss: 3.5558e-07\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 5.7803e-07 - val_loss: 3.4186e-07\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 5.1738e-07 - val_loss: 3.2043e-07\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 4.6752e-07 - val_loss: 3.1602e-07\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 4.3275e-07 - val_loss: 2.8831e-07\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 371us/step - loss: 4.1377e-07 - val_loss: 3.1939e-07\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 3.9679e-07 - val_loss: 2.6312e-07\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 3.6808e-07 - val_loss: 2.9382e-07\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 3.7810e-07 - val_loss: 2.4524e-07\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 368us/step - loss: 4.2986e-07 - val_loss: 3.1798e-07\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 377us/step - loss: 3.9823e-07 - val_loss: 7.4066e-07\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 368us/step - loss: 8.2528e-07 - val_loss: 1.7094e-06\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 8.3941e-06 - val_loss: 4.7994e-05\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 1.0139e-04 - val_loss: 3.2669e-05\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 371us/step - loss: 2.2013e-05 - val_loss: 1.9178e-05\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 373us/step - loss: 1.4619e-05 - val_loss: 7.5073e-07\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 370us/step - loss: 5.4194e-06 - val_loss: 1.9959e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 372us/step - loss: 2.8458e-06 - val_loss: 2.3630e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 371us/step - loss: 1.4085e-06 - val_loss: 1.0225e-06\n",
      "Epoch 00045: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_8 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 128, 256)          2304      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 64, 512)           1049088   \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 64, 512)           2097664   \n",
      "_________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1 (None, 128, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 128, 256)          1048832   \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 128, 1)            2049      \n",
      "_________________________________________________________________\n",
      "cropping1d_8 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 4,199,937\n",
      "Trainable params: 4,199,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 3s 4ms/step - loss: 0.1104 - val_loss: 0.0560\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0445 - val_loss: 0.0275\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0063\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 6.2844e-04 - val_loss: 3.1725e-04\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 2.0533e-04 - val_loss: 1.1998e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 8.7485e-05 - val_loss: 4.1265e-05\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.6818e-05 - val_loss: 2.2753e-05\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.7534e-05 - val_loss: 1.0668e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 9.5420e-06 - val_loss: 5.7726e-06\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.2587e-06 - val_loss: 3.2760e-06\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.4283e-06 - val_loss: 1.9627e-06\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 2.4144e-06 - val_loss: 1.4331e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.9192e-06 - val_loss: 9.9183e-07\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.5849e-06 - val_loss: 7.8816e-07\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.3783e-06 - val_loss: 6.7346e-07\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.2202e-06 - val_loss: 6.9343e-07\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.1711e-06 - val_loss: 5.7311e-07\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.0252e-06 - val_loss: 4.9122e-07\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 9.1565e-07 - val_loss: 4.4093e-07\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 8.2356e-07 - val_loss: 4.2424e-07\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 7.7106e-07 - val_loss: 4.1344e-07\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 7.2126e-07 - val_loss: 3.9659e-07\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 6.7351e-07 - val_loss: 3.4081e-07\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 6.0950e-07 - val_loss: 3.3640e-07\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.7001e-07 - val_loss: 3.0786e-07\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.2598e-07 - val_loss: 3.4727e-07\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.1657e-07 - val_loss: 3.4508e-07\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 4.7283e-07 - val_loss: 2.8072e-07\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 4.3226e-07 - val_loss: 2.5841e-07\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.9667e-07 - val_loss: 2.2447e-07\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.5998e-07 - val_loss: 2.1906e-07\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.3903e-07 - val_loss: 2.1896e-07\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.2711e-07 - val_loss: 2.2114e-07\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.1404e-07 - val_loss: 2.5147e-07\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.1126e-07 - val_loss: 2.6103e-07\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.1525e-07 - val_loss: 1.9991e-07\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 2.8388e-07 - val_loss: 1.6135e-07\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.1154e-07 - val_loss: 3.4938e-07\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 4.1348e-07 - val_loss: 4.4153e-07\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 6.8992e-07 - val_loss: 3.5645e-06\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 2.4680e-05 - val_loss: 5.4061e-05\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 2.1643e-05 - val_loss: 2.1916e-06\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.3532e-06 - val_loss: 6.6099e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.2377e-06 - val_loss: 5.9484e-07\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 1.0610e-06 - val_loss: 5.7704e-07\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 5.6994e-07 - val_loss: 3.7705e-07\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 1s 1ms/step - loss: 3.3230e-07 - val_loss: 2.0388e-07\n",
      "Epoch 00048: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_9 (ZeroPaddin (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 128, 512)          5120      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 64, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 64, 1024)          4719616   \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 64, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 64, 1024)          9438208   \n",
      "_________________________________________________________________\n",
      "up_sampling1d_9 (UpSampling1 (None, 128, 1024)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 128, 512)          4719104   \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 128, 1)            4609      \n",
      "_________________________________________________________________\n",
      "cropping1d_9 (Cropping1D)    (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 18,886,657\n",
      "Trainable params: 18,886,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 9s 10ms/step - loss: 0.7254 - val_loss: 0.0656\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0573 - val_loss: 0.0459\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0378 - val_loss: 0.0261\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0212 - val_loss: 0.0135\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0090 - val_loss: 0.0035\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 0.0019 - val_loss: 4.7828e-04\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.3359e-04 - val_loss: 2.5988e-04\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.8080e-04 - val_loss: 1.2089e-04\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.5336e-05 - val_loss: 5.6317e-05\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.8593e-05 - val_loss: 2.6596e-05\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.0157e-05 - val_loss: 1.0125e-05\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1630e-05 - val_loss: 7.1282e-06\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 7.2480e-06 - val_loss: 4.4804e-06\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.2874e-06 - val_loss: 3.6858e-06\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.2624e-06 - val_loss: 2.4135e-06\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.3368e-06 - val_loss: 2.6946e-06\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.4418e-06 - val_loss: 2.5293e-06\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.8424e-06 - val_loss: 1.6877e-06\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.2500e-06 - val_loss: 1.5010e-06\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.8680e-06 - val_loss: 1.3542e-06\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6386e-06 - val_loss: 1.3579e-06\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.9508e-06 - val_loss: 1.0168e-06\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.4037e-06 - val_loss: 1.1215e-06\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.2112e-06 - val_loss: 9.2364e-07\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.7219e-06 - val_loss: 1.2702e-05\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.5338e-05 - val_loss: 1.1532e-04\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.3890e-05 - val_loss: 2.8449e-05\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.5653e-05 - val_loss: 1.3753e-05\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.1960e-06 - val_loss: 4.3415e-06\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.8610e-06 - val_loss: 1.0801e-06\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.6193e-06 - val_loss: 8.2426e-07\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0383e-06 - val_loss: 7.5254e-07\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.7703e-07 - val_loss: 6.9369e-07\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.2023e-07 - val_loss: 6.0673e-07\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3587e-07 - val_loss: 6.2636e-07\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.2161e-07 - val_loss: 5.0111e-07\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.3544e-07 - val_loss: 8.0816e-07\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 6.4415e-07 - val_loss: 6.4211e-07\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 5.6213e-07 - val_loss: 5.3843e-07\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.8113e-07 - val_loss: 4.4779e-07\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 4.4639e-07 - val_loss: 6.2744e-07\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 1.1308e-06 - val_loss: 2.9544e-06\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.1212e-05 - val_loss: 4.7970e-05\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 8.8404e-05 - val_loss: 7.3262e-06\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 2.2778e-05 - val_loss: 1.4633e-05\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 9.5940e-06 - val_loss: 1.4225e-06\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 3.0874e-06 - val_loss: 3.6391e-06\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 4s 4ms/step - loss: 1.9824e-06 - val_loss: 1.1755e-06\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.7613e-06 - val_loss: 1.9185e-06\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 4s 4ms/step - loss: 1.0879e-06 - val_loss: 5.3801e-07\n",
      "Epoch 00050: early stopping\n"
     ]
    }
   ],
   "source": [
    "modelsLoss = []\n",
    "modelsEpochs = []\n",
    "for i in range(1,10):\n",
    "    numOfLayers = 1\n",
    "    filtersCountInFirstLayer = np.power(2,i)\n",
    "    [model, validatoinLoss, numOfEpochs, _] = train1DConv(numOfLayers, filtersCountInFirstLayer, filterSize = i)\n",
    "    modelsLoss.append(validatoinLoss)\n",
    "    modelsEpochs.append(numOfEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss)\n",
    "plt.title('Models validation loss vs. first layer filter count')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('first layer filter count')\n",
    "plt.xticks(np.arange(9), [2,4,8,16,32,64,128,256,512])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I tried different filter counts ranged from 2 to 512 (powers of 2). As you can see in figure above, using filter size 2 is not enough and results in the worst performance. As the different between other filter counts is not clear here, I plotted range 4 to 512 in the next figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelsLoss[1:])\n",
    "plt.title('Models validation loss vs. first layer filter count')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('first layer filter count')\n",
    "plt.xticks(np.arange(8), [4,8,16,32,64,128,256,512])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plot in more detail:\n",
    "As it is shown in figure above, we have the best performance in filter sizes 4 and 8. Although there is fluctuations in larger sizes results, all of them have worse performance (due lack of memory I could not try filter sizes more than 512. However, this does not seems to be a decsending trend). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final 1D Convolutional Network learning\n",
    "Now it is time to train our final model using the parameters that we found before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding1d_10 (ZeroPaddi (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 128, 4)            40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 64, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 64, 8)             296       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 64, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 64, 8)             584       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_10 (UpSampling (None, 128, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 128, 4)            292       \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 128, 1)            37        \n",
      "_________________________________________________________________\n",
      "cropping1d_10 (Cropping1D)   (None, 100, 1)            0         \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "900/900 [==============================] - 2s 2ms/step - loss: 0.1005 - val_loss: 0.0912\n",
      "Epoch 2/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0874 - val_loss: 0.0820\n",
      "Epoch 3/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0794 - val_loss: 0.0744\n",
      "Epoch 4/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0716 - val_loss: 0.0670\n",
      "Epoch 5/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0648 - val_loss: 0.0606\n",
      "Epoch 6/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0575 - val_loss: 0.0518\n",
      "Epoch 7/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0488 - val_loss: 0.0443\n",
      "Epoch 8/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0421 - val_loss: 0.0391\n",
      "Epoch 9/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 0.0373 - val_loss: 0.0349\n",
      "Epoch 10/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0330 - val_loss: 0.0306\n",
      "Epoch 11/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0289 - val_loss: 0.0267\n",
      "Epoch 12/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0254 - val_loss: 0.0235\n",
      "Epoch 13/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0223 - val_loss: 0.0207\n",
      "Epoch 14/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0197 - val_loss: 0.0183\n",
      "Epoch 15/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 0.0175 - val_loss: 0.0166\n",
      "Epoch 16/1000\n",
      "900/900 [==============================] - ETA: 0s - loss: 0.016 - 0s 58us/step - loss: 0.0159 - val_loss: 0.0152\n",
      "Epoch 17/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 0.0146 - val_loss: 0.0140\n",
      "Epoch 18/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 19/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 20/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 21/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 22/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 23/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 24/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 25/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 26/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 27/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 28/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 29/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.9553e-04 - val_loss: 9.0357e-04\n",
      "Epoch 30/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.6904e-04 - val_loss: 7.9148e-04\n",
      "Epoch 31/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.7127e-04 - val_loss: 7.1120e-04\n",
      "Epoch 32/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.9585e-04 - val_loss: 6.4943e-04\n",
      "Epoch 33/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.3383e-04 - val_loss: 5.9788e-04\n",
      "Epoch 34/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.8701e-04 - val_loss: 5.5082e-04\n",
      "Epoch 35/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.4119e-04 - val_loss: 5.0606e-04\n",
      "Epoch 36/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.0082e-04 - val_loss: 4.7125e-04\n",
      "Epoch 37/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.6539e-04 - val_loss: 4.4133e-04\n",
      "Epoch 38/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 4.3526e-04 - val_loss: 4.1550e-04\n",
      "Epoch 39/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 4.0999e-04 - val_loss: 3.8666e-04\n",
      "Epoch 40/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.8411e-04 - val_loss: 3.6205e-04\n",
      "Epoch 41/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.6106e-04 - val_loss: 3.4865e-04\n",
      "Epoch 42/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.4360e-04 - val_loss: 3.2633e-04\n",
      "Epoch 43/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.2578e-04 - val_loss: 3.0921e-04\n",
      "Epoch 44/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.1079e-04 - val_loss: 2.9578e-04\n",
      "Epoch 45/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.9581e-04 - val_loss: 2.8054e-04\n",
      "Epoch 46/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.8328e-04 - val_loss: 2.6861e-04\n",
      "Epoch 47/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.7161e-04 - val_loss: 2.5696e-04\n",
      "Epoch 48/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.5985e-04 - val_loss: 2.4719e-04\n",
      "Epoch 49/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5052e-04 - val_loss: 2.3768e-04\n",
      "Epoch 50/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.4071e-04 - val_loss: 2.3895e-04\n",
      "Epoch 51/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.3697e-04 - val_loss: 2.2118e-04\n",
      "Epoch 52/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.2523e-04 - val_loss: 2.1359e-04\n",
      "Epoch 53/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.1816e-04 - val_loss: 2.0939e-04\n",
      "Epoch 54/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.1224e-04 - val_loss: 1.9911e-04\n",
      "Epoch 55/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.0379e-04 - val_loss: 1.9252e-04\n",
      "Epoch 56/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.9773e-04 - val_loss: 1.8669e-04\n",
      "Epoch 57/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9248e-04 - val_loss: 1.8049e-04\n",
      "Epoch 58/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.8682e-04 - val_loss: 1.7644e-04\n",
      "Epoch 59/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.8226e-04 - val_loss: 1.7168e-04\n",
      "Epoch 60/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7715e-04 - val_loss: 1.6811e-04\n",
      "Epoch 61/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7316e-04 - val_loss: 1.6350e-04\n",
      "Epoch 62/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.6841e-04 - val_loss: 1.5972e-04\n",
      "Epoch 63/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.6461e-04 - val_loss: 1.5499e-04\n",
      "Epoch 64/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.6026e-04 - val_loss: 1.5167e-04\n",
      "Epoch 65/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5672e-04 - val_loss: 1.4814e-04\n",
      "Epoch 66/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5305e-04 - val_loss: 1.5107e-04\n",
      "Epoch 67/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.5193e-04 - val_loss: 1.4052e-04\n",
      "Epoch 68/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.4633e-04 - val_loss: 1.4182e-04\n",
      "Epoch 69/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4403e-04 - val_loss: 1.3575e-04\n",
      "Epoch 70/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3999e-04 - val_loss: 1.3108e-04\n",
      "Epoch 71/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 1.3650e-04 - val_loss: 1.2803e-04\n",
      "Epoch 72/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3340e-04 - val_loss: 1.2577e-04\n",
      "Epoch 73/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3077e-04 - val_loss: 1.2248e-04\n",
      "Epoch 74/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2791e-04 - val_loss: 1.1991e-04\n",
      "Epoch 75/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2491e-04 - val_loss: 1.1822e-04\n",
      "Epoch 76/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2271e-04 - val_loss: 1.1484e-04\n",
      "Epoch 77/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.2012e-04 - val_loss: 1.1230e-04\n",
      "Epoch 78/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1782e-04 - val_loss: 1.1215e-04\n",
      "Epoch 79/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1634e-04 - val_loss: 1.0764e-04\n",
      "Epoch 80/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 1.1345e-04 - val_loss: 1.1143e-04\n",
      "Epoch 81/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1364e-04 - val_loss: 1.0535e-04\n",
      "Epoch 82/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1001e-04 - val_loss: 1.0162e-04\n",
      "Epoch 83/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0689e-04 - val_loss: 1.0029e-04\n",
      "Epoch 84/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.0517e-04 - val_loss: 1.0359e-04\n",
      "Epoch 85/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0551e-04 - val_loss: 9.6818e-05\n",
      "Epoch 86/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.0206e-04 - val_loss: 9.7973e-05\n",
      "Epoch 87/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0156e-04 - val_loss: 9.4101e-05\n",
      "Epoch 88/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.9181e-05 - val_loss: 9.2457e-05\n",
      "Epoch 89/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 9.7549e-05 - val_loss: 9.0839e-05\n",
      "Epoch 90/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 9.5432e-05 - val_loss: 8.9064e-05\n",
      "Epoch 91/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 9.3030e-05 - val_loss: 8.7444e-05\n",
      "Epoch 92/1000\n",
      "900/900 [==============================] - 0s 59us/step - loss: 9.1674e-05 - val_loss: 8.6707e-05\n",
      "Epoch 93/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.1479e-05 - val_loss: 8.4156e-05\n",
      "Epoch 94/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 8.9211e-05 - val_loss: 8.2669e-05\n",
      "Epoch 95/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.7326e-05 - val_loss: 8.1028e-05\n",
      "Epoch 96/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.5707e-05 - val_loss: 7.9732e-05\n",
      "Epoch 97/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.4376e-05 - val_loss: 7.8959e-05\n",
      "Epoch 98/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 8.3301e-05 - val_loss: 7.7566e-05\n",
      "Epoch 99/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.2016e-05 - val_loss: 7.6126e-05\n",
      "Epoch 100/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.0689e-05 - val_loss: 7.5139e-05\n",
      "Epoch 101/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.9531e-05 - val_loss: 7.4351e-05\n",
      "Epoch 102/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.8444e-05 - val_loss: 7.3885e-05\n",
      "Epoch 103/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.7641e-05 - val_loss: 7.2215e-05\n",
      "Epoch 104/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.6522e-05 - val_loss: 7.0864e-05\n",
      "Epoch 105/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.4972e-05 - val_loss: 7.0447e-05\n",
      "Epoch 106/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.4161e-05 - val_loss: 6.8818e-05\n",
      "Epoch 107/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.2829e-05 - val_loss: 6.8255e-05\n",
      "Epoch 108/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.2238e-05 - val_loss: 6.7891e-05\n",
      "Epoch 109/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.1335e-05 - val_loss: 7.2098e-05\n",
      "Epoch 110/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.2573e-05 - val_loss: 6.9793e-05\n",
      "Epoch 111/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.1181e-05 - val_loss: 6.3747e-05\n",
      "Epoch 112/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.8450e-05 - val_loss: 6.4249e-05\n",
      "Epoch 113/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.7240e-05 - val_loss: 6.2480e-05\n",
      "Epoch 114/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.6166e-05 - val_loss: 6.1438e-05\n",
      "Epoch 115/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.5580e-05 - val_loss: 6.1993e-05\n",
      "Epoch 116/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 6.5003e-05 - val_loss: 5.9912e-05\n",
      "Epoch 117/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 6.3590e-05 - val_loss: 5.9391e-05\n",
      "Epoch 118/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.2865e-05 - val_loss: 5.8546e-05\n",
      "Epoch 119/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.1876e-05 - val_loss: 5.7326e-05\n",
      "Epoch 120/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 6.0937e-05 - val_loss: 5.7646e-05\n",
      "Epoch 121/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.0613e-05 - val_loss: 5.7694e-05\n",
      "Epoch 122/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9998e-05 - val_loss: 5.6335e-05\n",
      "Epoch 123/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.9331e-05 - val_loss: 5.5424e-05\n",
      "Epoch 124/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.8708e-05 - val_loss: 5.4751e-05\n",
      "Epoch 125/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.8036e-05 - val_loss: 5.4850e-05\n",
      "Epoch 126/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.7173e-05 - val_loss: 5.3193e-05\n",
      "Epoch 127/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 5.5970e-05 - val_loss: 5.2322e-05\n",
      "Epoch 128/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.5533e-05 - val_loss: 5.3492e-05\n",
      "Epoch 129/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.6088e-05 - val_loss: 5.1289e-05\n",
      "Epoch 130/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.4357e-05 - val_loss: 5.9231e-05\n",
      "Epoch 131/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 5.7466e-05 - val_loss: 5.2722e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.4688e-05 - val_loss: 5.4770e-05\n",
      "Epoch 133/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.4605e-05 - val_loss: 5.1741e-05\n",
      "Epoch 134/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 5.2785e-05 - val_loss: 4.8781e-05\n",
      "Epoch 135/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.1240e-05 - val_loss: 4.7370e-05\n",
      "Epoch 136/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 5.0009e-05 - val_loss: 4.6949e-05\n",
      "Epoch 137/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.9465e-05 - val_loss: 4.6262e-05\n",
      "Epoch 138/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.8754e-05 - val_loss: 4.6347e-05\n",
      "Epoch 139/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.8507e-05 - val_loss: 4.7105e-05\n",
      "Epoch 140/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.8530e-05 - val_loss: 4.5044e-05\n",
      "Epoch 141/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 4.7594e-05 - val_loss: 4.4247e-05\n",
      "Epoch 142/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.6737e-05 - val_loss: 4.3426e-05\n",
      "Epoch 143/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 4.6452e-05 - val_loss: 4.3343e-05\n",
      "Epoch 144/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.5699e-05 - val_loss: 4.2819e-05\n",
      "Epoch 145/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.5094e-05 - val_loss: 4.1881e-05\n",
      "Epoch 146/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.4334e-05 - val_loss: 4.1007e-05\n",
      "Epoch 147/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.3601e-05 - val_loss: 4.0342e-05\n",
      "Epoch 148/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.3010e-05 - val_loss: 4.1532e-05\n",
      "Epoch 149/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.3191e-05 - val_loss: 3.9518e-05\n",
      "Epoch 150/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.2627e-05 - val_loss: 3.9615e-05\n",
      "Epoch 151/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.1652e-05 - val_loss: 3.9379e-05\n",
      "Epoch 152/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.1269e-05 - val_loss: 3.9562e-05\n",
      "Epoch 153/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 4.1158e-05 - val_loss: 3.7514e-05\n",
      "Epoch 154/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 4.0156e-05 - val_loss: 3.8231e-05\n",
      "Epoch 155/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 4.0237e-05 - val_loss: 3.6957e-05\n",
      "Epoch 156/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.9542e-05 - val_loss: 3.8128e-05\n",
      "Epoch 157/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.9619e-05 - val_loss: 3.5729e-05\n",
      "Epoch 158/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.8559e-05 - val_loss: 3.6577e-05\n",
      "Epoch 159/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.8183e-05 - val_loss: 3.5788e-05\n",
      "Epoch 160/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.7742e-05 - val_loss: 3.4623e-05\n",
      "Epoch 161/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.7158e-05 - val_loss: 3.4765e-05\n",
      "Epoch 162/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.6770e-05 - val_loss: 3.4000e-05\n",
      "Epoch 163/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.6364e-05 - val_loss: 3.3496e-05\n",
      "Epoch 164/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.6088e-05 - val_loss: 3.3552e-05\n",
      "Epoch 165/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.5752e-05 - val_loss: 3.5658e-05\n",
      "Epoch 166/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.5953e-05 - val_loss: 3.2465e-05\n",
      "Epoch 167/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.4967e-05 - val_loss: 3.2512e-05\n",
      "Epoch 168/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.4543e-05 - val_loss: 3.1756e-05\n",
      "Epoch 169/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.4124e-05 - val_loss: 3.1676e-05\n",
      "Epoch 170/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.3771e-05 - val_loss: 3.1347e-05\n",
      "Epoch 171/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.3959e-05 - val_loss: 3.1746e-05\n",
      "Epoch 172/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 3.3562e-05 - val_loss: 3.1439e-05\n",
      "Epoch 173/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.3844e-05 - val_loss: 3.0258e-05\n",
      "Epoch 174/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.2932e-05 - val_loss: 3.3854e-05\n",
      "Epoch 175/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.3824e-05 - val_loss: 3.0320e-05\n",
      "Epoch 176/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.2916e-05 - val_loss: 3.2695e-05\n",
      "Epoch 177/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.3207e-05 - val_loss: 2.9534e-05\n",
      "Epoch 178/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 3.2083e-05 - val_loss: 3.4600e-05\n",
      "Epoch 179/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 3.3370e-05 - val_loss: 2.8377e-05\n",
      "Epoch 180/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.1535e-05 - val_loss: 2.9958e-05\n",
      "Epoch 181/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 3.1218e-05 - val_loss: 2.9308e-05\n",
      "Epoch 182/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 3.0773e-05 - val_loss: 2.7814e-05\n",
      "Epoch 183/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.9835e-05 - val_loss: 2.9047e-05\n",
      "Epoch 184/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 3.0014e-05 - val_loss: 2.7342e-05\n",
      "Epoch 185/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.9515e-05 - val_loss: 2.9837e-05\n",
      "Epoch 186/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 3.0120e-05 - val_loss: 2.6780e-05\n",
      "Epoch 187/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.8790e-05 - val_loss: 2.9747e-05\n",
      "Epoch 188/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.9573e-05 - val_loss: 2.6137e-05\n",
      "Epoch 189/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.8625e-05 - val_loss: 2.8416e-05\n",
      "Epoch 190/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 2.8554e-05 - val_loss: 2.6132e-05\n",
      "Epoch 191/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 2.7755e-05 - val_loss: 2.4890e-05\n",
      "Epoch 192/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 2.7372e-05 - val_loss: 2.4584e-05\n",
      "Epoch 193/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.6563e-05 - val_loss: 2.4889e-05\n",
      "Epoch 194/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 2.6742e-05 - val_loss: 2.4421e-05\n",
      "Epoch 195/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.6288e-05 - val_loss: 2.3997e-05\n",
      "Epoch 196/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.6038e-05 - val_loss: 2.4594e-05\n",
      "Epoch 197/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.6152e-05 - val_loss: 2.4130e-05\n",
      "Epoch 198/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.5752e-05 - val_loss: 2.3138e-05\n",
      "Epoch 199/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.5267e-05 - val_loss: 2.2869e-05\n",
      "Epoch 200/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.4837e-05 - val_loss: 2.3299e-05\n",
      "Epoch 201/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.4841e-05 - val_loss: 2.3515e-05\n",
      "Epoch 202/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.4641e-05 - val_loss: 2.2844e-05\n",
      "Epoch 203/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.4421e-05 - val_loss: 2.2356e-05\n",
      "Epoch 204/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.4084e-05 - val_loss: 2.2244e-05\n",
      "Epoch 205/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.3916e-05 - val_loss: 2.1807e-05\n",
      "Epoch 206/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.3602e-05 - val_loss: 2.3279e-05\n",
      "Epoch 207/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.4234e-05 - val_loss: 2.2031e-05\n",
      "Epoch 208/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 2.3513e-05 - val_loss: 2.1885e-05\n",
      "Epoch 209/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.3360e-05 - val_loss: 2.1127e-05\n",
      "Epoch 210/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2981e-05 - val_loss: 2.0948e-05\n",
      "Epoch 211/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2620e-05 - val_loss: 2.1719e-05\n",
      "Epoch 212/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2929e-05 - val_loss: 2.0439e-05\n",
      "Epoch 213/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2350e-05 - val_loss: 2.0323e-05\n",
      "Epoch 214/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2139e-05 - val_loss: 2.0764e-05\n",
      "Epoch 215/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.2229e-05 - val_loss: 1.9857e-05\n",
      "Epoch 216/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 2.1562e-05 - val_loss: 2.0645e-05\n",
      "Epoch 217/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 2.1824e-05 - val_loss: 1.9927e-05\n",
      "Epoch 218/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.1389e-05 - val_loss: 2.0611e-05\n",
      "Epoch 219/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 2.1542e-05 - val_loss: 2.3796e-05\n",
      "Epoch 220/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 2.3126e-05 - val_loss: 1.9208e-05\n",
      "Epoch 221/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.0747e-05 - val_loss: 1.8981e-05\n",
      "Epoch 222/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0794e-05 - val_loss: 1.8627e-05\n",
      "Epoch 223/1000\n",
      "900/900 [==============================] - 0s 49us/step - loss: 2.0349e-05 - val_loss: 1.8734e-05\n",
      "Epoch 224/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0299e-05 - val_loss: 1.8485e-05\n",
      "Epoch 225/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9982e-05 - val_loss: 1.8474e-05\n",
      "Epoch 226/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 2.0076e-05 - val_loss: 1.8635e-05\n",
      "Epoch 227/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0043e-05 - val_loss: 1.7854e-05\n",
      "Epoch 228/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9459e-05 - val_loss: 1.7707e-05\n",
      "Epoch 229/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.9494e-05 - val_loss: 1.7754e-05\n",
      "Epoch 230/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.9298e-05 - val_loss: 1.7651e-05\n",
      "Epoch 231/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9278e-05 - val_loss: 1.7972e-05\n",
      "Epoch 232/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.9531e-05 - val_loss: 1.7725e-05\n",
      "Epoch 233/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.9145e-05 - val_loss: 1.7388e-05\n",
      "Epoch 234/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.8974e-05 - val_loss: 1.7328e-05\n",
      "Epoch 235/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.8866e-05 - val_loss: 1.7194e-05\n",
      "Epoch 236/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.8549e-05 - val_loss: 1.7357e-05\n",
      "Epoch 237/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.8538e-05 - val_loss: 1.7219e-05\n",
      "Epoch 238/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.8580e-05 - val_loss: 1.6656e-05\n",
      "Epoch 239/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.8297e-05 - val_loss: 1.8489e-05\n",
      "Epoch 240/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.8654e-05 - val_loss: 1.6902e-05\n",
      "Epoch 241/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.8060e-05 - val_loss: 1.6049e-05\n",
      "Epoch 242/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7684e-05 - val_loss: 1.6435e-05\n",
      "Epoch 243/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.8187e-05 - val_loss: 1.5624e-05\n",
      "Epoch 244/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.7777e-05 - val_loss: 1.6515e-05\n",
      "Epoch 245/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 1.7454e-05 - val_loss: 1.6214e-05\n",
      "Epoch 246/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.7646e-05 - val_loss: 1.5531e-05\n",
      "Epoch 247/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6989e-05 - val_loss: 1.5951e-05\n",
      "Epoch 248/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7314e-05 - val_loss: 1.6572e-05\n",
      "Epoch 249/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7561e-05 - val_loss: 1.5511e-05\n",
      "Epoch 250/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.6930e-05 - val_loss: 1.7306e-05\n",
      "Epoch 251/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.7488e-05 - val_loss: 1.4975e-05\n",
      "Epoch 252/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.6523e-05 - val_loss: 1.4450e-05\n",
      "Epoch 253/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.6059e-05 - val_loss: 1.4497e-05\n",
      "Epoch 254/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.5970e-05 - val_loss: 1.4765e-05\n",
      "Epoch 255/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5953e-05 - val_loss: 1.4477e-05\n",
      "Epoch 256/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.6022e-05 - val_loss: 1.6539e-05\n",
      "Epoch 257/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.7269e-05 - val_loss: 1.4894e-05\n",
      "Epoch 258/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.6331e-05 - val_loss: 1.4672e-05\n",
      "Epoch 259/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.5708e-05 - val_loss: 1.4150e-05\n",
      "Epoch 260/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.5654e-05 - val_loss: 1.3786e-05\n",
      "Epoch 261/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.5410e-05 - val_loss: 1.5142e-05\n",
      "Epoch 262/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5923e-05 - val_loss: 1.3477e-05\n",
      "Epoch 263/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.5299e-05 - val_loss: 1.6118e-05\n",
      "Epoch 264/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6115e-05 - val_loss: 1.3313e-05\n",
      "Epoch 265/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.5155e-05 - val_loss: 1.3881e-05\n",
      "Epoch 266/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.5018e-05 - val_loss: 1.3101e-05\n",
      "Epoch 267/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4688e-05 - val_loss: 1.4140e-05\n",
      "Epoch 268/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.4908e-05 - val_loss: 1.2870e-05\n",
      "Epoch 269/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4626e-05 - val_loss: 1.3713e-05\n",
      "Epoch 270/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4796e-05 - val_loss: 1.3300e-05\n",
      "Epoch 271/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.5024e-05 - val_loss: 1.6724e-05\n",
      "Epoch 272/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6085e-05 - val_loss: 1.2736e-05\n",
      "Epoch 273/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.4631e-05 - val_loss: 1.2863e-05\n",
      "Epoch 274/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.4181e-05 - val_loss: 1.2492e-05\n",
      "Epoch 275/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.4053e-05 - val_loss: 1.3701e-05\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 57us/step - loss: 1.5011e-05 - val_loss: 1.2901e-05\n",
      "Epoch 277/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.4768e-05 - val_loss: 1.2497e-05\n",
      "Epoch 278/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.3777e-05 - val_loss: 1.2670e-05\n",
      "Epoch 279/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3835e-05 - val_loss: 1.2025e-05\n",
      "Epoch 280/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3496e-05 - val_loss: 1.2242e-05\n",
      "Epoch 281/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3382e-05 - val_loss: 1.1933e-05\n",
      "Epoch 282/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.3259e-05 - val_loss: 1.1599e-05\n",
      "Epoch 283/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3061e-05 - val_loss: 1.2675e-05\n",
      "Epoch 284/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.3635e-05 - val_loss: 1.1689e-05\n",
      "Epoch 285/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.3059e-05 - val_loss: 1.1575e-05\n",
      "Epoch 286/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2865e-05 - val_loss: 1.2205e-05\n",
      "Epoch 287/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.3190e-05 - val_loss: 1.1792e-05\n",
      "Epoch 288/1000\n",
      "900/900 [==============================] - 0s 58us/step - loss: 1.2934e-05 - val_loss: 1.1989e-05\n",
      "Epoch 289/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.2949e-05 - val_loss: 1.1265e-05\n",
      "Epoch 290/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2629e-05 - val_loss: 1.2425e-05\n",
      "Epoch 291/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.3387e-05 - val_loss: 1.0923e-05\n",
      "Epoch 292/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.2329e-05 - val_loss: 1.1139e-05\n",
      "Epoch 293/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2522e-05 - val_loss: 1.1430e-05\n",
      "Epoch 294/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2649e-05 - val_loss: 1.0897e-05\n",
      "Epoch 295/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2134e-05 - val_loss: 1.0822e-05\n",
      "Epoch 296/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2101e-05 - val_loss: 1.0748e-05\n",
      "Epoch 297/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1925e-05 - val_loss: 1.0804e-05\n",
      "Epoch 298/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1877e-05 - val_loss: 1.0572e-05\n",
      "Epoch 299/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.1787e-05 - val_loss: 1.0457e-05\n",
      "Epoch 300/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1755e-05 - val_loss: 1.0888e-05\n",
      "Epoch 301/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.2372e-05 - val_loss: 1.1755e-05\n",
      "Epoch 302/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.2287e-05 - val_loss: 1.2210e-05\n",
      "Epoch 303/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.2445e-05 - val_loss: 1.2353e-05\n",
      "Epoch 304/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.2644e-05 - val_loss: 1.1500e-05\n",
      "Epoch 305/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.2380e-05 - val_loss: 1.1503e-05\n",
      "Epoch 306/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.2007e-05 - val_loss: 1.0580e-05\n",
      "Epoch 307/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1400e-05 - val_loss: 1.0593e-05\n",
      "Epoch 308/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.1304e-05 - val_loss: 1.0081e-05\n",
      "Epoch 309/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.1632e-05 - val_loss: 1.0114e-05\n",
      "Epoch 310/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.1412e-05 - val_loss: 1.0249e-05\n",
      "Epoch 311/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.1098e-05 - val_loss: 1.0377e-05\n",
      "Epoch 312/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1297e-05 - val_loss: 9.7471e-06\n",
      "Epoch 313/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1063e-05 - val_loss: 9.7957e-06\n",
      "Epoch 314/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0934e-05 - val_loss: 9.9151e-06\n",
      "Epoch 315/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0854e-05 - val_loss: 1.0456e-05\n",
      "Epoch 316/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.1697e-05 - val_loss: 1.1060e-05\n",
      "Epoch 317/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.3203e-05 - val_loss: 9.5160e-06\n",
      "Epoch 318/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.0912e-05 - val_loss: 9.4828e-06\n",
      "Epoch 319/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.0507e-05 - val_loss: 9.4235e-06\n",
      "Epoch 320/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 1.0385e-05 - val_loss: 9.4790e-06\n",
      "Epoch 321/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.0720e-05 - val_loss: 9.0711e-06\n",
      "Epoch 322/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 1.0298e-05 - val_loss: 9.1302e-06\n",
      "Epoch 323/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.0452e-05 - val_loss: 1.0455e-05\n",
      "Epoch 324/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0641e-05 - val_loss: 9.1944e-06\n",
      "Epoch 325/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.0154e-05 - val_loss: 8.9579e-06\n",
      "Epoch 326/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0242e-05 - val_loss: 9.7458e-06\n",
      "Epoch 327/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.0163e-05 - val_loss: 9.1916e-06\n",
      "Epoch 328/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.0122e-05 - val_loss: 9.4681e-06\n",
      "Epoch 329/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0317e-05 - val_loss: 9.0857e-06\n",
      "Epoch 330/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0716e-05 - val_loss: 9.3584e-06\n",
      "Epoch 331/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0358e-05 - val_loss: 9.2495e-06\n",
      "Epoch 332/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 9.8749e-06 - val_loss: 8.7950e-06\n",
      "Epoch 333/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.7218e-06 - val_loss: 9.0210e-06\n",
      "Epoch 334/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.8542e-06 - val_loss: 8.7898e-06\n",
      "Epoch 335/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.6903e-06 - val_loss: 8.5021e-06\n",
      "Epoch 336/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 9.3529e-06 - val_loss: 8.8961e-06\n",
      "Epoch 337/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.4321e-06 - val_loss: 8.3117e-06\n",
      "Epoch 338/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.2333e-06 - val_loss: 9.1056e-06\n",
      "Epoch 339/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.0309e-05 - val_loss: 8.7612e-06\n",
      "Epoch 340/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 1.0497e-05 - val_loss: 1.0625e-05\n",
      "Epoch 341/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0456e-05 - val_loss: 8.8493e-06\n",
      "Epoch 342/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 9.4883e-06 - val_loss: 9.9152e-06\n",
      "Epoch 343/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.0031e-05 - val_loss: 8.2314e-06\n",
      "Epoch 344/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 9.6493e-06 - val_loss: 9.3990e-06\n",
      "Epoch 345/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.4709e-06 - val_loss: 8.9648e-06\n",
      "Epoch 346/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 9.4613e-06 - val_loss: 8.0852e-06\n",
      "Epoch 347/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.5135e-06 - val_loss: 7.9926e-06\n",
      "Epoch 348/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.1426e-06 - val_loss: 8.1844e-06\n",
      "Epoch 349/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 8.7859e-06 - val_loss: 7.8239e-06\n",
      "Epoch 350/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.6086e-06 - val_loss: 7.7763e-06\n",
      "Epoch 351/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 8.6080e-06 - val_loss: 8.6777e-06\n",
      "Epoch 352/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.3114e-06 - val_loss: 9.1543e-06\n",
      "Epoch 353/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 9.0977e-06 - val_loss: 7.8583e-06\n",
      "Epoch 354/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 8.6809e-06 - val_loss: 7.5043e-06\n",
      "Epoch 355/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.4530e-06 - val_loss: 7.8190e-06\n",
      "Epoch 356/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.1738e-06 - val_loss: 9.7273e-06\n",
      "Epoch 357/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 1.0322e-05 - val_loss: 1.1264e-05\n",
      "Epoch 358/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 9.4395e-06 - val_loss: 8.0242e-06\n",
      "Epoch 359/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 8.4091e-06 - val_loss: 7.2418e-06\n",
      "Epoch 360/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 8.1270e-06 - val_loss: 7.4346e-06\n",
      "Epoch 361/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 8.1273e-06 - val_loss: 7.5916e-06\n",
      "Epoch 362/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.4121e-06 - val_loss: 7.8750e-06\n",
      "Epoch 363/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 8.8215e-06 - val_loss: 7.2108e-06\n",
      "Epoch 364/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.4628e-06 - val_loss: 1.3402e-05\n",
      "Epoch 365/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 2.0611e-05 - val_loss: 2.6949e-05\n",
      "Epoch 366/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.6179e-05 - val_loss: 1.5320e-05\n",
      "Epoch 367/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 1.3805e-05 - val_loss: 1.0115e-05\n",
      "Epoch 368/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 1.0362e-05 - val_loss: 7.4277e-06\n",
      "Epoch 369/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 8.5458e-06 - val_loss: 7.8666e-06\n",
      "Epoch 370/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 8.7960e-06 - val_loss: 6.9380e-06\n",
      "Epoch 371/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.6566e-06 - val_loss: 6.8667e-06\n",
      "Epoch 372/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 7.5605e-06 - val_loss: 6.8768e-06\n",
      "Epoch 373/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.5490e-06 - val_loss: 6.7908e-06\n",
      "Epoch 374/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.5030e-06 - val_loss: 7.6418e-06\n",
      "Epoch 375/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.0676e-06 - val_loss: 7.5242e-06\n",
      "Epoch 376/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.8828e-06 - val_loss: 6.6713e-06\n",
      "Epoch 377/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.4097e-06 - val_loss: 6.8727e-06\n",
      "Epoch 378/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.5828e-06 - val_loss: 6.8889e-06\n",
      "Epoch 379/1000\n",
      "900/900 [==============================] - 0s 50us/step - loss: 8.1749e-06 - val_loss: 6.5286e-06\n",
      "Epoch 380/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.0758e-06 - val_loss: 7.0950e-06\n",
      "Epoch 381/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 7.5479e-06 - val_loss: 8.0706e-06\n",
      "Epoch 382/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.2908e-06 - val_loss: 7.3125e-06\n",
      "Epoch 383/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.1053e-06 - val_loss: 6.5377e-06\n",
      "Epoch 384/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.7383e-06 - val_loss: 6.7114e-06\n",
      "Epoch 385/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.5351e-06 - val_loss: 6.6889e-06\n",
      "Epoch 386/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.3348e-06 - val_loss: 6.7669e-06\n",
      "Epoch 387/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.4769e-06 - val_loss: 6.3178e-06\n",
      "Epoch 388/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.2625e-06 - val_loss: 6.6733e-06\n",
      "Epoch 389/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.0743e-06 - val_loss: 6.6871e-06\n",
      "Epoch 390/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 7.6507e-06 - val_loss: 6.2106e-06\n",
      "Epoch 391/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.4025e-06 - val_loss: 6.4671e-06\n",
      "Epoch 392/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.1732e-06 - val_loss: 7.2407e-06\n",
      "Epoch 393/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 7.6092e-06 - val_loss: 6.4019e-06\n",
      "Epoch 394/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.8987e-06 - val_loss: 6.0408e-06\n",
      "Epoch 395/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.8924e-06 - val_loss: 6.0297e-06\n",
      "Epoch 396/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.2057e-06 - val_loss: 7.8567e-06\n",
      "Epoch 397/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 8.1682e-06 - val_loss: 6.4195e-06\n",
      "Epoch 398/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.9039e-06 - val_loss: 6.4391e-06\n",
      "Epoch 399/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 6.7409e-06 - val_loss: 6.0995e-06\n",
      "Epoch 400/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.6102e-06 - val_loss: 5.8799e-06\n",
      "Epoch 401/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.6877e-06 - val_loss: 6.1328e-06\n",
      "Epoch 402/1000\n",
      "900/900 [==============================] - 0s 57us/step - loss: 6.7050e-06 - val_loss: 5.8662e-06\n",
      "Epoch 403/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 6.4147e-06 - val_loss: 6.3500e-06\n",
      "Epoch 404/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 6.7543e-06 - val_loss: 6.3407e-06\n",
      "Epoch 405/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.6664e-06 - val_loss: 5.8093e-06\n",
      "Epoch 406/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 6.3708e-06 - val_loss: 5.6914e-06\n",
      "Epoch 407/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.3465e-06 - val_loss: 5.6887e-06\n",
      "Epoch 408/1000\n",
      "900/900 [==============================] - 0s 51us/step - loss: 6.2864e-06 - val_loss: 5.6930e-06\n",
      "Epoch 409/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.3001e-06 - val_loss: 5.8826e-06\n",
      "Epoch 410/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.3515e-06 - val_loss: 5.6847e-06\n",
      "Epoch 411/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.0001e-06 - val_loss: 6.1908e-06\n",
      "Epoch 412/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 7.3436e-06 - val_loss: 5.4188e-06\n",
      "Epoch 413/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.1902e-06 - val_loss: 8.3447e-06\n",
      "Epoch 414/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 8.9437e-06 - val_loss: 8.4897e-06\n",
      "Epoch 415/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 7.8966e-06 - val_loss: 7.3769e-06\n",
      "Epoch 416/1000\n",
      "900/900 [==============================] - 0s 54us/step - loss: 7.1059e-06 - val_loss: 5.4449e-06\n",
      "Epoch 417/1000\n",
      "900/900 [==============================] - 0s 55us/step - loss: 7.6305e-06 - val_loss: 5.8149e-06\n",
      "Epoch 418/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.1925e-06 - val_loss: 5.4669e-06\n",
      "Epoch 419/1000\n",
      "900/900 [==============================] - 0s 53us/step - loss: 6.3193e-06 - val_loss: 5.5454e-06\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 51us/step - loss: 6.0827e-06 - val_loss: 6.1444e-06\n",
      "Epoch 421/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.3998e-06 - val_loss: 5.6201e-06\n",
      "Epoch 422/1000\n",
      "900/900 [==============================] - 0s 52us/step - loss: 6.2026e-06 - val_loss: 5.4240e-06\n",
      "Epoch 00422: early stopping\n"
     ]
    }
   ],
   "source": [
    "numOfLayers = 1\n",
    "filtersCountInFirstLayer = 4\n",
    "[model, validatoinLoss, numOfEpochs, history] = train1DConv(numOfLayers, filtersCountInFirstLayer, filterSize = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Network Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is:  1.0\n",
      "Recall is:  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = model.predict(LSTMTest_data)\n",
    "mse = (np.square(LSTMTest_data - predicted)).mean(axis=1)\n",
    "mse = mse.reshape(testDataSize)\n",
    "reshaped_test_labels = test_labels.reshape(testDataSize)\n",
    "mse_label = np.vstack((mse, reshaped_test_labels)).T\n",
    "precision = rankedPrecision(mse_label)\n",
    "recall = rankedRecall(mse_label)\n",
    "convPrecision = precision\n",
    "convRecall = recall\n",
    "print(\"Precision is: \", precision)\n",
    "print(\"Recall is: \", precision)\n",
    "#history.history['loss']\n",
    "show_curve(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGtFJREFUeJzt3XmUZGV9//H3BwYCKDgsI2F1XBDFBdERl0RFUOKSCCa4EKJoULIYiaAYzElEczTRaIIimkiECIafSlDUaFyQ3ajEAUYRUJF9YIBBZTWGxe/vj/u01DTVfWsGuqsmvF/n9Om6+/dWdd/PfZ5bVTdVhSRJs1ln3AVIkiafYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWGheJVmcpJIsGGHe1yT5xnzUdV9N368kZyR53bjrmgtJbkvyiJ55npXkh/NVk+aeYaEZJbkiyR1Jtpg2flk7MC4eT2WzawfqX7SD2o1JPptkq3HXNSjJo5P8e6vv5iTfS3JIknXHXVufqnpwVV3WM8/ZVbXjfNWkuWdYqM/lwL5TA0meAGw4vnJG9mdV9WDgUcCDgfePuZ5fSfJI4BzgauAJVfUQ4GXAEmDjcdY2m1Fag/q/y7BQn08Arx4Y3h84fnCGJA9JcnySlUmuTPJXSdZp09ZN8v52Bn0Z8OIhyx6TZEWSa5K8a9jZdTpHJLlh4Ez88X3FV9VNwOeAJw2sa50khyW5NMlPkpyYZLOB6b+Z5JtJbkpydZLXtPEvTnJ+klva+Hf0P31DvRP4ZlUdUlUrWp0/rKrfb/WS5CVJLmw1nJHksQP1XZHk0PYc3N6evy2TfDnJrUm+nmTTNu9U99iBSa5tz/ObB9a1a5Jvte2sSHJUkvUHpleSNyS5BLhkYNyj2uMXJbmobfeaJG9p43dLsnxgPY9t+3FT26+XDEz7eJIPJ/lSW885LVA1QQwL9fk2sEn7Z18XeAXwb9Pm+RDwEOARwHPowuW1bdrrgd8GdqE7c95n2rLHAXfRtQB2AfYEhvX17wk8G3g0sLDV8ZO+4pNsDvwu8OOB0QcBe7datwZ+Bny4zb898OW2T4voQmZZW+72tm8L6ULvT5Ls3VfDEM8DTpql5kcDnwTe1Gr4T+A/Bg/iwO8Bz6d7Pn6n1fyXwBZ0/9cHTVvtc4Ed6J7Hw5I8r42/Gzi4LfcMYA/gT6ctuzfwNGCnIeUeA/xRVW0MPB44bcj+rAf8B/A14KHAG4ETkgx2U+1LF6Kb0r1W7x6yLY1TVfnjz9Af4Aq6A9tfAX8HvAA4BVgAFLAYWBf4X2CngeX+CDijPT4N+OOBaXu2ZRcAW7ZlNxyYvi9wenv8GuAb7fHuwI+ApwPr9NR9BvBz4Oa2rWXA9gPTLwb2GBjeCriz1fQ24OQRn58PAEe0x4un9mughtfNsNydwAtmWe9fAycODK8DXAPsNvC67Dcw/TPAPw0MvxH43LS6HjMw/e+BY2bY9psG978tu/u0eQp4VHt8VXu9N5k2z27A8vb4WcB1g68bXRi+oz3+OPCxgWkvAn4w7r9/f1b9sWWhUXwC+H26g/fx06ZtAawPXDkw7kpgm/Z4a7q++cFpUx4GrAesaN0TNwEfpTv7XEVVnQYcRdcCuD7J0Uk2maXmg6q7FvBEurPVbadt9+SBbV5Md4a9JbAdcOmwFSZ5WpLTW3fbzcAft/1fXT+hC6iZbM3A81RVv6R7DrcZmOf6gcf/M2T4wdPWOf012Bp+daH9i0muS3IL8Lfce5+uZma/R3dwvzLJmUmeMcP+XN32Y7CGwf25buDxz4fUrzEzLNSrqq6ku9D9IuCz0ybfSHem/LCBcdvTnQkDrKA7AA9Om3I1Xctii6pa2H42qarHzVDHkVX1FOBxdN0vh45Q+wXAu4APJ8nAdl84sM2FVbVBVV3Tps3UX/7/gC8A27Ug+mcgM8w7m6/THWRnci0Dz2erezvueU7XxPTX4Nr2+J+AHwA7VNUmdF1Z0/dpxq+mrqrvVNVedAH/OeDEIbNdC2w3dR1roIb7sj+aZ4aFRnUAXXfE7YMjq+puugPEu5NsnORhwCHcc13jROCgJNu2i66HDSy7gq4f+x+SbNIuPD8yyXOmbzzJU9uZ/Xp01w5+QdcaGMVxdAezqYuq/9zqfVhb96Ike7VpJwDPS/LyJAuSbJ5k6uL4xsBPq+oXSXala22ticOBZyZ5X5JfbzU8Ksm/JVlI95y9OMkebX/fTBeq31zD7QH8dZKNkjyO7nrSpwf26RbgtiSPAf5k1BUmWT/JfkkeUlV3tvUMe03OoXvN3ppkvSS70V1n+dSa747mm2GhkVTVpVW1dIbJb6Q7GFwGfIPuDPzYNu1fgK8C3wXO494tk1fTdWNdRHeh+SSGd9Fs0tb1M7oujJ8w4tthq+oO4Ei6awEAH6RrIXwtya10F/Gf1ua9iq4F9Wbgp3TXO3Zuy/0p8Ddtmbcz/Cx6lHoupbuYvBi4sHVpfQZYCtxaVT8E/oDuIvuNdAfW32n7sabOpLtwfCrw/qr6Whv/FrrQu5Xu+f308MVn9CrgitaF9cet7lW0ul8CvJBufz4CvLqqfrAG+6ExSZU3P5L+r0r3wcnLgfWq6q7xVqO1mS0LSVIvw0KS1MtuKElSL1sWkqRea/UXg22xxRa1ePHicZchSWuVc88998aqWrQ6y6zVYbF48WKWLp3p3ZySpGGSXNk/16rshpIk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJveYsLJIcm+5+yd8fGLdZklOSXNJ+T90nOEmOTPLjdPcVfvJc1SVJWn1z2bL4ON1tOAcdBpxaVTvQfVXy1L0NXkh3f+AdgAPpbsgiSZoQcxYWVXUW3f0ABu1FdyMa2u+9B8YfX51vAwuTzHbbSUnSPJrvT3Bv2e6ORlWtSDJ1r+VtWPU+v8vbuBXTV5DkQLrWB9tvv/30ySM74pQfrfGymt3Bz3/0uEvQhPD/bO7M9//ZpFzgHnYf46Ffh1tVR1fVkqpasmjRan21iSRpDc13WFw/1b3Uft/Qxi9n1RvKb8s9N5SXJI3ZfIfFF4D92+P9gc8PjH91e1fU04Gbp7qrJEnjN2fXLJJ8EtgN2CLJcuBw4D3AiUkOAK4CXtZm/0/gRXQ3lP858Nq5qkuStPrmLCyqat8ZJu0xZN4C3jBXtUiS7ptJucAtSZpghoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6jSUskhyc5MIk30/yySQbJHl4knOSXJLk00nWH0dtkqR7m/ewSLINcBCwpKoeD6wLvBJ4L3BEVe0A/Aw4YL5rkyQNN65uqAXAhkkWABsBK4DdgZPa9OOAvcdUmyRpmnkPi6q6Bng/cBVdSNwMnAvcVFV3tdmWA9sMWz7JgUmWJlm6cuXK+ShZkh7wxtENtSmwF/BwYGvgQcALh8xaw5avqqOraklVLVm0aNHcFSpJ+pVxdEM9D7i8qlZW1Z3AZ4FnAgtbtxTAtsC1Y6hNkjTEOMLiKuDpSTZKEmAP4CLgdGCfNs/+wOfHUJskaYgF/bPcv6rqnCQnAecBdwHnA0cDXwI+leRdbdwx812bJtsRp/xo3CX8n3Xw8x897hI04eY9LACq6nDg8GmjLwN2HUM5kqQefoJbktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVKvsYRFkoVJTkrygyQXJ3lGks2SnJLkkvZ703HUJkm6t3G1LD4IfKWqHgPsDFwMHAacWlU7AKe2YUnSBJj3sEiyCfBs4BiAqrqjqm4C9gKOa7MdB+w937VJkoYbR8viEcBK4F+TnJ/kY0keBGxZVSsA2u+HjqE2SdIQ4wiLBcCTgX+qql2A21mNLqckByZZmmTpypUr56pGSdKAcYTFcmB5VZ3Thk+iC4/rk2wF0H7fMGzhqjq6qpZU1ZJFixbNS8GS9EA372FRVdcBVyfZsY3aA7gI+AKwfxu3P/D5+a5NkjTcgtkmJjlktulV9Y9ruN03AickWR+4DHgtXXCdmOQA4CrgZWu4bknS/WzWsAA2nouNVtUyYMmQSXvMxfYkSffNrGFRVe+cr0IkSZOrrxvqyNmmV9VB9285kqRJ1NcNde68VCFJmmh93VDHzTZdkvTA0NeyACDJIuAvgJ2ADabGV9Xuc1SXJGmCjPo5ixPovuzv4cA7gSuA78xRTZKkCTNqWGxeVccAd1bVmVX1h8DT57AuSdIEGakbCriz/V6R5MXAtcC2c1OSJGnSjBoW70ryEODNwIeATYCD56wqSdJEGSksquqL7eHNwHPnrhxJ0iQa6ZpFkuOSLBwY3jTJsXNXliRpkox6gfuJ7W52AFTVz4Bd5qYkSdKkGTUs1kmy6dRAks0Y/XqHJGktN+oB/x+AbyY5CSjg5cC756wqSdJEGfUC9/FJlgK7AwF+t6oumtPKJEkTY3XulLcZcHtVfQhYmeThc1STJGnCjPpuqMPpvhvqbW3UesC/zVVRkqTJMmrL4qXAS4DbAarqWuboLnqSpMkzaljcUVVFd3GbJA+au5IkSZNm1LA4MclHgYVJXg98HfjY3JUlSZoko74b6v1Jng/cAuwIvL2qTpnTyiRJE2PkD9a1cDgFIMm6SfarqhPmrDJJ0sSYtRsqySZJ3pbkqCR7pvNnwGV0H8yTJD0A9LUsPgH8DPgW8DrgUGB9YK+qWjbHtUmSJkRfWDyiqp4AkORjwI3A9lV165xXJkmaGH3vhpq6Qx5VdTdwuUEhSQ88fS2LnZPc0h4H2LANB6iq2mROq5MkTYRZw6Kq1p2vQiRJk2t1vkhQkvQAZVhIknoZFpKkXoaFJKmXYSFJ6jW2sGjfL3V+ki+24YcnOSfJJUk+nWT9cdUmSVrVOFsWfw5cPDD8XuCIqtqB7itGDhhLVZKkexlLWCTZFngx7Z4YSQLsDpzUZjkO2HsctUmS7m1cLYsPAG8FftmGNwduqqq72vByYJthCyY5MMnSJEtXrlw595VKkuY/LJL8NnBDVZ07OHrIrDVs+ao6uqqWVNWSRYsWzUmNkqRVjXzzo/vRbwAvSfIiYANgE7qWxsIkC1rrYlvg2jHUJkkaYt5bFlX1tqratqoWA68ETquq/YDTgX3abPsDn5/v2iRJw03S5yz+AjgkyY/prmEcM+Z6JEnNOLqhfqWqzgDOaI8vA3YdZz2SpOEmqWUhSZpQhoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6zXtYJNkuyelJLk5yYZI/b+M3S3JKkkva703nuzZJ0nDjaFncBby5qh4LPB14Q5KdgMOAU6tqB+DUNixJmgDzHhZVtaKqzmuPbwUuBrYB9gKOa7MdB+w937VJkoYb6zWLJIuBXYBzgC2ragV0gQI8dIZlDkyyNMnSlStXzlepkvSANrawSPJg4DPAm6rqllGXq6qjq2pJVS1ZtGjR3BUoSfqVsYRFkvXoguKEqvpsG319kq3a9K2AG8ZRmyTp3sbxbqgAxwAXV9U/Dkz6ArB/e7w/8Pn5rk2SNNyCMWzzN4BXARckWdbG/SXwHuDEJAcAVwEvG0NtkqQh5j0squobQGaYvMd81iJJGo2f4JYk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1mqiwSPKCJD9M8uMkh427HklSZ2LCIsm6wIeBFwI7Afsm2Wm8VUmSYILCAtgV+HFVXVZVdwCfAvYac02SJGDBuAsYsA1w9cDwcuBp02dKciBwYBu8LckP56G2SbAFcOO4ixjFIeMuYDKsNa8X+Jo1D6TX7GGru8AkhUWGjKt7jag6Gjh67suZLEmWVtWScdeh0fh6rX18zWY3Sd1Qy4HtBoa3Ba4dUy2SpAGTFBbfAXZI8vAk6wOvBL4w5pokSUxQN1RV3ZXkz4CvAusCx1bVhWMua5I84Lre1nK+XmsfX7NZpOpelwUkSVrFJHVDSZImlGEhSeplWIxJktuGjNsxyRlJliW5OMnRSX6rDS9Lclv7OpRlSY5PsluSSnLAwDp2aePeMr97NHmSvLQ9F48ZYd43JdloNde/W5KbB16fZUmet+YV927v40n2mcP1H5vkhiTfH7Ldy5N8N8mP2t/eNrOsZ9ckZ7W/1R8k+djqPrdrWP/i6bXPMN9fThv+5hzUMvS1auOvSfJrbXiLJFf0rGthkj+9v2ts677XcWgmhsVkORI4oqqeVFWPBT5UVV9tw08ClgL7teFXt2UuAF4xsI5XAt+d37In1r7AN+iekz5vAtbkgHb21OvTfr6+BuuYE0lW9w0sHwdeMMO0Q6tqZ2BH4Hzg9Pauxenb3BL4d+AvqmpH4LHAV4CNV7OWubRKWFTVM+d5+3cDf7ga8y8E7tewSGe1jv+GxWTZiu7zJgBU1QUjLHMVsEGSLZOE7p/9y3NU31ojyYOB3wAOoIVFawl8cWCeo5K8JslBwNZ0B8DT27R9k1yQ5PtJ3rua217cWob/kuTCJF9LsmGb9qgkX29n6ecleWT7x31f29YFSV7R5k2r8aIkXwIeOrCNpyQ5M8m5Sb6aZKs2/owkf5vkTODPV6fuqjoL+GnPPFVVRwDX0X2P23RvAI6rqm8NzH9SVV2fZLMkn0vyvSTfTvLEVvM7WqvmjCSXtdeDJO8dPKNu8715pudrUHtdjxoY/mJ7/d8DbNhagSe0abe13zO9Dru12k5qLaUT2v8aSd6e5DttmaOnxvf4AHDwsDBPcmhb3/eSvLONfg/wyFbz+5J8JMlL2vwnJzm2PT4gybva40NaTd9P8qY2burv8iPAeQx8ri1dC+dbSV48U9GGxWQ5AjgtyZeTHJxk4YjLnQS8DHgm3R/B/85VgWuRvYGvVNWPgJ8mefJMM1bVkXQfAH1uVT03ydbAe4HdgScBT02y9wyLPyurdkM9so3fAfhwVT0OuAn4vTb+hDZ+Z7rXawXwu207OwPPA97XDv4vpTuTfwLw+jY/SdYDPgTsU1VPAY4F3j1Q08Kqek5V/cNoT9UaOQ8Y1r33eODcGZZ5J3B+VT2R7uz++IFpjwF+i+474g5v+/gpVm01v5yu1TLT89Wrqg4D/qe1AvebNnm29e5C1/rcCXgE3YkIwFFV9dSqejywIfDbI5RxFV2L91WDI5PsSfd3s2ur4ylJng0cBlzaaj4UOAt4Vltsm1YTwG8CZyd5CvBauq9Lejrw+iS7tHl2BI6vql2q6sq23S2BLwFvr6ovzVS0YTFBqupf6Zrt/w7sBnw7rW+zx4l0YbEv8Mk5K3Dtsi/dwYb2e9/VWPapwBlVtbKq7qI7wD97hnmnd0Nd2sZfXlXL2uNzgcVJNga2qaqTAarqF1X1c7p/8k9W1d1VdT1wZqvh2QPjrwVOa+vbke6gfEqSZcBf0X3jwZRPr8a+rqlRzqCn+03gEwBVdRqweZKHtGlfqqr/raobgRuALavqfOChSbZOsjPws6q6ipmfr/tqtvX+d1Utr6pfAsuAxW38c5Ock+QCupOLx424rb8FDmXVY/Ce7ed87gnjHYYsezbdScpOwEXA9S3UngF8s+3HyVV1e1XdBnyWe8Llyqr69sC61gNOBd5aVafMVvDEfChPnXZQOBY4Nt3FutnO1KaWuS7JncDz6boe5rsPdqIk2ZzuH/fxSYruQ55F940Ag/+cG8y0ihnW+1Lg8Db4up4yBlt3d9Oddc50gJ3twDvsg1ABLqyqZ8ywzO09td0fdgFOHfKcXAg8Bfj8kGVm+/636c/X1LHpJGAf4Ne5J/xHCaq7GO217qtvyr3qS7IB8BFgSVVdneQdI26HqvpxC/qXT9v+31XVR1cpKlk8bdlrkmxK1+V8FrBZW89tVXVrT1fY9L+Nu+iOL79FF44zsmUxQdLd/Gm99vjXgc2Ba0Zc/O10FxXvnqv61iL70DW1H1ZVi6tqO+DyNm2nJL/Wzmj3GFjmVu65CHsO8JzWj7suXavkzKo6eaAFsXR1i6qqW4DlU11arY6N6P7hX5Fk3SSL6FoU/93Gv7KN3wp4blvVD4FFSZ7R1rNeklHPaO+T1q9/EN31ta8MeU6OAvZP8rSBZf6g/T2fBezXxu0G3Niek9l8iu6a0z50wQEzP1+DrgCelGSdJNvRde1MuXPq/2yaUdY7aCoYbkx3jWx136n2bmDwXYtfBf6wrYsk2yR5KKv+bU75Fl232Fl0LY23tN9T+7F3ko2SPIiuO/Nshiu6i+2PSc8N52xZjM9GSZYPDP8jXVfCB5P8oo07tKquG2VlVXW/v/1vLbYv3UXBQZ8Bfp+uy+57wCV0zf0pRwNfTrKiXbd4G3A63dnef1bVsDNlaNcsBobfRfeutZm8Cvhokr8B7qTrPjyZrgvhu3T/vG9trcWT6VpIFwA/op35VdUd6d6WeWQLvQV0F03v09fjJPkkXffnFu1v8/CqOqZNfl+Sv6Z7x9i36a7v3DF9He1C9iuB97cD3S/pDl6fBd4B/GuS7wE/B/bvq6mqLmzdd9dU1Yo2eqbna/HAov9Fd4JwAfB9um6dKUcD30ty3rTrFjOtd+hbr6vqpiT/0rZxBd33242s7dt5wJPb8NeSPBb4Vmsc3Ab8QVVdmuS/Wk/Dl9t1i7OBPVsL5Uq61sXZbT3nJfk49wTdx6rq/OktlIE67m6v2X8kuaWqPjJsPr/uQ5LUy24oSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9fr/GrsMtbaQf0oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('LSTM', 'Auto-Encoder', '1D-Convolutional Network')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [lstmPrecision,autoencoderPrecision,convPrecision]\n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Models Precision Comparision')\n",
    " \n",
    "plt.show()\n",
    "\n",
    "objects = ('LSTM', 'Auto-Encoder', '1D-Convolutional Network')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [lstmRecall,autoencoderRecall,convRecall]\n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Models Recall Comparision')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in images above, both LSTM and one dimensional convolutional network have a great performance on detecting anomalies in our dataset. However, this does not say that these models are outperforming Auto-Encoder in anomaly detection and all the results are espesific to this dataset. Because we are just using a relatively simple synthetic dataset with one feature consisting of 0s and 1s. In real world there are more complex patterns which might be harder to learn. For future works, we should try these models (of course after tuning them well) on different datasets. Other thing that we should mention here is that, there are more parameters to tune in each of these architectures, like number of Dense layers in LSTM network, Or different optimizers in Auto-Encoder that we could not test all of them due lack of time but in more complex tasks it might be necessary to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "<ol>\n",
    "    <li>\n",
    "      O. Gorokhov, M. Petrovskiy, and I. Mashechkin, \"Convolutional neural networks for unsupervised anomaly detection in text data,\" in International Conference on Intelligent Data Engineering and Automated Learning, 2017, pp. 500-507.  \n",
    "    </li>\n",
    "    <li>\n",
    "      D. Kwon, K. Natarajan, S. C. Suh, H. Kim, and J. Kim, \"An empirical study on network anomaly detection using convolutional neural networks,\" in 2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS), 2018, pp. 1595-1598. \n",
    "    </li>\n",
    "    <li>\n",
    "      D. Sovilja, P. Budnaraina, S. Sanner, G. Salmonb, and M. Raob, \"A Comparative Evaluation of Unsupervised Deep Learning Techniques for Intrusion Detection in Sequential Data Streams.\" \n",
    "    </li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
